doctype-html-html-class-client-nojs-lang-en-dir-ltr-head-meta-charset-utf-8-title-list-of-datasets-for-machine-learning-research-wikipedia-title-script-document-documentelement-classname-document-documentelement-classname-replace-s-client-nojs-s-1client-js-2-rlconf-wgcanonicalnamespace-wgcanonicalspecialpagename-1-wgnamespacenumber-0-wgpagename-list-of-datasets-for-machine-learning-research-wgtitle-list-of-datasets-for-machine-learning-research-wgcurrevisionid-902152298-wgrevisionid-902152298-wgarticleid-49082762-wgisarticle-0-wgisredirect-1-wgaction-view-wgusername-null-wgusergroups-wgcategories-cs1-maint-multiple-names-authors-list-use-dmy-dates-from-september-2017-datasets-in-machine-learning-machine-learning-artificial-intelligence-wgbreakframes-1-wgpagecontentlanguage-en-wgpagecontentmodel-wikitext-wgseparatortransformtable-wgdigittransformtable-wgdefaultdateformat-dmy-wgmonthnames-january-february-march-april-may-june-july-august-september-october-november-december-wgmonthnamesshort-jan-feb-mar-apr-may-jun-jul-aug-sep-oct-nov-dec-wgrelevantpagename-list-of-datasets-for-machine-learning-research-wgrelevantarticleid-49082762-wgrequestid-xqt8uqpaicoaafnd-p0aaaal-wgcspnonce-1-wgisprobablyeditable-0-wgrelevantpageisprobablyeditable-0-wgrestrictionedit-wgrestrictionmove-wgmediavieweronclick-0-wgmediaviewerenabledbydefault-0-wgpopupsreferencepreviews-1-wgpopupsconflictswithnavpopupgadget-1-wgvisualeditor-pagelanguagecode-en-pagelanguagedir-ltr-pagevariantfallbacks-en-wgmfdisplaywikibasedescriptions-search-0-nearby-0-watchlist-0-tagline-1-wgwmeschemaeditattemptstepoversample-1-wgpoweredbyhhvm-0-wgulscurrentautonym-english-wgnoticeproject-wikipedia-wgcentralnoticecategoriesusinglegacy-fundraising-fundraising-wgwikibaseitemid-q23038294-wgcentralauthmobiledomain-1-wgeditsubmitbuttonlabelpublish-0-rlstate-ext-gadget-charinsert-styles-ready-ext-globalcssjs-user-styles-ready-ext-globalcssjs-site-styles-ready-site-styles-ready-noscript-ready-user-styles-ready-ext-globalcssjs-user-ready-ext-globalcssjs-site-ready-user-ready-user-options-ready-user-tokens-loading-ext-cite-styles-ready-mediawiki-legacy-shared-ready-mediawiki-legacy-commonprint-ready-jquery-tablesorter-styles-ready-mediawiki-toc-styles-ready-wikibase-client-init-ready-ext-visualeditor-desktoparticletarget-noscript-ready-ext-uls-interlanguage-ready-ext-wikimediabadges-ready-ext-3d-styles-ready-mediawiki-skinning-interface-ready-skins-vector-styles-ready-rlpagemodules-ext-cite-ux-enhancements-ext-scribunto-logs-site-mediawiki-page-startup-mediawiki-page-ready-jquery-tablesorter-mediawiki-toc-mediawiki-searchsuggest-ext-gadget-teahouse-ext-gadget-referencetooltips-ext-gadget-watchlist-notice-ext-gadget-drn-wizard-ext-gadget-charinsert-ext-gadget-reftoolbar-ext-gadget-extra-toolbar-buttons-ext-gadget-switcher-ext-centralauth-centralautologin-mmv-head-mmv-bootstrap-autostart-ext-popups-ext-visualeditor-desktoparticletarget-init-ext-visualeditor-targetloader-ext-eventlogging-ext-wikimediaevents-ext-navigationtiming-ext-uls-compactlinks-ext-uls-interface-ext-quicksurveys-init-ext-centralnotice-geoip-ext-centralnotice-startup-skins-vector-js-script-script-rlq-window-rlq-push-function-mw-loader-implement-user-tokens-0tffind-function-jquery-require-module-nomin-mw-user-tokens-set-edittoken-patroltoken-watchtoken-csrftoken-script-link-rel-stylesheet-href-w-load-php-lang-en-modules-ext-3d-styles-7cext-cite-styles-7cext-uls-interlanguage-7cext-visualeditor-desktoparticletarget-noscript-7cext-wikimediabadges-7cjquery-tablesorter-styles-7cmediawiki-legacy-commonprint-2cshared-7cmediawiki-skinning-interface-7cmediawiki-toc-styles-7cskins-vector-styles-7cwikibase-client-init-only-styles-skin-vector-script-async-src-w-load-php-lang-en-modules-startup-only-scripts-skin-vector-script-meta-name-resourceloaderdynamicstyles-content-link-rel-stylesheet-href-w-load-php-lang-en-modules-ext-gadget-charinsert-styles-only-styles-skin-vector-link-rel-stylesheet-href-w-load-php-lang-en-modules-site-styles-only-styles-skin-vector-meta-name-generator-content-mediawiki-1-34-0-wmf-8-meta-name-referrer-content-origin-meta-name-referrer-content-origin-when-crossorigin-meta-name-referrer-content-origin-when-cross-origin-meta-property-og-image-content-https-upload-wikimedia-org-wikipedia-commons-thumb-f-fe-kernel-machine-svg-1200px-kernel-machine-svg-png-link-rel-alternate-href-android-app-org-wikipedia-http-en-m-wikipedia-org-wiki-list-of-datasets-for-machine-learning-research-link-rel-alternate-type-application-x-wiki-title-edit-this-page-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-link-rel-edit-title-edit-this-page-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-link-rel-apple-touch-icon-href-static-apple-touch-wikipedia-png-link-rel-shortcut-icon-href-static-favicon-wikipedia-ico-link-rel-search-type-application-opensearchdescription-xml-href-w-opensearch-desc-php-title-wikipedia-en-link-rel-edituri-type-application-rsd-xml-href-en-wikipedia-org-w-api-php-action-rsd-link-rel-license-href-creativecommons-org-licenses-by-sa-3-0-link-rel-canonical-href-https-en-wikipedia-org-wiki-list-of-datasets-for-machine-learning-research-link-rel-dns-prefetch-href-login-wikimedia-org-link-rel-dns-prefetch-href-meta-wikimedia-org-if-lt-ie-9-script-src-w-load-php-lang-qqx-modules-html5shiv-only-scripts-skin-fallback-sync-1-script-endif-head-body-class-mediawiki-ltr-sitedir-ltr-mw-hide-empty-elt-ns-0-ns-subject-mw-editable-page-list-of-datasets-for-machine-learning-research-rootpage-list-of-datasets-for-machine-learning-research-skin-vector-action-view-div-id-mw-page-base-class-noprint-div-div-id-mw-head-base-class-noprint-div-div-id-content-class-mw-body-role-main-a-id-top-a-div-id-sitenotice-class-mw-body-content-centralnotice-div-div-class-mw-indicators-mw-body-content-div-h1-id-firstheading-class-firstheading-lang-en-list-of-datasets-for-machine-learning-research-h1-div-id-bodycontent-class-mw-body-content-div-id-sitesub-class-noprint-from-wikipedia-the-free-encyclopedia-div-div-id-contentsub-div-div-id-jump-to-nav-div-a-class-mw-jump-link-href-mw-head-jump-to-navigation-a-a-class-mw-jump-link-href-p-search-jump-to-search-a-div-id-mw-content-text-lang-en-dir-ltr-class-mw-content-ltr-div-class-mw-parser-output-p-class-mw-empty-elt-p-table-class-vertical-navbox-nowraplinks-style-float-right-clear-right-width-22-0em-margin-0-0-1-0em-1-0em-background-f9f9f9-border-1px-solid-aaa-padding-0-2em-border-spacing-0-4em-0-text-align-center-line-height-1-4em-font-size-88-tbody-tr-th-style-padding-0-2em-0-4em-0-2em-font-size-145-line-height-1-2em-a-href-wiki-machine-learning-title-machine-learning-machine-learning-a-and-br-a-href-wiki-data-mining-title-data-mining-data-mining-a-th-tr-tr-td-style-padding-0-2em-0-0-4em-padding-0-25em-0-25em-0-75em-a-href-wiki-file-kernel-machine-svg-class-image-img-alt-kernel-machine-svg-src-upload-wikimedia-org-wikipedia-commons-thumb-f-fe-kernel-machine-svg-220px-kernel-machine-svg-png-decoding-async-width-220-height-100-srcset-upload-wikimedia-org-wikipedia-commons-thumb-f-fe-kernel-machine-svg-330px-kernel-machine-svg-png-1-5x-upload-wikimedia-org-wikipedia-commons-thumb-f-fe-kernel-machine-svg-440px-kernel-machine-svg-png-2x-data-file-width-512-data-file-height-233-a-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-problems-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-statistical-classification-title-statistical-classification-classification-a-li-li-a-href-wiki-cluster-analysis-title-cluster-analysis-clustering-a-li-li-a-href-wiki-regression-analysis-title-regression-analysis-regression-a-li-li-a-href-wiki-anomaly-detection-title-anomaly-detection-anomaly-detection-a-li-li-a-href-wiki-automated-machine-learning-title-automated-machine-learning-automl-a-li-li-a-href-wiki-association-rule-learning-title-association-rule-learning-association-rules-a-li-li-a-href-wiki-reinforcement-learning-title-reinforcement-learning-reinforcement-learning-a-li-li-a-href-wiki-structured-prediction-title-structured-prediction-structured-prediction-a-li-li-a-href-wiki-feature-engineering-title-feature-engineering-feature-engineering-a-li-li-a-href-wiki-feature-learning-title-feature-learning-feature-learning-a-li-li-a-href-wiki-online-machine-learning-title-online-machine-learning-online-learning-a-li-li-a-href-wiki-semi-supervised-learning-title-semi-supervised-learning-semi-supervised-learning-a-li-li-a-href-wiki-unsupervised-learning-title-unsupervised-learning-unsupervised-learning-a-li-li-a-href-wiki-learning-to-rank-title-learning-to-rank-learning-to-rank-a-li-li-a-href-wiki-grammar-induction-title-grammar-induction-grammar-induction-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-div-style-padding-0-1em-0-line-height-1-2em-a-href-wiki-supervised-learning-title-supervised-learning-supervised-learning-a-br-style-data-mw-deduplicate-templatestyles-r886047488-mw-parser-output-nobold-font-weight-normal-style-span-class-nobold-span-style-font-size-85-b-a-href-wiki-statistical-classification-title-statistical-classification-classification-a-b-b-a-href-wiki-regression-analysis-title-regression-analysis-regression-a-b-span-span-div-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-decision-tree-learning-title-decision-tree-learning-decision-trees-a-li-li-a-href-wiki-ensemble-learning-title-ensemble-learning-ensembles-a-ul-li-a-href-wiki-bootstrap-aggregating-title-bootstrap-aggregating-bagging-a-li-li-a-href-wiki-boosting-machine-learning-title-boosting-machine-learning-boosting-a-li-li-a-href-wiki-random-forest-title-random-forest-random-forest-a-li-ul-li-li-a-href-wiki-k-nearest-neighbors-algorithm-title-k-nearest-neighbors-algorithm-i-k-i-nn-a-li-li-a-href-wiki-linear-regression-title-linear-regression-linear-regression-a-li-li-a-href-wiki-naive-bayes-classifier-title-naive-bayes-classifier-naive-bayes-a-li-li-a-href-wiki-artificial-neural-network-title-artificial-neural-network-artificial-neural-networks-a-li-li-a-href-wiki-logistic-regression-title-logistic-regression-logistic-regression-a-li-li-a-href-wiki-perceptron-title-perceptron-perceptron-a-li-li-a-href-wiki-relevance-vector-machine-title-relevance-vector-machine-relevance-vector-machine-rvm-a-li-li-a-href-wiki-support-vector-machine-title-support-vector-machine-support-vector-machine-svm-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-a-href-wiki-cluster-analysis-title-cluster-analysis-clustering-a-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-birch-title-birch-birch-a-li-li-a-href-wiki-cure-data-clustering-algorithm-class-mw-redirect-title-cure-data-clustering-algorithm-cure-a-li-li-a-href-wiki-hierarchical-clustering-title-hierarchical-clustering-hierarchical-a-li-li-a-href-wiki-k-means-clustering-title-k-means-clustering-i-k-i-means-a-li-li-a-href-wiki-expectation-e2-80-93maximization-algorithm-title-expectation-maximization-algorithm-expectation-maximization-em-a-li-li-br-a-href-wiki-dbscan-title-dbscan-dbscan-a-li-li-a-href-wiki-optics-algorithm-title-optics-algorithm-optics-a-li-li-a-href-wiki-mean-shift-class-mw-redirect-title-mean-shift-mean-shift-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-a-href-wiki-dimensionality-reduction-title-dimensionality-reduction-dimensionality-reduction-a-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-factor-analysis-title-factor-analysis-factor-analysis-a-li-li-a-href-wiki-canonical-correlation-analysis-class-mw-redirect-title-canonical-correlation-analysis-cca-a-li-li-a-href-wiki-independent-component-analysis-title-independent-component-analysis-ica-a-li-li-a-href-wiki-linear-discriminant-analysis-title-linear-discriminant-analysis-lda-a-li-li-a-href-wiki-non-negative-matrix-factorization-title-non-negative-matrix-factorization-nmf-a-li-li-a-href-wiki-principal-component-analysis-title-principal-component-analysis-pca-a-li-li-a-href-wiki-t-distributed-stochastic-neighbor-embedding-title-t-distributed-stochastic-neighbor-embedding-t-sne-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-a-href-wiki-structured-prediction-title-structured-prediction-structured-prediction-a-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-graphical-model-title-graphical-model-graphical-models-a-ul-li-a-href-wiki-bayesian-network-title-bayesian-network-bayes-net-a-li-li-a-href-wiki-conditional-random-field-title-conditional-random-field-conditional-random-field-a-li-li-a-href-wiki-hidden-markov-model-title-hidden-markov-model-hidden-markov-a-li-ul-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-a-href-wiki-anomaly-detection-title-anomaly-detection-anomaly-detection-a-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-k-nearest-neighbors-classification-class-mw-redirect-title-k-nearest-neighbors-classification-i-k-i-nn-a-li-li-a-href-wiki-local-outlier-factor-title-local-outlier-factor-local-outlier-factor-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-a-href-wiki-artificial-neural-networks-class-mw-redirect-title-artificial-neural-networks-artificial-neural-networks-a-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-autoencoder-title-autoencoder-autoencoder-a-li-li-a-href-wiki-deep-learning-title-deep-learning-deep-learning-a-li-li-a-href-wiki-deepdream-title-deepdream-deepdream-a-li-li-a-href-wiki-multilayer-perceptron-title-multilayer-perceptron-multilayer-perceptron-a-li-li-a-href-wiki-recurrent-neural-network-title-recurrent-neural-network-rnn-a-ul-li-a-href-wiki-long-short-term-memory-title-long-short-term-memory-lstm-a-li-li-a-href-wiki-gated-recurrent-unit-title-gated-recurrent-unit-gru-a-li-ul-li-li-a-href-wiki-restricted-boltzmann-machine-title-restricted-boltzmann-machine-restricted-boltzmann-machine-a-li-li-a-href-wiki-generative-adversarial-network-title-generative-adversarial-network-gan-a-li-li-a-href-wiki-self-organizing-map-title-self-organizing-map-som-a-li-li-a-href-wiki-convolutional-neural-network-title-convolutional-neural-network-convolutional-neural-network-a-ul-li-a-href-wiki-u-net-title-u-net-u-net-a-li-ul-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-a-href-wiki-reinforcement-learning-title-reinforcement-learning-reinforcement-learning-a-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-q-learning-title-q-learning-q-learning-a-li-li-a-href-wiki-state-e2-80-93action-e2-80-93reward-e2-80-93state-e2-80-93action-title-state-action-reward-state-action-sarsa-a-li-li-a-href-wiki-temporal-difference-learning-title-temporal-difference-learning-temporal-difference-td-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-theory-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-bias-e2-80-93variance-dilemma-class-mw-redirect-title-bias-variance-dilemma-bias-variance-dilemma-a-li-li-a-href-wiki-computational-learning-theory-title-computational-learning-theory-computational-learning-theory-a-li-li-a-href-wiki-empirical-risk-minimization-title-empirical-risk-minimization-empirical-risk-minimization-a-li-li-a-href-wiki-occam-learning-title-occam-learning-occam-learning-a-li-li-a-href-wiki-probably-approximately-correct-learning-title-probably-approximately-correct-learning-pac-learning-a-li-li-a-href-wiki-statistical-learning-theory-title-statistical-learning-theory-statistical-learning-a-li-li-a-href-wiki-vapnik-e2-80-93chervonenkis-theory-title-vapnik-chervonenkis-theory-vc-theory-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-machine-learning-venues-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-conference-on-neural-information-processing-systems-title-conference-on-neural-information-processing-systems-nips-a-li-li-a-href-wiki-international-conference-on-machine-learning-title-international-conference-on-machine-learning-icml-a-li-li-a-href-wiki-machine-learning-journal-title-machine-learning-journal-ml-a-li-li-a-href-wiki-journal-of-machine-learning-research-title-journal-of-machine-learning-research-jmlr-a-li-li-a-rel-nofollow-class-external-text-href-https-arxiv-org-list-cs-lg-recent-arxiv-cs-lg-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-a-href-wiki-glossary-of-artificial-intelligence-title-glossary-of-artificial-intelligence-glossary-of-artificial-intelligence-a-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-glossary-of-artificial-intelligence-title-glossary-of-artificial-intelligence-glossary-of-artificial-intelligence-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-related-articles-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-class-mw-selflink-selflink-list-of-datasets-for-machine-learning-research-a-li-li-a-href-wiki-outline-of-machine-learning-title-outline-of-machine-learning-outline-of-machine-learning-a-li-ul-div-div-div-td-tr-tr-td-class-plainlist-style-padding-0-3em-0-4em-0-3em-font-weight-bold-border-top-1px-solid-aaa-border-bottom-1px-solid-aaa-border-top-1px-solid-aaa-border-bottom-1px-solid-aaa-ul-li-a-href-wiki-file-portal-puzzle-svg-class-image-img-alt-portal-puzzle-svg-src-upload-wikimedia-org-wikipedia-en-thumb-f-fd-portal-puzzle-svg-16px-portal-puzzle-svg-png-decoding-async-width-16-height-14-class-noviewer-srcset-upload-wikimedia-org-wikipedia-en-thumb-f-fd-portal-puzzle-svg-24px-portal-puzzle-svg-png-1-5x-upload-wikimedia-org-wikipedia-en-thumb-f-fd-portal-puzzle-svg-32px-portal-puzzle-svg-png-2x-data-file-width-32-data-file-height-28-a-a-href-wiki-portal-machine-learning-title-portal-machine-learning-machine-learning-portal-a-li-ul-td-tr-tr-td-style-text-align-right-font-size-115-padding-top-0-6em-div-class-plainlinks-hlist-navbar-mini-ul-li-class-nv-view-a-href-wiki-template-machine-learning-bar-title-template-machine-learning-bar-abbr-title-view-this-template-v-abbr-a-li-li-class-nv-talk-a-href-wiki-template-talk-machine-learning-bar-title-template-talk-machine-learning-bar-abbr-title-discuss-this-template-t-abbr-a-li-li-class-nv-edit-a-class-external-text-href-en-wikipedia-org-w-index-php-title-template-machine-learning-bar-action-edit-abbr-title-edit-this-template-e-abbr-a-li-ul-div-td-tr-tbody-table-p-these-a-href-wiki-data-set-title-data-set-datasets-a-are-used-for-a-href-wiki-machine-learning-class-mw-redirect-title-machine-learning-machine-learning-a-research-and-have-been-cited-in-a-href-wiki-peer-review-title-peer-review-peer-reviewed-a-academic-journals-datasets-are-an-integral-part-of-the-field-of-machine-learning-major-advances-in-this-field-can-result-from-advances-in-learning-a-href-wiki-algorithm-title-algorithm-algorithms-a-such-as-a-href-wiki-deep-learning-title-deep-learning-deep-learning-a-computer-hardware-and-less-intuitively-the-availability-of-high-quality-training-datasets-sup-id-cite-ref-1-class-reference-a-href-cite-note-1-1-a-sup-high-quality-labeled-training-datasets-for-a-href-wiki-supervised-learning-title-supervised-learning-supervised-a-and-a-href-wiki-semi-supervised-learning-title-semi-supervised-learning-semi-supervised-a-machine-learning-algorithms-are-usually-difficult-and-expensive-to-produce-because-of-the-large-amount-of-time-needed-to-label-the-data-although-they-do-not-need-to-be-labeled-high-quality-datasets-for-a-href-wiki-unsupervised-learning-title-unsupervised-learning-unsupervised-a-learning-can-also-be-difficult-and-costly-to-produce-sup-id-cite-ref-2-class-reference-a-href-cite-note-2-2-a-sup-sup-id-cite-ref-3-class-reference-a-href-cite-note-3-3-a-sup-sup-id-cite-ref-4-class-reference-a-href-cite-note-4-4-a-sup-sup-id-cite-ref-5-class-reference-a-href-cite-note-5-5-a-sup-p-div-id-toc-class-toc-input-type-checkbox-role-button-id-toctogglecheckbox-class-toctogglecheckbox-style-display-none-div-class-toctitle-lang-en-dir-ltr-h2-contents-h2-span-class-toctogglespan-label-class-toctogglelabel-for-toctogglecheckbox-label-span-div-ul-li-class-toclevel-1-tocsection-1-a-href-image-data-span-class-tocnumber-1-span-span-class-toctext-image-data-span-a-ul-li-class-toclevel-2-tocsection-2-a-href-facial-recognition-span-class-tocnumber-1-1-span-span-class-toctext-facial-recognition-span-a-li-li-class-toclevel-2-tocsection-3-a-href-action-recognition-span-class-tocnumber-1-2-span-span-class-toctext-action-recognition-span-a-li-li-class-toclevel-2-tocsection-4-a-href-object-detection-and-recognition-span-class-tocnumber-1-3-span-span-class-toctext-object-detection-and-recognition-span-a-li-li-class-toclevel-2-tocsection-5-a-href-handwriting-and-character-recognition-span-class-tocnumber-1-4-span-span-class-toctext-handwriting-and-character-recognition-span-a-li-li-class-toclevel-2-tocsection-6-a-href-aerial-images-span-class-tocnumber-1-5-span-span-class-toctext-aerial-images-span-a-li-li-class-toclevel-2-tocsection-7-a-href-other-images-span-class-tocnumber-1-6-span-span-class-toctext-other-images-span-a-li-ul-li-li-class-toclevel-1-tocsection-8-a-href-text-data-span-class-tocnumber-2-span-span-class-toctext-text-data-span-a-ul-li-class-toclevel-2-tocsection-9-a-href-reviews-span-class-tocnumber-2-1-span-span-class-toctext-reviews-span-a-li-li-class-toclevel-2-tocsection-10-a-href-news-articles-span-class-tocnumber-2-2-span-span-class-toctext-news-articles-span-a-li-li-class-toclevel-2-tocsection-11-a-href-messages-span-class-tocnumber-2-3-span-span-class-toctext-messages-span-a-li-li-class-toclevel-2-tocsection-12-a-href-twitter-and-tweets-span-class-tocnumber-2-4-span-span-class-toctext-twitter-and-tweets-span-a-li-li-class-toclevel-2-tocsection-13-a-href-dialogues-span-class-tocnumber-2-5-span-span-class-toctext-dialogues-span-a-li-li-class-toclevel-2-tocsection-14-a-href-other-text-span-class-tocnumber-2-6-span-span-class-toctext-other-text-span-a-li-ul-li-li-class-toclevel-1-tocsection-15-a-href-sound-data-span-class-tocnumber-3-span-span-class-toctext-sound-data-span-a-ul-li-class-toclevel-2-tocsection-16-a-href-speech-span-class-tocnumber-3-1-span-span-class-toctext-speech-span-a-li-li-class-toclevel-2-tocsection-17-a-href-music-span-class-tocnumber-3-2-span-span-class-toctext-music-span-a-li-li-class-toclevel-2-tocsection-18-a-href-other-sounds-span-class-tocnumber-3-3-span-span-class-toctext-other-sounds-span-a-li-ul-li-li-class-toclevel-1-tocsection-19-a-href-signal-data-span-class-tocnumber-4-span-span-class-toctext-signal-data-span-a-ul-li-class-toclevel-2-tocsection-20-a-href-electrical-span-class-tocnumber-4-1-span-span-class-toctext-electrical-span-a-li-li-class-toclevel-2-tocsection-21-a-href-motion-tracking-span-class-tocnumber-4-2-span-span-class-toctext-motion-tracking-span-a-li-li-class-toclevel-2-tocsection-22-a-href-other-signals-span-class-tocnumber-4-3-span-span-class-toctext-other-signals-span-a-li-ul-li-li-class-toclevel-1-tocsection-23-a-href-physical-data-span-class-tocnumber-5-span-span-class-toctext-physical-data-span-a-ul-li-class-toclevel-2-tocsection-24-a-href-high-energy-physics-span-class-tocnumber-5-1-span-span-class-toctext-high-energy-physics-span-a-li-li-class-toclevel-2-tocsection-25-a-href-systems-span-class-tocnumber-5-2-span-span-class-toctext-systems-span-a-li-li-class-toclevel-2-tocsection-26-a-href-astronomy-span-class-tocnumber-5-3-span-span-class-toctext-astronomy-span-a-li-li-class-toclevel-2-tocsection-27-a-href-earth-science-span-class-tocnumber-5-4-span-span-class-toctext-earth-science-span-a-li-li-class-toclevel-2-tocsection-28-a-href-other-physical-span-class-tocnumber-5-5-span-span-class-toctext-other-physical-span-a-li-ul-li-li-class-toclevel-1-tocsection-29-a-href-biological-data-span-class-tocnumber-6-span-span-class-toctext-biological-data-span-a-ul-li-class-toclevel-2-tocsection-30-a-href-human-span-class-tocnumber-6-1-span-span-class-toctext-human-span-a-li-li-class-toclevel-2-tocsection-31-a-href-animal-span-class-tocnumber-6-2-span-span-class-toctext-animal-span-a-li-li-class-toclevel-2-tocsection-32-a-href-plant-span-class-tocnumber-6-3-span-span-class-toctext-plant-span-a-li-li-class-toclevel-2-tocsection-33-a-href-microbe-span-class-tocnumber-6-4-span-span-class-toctext-microbe-span-a-li-li-class-toclevel-2-tocsection-34-a-href-drug-discovery-span-class-tocnumber-6-5-span-span-class-toctext-drug-discovery-span-a-li-ul-li-li-class-toclevel-1-tocsection-35-a-href-anomaly-data-span-class-tocnumber-7-span-span-class-toctext-anomaly-data-span-a-li-li-class-toclevel-1-tocsection-36-a-href-question-answering-data-span-class-tocnumber-8-span-span-class-toctext-question-answering-data-span-a-li-li-class-toclevel-1-tocsection-37-a-href-multivariate-data-span-class-tocnumber-9-span-span-class-toctext-multivariate-data-span-a-ul-li-class-toclevel-2-tocsection-38-a-href-financial-span-class-tocnumber-9-1-span-span-class-toctext-financial-span-a-li-li-class-toclevel-2-tocsection-39-a-href-weather-span-class-tocnumber-9-2-span-span-class-toctext-weather-span-a-li-li-class-toclevel-2-tocsection-40-a-href-census-span-class-tocnumber-9-3-span-span-class-toctext-census-span-a-li-li-class-toclevel-2-tocsection-41-a-href-transit-span-class-tocnumber-9-4-span-span-class-toctext-transit-span-a-li-li-class-toclevel-2-tocsection-42-a-href-internet-span-class-tocnumber-9-5-span-span-class-toctext-internet-span-a-li-li-class-toclevel-2-tocsection-43-a-href-games-span-class-tocnumber-9-6-span-span-class-toctext-games-span-a-li-li-class-toclevel-2-tocsection-44-a-href-other-multivariate-span-class-tocnumber-9-7-span-span-class-toctext-other-multivariate-span-a-li-ul-li-li-class-toclevel-1-tocsection-45-a-href-curated-repositories-of-datasets-span-class-tocnumber-10-span-span-class-toctext-curated-repositories-of-datasets-span-a-li-li-class-toclevel-1-tocsection-46-a-href-see-also-span-class-tocnumber-11-span-span-class-toctext-see-also-span-a-li-li-class-toclevel-1-tocsection-47-a-href-references-span-class-tocnumber-12-span-span-class-toctext-references-span-a-li-ul-div-h2-span-class-mw-headline-id-image-data-image-data-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-1-title-edit-section-image-data-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-datasets-consisting-primarily-of-images-or-videos-for-tasks-such-as-a-href-wiki-object-detection-title-object-detection-object-detection-a-a-href-wiki-facial-recognition-system-title-facial-recognition-system-facial-recognition-a-and-a-href-wiki-multi-label-classification-title-multi-label-classification-multi-label-classification-a-p-h3-span-class-mw-headline-id-facial-recognition-facial-recognition-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-2-title-edit-section-facial-recognition-edit-a-span-class-mw-editsection-bracket-span-span-h3-p-in-a-href-wiki-computer-vision-title-computer-vision-computer-vision-a-face-images-have-been-used-extensively-to-develop-a-href-wiki-facial-recognition-system-title-facial-recognition-system-facial-recognition-systems-a-a-href-wiki-face-detection-title-face-detection-face-detection-a-and-many-other-projects-that-use-images-of-faces-p-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-a-href-wiki-feret-facial-recognition-technology-title-feret-facial-recognition-technology-feret-facial-recognition-technology-a-td-td-11338-images-of-1199-individuals-in-different-positions-and-at-different-times-td-td-none-td-td-11338-td-td-images-td-td-classification-face-recognition-td-td-2003-td-td-sup-id-cite-ref-4-6-0-class-reference-a-href-cite-note-4-6-6-a-sup-sup-id-cite-ref-7-class-reference-a-href-cite-note-7-7-a-sup-td-td-a-href-wiki-united-states-department-of-defense-title-united-states-department-of-defense-united-states-department-of-defense-a-td-tr-tr-td-cmu-pose-illumination-and-expression-pie-td-td-41368-color-images-of-68-people-in-13-different-poses-td-td-images-labeled-with-expressions-td-td-41368-td-td-images-text-td-td-classification-face-recognition-td-td-2000-td-td-sup-id-cite-ref-8-class-reference-a-href-cite-note-8-8-a-sup-sup-id-cite-ref-9-class-reference-a-href-cite-note-9-9-a-sup-td-td-r-gross-et-al-td-tr-tr-td-ryerson-audio-visual-database-of-emotional-speech-and-song-ravdess-td-td-7356-video-and-audio-recordings-of-24-professional-actors-8-emotions-each-at-two-intensities-td-td-files-labelled-with-expression-perceptual-validation-ratings-provided-by-319-raters-td-td-7356-td-td-video-sound-files-td-td-classification-face-recognition-voice-recognition-td-td-2018-td-td-sup-id-cite-ref-10-class-reference-a-href-cite-note-10-10-a-sup-sup-id-cite-ref-11-class-reference-a-href-cite-note-11-11-a-sup-td-td-s-r-livingstone-and-f-a-russo-td-tr-tr-td-scface-td-td-color-images-of-faces-at-various-angles-td-td-location-of-facial-features-extracted-coordinates-of-features-given-td-td-4160-td-td-images-text-td-td-a-href-wiki-statistical-classification-title-statistical-classification-classification-a-face-recognition-td-td-2011-td-td-sup-id-cite-ref-0-12-0-class-reference-a-href-cite-note-0-12-12-a-sup-sup-id-cite-ref-13-class-reference-a-href-cite-note-13-13-a-sup-td-td-m-grgic-et-al-td-tr-tr-td-youtube-faces-db-td-td-videos-of-1595-different-people-gathered-from-youtube-each-clip-is-between-48-and-6070-frames-td-td-identity-of-those-appearing-in-videos-and-descriptors-td-td-3425-videos-td-td-video-text-td-td-video-classification-face-recognition-td-td-2011-td-td-sup-id-cite-ref-14-class-reference-a-href-cite-note-14-14-a-sup-sup-id-cite-ref-15-class-reference-a-href-cite-note-15-15-a-sup-td-td-l-wolf-et-al-td-tr-tr-td-300-videos-in-the-wild-td-td-114-videos-annotated-for-facial-landmark-tracking-the-68-landmark-mark-up-is-applied-to-every-frame-td-td-none-td-td-114-videos-218000-frames-td-td-video-annotation-file-td-td-facial-landmark-tracking-td-td-2015-td-td-sup-id-cite-ref-16-class-reference-a-href-cite-note-16-16-a-sup-td-td-shen-jie-et-al-td-tr-tr-td-grammatical-facial-expressions-dataset-td-td-grammatical-facial-expressions-from-brazilian-sign-language-td-td-microsoft-kinect-features-extracted-td-td-27965-td-td-text-td-td-facial-gesture-recognition-td-td-2014-td-td-sup-id-cite-ref-17-class-reference-a-href-cite-note-17-17-a-sup-td-td-f-freitas-et-al-td-tr-tr-td-cmu-face-images-dataset-td-td-images-of-faces-each-person-is-photographed-multiple-times-to-capture-different-expressions-td-td-labels-and-features-td-td-640-td-td-images-text-td-td-face-recognition-td-td-1999-td-td-sup-id-cite-ref-18-class-reference-a-href-cite-note-18-18-a-sup-sup-id-cite-ref-19-class-reference-a-href-cite-note-19-19-a-sup-td-td-t-mitchell-td-tr-tr-td-yale-face-database-td-td-faces-of-15-individuals-in-11-different-expressions-td-td-labels-of-expressions-td-td-165-td-td-images-td-td-face-recognition-td-td-1997-td-td-sup-id-cite-ref-20-class-reference-a-href-cite-note-20-20-a-sup-sup-id-cite-ref-21-class-reference-a-href-cite-note-21-21-a-sup-td-td-j-yang-et-al-td-tr-tr-td-cohn-kanade-au-coded-expression-database-td-td-large-database-of-images-with-labels-for-expressions-td-td-tracking-of-certain-facial-features-td-td-500-sequences-td-td-images-text-td-td-facial-expression-analysis-td-td-2000-td-td-sup-id-cite-ref-22-class-reference-a-href-cite-note-22-22-a-sup-sup-id-cite-ref-23-class-reference-a-href-cite-note-23-23-a-sup-td-td-t-kanade-et-al-td-tr-tr-td-facescrub-td-td-images-of-public-figures-scrubbed-from-image-searching-td-td-name-and-m-f-annotation-td-td-107818-td-td-images-text-td-td-face-recognition-td-td-2014-td-td-sup-id-cite-ref-24-class-reference-a-href-cite-note-24-24-a-sup-sup-id-cite-ref-25-class-reference-a-href-cite-note-25-25-a-sup-td-td-h-ng-et-al-td-tr-tr-td-bioid-face-database-td-td-images-of-faces-with-eye-positions-marked-td-td-manually-set-eye-positions-td-td-1521-td-td-images-text-td-td-face-recognition-td-td-2001-td-td-sup-id-cite-ref-26-class-reference-a-href-cite-note-26-26-a-sup-sup-id-cite-ref-27-class-reference-a-href-cite-note-27-27-a-sup-td-td-bioid-td-tr-tr-td-skin-segmentation-dataset-td-td-randomly-sampled-color-values-from-face-images-td-td-b-g-r-values-extracted-td-td-245057-td-td-text-td-td-segmentation-classification-td-td-2012-td-td-sup-id-cite-ref-28-class-reference-a-href-cite-note-28-28-a-sup-sup-id-cite-ref-29-class-reference-a-href-cite-note-29-29-a-sup-td-td-r-bhatt-td-tr-tr-td-bosphorus-td-td-3d-face-image-database-td-td-34-action-units-and-6-expressions-labeled-24-facial-landmarks-labeled-td-td-4652-td-td-p-images-text-p-td-td-face-recognition-classification-td-td-2008-td-td-sup-id-cite-ref-30-class-reference-a-href-cite-note-30-30-a-sup-sup-id-cite-ref-31-class-reference-a-href-cite-note-31-31-a-sup-td-td-a-savran-et-al-td-tr-tr-td-uoy-3d-face-td-td-neutral-face-5-expressions-anger-happiness-sadness-eyes-closed-eyebrows-raised-td-td-labeling-td-td-5250-td-td-p-images-text-p-td-td-face-recognition-classification-td-td-2004-td-td-sup-id-cite-ref-32-class-reference-a-href-cite-note-32-32-a-sup-sup-id-cite-ref-33-class-reference-a-href-cite-note-33-33-a-sup-td-td-a-href-wiki-university-of-york-title-university-of-york-university-of-york-a-td-tr-tr-td-casia-td-td-expressions-anger-smile-laugh-surprise-closed-eyes-td-td-none-td-td-4624-td-td-p-images-text-p-td-td-face-recognition-classification-td-td-2007-td-td-sup-id-cite-ref-34-class-reference-a-href-cite-note-34-34-a-sup-sup-id-cite-ref-35-class-reference-a-href-cite-note-35-35-a-sup-td-td-a-href-wiki-institute-of-automation-chinese-academy-of-sciences-class-mw-redirect-title-institute-of-automation-chinese-academy-of-sciences-institute-of-automation-chinese-academy-of-sciences-a-td-tr-tr-td-casia-td-td-expressions-anger-disgust-fear-happiness-sadness-surprise-td-td-none-td-td-480-td-td-annotated-visible-spectrum-and-near-infrared-video-captures-at-25-frames-per-second-td-td-face-recognition-classification-td-td-2011-td-td-sup-id-cite-ref-36-class-reference-a-href-cite-note-36-36-a-sup-td-td-zhao-g-et-al-td-tr-tr-td-bu-3dfe-td-td-neutral-face-and-6-expressions-anger-happiness-sadness-surprise-disgust-fear-4-levels-3d-images-extracted-td-td-none-td-td-2500-td-td-images-text-td-td-facial-expression-recognition-classification-td-td-2006-td-td-sup-id-cite-ref-37-class-reference-a-href-cite-note-37-37-a-sup-td-td-a-href-wiki-binghamton-university-title-binghamton-university-binghamton-university-a-td-tr-tr-td-a-href-wiki-face-recognition-grand-challenge-title-face-recognition-grand-challenge-face-recognition-grand-challenge-a-dataset-td-td-up-to-22-samples-for-each-subject-expressions-anger-happiness-sadness-surprise-disgust-puffy-3d-data-td-td-none-td-td-4007-td-td-images-text-td-td-face-recognition-classification-td-td-2004-td-td-sup-id-cite-ref-38-class-reference-a-href-cite-note-38-38-a-sup-sup-id-cite-ref-39-class-reference-a-href-cite-note-39-39-a-sup-td-td-a-href-wiki-national-institute-of-standards-and-technology-title-national-institute-of-standards-and-technology-national-institute-of-standards-and-technology-a-td-tr-tr-td-gavabdb-td-td-up-to-61-samples-for-each-subject-expressions-neutral-face-smile-frontal-accentuated-laugh-frontal-random-gesture-3d-images-td-td-none-td-td-549-td-td-images-text-td-td-face-recognition-classification-td-td-2008-td-td-sup-id-cite-ref-40-class-reference-a-href-cite-note-40-40-a-sup-sup-id-cite-ref-41-class-reference-a-href-cite-note-41-41-a-sup-td-td-a-href-wiki-king-juan-carlos-university-title-king-juan-carlos-university-king-juan-carlos-university-a-td-tr-tr-td-3d-rma-td-td-up-to-100-subjects-expressions-mostly-neutral-several-poses-as-well-td-td-none-td-td-9971-td-td-images-text-td-td-face-recognition-classification-td-td-2004-td-td-sup-id-cite-ref-42-class-reference-a-href-cite-note-42-42-a-sup-sup-id-cite-ref-43-class-reference-a-href-cite-note-43-43-a-sup-td-td-a-href-wiki-royal-military-academy-belgium-title-royal-military-academy-belgium-royal-military-academy-belgium-a-td-tr-tr-td-sof-td-td-112-persons-66-males-and-46-females-wear-glasses-under-different-illumination-conditions-td-td-a-set-of-synthetic-filters-blur-occlusions-noise-and-posterization-with-different-level-of-difficulty-td-td-42592-2662-original-image-x-16-synthetic-image-td-td-images-mat-file-td-td-gender-classification-face-detection-face-recognition-age-estimation-and-glasses-detection-td-td-2017-td-td-sup-id-cite-ref-44-class-reference-a-href-cite-note-44-44-a-sup-sup-id-cite-ref-45-class-reference-a-href-cite-note-45-45-a-sup-td-td-afifi-m-et-al-td-tr-tr-td-imdb-wiki-td-td-imdb-and-wikipedia-face-images-with-gender-and-age-labels-td-td-none-td-td-523051-td-td-images-td-td-gender-classification-face-detection-face-recognition-age-estimation-td-td-2015-td-td-sup-id-cite-ref-46-class-reference-a-href-cite-note-46-46-a-sup-td-td-r-rothe-r-timofte-l-v-gool-td-tr-tbody-table-h3-span-class-mw-headline-id-action-recognition-action-recognition-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-3-title-edit-section-action-recognition-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-human-motion-database-hmdb51-td-td-51-action-categories-each-containing-at-least-101-clips-extracted-from-a-range-of-sources-td-td-none-td-td-6766-video-clips-td-td-video-clips-td-td-action-classification-td-td-2011-td-td-sup-id-cite-ref-47-class-reference-a-href-cite-note-47-47-a-sup-td-td-h-kuehne-et-al-td-tr-tr-td-tv-human-interaction-dataset-td-td-videos-from-20-different-tv-shows-for-prediction-social-actions-handshake-high-five-hug-kiss-and-none-td-td-none-td-td-6766-video-clips-td-td-video-clips-td-td-action-prediction-td-td-2013-td-td-sup-id-cite-ref-48-class-reference-a-href-cite-note-48-48-a-sup-td-td-patron-perez-a-et-al-td-tr-tr-td-ut-interaction-td-td-people-acting-out-one-of-6-actions-shake-hands-point-hug-push-kick-and-punch-sometimes-with-multiple-groups-in-the-same-video-clip-td-td-none-td-td-120-video-clips-td-td-video-clips-td-td-action-prediction-td-td-2009-td-td-sup-id-cite-ref-49-class-reference-a-href-cite-note-49-49-a-sup-td-td-ryoo-m-s-et-al-td-tr-tr-td-ut-kinect-td-td-10-different-people-performing-one-of-6-actions-walk-sit-down-stand-up-pick-up-carry-throw-push-pull-wave-hands-and-clap-hands-in-an-office-setting-td-td-none-td-td-200-video-clips-with-depth-information-at-15-frames-per-second-td-td-video-clips-with-depth-information-td-td-action-classification-td-td-2012-td-td-sup-id-cite-ref-50-class-reference-a-href-cite-note-50-50-a-sup-td-td-xia-l-et-al-td-tr-tr-td-sbu-interact-td-td-seven-participants-performing-one-of-8-actions-together-approaching-departing-pushing-kicking-punching-exchanging-objects-hugging-and-shaking-hands-in-an-office-setting-td-td-none-td-td-around-300-interactions-td-td-video-clips-with-depth-information-td-td-action-classification-td-td-2012-td-td-sup-id-cite-ref-51-class-reference-a-href-cite-note-51-51-a-sup-td-td-yun-k-et-al-td-tr-tr-td-berkeley-multimodal-human-action-database-mhad-td-td-recordings-of-a-single-person-performing-12-actions-td-td-mocap-pre-processing-td-td-660-action-samples-td-td-8-phasespace-motion-capture-2-stereo-cameras-4-quad-cameras-6-accelerometers-4-microphones-td-td-action-classification-td-td-2013-td-td-sup-id-cite-ref-52-class-reference-a-href-cite-note-52-52-a-sup-td-td-ofli-f-et-al-td-tr-tr-td-ucf-101-dataset-td-td-self-described-as-a-dataset-of-101-human-actions-classes-from-videos-in-the-wild-dataset-is-large-with-over-27-hours-of-video-td-td-actions-classified-and-labeled-td-td-13000-td-td-video-images-text-td-td-classification-action-detection-td-td-2012-td-td-sup-id-cite-ref-53-class-reference-a-href-cite-note-53-53-a-sup-sup-id-cite-ref-54-class-reference-a-href-cite-note-54-54-a-sup-td-td-k-soomro-et-al-td-tr-tr-td-thumos-dataset-td-td-large-video-dataset-for-action-classification-td-td-actions-classified-and-labeled-td-td-45m-frames-of-video-td-td-video-images-text-td-td-classification-action-detection-td-td-2013-td-td-sup-id-cite-ref-55-class-reference-a-href-cite-note-55-55-a-sup-sup-id-cite-ref-56-class-reference-a-href-cite-note-56-56-a-sup-td-td-y-jiang-et-al-td-tr-tr-td-activitynet-td-td-large-video-dataset-for-activity-recognition-and-detection-td-td-actions-classified-and-labeled-td-td-10024-td-td-video-images-text-td-td-classification-action-detection-td-td-2015-td-td-sup-id-cite-ref-57-class-reference-a-href-cite-note-57-57-a-sup-td-td-heilbron-et-al-td-tr-tr-td-msp-avatar-td-td-improvised-scenarios-annotated-for-discourse-functions-contrast-confirmation-negation-question-uncertainty-suggest-giving-orders-warn-inform-size-description-using-pronouns-td-td-actions-classified-and-labeled-td-td-74-sessions-td-td-motion-captured-video-audio-td-td-classification-action-detection-td-td-2015-td-td-sup-id-cite-ref-58-class-reference-a-href-cite-note-58-58-a-sup-td-td-sadoughi-n-et-al-td-tr-tr-td-lilir-twotalk-corpus-td-td-video-datasets-for-non-verbal-communication-activity-recognition-agreement-thinking-asking-and-understanding-td-td-actions-classified-and-labeled-td-td-527-td-td-video-td-td-action-detection-td-td-2011-td-td-sup-id-cite-ref-59-class-reference-a-href-cite-note-59-59-a-sup-td-td-sheerman-chase-et-al-td-tr-tr-td-mexaction2-td-td-video-dataset-for-action-localization-and-spotting-td-td-actions-classified-and-labeled-td-td-1000-td-td-video-td-td-action-detection-td-td-2014-td-td-sup-id-cite-ref-60-class-reference-a-href-cite-note-60-60-a-sup-td-td-stoian-et-al-td-tr-tbody-table-h3-span-class-mw-headline-id-object-detection-and-recognition-object-detection-and-recognition-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-4-title-edit-section-object-detection-and-recognition-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-visual-genome-td-td-images-and-their-description-td-td-td-td-108000-td-td-images-text-td-td-image-captioning-td-td-2016-td-td-sup-id-cite-ref-61-class-reference-a-href-cite-note-61-61-a-sup-td-td-r-krishna-et-al-td-tr-tr-td-davis-densely-annotated-video-segmentation-2017-td-td-150-video-sequences-containing-10459-frames-with-a-total-of-376-objects-annotated-td-td-dataset-released-for-the-2017-davis-challenge-with-a-dedicated-workshop-co-located-with-cvpr-2017-the-videos-contain-several-types-of-objects-and-humans-with-a-high-quality-segmentation-annotation-in-each-video-sequence-multiple-instances-are-annotated-td-td-10459-td-td-frames-annotated-td-td-video-object-segmentation-td-td-2017-td-td-sup-id-cite-ref-62-class-reference-a-href-cite-note-62-62-a-sup-td-td-pont-tuset-j-et-al-td-tr-tr-td-davis-densely-annotated-video-segmentation-2016-td-td-50-video-sequences-containing-3455-frames-with-a-total-of-50-objects-annotated-td-td-dataset-released-with-the-cvpr-2016-paper-the-videos-contain-several-types-of-objects-and-humans-with-a-high-quality-segmentation-annotation-in-each-video-sequence-a-single-instance-is-annotated-td-td-3455-td-td-frames-annotated-td-td-video-object-segmentation-td-td-2016-td-td-sup-id-cite-ref-63-class-reference-a-href-cite-note-63-63-a-sup-td-td-perazzi-f-et-al-td-tr-tr-td-t-less-an-rgb-d-dataset-for-6d-pose-estimation-of-texture-less-objects-td-td-30-industry-relevant-objects-39k-training-and-10k-test-images-from-each-of-three-sensors-two-types-of-3d-models-for-each-object-td-td-6d-poses-for-all-modeled-objects-in-all-images-per-pixel-labelling-can-be-obtained-by-rendering-of-the-object-models-at-the-ground-truth-poses-td-td-49000-td-td-rgb-d-images-3d-object-models-td-td-6d-object-pose-estimation-object-detection-td-td-2017-td-td-sup-id-cite-ref-64-class-reference-a-href-cite-note-64-64-a-sup-td-td-t-hodan-et-al-td-tr-tr-td-berkeley-3-d-object-dataset-td-td-849-images-taken-in-75-different-scenes-about-50-different-object-classes-are-labeled-td-td-object-bounding-boxes-and-labeling-td-td-849-td-td-labeled-images-text-td-td-object-recognition-td-td-2014-td-td-sup-id-cite-ref-6-65-0-class-reference-a-href-cite-note-6-65-65-a-sup-sup-id-cite-ref-66-class-reference-a-href-cite-note-66-66-a-sup-td-td-a-janoch-et-al-td-tr-tr-td-berkeley-segmentation-data-set-and-benchmarks-500-bsds500-td-td-500-natural-images-explicitly-separated-into-disjoint-train-validation-and-test-subsets-benchmarking-code-based-on-bsds300-td-td-each-image-segmented-by-five-different-subjects-on-average-td-td-500-td-td-segmented-images-td-td-contour-detection-and-hierarchical-image-segmentation-td-td-2011-td-td-sup-id-cite-ref-67-class-reference-a-href-cite-note-67-67-a-sup-td-td-a-href-wiki-university-of-california-berkeley-title-university-of-california-berkeley-university-of-california-berkeley-a-td-tr-tr-td-microsoft-common-objects-in-context-coco-td-td-complex-everyday-scenes-of-common-objects-in-their-natural-context-td-td-object-highlighting-labeling-and-classification-into-91-object-types-td-td-2500000-td-td-labeled-images-text-td-td-object-recognition-td-td-2015-td-td-sup-id-cite-ref-68-class-reference-a-href-cite-note-68-68-a-sup-sup-id-cite-ref-69-class-reference-a-href-cite-note-69-69-a-sup-td-td-t-lin-et-al-td-tr-tr-td-sun-database-td-td-very-large-scene-and-object-recognition-database-td-td-places-and-objects-are-labeled-objects-are-segmented-td-td-131067-td-td-images-text-td-td-object-recognition-scene-recognition-td-td-2014-td-td-sup-id-cite-ref-70-class-reference-a-href-cite-note-70-70-a-sup-sup-id-cite-ref-71-class-reference-a-href-cite-note-71-71-a-sup-td-td-j-xiao-et-al-td-tr-tr-td-a-href-wiki-imagenet-title-imagenet-imagenet-a-td-td-labeled-object-image-database-used-in-the-a-href-wiki-imagenet-large-scale-visual-recognition-challenge-class-mw-redirect-title-imagenet-large-scale-visual-recognition-challenge-imagenet-large-scale-visual-recognition-challenge-a-td-td-labeled-objects-bounding-boxes-descriptive-words-sift-features-td-td-14197122-td-td-images-text-td-td-object-recognition-scene-recognition-td-td-2009-2014-td-td-sup-id-cite-ref-72-class-reference-a-href-cite-note-72-72-a-sup-sup-id-cite-ref-02-73-0-class-reference-a-href-cite-note-02-73-73-a-sup-sup-id-cite-ref-74-class-reference-a-href-cite-note-74-74-a-sup-td-td-j-deng-et-al-td-tr-tr-td-open-images-td-td-a-large-set-of-images-listed-as-having-cc-by-2-0-license-with-image-level-labels-and-bounding-boxes-spanning-thousands-of-classes-td-td-image-level-labels-bounding-boxes-td-td-9178275-td-td-images-text-td-td-classification-object-recognition-td-td-2017-td-td-sup-id-cite-ref-75-class-reference-a-href-cite-note-75-75-a-sup-td-td-td-tr-tr-td-tv-news-channel-commercial-detection-dataset-td-td-tv-commercials-and-news-broadcasts-td-td-audio-and-video-features-extracted-from-still-images-td-td-129685-td-td-text-td-td-clustering-classification-td-td-2015-td-td-sup-id-cite-ref-76-class-reference-a-href-cite-note-76-76-a-sup-sup-id-cite-ref-77-class-reference-a-href-cite-note-77-77-a-sup-td-td-p-guha-et-al-td-tr-tr-td-statlog-image-segmentation-dataset-td-td-the-instances-were-drawn-randomly-from-a-database-of-7-outdoor-images-and-hand-segmented-to-create-a-classification-for-every-pixel-td-td-many-features-calculated-td-td-2310-td-td-text-td-td-classification-td-td-1990-td-td-sup-id-cite-ref-78-class-reference-a-href-cite-note-78-78-a-sup-td-td-a-href-wiki-university-of-massachusetts-title-university-of-massachusetts-university-of-massachusetts-a-td-tr-tr-td-a-href-wiki-caltech-101-title-caltech-101-caltech-101-a-td-td-pictures-of-objects-td-td-detailed-object-outlines-marked-td-td-9146-td-td-images-td-td-classification-object-recognition-td-td-2003-td-td-sup-id-cite-ref-79-class-reference-a-href-cite-note-79-79-a-sup-sup-id-cite-ref-80-class-reference-a-href-cite-note-80-80-a-sup-td-td-f-li-et-al-td-tr-tr-td-caltech-256-td-td-large-dataset-of-images-for-object-classification-td-td-images-categorized-and-hand-sorted-td-td-30607-td-td-images-text-td-td-classification-object-detection-td-td-2007-td-td-sup-id-cite-ref-81-class-reference-a-href-cite-note-81-81-a-sup-sup-id-cite-ref-82-class-reference-a-href-cite-note-82-82-a-sup-td-td-g-griffin-et-al-td-tr-tr-td-sift10m-dataset-td-td-sift-features-of-caltech-256-dataset-td-td-extensive-sift-feature-extraction-td-td-11164866-td-td-text-td-td-classification-object-detection-td-td-2016-td-td-sup-id-cite-ref-83-class-reference-a-href-cite-note-83-83-a-sup-td-td-x-fu-et-al-td-tr-tr-td-labelme-td-td-annotated-pictures-of-scenes-td-td-objects-outlined-td-td-187240-td-td-images-text-td-td-classification-object-detection-td-td-2005-td-td-sup-id-cite-ref-84-class-reference-a-href-cite-note-84-84-a-sup-td-td-a-href-wiki-mit-computer-science-and-artificial-intelligence-laboratory-title-mit-computer-science-and-artificial-intelligence-laboratory-mit-computer-science-and-artificial-intelligence-laboratory-a-td-tr-tr-td-cityscapes-dataset-td-td-stereo-video-sequences-recorded-in-street-scenes-with-pixel-level-annotations-metadata-also-included-td-td-pixel-level-segmentation-and-labeling-td-td-25000-td-td-images-text-td-td-classification-object-detection-td-td-2016-td-td-sup-id-cite-ref-85-class-reference-a-href-cite-note-85-85-a-sup-td-td-a-href-wiki-daimler-ag-title-daimler-ag-daimler-ag-a-et-al-td-tr-tr-td-pascal-voc-dataset-td-td-large-number-of-images-for-classification-tasks-td-td-labeling-bounding-box-included-td-td-500000-td-td-images-text-td-td-classification-object-detection-td-td-2010-td-td-sup-id-cite-ref-86-class-reference-a-href-cite-note-86-86-a-sup-sup-id-cite-ref-87-class-reference-a-href-cite-note-87-87-a-sup-td-td-m-everingham-et-al-td-tr-tr-td-a-href-wiki-cifar-10-title-cifar-10-cifar-10-a-dataset-td-td-many-small-low-resolution-images-of-10-classes-of-objects-td-td-classes-labelled-training-set-splits-created-td-td-60000-td-td-images-td-td-classification-td-td-2009-td-td-sup-id-cite-ref-02-73-1-class-reference-a-href-cite-note-02-73-73-a-sup-sup-id-cite-ref-12-88-0-class-reference-a-href-cite-note-12-88-88-a-sup-td-td-a-krizhevsky-et-al-td-tr-tr-td-cifar-100-dataset-td-td-like-cifar-10-above-but-100-classes-of-objects-are-given-td-td-classes-labelled-training-set-splits-created-td-td-60000-td-td-images-td-td-classification-td-td-2009-td-td-sup-id-cite-ref-02-73-2-class-reference-a-href-cite-note-02-73-73-a-sup-sup-id-cite-ref-12-88-1-class-reference-a-href-cite-note-12-88-88-a-sup-td-td-a-krizhevsky-et-al-td-tr-tr-td-cinic-10-dataset-td-td-a-unified-contribution-of-cifar-10-and-imagenet-with-10-classes-and-3-splits-larger-than-cifar-10-td-td-classes-labelled-training-validation-test-set-splits-created-td-td-270000-td-td-images-td-td-classification-td-td-2018-td-td-sup-id-cite-ref-89-class-reference-a-href-cite-note-89-89-a-sup-td-td-luke-n-darlow-elliot-j-crowley-antreas-antoniou-amos-j-storkey-td-tr-tr-td-fashion-mnist-td-td-a-mnist-like-fashion-product-database-td-td-classes-labelled-training-set-splits-created-td-td-60000-td-td-images-td-td-classification-td-td-2017-td-td-sup-id-cite-ref-90-class-reference-a-href-cite-note-90-90-a-sup-td-td-zalando-se-td-tr-tr-td-notmnist-td-td-some-publicly-available-fonts-and-extracted-glyphs-from-them-to-make-a-dataset-similar-to-mnist-there-are-10-classes-with-letters-a-j-taken-from-different-fonts-td-td-classes-labelled-training-set-splits-created-td-td-500000-td-td-images-td-td-classification-td-td-2011-td-td-sup-id-cite-ref-91-class-reference-a-href-cite-note-91-91-a-sup-td-td-yaroslav-bulatov-td-tr-tr-td-german-traffic-sign-detection-benchmark-dataset-td-td-images-from-vehicles-of-traffic-signs-on-german-roads-these-signs-comply-with-un-standards-and-therefore-are-the-same-as-in-other-countries-td-td-signs-manually-labeled-td-td-900-td-td-images-td-td-classification-td-td-2013-td-td-sup-id-cite-ref-92-class-reference-a-href-cite-note-92-92-a-sup-sup-id-cite-ref-93-class-reference-a-href-cite-note-93-93-a-sup-td-td-s-houben-et-al-td-tr-tr-td-kitti-vision-benchmark-dataset-td-td-autonomous-vehicles-driving-through-a-mid-size-city-captured-images-of-various-areas-using-cameras-and-laser-scanners-td-td-many-benchmarks-extracted-from-data-td-td-100-gb-of-data-td-td-images-text-td-td-classification-object-detection-td-td-2012-td-td-sup-id-cite-ref-94-class-reference-a-href-cite-note-94-94-a-sup-sup-id-cite-ref-95-class-reference-a-href-cite-note-95-95-a-sup-td-td-a-geiger-et-al-td-tr-tr-td-linnaeus-5-dataset-td-td-images-of-5-classes-of-objects-td-td-classes-labelled-training-set-splits-created-td-td-8000-td-td-images-td-td-classification-td-td-2017-td-td-sup-id-cite-ref-96-class-reference-a-href-cite-note-96-96-a-sup-td-td-chaladze-kalatozishvili-td-tr-tr-td-fieldsafe-td-td-multi-modal-dataset-for-obstacle-detection-in-agriculture-including-stereo-camera-thermal-camera-web-camera-360-degree-camera-lidar-radar-and-precise-localization-td-td-classes-labelled-geographically-td-td-400-gb-of-data-td-td-images-and-3d-point-clouds-td-td-classification-object-detection-object-localization-td-td-2017-td-td-sup-id-cite-ref-97-class-reference-a-href-cite-note-97-97-a-sup-td-td-m-kragh-et-al-td-tr-tr-td-11k-hands-td-td-11076-hand-images-1600-x-1200-pixels-of-190-subjects-of-varying-ages-between-18-75-years-old-for-gender-recognition-and-biometric-identification-td-td-none-td-td-11076-hand-images-td-td-images-and-mat-txt-and-csv-label-files-td-td-gender-recognition-and-biometric-identification-td-td-2017-td-td-sup-id-cite-ref-98-class-reference-a-href-cite-note-98-98-a-sup-td-td-m-afifi-td-tr-tr-td-core50-td-td-specifically-designed-for-continuous-lifelong-learning-and-object-recognition-is-a-collection-of-more-than-500-videos-30fps-of-50-domestic-objects-belonging-to-10-different-categories-td-td-classes-labelled-training-set-splits-created-based-on-a-3-way-multi-runs-benchmark-td-td-164866-rbg-d-images-td-td-images-png-or-pkl-p-and-pkl-txt-tsv-label-files-p-td-td-classification-object-recognition-td-td-2017-td-td-sup-id-cite-ref-99-class-reference-a-href-cite-note-99-99-a-sup-td-td-v-lomonaco-and-d-maltoni-td-tr-tbody-table-h3-span-class-mw-headline-id-handwriting-and-character-recognition-handwriting-and-character-recognition-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-5-title-edit-section-handwriting-and-character-recognition-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-dataset-name-th-th-brief-description-th-th-preprocessing-th-th-instances-th-th-format-th-th-default-task-th-th-created-updated-th-th-reference-th-th-creator-th-tr-tr-td-artificial-characters-dataset-td-td-artificially-generated-data-describing-the-structure-of-10-capital-english-letters-td-td-coordinates-of-lines-drawn-given-as-integers-various-other-features-td-td-6000-td-td-text-td-td-handwriting-recognition-classification-td-td-1992-td-td-sup-id-cite-ref-100-class-reference-a-href-cite-note-100-100-a-sup-td-td-h-guvenir-et-al-td-tr-tr-td-letter-dataset-td-td-upper-case-printed-letters-td-td-17-features-are-extracted-from-all-images-td-td-20000-td-td-text-td-td-ocr-classification-td-td-1991-td-td-sup-id-cite-ref-101-class-reference-a-href-cite-note-101-101-a-sup-sup-id-cite-ref-102-class-reference-a-href-cite-note-102-102-a-sup-td-td-d-slate-et-al-td-tr-tr-td-character-trajectories-dataset-td-td-labeled-samples-of-pen-tip-trajectories-for-people-writing-simple-characters-td-td-3-dimensional-pen-tip-velocity-trajectory-matrix-for-each-sample-td-td-2858-td-td-text-td-td-handwriting-recognition-classification-td-td-2008-td-td-sup-id-cite-ref-103-class-reference-a-href-cite-note-103-103-a-sup-sup-id-cite-ref-104-class-reference-a-href-cite-note-104-104-a-sup-td-td-b-williams-td-tr-tr-td-chars74k-dataset-td-td-character-recognition-in-natural-images-of-symbols-used-in-both-english-and-a-href-wiki-kannada-alphabet-class-mw-redirect-title-kannada-alphabet-kannada-a-td-td-td-td-74107-td-td-td-td-character-recognition-handwriting-recognition-ocr-classification-td-td-2009-td-td-sup-id-cite-ref-105-class-reference-a-href-cite-note-105-105-a-sup-td-td-t-de-campos-td-tr-tr-td-uji-pen-characters-dataset-td-td-isolated-handwritten-characters-td-td-coordinates-of-pen-position-as-characters-were-written-given-td-td-11640-td-td-text-td-td-handwriting-recognition-classification-td-td-2009-td-td-sup-id-cite-ref-106-class-reference-a-href-cite-note-106-106-a-sup-sup-id-cite-ref-107-class-reference-a-href-cite-note-107-107-a-sup-td-td-f-prat-et-al-td-tr-tr-td-gisette-dataset-td-td-handwriting-samples-from-the-often-confused-4-and-9-characters-td-td-features-extracted-from-images-split-into-train-test-handwriting-images-size-normalized-td-td-13500-td-td-images-text-td-td-handwriting-recognition-classification-td-td-2003-td-td-sup-id-cite-ref-108-class-reference-a-href-cite-note-108-108-a-sup-td-td-yann-lecun-et-al-td-tr-tr-td-a-href-wiki-mnist-database-title-mnist-database-mnist-database-a-td-td-database-of-handwritten-digits-td-td-hand-labeled-td-td-60000-td-td-images-text-td-td-classification-td-td-1998-td-td-sup-id-cite-ref-109-class-reference-a-href-cite-note-109-109-a-sup-sup-id-cite-ref-110-class-reference-a-href-cite-note-110-110-a-sup-td-td-a-href-wiki-national-institute-of-standards-and-technology-title-national-institute-of-standards-and-technology-national-institute-of-standards-and-technology-a-td-tr-tr-td-optical-recognition-of-handwritten-digits-dataset-td-td-normalized-bitmaps-of-handwritten-data-td-td-size-normalized-and-mapped-to-bitmaps-td-td-5620-td-td-images-text-td-td-handwriting-recognition-classification-td-td-1998-td-td-sup-id-cite-ref-111-class-reference-a-href-cite-note-111-111-a-sup-td-td-e-alpaydin-et-al-td-tr-tr-td-pen-based-recognition-of-handwritten-digits-dataset-td-td-handwritten-digits-on-electronic-pen-tablet-td-td-feature-vectors-extracted-to-be-uniformly-spaced-td-td-10992-td-td-images-text-td-td-handwriting-recognition-classification-td-td-1998-td-td-sup-id-cite-ref-112-class-reference-a-href-cite-note-112-112-a-sup-sup-id-cite-ref-113-class-reference-a-href-cite-note-113-113-a-sup-td-td-e-alpaydin-et-al-td-tr-tr-td-semeion-handwritten-digit-dataset-td-td-handwritten-digits-from-80-people-td-td-all-handwritten-digits-have-been-normalized-for-size-and-mapped-to-the-same-grid-td-td-1593-td-td-images-text-td-td-handwriting-recognition-classification-td-td-2008-td-td-sup-id-cite-ref-114-class-reference-a-href-cite-note-114-114-a-sup-td-td-t-srl-td-tr-tr-td-hasyv2-td-td-handwritten-mathematical-symbols-td-td-all-symbols-are-centered-and-of-size-32px-x-32px-td-td-168233-td-td-images-text-td-td-classification-td-td-2017-td-td-sup-id-cite-ref-115-class-reference-a-href-cite-note-115-115-a-sup-td-td-martin-thoma-td-tr-tr-td-noisy-handwritten-bangla-dataset-td-td-includes-handwritten-numeral-dataset-10-classes-and-basic-character-dataset-50-classes-each-dataset-has-three-types-of-noise-white-gaussian-motion-blur-and-reduced-contrast-td-td-all-images-are-centered-and-of-size-32x32-td-td-numeral-dataset-p-23330-p-p-character-dataset-p-p-76000-p-td-td-images-p-text-p-td-td-handwriting-recognition-p-classification-p-td-td-2017-td-td-sup-id-cite-ref-116-class-reference-a-href-cite-note-116-116-a-sup-td-td-m-karki-et-al-td-tr-tbody-table-h3-span-class-mw-headline-id-aerial-images-aerial-images-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-6-title-edit-section-aerial-images-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-aerial-image-segmentation-dataset-td-td-80-high-resolution-aerial-images-with-spatial-resolution-ranging-from-0-3-to-1-0-td-td-images-manually-segmented-td-td-80-td-td-images-td-td-aerial-classification-object-detection-td-td-2013-td-td-sup-id-cite-ref-117-class-reference-a-href-cite-note-117-117-a-sup-sup-id-cite-ref-118-class-reference-a-href-cite-note-118-118-a-sup-td-td-j-yuan-et-al-td-tr-tr-td-kit-ais-data-set-td-td-multiple-labeled-training-and-evaluation-datasets-of-aerial-images-of-crowds-td-td-images-manually-labeled-to-show-paths-of-individuals-through-crowds-td-td-150-td-td-images-with-paths-td-td-people-tracking-aerial-tracking-td-td-2012-td-td-sup-id-cite-ref-119-class-reference-a-href-cite-note-119-119-a-sup-sup-id-cite-ref-120-class-reference-a-href-cite-note-120-120-a-sup-td-td-m-butenuth-et-al-td-tr-tr-td-wilt-dataset-td-td-remote-sensing-data-of-diseased-trees-and-other-land-cover-td-td-various-features-extracted-td-td-4899-td-td-images-td-td-classification-aerial-object-detection-td-td-2014-td-td-sup-id-cite-ref-121-class-reference-a-href-cite-note-121-121-a-sup-sup-id-cite-ref-122-class-reference-a-href-cite-note-122-122-a-sup-td-td-b-johnson-td-tr-tr-td-forest-type-mapping-dataset-td-td-satellite-imagery-of-forests-in-japan-td-td-image-wavelength-bands-extracted-td-td-326-td-td-text-td-td-classification-td-td-2015-td-td-sup-id-cite-ref-123-class-reference-a-href-cite-note-123-123-a-sup-sup-id-cite-ref-124-class-reference-a-href-cite-note-124-124-a-sup-td-td-b-johnson-td-tr-tr-td-a-href-wiki-overhead-imagery-research-data-set-title-overhead-imagery-research-data-set-overhead-imagery-research-data-set-a-td-td-annotated-overhead-imagery-images-with-multiple-objects-td-td-over-30-annotations-and-over-60-statistics-that-describe-the-target-within-the-context-of-the-image-td-td-1000-td-td-images-text-td-td-classification-td-td-2009-td-td-sup-id-cite-ref-125-class-reference-a-href-cite-note-125-125-a-sup-sup-id-cite-ref-126-class-reference-a-href-cite-note-126-126-a-sup-td-td-f-tanner-et-al-td-tr-tr-td-spacenet-td-td-spacenet-is-a-corpus-of-commercial-satellite-imagery-and-labeled-training-data-td-td-geotiff-and-geojson-files-containing-building-footprints-td-td-17533-td-td-images-td-td-classification-object-identification-td-td-2017-td-td-sup-id-cite-ref-127-class-reference-a-href-cite-note-127-127-a-sup-sup-id-cite-ref-128-class-reference-a-href-cite-note-128-128-a-sup-sup-id-cite-ref-129-class-reference-a-href-cite-note-129-129-a-sup-td-td-a-href-wiki-digitalglobe-title-digitalglobe-digitalglobe-inc-a-td-tr-tr-td-uc-merced-land-use-dataset-td-td-these-images-were-manually-extracted-from-large-images-from-the-usgs-national-map-urban-area-imagery-collection-for-various-urban-areas-around-the-us-td-td-this-is-a-21-class-land-use-image-dataset-meant-for-research-purposes-there-are-100-images-for-each-class-td-td-2100-td-td-image-chips-of-256x256-30-cm-1-foot-gsd-td-td-land-cover-classification-td-td-2010-td-td-sup-id-cite-ref-130-class-reference-a-href-cite-note-130-130-a-sup-td-td-yi-yang-and-shawn-newsam-td-tr-tr-td-sat-4-airborne-dataset-td-td-images-were-extracted-from-the-national-agriculture-imagery-program-naip-dataset-td-td-sat-4-has-four-broad-land-cover-classes-includes-barren-land-trees-grassland-and-a-class-that-consists-of-all-land-cover-classes-other-than-the-above-three-td-td-500000-td-td-images-td-td-classification-td-td-2015-td-td-sup-id-cite-ref-1-131-0-class-reference-a-href-cite-note-1-131-131-a-sup-td-td-s-basu-et-al-td-tr-tr-td-sat-6-airborne-dataset-td-td-images-were-extracted-from-the-national-agriculture-imagery-program-naip-dataset-td-td-sat-6-has-six-broad-land-cover-classes-includes-barren-land-trees-grassland-roads-buildings-and-water-bodies-td-td-405000-td-td-images-td-td-classification-td-td-2015-td-td-sup-id-cite-ref-1-131-1-class-reference-a-href-cite-note-1-131-131-a-sup-td-td-s-basu-et-al-td-tr-tbody-table-h3-span-class-mw-headline-id-other-images-other-images-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-7-title-edit-section-other-images-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-quantum-simulations-of-an-electron-in-a-two-dimensional-potential-well-td-td-labelled-images-of-raw-input-to-a-simulation-of-2d-quantum-mechanics-td-td-raw-data-in-hdf5-format-and-output-labels-from-quantum-simulation-td-td-1-3-million-images-td-td-labeled-images-td-td-regression-td-td-2017-td-td-sup-id-cite-ref-132-class-reference-a-href-cite-note-132-132-a-sup-td-td-k-mills-et-al-td-tr-tr-td-mpii-cooking-activities-dataset-td-td-videos-and-images-of-various-cooking-activities-td-td-activity-paths-and-directions-labels-fine-grained-motion-labeling-activity-class-still-image-extraction-and-labeling-td-td-881755-frames-td-td-labeled-video-images-text-td-td-classification-td-td-2012-td-td-sup-id-cite-ref-133-class-reference-a-href-cite-note-133-133-a-sup-sup-id-cite-ref-134-class-reference-a-href-cite-note-134-134-a-sup-td-td-m-rohrbach-et-al-td-tr-tr-td-famos-dataset-td-td-5000-unique-microstructures-all-samples-have-been-acquired-3-times-with-two-different-cameras-td-td-original-png-files-sorted-per-camera-and-then-per-acquisition-matlab-datafiles-with-one-16384-times-5000-matrix-per-camera-per-acquisition-td-td-30000-td-td-images-and-mat-files-td-td-authentication-td-td-2012-td-td-sup-id-cite-ref-135-class-reference-a-href-cite-note-135-135-a-sup-td-td-s-voloshynovskiy-et-al-td-tr-tr-td-pharmapack-dataset-td-td-1000-unique-classes-with-54-images-per-class-td-td-class-labeling-many-local-descriptors-like-sift-and-akaze-and-local-feature-agreators-like-fisher-vector-fv-td-td-54000-td-td-images-and-mat-files-td-td-fine-grain-classification-td-td-2017-td-td-sup-id-cite-ref-136-class-reference-a-href-cite-note-136-136-a-sup-td-td-o-taran-and-s-rezaeifar-et-al-td-tr-tr-td-stanford-dogs-dataset-td-td-images-of-120-breeds-of-dogs-from-around-the-world-td-td-train-test-splits-and-imagenet-annotations-provided-td-td-20580-td-td-images-text-td-td-fine-grain-classification-td-td-2011-td-td-sup-id-cite-ref-137-class-reference-a-href-cite-note-137-137-a-sup-sup-id-cite-ref-7-138-0-class-reference-a-href-cite-note-7-138-138-a-sup-td-td-a-khosla-et-al-td-tr-tr-td-the-oxford-iiit-pet-dataset-td-td-37-categories-of-pets-with-roughly-200-images-of-each-td-td-breed-labeled-tight-bounding-box-foreground-background-segmentation-td-td-7400-td-td-images-text-td-td-classification-object-detection-td-td-2012-td-td-sup-id-cite-ref-7-138-1-class-reference-a-href-cite-note-7-138-138-a-sup-sup-id-cite-ref-razavian-ali-2014-139-0-class-reference-a-href-cite-note-razavian-ali-2014-139-139-a-sup-td-td-o-parkhi-et-al-td-tr-tr-td-corel-image-features-data-set-td-td-database-of-images-with-features-extracted-td-td-many-features-including-color-histogram-co-occurrence-texture-and-colormoments-td-td-68040-td-td-text-td-td-classification-object-detection-td-td-1999-td-td-sup-id-cite-ref-140-class-reference-a-href-cite-note-140-140-a-sup-sup-id-cite-ref-141-class-reference-a-href-cite-note-141-141-a-sup-td-td-m-ortega-bindenberger-et-al-td-tr-tr-td-online-video-characteristics-and-transcoding-time-dataset-td-td-transcoding-times-for-various-different-videos-and-video-properties-td-td-video-features-given-td-td-168286-td-td-text-td-td-regression-td-td-2015-td-td-sup-id-cite-ref-142-class-reference-a-href-cite-note-142-142-a-sup-td-td-t-deneke-et-al-td-tr-tr-td-microsoft-sequential-image-narrative-dataset-sind-td-td-dataset-for-sequential-vision-to-language-td-td-descriptive-caption-and-storytelling-given-for-each-photo-and-photos-are-arranged-in-sequences-td-td-81743-td-td-images-text-td-td-visual-storytelling-td-td-2016-td-td-sup-id-cite-ref-143-class-reference-a-href-cite-note-143-143-a-sup-td-td-a-href-wiki-microsoft-research-title-microsoft-research-microsoft-research-a-td-tr-tr-td-caltech-ucsd-birds-200-2011-dataset-td-td-large-dataset-of-images-of-birds-td-td-part-locations-for-birds-bounding-boxes-312-binary-attributes-given-td-td-11788-td-td-images-text-td-td-classification-td-td-2011-td-td-sup-id-cite-ref-144-class-reference-a-href-cite-note-144-144-a-sup-sup-id-cite-ref-145-class-reference-a-href-cite-note-145-145-a-sup-td-td-c-wah-et-al-td-tr-tr-td-youtube-8m-td-td-large-and-diverse-labeled-video-dataset-td-td-youtube-video-ids-and-associated-labels-from-a-diverse-vocabulary-of-4800-visual-entities-td-td-8-million-td-td-video-text-td-td-video-classification-td-td-2016-td-td-sup-id-cite-ref-146-class-reference-a-href-cite-note-146-146-a-sup-sup-id-cite-ref-147-class-reference-a-href-cite-note-147-147-a-sup-td-td-s-abu-el-haija-et-al-td-tr-tr-td-yfcc100m-td-td-large-and-diverse-labeled-image-and-video-dataset-td-td-flickr-videos-and-images-and-associated-description-titles-tags-and-other-metadata-such-as-exif-and-geotags-td-td-100-million-td-td-video-image-text-td-td-video-and-image-classification-td-td-2016-td-td-sup-id-cite-ref-148-class-reference-a-href-cite-note-148-148-a-sup-sup-id-cite-ref-149-class-reference-a-href-cite-note-149-149-a-sup-td-td-b-thomee-et-al-td-tr-tr-td-discrete-liris-accede-td-td-short-videos-annotated-for-valence-and-arousal-td-td-valence-and-arousal-labels-td-td-9800-td-td-video-td-td-video-emotion-elicitation-detection-td-td-2015-td-td-sup-id-cite-ref-150-class-reference-a-href-cite-note-150-150-a-sup-td-td-y-baveye-et-al-td-tr-tr-td-continuous-liris-accede-td-td-long-videos-annotated-for-valence-and-arousal-while-also-collecting-galvanic-skin-response-td-td-valence-and-arousal-labels-td-td-30-td-td-video-td-td-video-emotion-elicitation-detection-td-td-2015-td-td-sup-id-cite-ref-151-class-reference-a-href-cite-note-151-151-a-sup-td-td-y-baveye-et-al-td-tr-tr-td-mediaeval-liris-accede-td-td-extension-of-discrete-liris-accede-including-annotations-for-violence-levels-of-the-films-td-td-violence-valence-and-arousal-labels-td-td-10900-td-td-video-td-td-video-emotion-elicitation-detection-td-td-2015-td-td-sup-id-cite-ref-152-class-reference-a-href-cite-note-152-152-a-sup-td-td-y-baveye-et-al-td-tr-tr-td-leeds-sports-pose-td-td-articulated-human-pose-annotations-in-2000-natural-sports-images-from-flickr-td-td-rough-crop-around-single-person-of-interest-with-14-joint-labels-td-td-2000-td-td-images-plus-mat-file-labels-td-td-human-pose-estimation-td-td-2010-td-td-sup-id-cite-ref-153-class-reference-a-href-cite-note-153-153-a-sup-td-td-s-johnson-and-m-everingham-td-tr-tr-td-leeds-sports-pose-extended-training-td-td-articulated-human-pose-annotations-in-10000-natural-sports-images-from-flickr-td-td-14-joint-labels-via-crowdsourcing-td-td-10000-td-td-images-plus-mat-file-labels-td-td-human-pose-estimation-td-td-2011-td-td-sup-id-cite-ref-154-class-reference-a-href-cite-note-154-154-a-sup-td-td-s-johnson-and-m-everingham-td-tr-tr-td-mcq-dataset-td-td-6-different-real-multiple-choice-based-exams-735-answer-sheets-and-33540-answer-boxes-to-evaluate-computer-vision-techniques-and-systems-developed-for-multiple-choice-test-assessment-systems-td-td-none-td-td-735-answer-sheets-and-33540-answer-boxes-td-td-images-and-mat-file-labels-td-td-development-of-multiple-choice-test-assessment-systems-td-td-2017-td-td-sup-id-cite-ref-155-class-reference-a-href-cite-note-155-155-a-sup-sup-id-cite-ref-156-class-reference-a-href-cite-note-156-156-a-sup-td-td-afifi-m-et-al-td-tr-tr-td-surveillance-videos-td-td-real-surveillance-videos-cover-a-large-surveillance-time-7-days-with-24-hours-each-td-td-none-td-td-19-surveillance-videos-7-days-with-24-hours-each-td-td-videos-td-td-data-compression-td-td-2016-td-td-sup-id-cite-ref-157-class-reference-a-href-cite-note-157-157-a-sup-td-td-taj-eddin-i-a-t-f-et-al-td-tr-tr-td-lila-bc-td-td-labeled-information-library-of-alexandria-biology-and-conservation-labeled-images-that-support-machine-learning-research-around-ecology-and-environmental-science-td-td-none-td-td-10m-images-td-td-images-td-td-classification-td-td-2019-td-td-sup-id-cite-ref-tabaknorouzzadeh2018-158-0-class-reference-a-href-cite-note-tabaknorouzzadeh2018-158-158-a-sup-td-td-lila-working-group-td-tr-tr-td-can-we-see-photosynthesis-td-td-32-videos-for-eight-live-and-eight-dead-leaves-recorded-under-both-dc-and-ac-lighting-conditions-td-td-none-td-td-32-videos-td-td-videos-td-td-liveness-detection-of-plants-td-td-2017-td-td-sup-id-cite-ref-159-class-reference-a-href-cite-note-159-159-a-sup-td-td-taj-eddin-i-a-t-f-et-al-td-tr-tbody-table-h2-span-class-mw-headline-id-text-data-text-data-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-8-title-edit-section-text-data-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-datasets-consisting-primarily-of-text-for-tasks-such-as-a-href-wiki-natural-language-processing-title-natural-language-processing-natural-language-processing-a-a-href-wiki-sentiment-analysis-title-sentiment-analysis-sentiment-analysis-a-translation-and-a-href-wiki-cluster-analysis-title-cluster-analysis-cluster-analysis-a-p-h3-span-class-mw-headline-id-reviews-reviews-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-9-title-edit-section-reviews-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-amazon-reviews-td-td-us-product-reviews-from-a-href-wiki-amazon-com-class-mw-redirect-title-amazon-com-amazon-com-a-td-td-none-td-td-82m-td-td-text-td-td-classification-sentiment-analysis-td-td-2015-td-td-sup-id-cite-ref-160-class-reference-a-href-cite-note-160-160-a-sup-td-td-mcauley-et-al-td-tr-tr-td-opinrank-review-dataset-td-td-reviews-of-cars-and-hotels-from-a-href-wiki-edmunds-com-class-mw-redirect-title-edmunds-com-edmunds-com-a-and-a-href-wiki-tripadvisor-title-tripadvisor-tripadvisor-a-respectively-td-td-none-td-td-42230-259000-respectively-td-td-text-td-td-sentiment-analysis-clustering-td-td-2011-td-td-sup-id-cite-ref-161-class-reference-a-href-cite-note-161-161-a-sup-sup-id-cite-ref-162-class-reference-a-href-cite-note-162-162-a-sup-td-td-k-ganesan-et-al-td-tr-tr-td-movielens-td-td-22000000-ratings-and-580000-tags-applied-to-33000-movies-by-240000-users-td-td-none-td-td-22m-td-td-text-td-td-regression-clustering-classification-td-td-2016-td-td-sup-id-cite-ref-163-class-reference-a-href-cite-note-163-163-a-sup-td-td-a-href-wiki-grouplens-research-title-grouplens-research-grouplens-research-a-td-tr-tr-td-yahoo-music-user-ratings-of-musical-artists-td-td-over-10m-ratings-of-artists-by-yahoo-users-td-td-none-described-td-td-10m-td-td-text-td-td-clustering-regression-td-td-2004-td-td-sup-id-cite-ref-164-class-reference-a-href-cite-note-164-164-a-sup-sup-id-cite-ref-165-class-reference-a-href-cite-note-165-165-a-sup-td-td-a-href-wiki-yahoo-title-yahoo-yahoo-a-td-tr-tr-td-car-evaluation-data-set-td-td-car-properties-and-their-overall-acceptability-td-td-six-categorical-features-given-td-td-1728-td-td-text-td-td-classification-td-td-1997-td-td-sup-id-cite-ref-166-class-reference-a-href-cite-note-166-166-a-sup-sup-id-cite-ref-167-class-reference-a-href-cite-note-167-167-a-sup-td-td-m-bohanec-td-tr-tr-td-youtube-comedy-slam-preference-dataset-td-td-user-vote-data-for-pairs-of-videos-shown-on-youtube-users-voted-on-funnier-videos-td-td-video-metadata-given-td-td-1138562-td-td-text-td-td-classification-td-td-2012-td-td-sup-id-cite-ref-168-class-reference-a-href-cite-note-168-168-a-sup-sup-id-cite-ref-169-class-reference-a-href-cite-note-169-169-a-sup-td-td-google-td-tr-tr-td-skytrax-user-reviews-dataset-td-td-user-reviews-of-airlines-airports-seats-and-lounges-from-skytrax-td-td-ratings-are-fine-grain-and-include-many-aspects-of-airport-experience-td-td-41396-td-td-text-td-td-classification-regression-td-td-2015-td-td-sup-id-cite-ref-170-class-reference-a-href-cite-note-170-170-a-sup-td-td-q-nguyen-td-tr-tr-td-teaching-assistant-evaluation-dataset-td-td-teaching-assistant-reviews-td-td-features-of-each-instance-such-as-class-class-size-and-instructor-are-given-td-td-151-td-td-text-td-td-classification-td-td-1997-td-td-sup-id-cite-ref-171-class-reference-a-href-cite-note-171-171-a-sup-sup-id-cite-ref-172-class-reference-a-href-cite-note-172-172-a-sup-td-td-w-loh-et-al-td-tr-tbody-table-h3-span-class-mw-headline-id-news-articles-news-articles-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-10-title-edit-section-news-articles-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-nysk-dataset-td-td-english-news-articles-about-the-case-relating-to-allegations-of-sexual-assault-against-the-former-a-href-wiki-international-monetary-fund-title-international-monetary-fund-imf-a-director-a-href-wiki-dominique-strauss-kahn-title-dominique-strauss-kahn-dominique-strauss-kahn-a-td-td-filtered-and-presented-in-xml-format-td-td-10421-td-td-xml-text-td-td-sentiment-analysis-topic-extraction-td-td-2013-td-td-sup-id-cite-ref-173-class-reference-a-href-cite-note-173-173-a-sup-td-td-dermouche-m-et-al-td-tr-tr-td-the-reuters-corpus-volume-1-td-td-large-corpus-of-a-href-wiki-reuters-title-reuters-reuters-a-news-stories-in-english-td-td-fine-grain-categorization-and-topic-codes-td-td-810000-td-td-text-td-td-classification-clustering-a-href-wiki-automatic-summarization-title-automatic-summarization-summarization-a-td-td-2002-td-td-sup-id-cite-ref-174-class-reference-a-href-cite-note-174-174-a-sup-td-td-a-href-wiki-reuters-title-reuters-reuters-a-td-tr-tr-td-the-reuters-corpus-volume-2-td-td-large-corpus-of-a-href-wiki-reuters-title-reuters-reuters-a-news-stories-in-multiple-languages-td-td-fine-grain-categorization-and-topic-codes-td-td-487000-td-td-text-td-td-classification-clustering-summarization-td-td-2005-td-td-sup-id-cite-ref-175-class-reference-a-href-cite-note-175-175-a-sup-td-td-a-href-wiki-reuters-title-reuters-reuters-a-td-tr-tr-td-thomson-reuters-text-research-collection-td-td-large-corpus-of-news-stories-td-td-details-not-described-td-td-1800370-td-td-text-td-td-classification-clustering-summarization-td-td-2009-td-td-sup-id-cite-ref-176-class-reference-a-href-cite-note-176-176-a-sup-td-td-t-rose-et-al-td-tr-tr-td-saudi-newspapers-corpus-td-td-31030-arabic-newspaper-articles-td-td-metadata-extracted-td-td-31030-td-td-json-td-td-summarization-clustering-td-td-2015-td-td-sup-id-cite-ref-177-class-reference-a-href-cite-note-177-177-a-sup-td-td-m-alhagri-td-tr-tr-td-re3d-relationship-and-entity-extraction-evaluation-dataset-td-td-entity-and-relation-marked-data-from-various-news-and-government-sources-sponsored-by-dstl-td-td-filtered-categorisation-using-baleen-types-td-td-not-known-td-td-json-td-td-classification-entity-and-relation-recognition-td-td-2017-td-td-sup-id-cite-ref-178-class-reference-a-href-cite-note-178-178-a-sup-td-td-dstl-td-tr-tr-td-a-href-wiki-examiner-com-title-examiner-com-examiner-a-pseudo-news-corpus-td-td-clickbait-spam-crowd-sourced-headlines-from-2010-to-2015-td-td-publish-date-and-headlines-td-td-3089781-td-td-csv-td-td-clustering-events-sentiment-td-td-2017-td-td-sup-id-cite-ref-179-class-reference-a-href-cite-note-179-179-a-sup-td-td-r-kulkarni-td-tr-tr-td-a-href-wiki-australian-broadcasting-corporation-title-australian-broadcasting-corporation-abc-a-australia-news-corpus-td-td-entire-news-corpus-of-abc-australia-from-2003-to-2017-td-td-publish-date-and-headlines-td-td-1103664-td-td-csv-td-td-clustering-events-sentiment-td-td-2017-td-td-sup-id-cite-ref-180-class-reference-a-href-cite-note-180-180-a-sup-td-td-r-kulkarni-td-tr-tr-td-worldwide-news-aggregate-of-20k-a-href-wiki-web-feed-title-web-feed-feeds-a-td-td-one-week-snapshot-of-all-online-headlines-in-20-languages-td-td-publish-time-url-and-headlines-td-td-1398431-td-td-csv-td-td-clustering-events-language-detection-td-td-2017-td-td-sup-id-cite-ref-181-class-reference-a-href-cite-note-181-181-a-sup-td-td-r-kulkarni-td-tr-tr-td-a-href-wiki-reuters-title-reuters-reuters-a-news-wire-headline-td-td-11-years-of-timestamped-events-published-on-the-news-wire-td-td-publish-time-headline-text-td-td-16121310-td-td-csv-td-td-nlp-computational-linguistics-events-td-td-2018-td-td-sup-id-cite-ref-182-class-reference-a-href-cite-note-182-182-a-sup-td-td-r-kulkarni-td-tr-tr-td-a-href-wiki-the-irish-times-title-the-irish-times-the-irish-times-a-the-irish-times-irs-td-td-23-years-of-events-from-ireland-td-td-publish-time-headline-text-td-td-1425460-td-td-csv-td-td-nlp-computational-linguistics-events-td-td-2018-td-td-sup-id-cite-ref-183-class-reference-a-href-cite-note-183-183-a-sup-td-td-r-kulkarni-td-tr-tr-td-news-headlines-dataset-for-sarcasm-detection-td-td-high-quality-dataset-with-sarcastic-and-non-sarcastic-news-headlines-td-td-clean-normalized-text-td-td-26709-td-td-json-td-td-nlp-classification-linguistics-td-td-2018-td-td-sup-id-cite-ref-184-class-reference-a-href-cite-note-184-184-a-sup-td-td-rishabh-misra-td-tr-tbody-table-h3-span-class-mw-headline-id-messages-messages-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-11-title-edit-section-messages-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-style-width-100-class-wikitable-sortable-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-enron-email-dataset-td-td-emails-from-employees-at-a-href-wiki-enron-title-enron-enron-a-organized-into-folders-td-td-attachments-removed-invalid-email-addresses-converted-to-user-enron-com-or-no-address-enron-com-td-td-500000-td-td-text-td-td-a-href-wiki-social-network-analysis-title-social-network-analysis-network-analysis-a-sentiment-analysis-td-td-2004-2015-td-td-sup-id-cite-ref-185-class-reference-a-href-cite-note-185-185-a-sup-sup-id-cite-ref-186-class-reference-a-href-cite-note-186-186-a-sup-td-td-klimt-b-and-y-yang-td-tr-tr-td-ling-spam-dataset-td-td-corpus-containing-both-legitimate-and-a-href-wiki-email-spam-title-email-spam-spam-a-emails-td-td-four-version-of-the-corpus-involving-whether-or-not-a-a-href-wiki-lemmatisation-title-lemmatisation-lemmatiser-a-or-stop-list-was-enabled-td-td-td-td-text-td-td-classification-td-td-2000-td-td-sup-id-cite-ref-187-class-reference-a-href-cite-note-187-187-a-sup-sup-id-cite-ref-188-class-reference-a-href-cite-note-188-188-a-sup-td-td-androutsopoulos-j-et-al-td-tr-tr-td-sms-spam-collection-dataset-td-td-collected-sms-spam-messages-td-td-none-td-td-5574-td-td-text-td-td-classification-td-td-2011-td-td-sup-id-cite-ref-189-class-reference-a-href-cite-note-189-189-a-sup-sup-id-cite-ref-190-class-reference-a-href-cite-note-190-190-a-sup-td-td-t-almeida-et-al-td-tr-tr-td-twenty-newsgroups-dataset-td-td-messages-from-20-different-newsgroups-td-td-none-td-td-20000-td-td-text-td-td-natural-language-processing-td-td-1999-td-td-sup-id-cite-ref-191-class-reference-a-href-cite-note-191-191-a-sup-td-td-t-mitchell-et-al-td-tr-tr-td-spambase-dataset-td-td-spam-emails-td-td-many-text-features-extracted-td-td-4601-td-td-text-td-td-spam-detection-classification-td-td-1999-td-td-sup-id-cite-ref-192-class-reference-a-href-cite-note-192-192-a-sup-td-td-m-hopkins-et-al-td-tr-tbody-table-h3-span-class-mw-headline-id-twitter-and-tweets-twitter-and-tweets-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-12-title-edit-section-twitter-and-tweets-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-style-width-100-class-wikitable-sortable-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-movietweetings-td-td-movie-rating-dataset-based-on-public-and-well-structured-tweets-td-td-td-td-710000-td-td-text-td-td-classification-regression-td-td-2018-td-td-sup-id-cite-ref-193-class-reference-a-href-cite-note-193-193-a-sup-td-td-s-dooms-td-tr-tr-td-twitter100k-td-td-pairs-of-images-and-tweets-td-td-td-td-100000-td-td-text-and-images-td-td-cross-media-retrieval-td-td-2017-td-td-sup-id-cite-ref-194-class-reference-a-href-cite-note-194-194-a-sup-sup-id-cite-ref-195-class-reference-a-href-cite-note-195-195-a-sup-td-td-y-hu-et-al-td-tr-tr-td-sentiment140-td-td-tweet-data-from-2009-including-original-text-time-stamp-user-and-sentiment-td-td-classified-using-distant-supervision-from-presence-of-emoticon-in-tweet-td-td-1578627-td-td-tweets-comma-separated-values-td-td-sentiment-analysis-td-td-2009-td-td-sup-id-cite-ref-196-class-reference-a-href-cite-note-196-196-a-sup-sup-id-cite-ref-197-class-reference-a-href-cite-note-197-197-a-sup-td-td-a-go-et-al-td-tr-tr-td-asu-twitter-dataset-td-td-twitter-network-data-not-actual-tweets-shows-connections-between-a-large-number-of-users-td-td-none-td-td-11316811-users-85331846-connections-td-td-text-td-td-clustering-graph-analysis-td-td-2009-td-td-sup-id-cite-ref-198-class-reference-a-href-cite-note-198-198-a-sup-sup-id-cite-ref-199-class-reference-a-href-cite-note-199-199-a-sup-td-td-r-zafarani-et-al-td-tr-tr-td-snap-social-circles-twitter-database-td-td-large-twitter-network-data-td-td-node-features-circles-and-ego-networks-td-td-1768149-td-td-text-td-td-clustering-graph-analysis-td-td-2012-td-td-sup-id-cite-ref-200-class-reference-a-href-cite-note-200-200-a-sup-sup-id-cite-ref-201-class-reference-a-href-cite-note-201-201-a-sup-td-td-j-mcauley-et-al-td-tr-tr-td-twitter-dataset-for-arabic-sentiment-analysis-td-td-arabic-tweets-td-td-samples-hand-labeled-as-positive-or-negative-td-td-2000-td-td-text-td-td-classification-td-td-2014-td-td-sup-id-cite-ref-202-class-reference-a-href-cite-note-202-202-a-sup-sup-id-cite-ref-203-class-reference-a-href-cite-note-203-203-a-sup-td-td-n-abdulla-td-tr-tr-td-buzz-in-social-media-dataset-td-td-data-from-twitter-and-tom-s-hardware-this-dataset-focuses-on-specific-buzz-topics-being-discussed-on-those-sites-td-td-data-is-windowed-so-that-the-user-can-attempt-to-predict-the-events-leading-up-to-social-media-buzz-td-td-140000-td-td-text-td-td-regression-classification-td-td-2013-td-td-sup-id-cite-ref-204-class-reference-a-href-cite-note-204-204-a-sup-sup-id-cite-ref-205-class-reference-a-href-cite-note-205-205-a-sup-td-td-f-kawala-et-al-td-tr-tr-td-paraphrase-and-semantic-similarity-in-twitter-pit-td-td-this-dataset-focuses-on-whether-tweets-have-almost-same-meaning-information-or-not-manually-labeled-td-td-tokenization-part-of-speech-and-named-entity-tagging-td-td-18762-td-td-text-td-td-regression-classification-td-td-2015-td-td-sup-id-cite-ref-206-class-reference-a-href-cite-note-206-206-a-sup-sup-id-cite-ref-207-class-reference-a-href-cite-note-207-207-a-sup-td-td-xu-et-al-td-tr-tr-td-geoparse-twitter-benchmark-dataset-td-td-this-dataset-contains-tweets-during-different-news-events-in-different-countries-manually-labeled-location-mentions-td-td-location-annotations-added-to-json-metadata-td-td-6386-td-td-tweets-json-td-td-classification-information-extraction-td-td-2014-td-td-sup-id-cite-ref-208-class-reference-a-href-cite-note-208-208-a-sup-sup-id-cite-ref-209-class-reference-a-href-cite-note-209-209-a-sup-td-td-s-e-middleton-et-al-td-tr-tbody-table-h3-span-class-mw-headline-id-dialogues-dialogues-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-13-title-edit-section-dialogues-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-style-width-100-class-wikitable-sortable-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-nps-chat-corpus-td-td-posts-from-age-specific-online-chat-rooms-td-td-hand-privacy-masked-tagged-for-part-of-speech-and-dialogue-act-td-td-500000-td-td-xml-td-td-nlp-programming-linguistics-td-td-2007-td-td-sup-id-cite-ref-210-class-reference-a-href-cite-note-210-210-a-sup-td-td-forsyth-e-lin-j-martell-c-td-tr-tr-td-twitter-triple-corpus-td-td-a-b-a-triples-extracted-from-twitter-td-td-td-td-4232-td-td-text-td-td-nlp-td-td-2016-td-td-sup-id-cite-ref-211-class-reference-a-href-cite-note-211-211-a-sup-td-td-sordini-a-et-al-td-tr-tr-td-usenet-corpus-td-td-usenet-forum-postings-td-td-anonymized-e-mails-and-urls-omitted-documents-with-lengths-500-words-or-500000-words-or-that-were-90-english-td-td-7-billion-td-td-text-td-td-td-td-2011-td-td-sup-id-cite-ref-212-class-reference-a-href-cite-note-212-212-a-sup-td-td-shaoul-c-westbury-c-td-tr-tr-td-nus-sms-corpus-td-td-sms-messages-collected-between-two-users-with-timing-analysis-td-td-td-td-10000-td-td-xml-td-td-nlp-td-td-2011-td-td-sup-id-cite-ref-213-class-reference-a-href-cite-note-213-213-a-sup-td-td-kan-m-td-tr-tr-td-reddit-all-comments-corpus-td-td-all-reddit-comments-as-of-2015-td-td-td-td-1-7-billion-td-td-json-td-td-nlp-research-td-td-2015-td-td-sup-id-cite-ref-214-class-reference-a-href-cite-note-214-214-a-sup-td-td-stuck-in-the-matrix-td-tr-tr-td-ubuntu-dialogue-corpus-td-td-dialogues-extracted-from-ubuntu-chat-stream-on-irc-td-td-td-td-td-td-csv-td-td-dialogue-systems-research-td-td-2015-td-td-sup-id-cite-ref-215-class-reference-a-href-cite-note-215-215-a-sup-td-td-lowe-r-et-al-td-tr-tbody-table-h3-span-class-mw-headline-id-other-text-other-text-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-14-title-edit-section-other-text-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-style-width-100-class-wikitable-sortable-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-web-of-science-dataset-td-td-hierarchical-datasets-for-text-classification-td-td-none-td-td-46985-td-td-text-td-td-classification-p-categorization-p-td-td-2017-td-td-sup-id-cite-ref-kow2017-216-0-class-reference-a-href-cite-note-kow2017-216-216-a-sup-sup-id-cite-ref-kow2017wos-217-0-class-reference-a-href-cite-note-kow2017wos-217-217-a-sup-td-td-k-kowsari-et-al-td-tr-tr-td-legal-case-reports-td-td-a-href-wiki-federal-court-of-australia-title-federal-court-of-australia-federal-court-of-australia-a-cases-from-2006-to-2009-td-td-none-td-td-4000-td-td-text-td-td-summarization-p-citation-analysis-p-td-td-2012-td-td-sup-id-cite-ref-218-class-reference-a-href-cite-note-218-218-a-sup-sup-id-cite-ref-219-class-reference-a-href-cite-note-219-219-a-sup-td-td-f-galgani-et-al-td-tr-tr-td-blogger-authorship-corpus-td-td-blog-entries-of-19320-people-from-blogger-com-td-td-blogger-self-provided-gender-age-industry-and-astrological-sign-td-td-681288-td-td-text-td-td-sentiment-analysis-summarization-classification-td-td-2006-td-td-sup-id-cite-ref-220-class-reference-a-href-cite-note-220-220-a-sup-sup-id-cite-ref-221-class-reference-a-href-cite-note-221-221-a-sup-td-td-j-schler-et-al-td-tr-tr-td-social-structure-of-facebook-networks-td-td-large-dataset-of-the-social-structure-of-facebook-td-td-none-td-td-100-colleges-covered-td-td-text-td-td-network-analysis-clustering-td-td-2012-td-td-sup-id-cite-ref-222-class-reference-a-href-cite-note-222-222-a-sup-sup-id-cite-ref-223-class-reference-a-href-cite-note-223-223-a-sup-td-td-a-traud-et-al-td-tr-tr-td-dataset-for-the-machine-comprehension-of-text-td-td-stories-and-associated-questions-for-testing-comprehension-of-text-td-td-none-td-td-660-td-td-text-td-td-natural-language-processing-machine-comprehension-td-td-2013-td-td-sup-id-cite-ref-224-class-reference-a-href-cite-note-224-224-a-sup-sup-id-cite-ref-225-class-reference-a-href-cite-note-225-225-a-sup-td-td-m-richardson-et-al-td-tr-tr-td-the-penn-treebank-project-td-td-naturally-occurring-text-annotated-for-linguistic-structure-td-td-text-is-parsed-into-semantic-trees-td-td-1m-words-td-td-text-td-td-natural-language-processing-summarization-td-td-1995-td-td-sup-id-cite-ref-226-class-reference-a-href-cite-note-226-226-a-sup-sup-id-cite-ref-227-class-reference-a-href-cite-note-227-227-a-sup-td-td-m-marcus-et-al-td-tr-tr-td-dexter-dataset-td-td-task-given-is-to-determine-from-features-given-which-articles-are-about-corporate-acquisitions-td-td-features-extracted-include-word-stems-distractor-features-included-td-td-2600-td-td-text-td-td-classification-td-td-2008-td-td-sup-id-cite-ref-228-class-reference-a-href-cite-note-228-228-a-sup-td-td-a-href-wiki-reuters-title-reuters-reuters-a-td-tr-tr-td-google-books-n-grams-td-td-a-href-wiki-n-gram-title-n-gram-n-grams-a-from-a-very-large-corpus-of-books-td-td-none-td-td-2-2-tb-of-text-td-td-text-td-td-classification-clustering-regression-td-td-2011-td-td-sup-id-cite-ref-229-class-reference-a-href-cite-note-229-229-a-sup-sup-id-cite-ref-230-class-reference-a-href-cite-note-230-230-a-sup-td-td-google-td-tr-tr-td-personae-corpus-td-td-collected-for-experiments-in-authorship-attribution-and-personality-prediction-consists-of-145-dutch-language-essays-td-td-in-addition-to-normal-texts-syntactically-annotated-texts-are-given-td-td-145-td-td-text-td-td-classification-regression-td-td-2008-td-td-sup-id-cite-ref-231-class-reference-a-href-cite-note-231-231-a-sup-sup-id-cite-ref-232-class-reference-a-href-cite-note-232-232-a-sup-td-td-k-luyckx-et-al-td-tr-tr-td-cnae-9-dataset-td-td-categorization-task-for-free-text-descriptions-of-brazilian-companies-td-td-word-frequency-has-been-extracted-td-td-1080-td-td-text-td-td-classification-td-td-2012-td-td-sup-id-cite-ref-233-class-reference-a-href-cite-note-233-233-a-sup-sup-id-cite-ref-234-class-reference-a-href-cite-note-234-234-a-sup-td-td-p-ciarelli-et-al-td-tr-tr-td-sentiment-labeled-sentences-dataset-td-td-3000-sentiment-labeled-sentences-td-td-sentiment-of-each-sentence-has-been-hand-labeled-as-positive-or-negative-td-td-3000-td-td-text-td-td-classification-sentiment-analysis-td-td-2015-td-td-sup-id-cite-ref-235-class-reference-a-href-cite-note-235-235-a-sup-sup-id-cite-ref-236-class-reference-a-href-cite-note-236-236-a-sup-td-td-d-kotzias-td-tr-tr-td-blogfeedback-dataset-td-td-dataset-to-predict-the-number-of-comments-a-post-will-receive-based-on-features-of-that-post-td-td-many-features-of-each-post-extracted-td-td-60021-td-td-text-td-td-regression-td-td-2014-td-td-sup-id-cite-ref-237-class-reference-a-href-cite-note-237-237-a-sup-sup-id-cite-ref-238-class-reference-a-href-cite-note-238-238-a-sup-td-td-k-buza-td-tr-tr-td-stanford-natural-language-inference-snli-corpus-td-td-image-captions-matched-with-newly-constructed-sentences-to-form-entailment-contradiction-or-neutral-pairs-td-td-entailment-class-labels-syntactic-parsing-by-the-stanford-pcfg-parser-td-td-570000-td-td-text-td-td-natural-language-inference-recognizing-textual-entailment-td-td-2015-td-td-sup-id-cite-ref-239-class-reference-a-href-cite-note-239-239-a-sup-td-td-s-bowman-et-al-td-tr-tr-td-dsl-corpus-collection-dslcc-td-td-a-multilingual-collection-of-short-excerpts-of-journalistic-texts-in-similar-languages-and-dialects-td-td-none-td-td-294000-phrases-td-td-text-td-td-discriminating-between-similar-languages-td-td-2017-td-td-sup-id-cite-ref-240-class-reference-a-href-cite-note-240-240-a-sup-td-td-tan-liling-et-al-td-tr-tr-td-a-href-wiki-urban-dictionary-title-urban-dictionary-urban-dictionary-a-dataset-td-td-corpus-of-words-votes-and-definitions-td-td-user-names-anonymised-td-td-2606522-td-td-csv-td-td-nlp-machine-comprehension-td-td-2016-05-td-td-sup-id-cite-ref-241-class-reference-a-href-cite-note-241-241-a-sup-td-td-anonymous-td-tr-tr-td-t-rex-td-td-a-href-wiki-wikipedia-title-wikipedia-wikipedia-a-abstracts-aligned-with-a-href-wiki-wikidata-title-wikidata-wikidata-a-entities-td-td-alignment-of-wikidata-triples-with-wikipedia-abstracts-td-td-11m-aligned-triples-td-td-json-and-nif-a-rel-nofollow-class-external-autonumber-href-https-hadyelsahar-github-io-t-rex-1-a-td-td-nlp-relation-extraction-td-td-2018-td-td-sup-id-cite-ref-242-class-reference-a-href-cite-note-242-242-a-sup-td-td-h-elsahar-et-al-td-tr-tbody-table-h2-span-class-mw-headline-id-sound-data-sound-data-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-15-title-edit-section-sound-data-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-datasets-of-sounds-and-sound-features-p-h3-span-class-mw-headline-id-speech-speech-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-16-title-edit-section-speech-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-zero-resource-speech-challenge-2015-td-td-spontaneous-speech-english-read-speech-xitsonga-td-td-raw-wav-td-td-english-5h-12-speakers-xitsonga-2h30-24-speakers-td-td-sound-td-td-unsupervised-discovery-of-speech-features-subword-units-word-units-td-td-2015-td-td-sup-id-cite-ref-243-class-reference-a-href-cite-note-243-243-a-sup-sup-id-cite-ref-244-class-reference-a-href-cite-note-244-244-a-sup-td-td-versteegh-et-al-td-tr-tr-td-parkinson-speech-dataset-td-td-multiple-recordings-of-people-with-and-without-parkinson-s-disease-td-td-voice-features-extracted-disease-scored-by-physician-using-a-href-wiki-unified-parkinson-27s-disease-rating-scale-title-unified-parkinsons-disease-rating-scale-unified-parkinson-s-disease-rating-scale-a-td-td-1040-td-td-text-td-td-classification-regression-td-td-2013-td-td-sup-id-cite-ref-245-class-reference-a-href-cite-note-245-245-a-sup-sup-id-cite-ref-246-class-reference-a-href-cite-note-246-246-a-sup-td-td-b-e-sakar-et-al-td-tr-tr-td-spoken-arabic-digits-td-td-spoken-arabic-digits-from-44-male-and-44-female-td-td-time-series-of-a-href-wiki-mel-frequency-cepstrum-title-mel-frequency-cepstrum-mel-frequency-cepstrum-a-coefficients-td-td-8800-td-td-text-td-td-classification-td-td-2010-td-td-sup-id-cite-ref-2-247-0-class-reference-a-href-cite-note-2-247-247-a-sup-sup-id-cite-ref-248-class-reference-a-href-cite-note-248-248-a-sup-td-td-m-bedda-et-al-td-tr-tr-td-isolet-dataset-td-td-spoken-letter-names-td-td-features-extracted-from-sounds-td-td-7797-td-td-text-td-td-classification-td-td-1994-td-td-sup-id-cite-ref-249-class-reference-a-href-cite-note-249-249-a-sup-sup-id-cite-ref-250-class-reference-a-href-cite-note-250-250-a-sup-td-td-r-cole-et-al-td-tr-tr-td-japanese-vowels-dataset-td-td-nine-male-speakers-uttered-two-japanese-vowels-successively-td-td-applied-12-degree-linear-prediction-analysis-to-it-to-obtain-a-discrete-time-series-with-12-cepstrum-coefficients-td-td-640-td-td-text-td-td-classification-td-td-1999-td-td-sup-id-cite-ref-251-class-reference-a-href-cite-note-251-251-a-sup-sup-id-cite-ref-252-class-reference-a-href-cite-note-252-252-a-sup-td-td-m-kudo-et-al-td-tr-tr-td-parkinson-s-telemonitoring-dataset-td-td-multiple-recordings-of-people-with-and-without-parkinson-s-disease-td-td-sound-features-extracted-td-td-5875-td-td-text-td-td-classification-td-td-2009-td-td-sup-id-cite-ref-253-class-reference-a-href-cite-note-253-253-a-sup-sup-id-cite-ref-254-class-reference-a-href-cite-note-254-254-a-sup-td-td-a-tsanas-et-al-td-tr-tr-td-a-href-wiki-timit-title-timit-timit-a-td-td-recordings-of-630-speakers-of-eight-major-dialects-of-american-english-each-reading-ten-phonetically-rich-sentences-td-td-speech-is-lexically-and-phonemically-transcribed-td-td-6300-td-td-text-td-td-speech-recognition-classification-td-td-1986-td-td-sup-id-cite-ref-255-class-reference-a-href-cite-note-255-255-a-sup-sup-id-cite-ref-256-class-reference-a-href-cite-note-256-256-a-sup-td-td-j-garofolo-et-al-td-tr-tr-td-a-href-wiki-arabic-speech-corpus-title-arabic-speech-corpus-arabic-speech-corpus-a-td-td-a-single-speaker-a-href-wiki-modern-standard-arabic-title-modern-standard-arabic-modern-standard-arabic-a-msa-speech-corpus-with-phonetic-and-orthographic-transcripts-aligned-to-phoneme-level-td-td-speech-is-orthographically-and-phonetically-transcribed-with-stress-marks-td-td-1900-td-td-text-wav-td-td-speech-synthesis-speech-recognition-corpus-alignment-speech-therapy-education-td-td-2016-td-td-sup-id-cite-ref-halabi2016-257-0-class-reference-a-href-cite-note-halabi2016-257-257-a-sup-td-td-n-halabi-td-tr-tbody-table-h3-span-class-mw-headline-id-music-music-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-17-title-edit-section-music-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-geographical-original-of-music-data-set-td-td-audio-features-of-music-samples-from-different-locations-td-td-audio-features-extracted-using-marsyas-software-td-td-1059-td-td-text-td-td-geographical-classification-clustering-td-td-2014-td-td-sup-id-cite-ref-258-class-reference-a-href-cite-note-258-258-a-sup-sup-id-cite-ref-259-class-reference-a-href-cite-note-259-259-a-sup-td-td-f-zhou-et-al-td-tr-tr-td-million-song-dataset-td-td-audio-features-from-one-million-different-songs-td-td-audio-features-extracted-td-td-1m-td-td-text-td-td-classification-clustering-td-td-2011-td-td-sup-id-cite-ref-260-class-reference-a-href-cite-note-260-260-a-sup-sup-id-cite-ref-261-class-reference-a-href-cite-note-261-261-a-sup-td-td-t-bertin-mahieux-et-al-td-tr-tr-td-a-href-wiki-free-music-archive-title-free-music-archive-free-music-archive-a-td-td-audio-under-a-href-wiki-creative-commons-license-title-creative-commons-license-creative-commons-a-from-100k-songs-343-days-1tib-with-a-hierarchy-of-161-genres-metadata-user-data-free-form-text-td-td-raw-audio-and-audio-features-td-td-106574-td-td-text-mp3-td-td-classification-recommendation-td-td-2017-td-td-sup-id-cite-ref-262-class-reference-a-href-cite-note-262-262-a-sup-td-td-m-defferrard-et-al-td-tr-tr-td-bach-choral-harmony-dataset-td-td-bach-chorale-chords-td-td-audio-features-extracted-td-td-5665-td-td-text-td-td-classification-td-td-2014-td-td-sup-id-cite-ref-263-class-reference-a-href-cite-note-263-263-a-sup-sup-id-cite-ref-264-class-reference-a-href-cite-note-264-264-a-sup-td-td-d-radicioni-et-al-td-tr-tbody-table-h3-span-class-mw-headline-id-other-sounds-other-sounds-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-18-title-edit-section-other-sounds-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-style-width-100-class-wikitable-sortable-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-urbansound-td-td-labeled-sound-recordings-of-sounds-like-air-conditioners-car-horns-and-children-playing-td-td-sorted-into-folders-by-class-of-events-as-well-as-metadata-in-a-json-file-and-annotations-in-a-csv-file-td-td-1059-td-td-sound-p-a-href-wiki-wav-title-wav-wav-a-p-td-td-classification-td-td-2014-td-td-sup-id-cite-ref-265-class-reference-a-href-cite-note-265-265-a-sup-sup-id-cite-ref-266-class-reference-a-href-cite-note-266-266-a-sup-td-td-j-salamon-et-al-td-tr-tr-td-audioset-td-td-10-second-sound-snippets-from-youtube-videos-and-an-ontology-of-over-500-labels-td-td-128-d-pca-d-vgg-ish-features-every-1-second-td-td-2084320-td-td-text-csv-and-tensorflow-record-files-td-td-classification-td-td-2017-td-td-sup-id-cite-ref-267-class-reference-a-href-cite-note-267-267-a-sup-td-td-j-gemmeke-et-al-google-td-tr-tr-td-bird-audio-detection-challenge-td-td-audio-from-environmental-monitoring-stations-plus-crowdsourced-recordings-td-td-td-td-17000-td-td-td-td-classification-td-td-2016-2018-td-td-sup-id-cite-ref-268-class-reference-a-href-cite-note-268-268-a-sup-sup-id-cite-ref-269-class-reference-a-href-cite-note-269-269-a-sup-td-td-a-href-wiki-queen-mary-university-class-mw-redirect-title-queen-mary-university-queen-mary-university-a-and-a-href-wiki-ieee-signal-processing-society-title-ieee-signal-processing-society-ieee-signal-processing-society-a-td-tr-tbody-table-h2-span-class-mw-headline-id-signal-data-signal-data-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-19-title-edit-section-signal-data-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-datasets-containing-electric-signal-information-requiring-some-sort-of-a-href-wiki-signal-processing-title-signal-processing-signal-processing-a-for-further-analysis-p-h3-span-class-mw-headline-id-electrical-electrical-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-20-title-edit-section-electrical-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-style-width-100-class-wikitable-sortable-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-witty-worm-dataset-td-td-dataset-detailing-the-spread-of-the-a-href-wiki-witty-computer-worm-title-witty-computer-worm-witty-worm-a-and-the-infected-computers-td-td-split-into-a-publicly-available-set-and-a-restricted-set-containing-more-sensitive-information-like-ip-and-udp-headers-td-td-55909-ip-addresses-td-td-text-td-td-classification-td-td-2004-td-td-sup-id-cite-ref-270-class-reference-a-href-cite-note-270-270-a-sup-sup-id-cite-ref-271-class-reference-a-href-cite-note-271-271-a-sup-td-td-center-for-applied-internet-data-analysis-td-tr-tr-td-cuff-less-blood-pressure-estimation-dataset-td-td-cleaned-vital-signals-from-human-patients-which-can-be-used-to-estimate-blood-pressure-td-td-125-hz-vital-signs-have-been-cleaned-td-td-12000-td-td-text-td-td-classification-regression-td-td-2015-td-td-sup-id-cite-ref-272-class-reference-a-href-cite-note-272-272-a-sup-sup-id-cite-ref-273-class-reference-a-href-cite-note-273-273-a-sup-td-td-m-kachuee-et-al-td-tr-tr-td-gas-sensor-array-drift-dataset-td-td-measurements-from-16-chemical-sensors-utilized-in-simulations-for-drift-compensation-td-td-extensive-number-of-features-given-td-td-13910-td-td-text-td-td-classification-td-td-2012-td-td-sup-id-cite-ref-274-class-reference-a-href-cite-note-274-274-a-sup-sup-id-cite-ref-275-class-reference-a-href-cite-note-275-275-a-sup-td-td-a-vergara-td-tr-tr-td-servo-dataset-td-td-data-covering-the-nonlinear-relationships-observed-in-a-servo-amplifier-circuit-td-td-levels-of-various-components-as-a-function-of-other-components-are-given-td-td-167-td-td-text-td-td-regression-td-td-1993-td-td-sup-id-cite-ref-276-class-reference-a-href-cite-note-276-276-a-sup-sup-id-cite-ref-277-class-reference-a-href-cite-note-277-277-a-sup-td-td-k-ullrich-td-tr-tr-td-ujiindoorloc-mag-dataset-td-td-indoor-localization-database-to-test-indoor-positioning-systems-data-is-magnetic-field-based-td-td-train-and-test-splits-given-td-td-40000-td-td-text-td-td-classification-regression-clustering-td-td-2015-td-td-sup-id-cite-ref-278-class-reference-a-href-cite-note-278-278-a-sup-sup-id-cite-ref-279-class-reference-a-href-cite-note-279-279-a-sup-td-td-d-rambla-et-al-td-tr-tr-td-sensorless-drive-diagnosis-dataset-td-td-electrical-signals-from-motors-with-defective-components-td-td-statistical-features-extracted-td-td-58508-td-td-text-td-td-classification-td-td-2015-td-td-sup-id-cite-ref-280-class-reference-a-href-cite-note-280-280-a-sup-sup-id-cite-ref-281-class-reference-a-href-cite-note-281-281-a-sup-td-td-m-bator-td-tr-tbody-table-h3-span-class-mw-headline-id-motion-tracking-motion-tracking-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-21-title-edit-section-motion-tracking-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-wearable-computing-classification-of-body-postures-and-movements-puc-rio-td-td-people-performing-five-standard-actions-while-wearing-motion-tackers-td-td-none-td-td-165632-td-td-text-td-td-classification-td-td-2013-td-td-sup-id-cite-ref-282-class-reference-a-href-cite-note-282-282-a-sup-sup-id-cite-ref-283-class-reference-a-href-cite-note-283-283-a-sup-td-td-a-href-wiki-pontifical-catholic-university-of-rio-de-janeiro-title-pontifical-catholic-university-of-rio-de-janeiro-pontifical-catholic-university-of-rio-de-janeiro-a-td-tr-tr-td-gesture-phase-segmentation-dataset-td-td-features-extracted-from-video-of-people-doing-various-gestures-td-td-features-extracted-aim-at-studying-gesture-phase-segmentation-td-td-9900-td-td-text-td-td-classification-clustering-td-td-2014-td-td-sup-id-cite-ref-284-class-reference-a-href-cite-note-284-284-a-sup-sup-id-cite-ref-285-class-reference-a-href-cite-note-285-285-a-sup-td-td-r-madeo-et-a-td-tr-tr-td-vicon-physical-action-data-set-dataset-td-td-10-normal-and-10-aggressive-physical-actions-that-measure-the-human-activity-tracked-by-a-3d-tracker-td-td-many-parameters-recorded-by-3d-tracker-td-td-3000-td-td-text-td-td-classification-td-td-2011-td-td-sup-id-cite-ref-286-class-reference-a-href-cite-note-286-286-a-sup-sup-id-cite-ref-287-class-reference-a-href-cite-note-287-287-a-sup-td-td-t-theodoridis-td-tr-tr-td-daily-and-sports-activities-dataset-td-td-motor-sensor-data-for-19-daily-and-sports-activities-td-td-many-sensors-given-no-preprocessing-done-on-signals-td-td-9120-td-td-text-td-td-classification-td-td-2013-td-td-sup-id-cite-ref-288-class-reference-a-href-cite-note-288-288-a-sup-sup-id-cite-ref-289-class-reference-a-href-cite-note-289-289-a-sup-td-td-b-barshan-et-al-td-tr-tr-td-human-activity-recognition-using-smartphones-dataset-td-td-gyroscope-and-accelerometer-data-from-people-wearing-smartphones-and-performing-normal-actions-td-td-actions-performed-are-labeled-all-signals-preprocessed-for-noise-td-td-10299-td-td-text-td-td-classification-td-td-2012-td-td-sup-id-cite-ref-290-class-reference-a-href-cite-note-290-290-a-sup-sup-id-cite-ref-291-class-reference-a-href-cite-note-291-291-a-sup-td-td-j-reyes-ortiz-et-al-td-tr-tr-td-australian-sign-language-signs-td-td-australian-sign-language-signs-captured-by-motion-tracking-gloves-td-td-none-td-td-2565-td-td-text-td-td-classification-td-td-2002-td-td-sup-id-cite-ref-292-class-reference-a-href-cite-note-292-292-a-sup-sup-id-cite-ref-293-class-reference-a-href-cite-note-293-293-a-sup-td-td-m-kadous-td-tr-tr-td-weight-lifting-exercises-monitored-with-inertial-measurement-units-td-td-five-variations-of-the-biceps-curl-exercise-monitored-with-imus-td-td-some-statistics-calculated-from-raw-data-td-td-39242-td-td-text-td-td-classification-td-td-2013-td-td-sup-id-cite-ref-294-class-reference-a-href-cite-note-294-294-a-sup-sup-id-cite-ref-295-class-reference-a-href-cite-note-295-295-a-sup-td-td-w-ugulino-et-al-td-tr-tr-td-semg-for-basic-hand-movements-dataset-td-td-two-databases-of-surface-electromyographic-signals-of-6-hand-movements-td-td-none-td-td-3000-td-td-text-td-td-classification-td-td-2014-td-td-sup-id-cite-ref-296-class-reference-a-href-cite-note-296-296-a-sup-sup-id-cite-ref-andrianesis-konstantinos-2015-297-0-class-reference-a-href-cite-note-andrianesis-konstantinos-2015-297-297-a-sup-td-td-c-sapsanis-et-al-td-tr-tr-td-realdisp-activity-recognition-dataset-td-td-evaluate-techniques-dealing-with-the-effects-of-sensor-displacement-in-wearable-activity-recognition-td-td-none-td-td-1419-td-td-text-td-td-classification-td-td-2014-td-td-sup-id-cite-ref-andrianesis-konstantinos-2015-297-1-class-reference-a-href-cite-note-andrianesis-konstantinos-2015-297-297-a-sup-sup-id-cite-ref-298-class-reference-a-href-cite-note-298-298-a-sup-td-td-o-banos-et-al-td-tr-tr-td-heterogeneity-activity-recognition-dataset-td-td-data-from-multiple-different-smart-devices-for-humans-performing-various-activities-td-td-none-td-td-43930257-td-td-text-td-td-classification-clustering-td-td-2015-td-td-sup-id-cite-ref-299-class-reference-a-href-cite-note-299-299-a-sup-sup-id-cite-ref-300-class-reference-a-href-cite-note-300-300-a-sup-td-td-a-stisen-et-al-td-tr-tr-td-indoor-user-movement-prediction-from-rss-data-td-td-temporal-wireless-network-data-that-can-be-used-to-track-the-movement-of-people-in-an-office-td-td-none-td-td-13197-td-td-text-td-td-classification-td-td-2016-td-td-sup-id-cite-ref-301-class-reference-a-href-cite-note-301-301-a-sup-sup-id-cite-ref-302-class-reference-a-href-cite-note-302-302-a-sup-td-td-d-bacciu-td-tr-tr-td-pamap2-physical-activity-monitoring-dataset-td-td-18-different-types-of-physical-activities-performed-by-9-subjects-wearing-3-imus-td-td-none-td-td-3850505-td-td-text-td-td-classification-td-td-2012-td-td-sup-id-cite-ref-303-class-reference-a-href-cite-note-303-303-a-sup-td-td-a-reiss-td-tr-tr-td-opportunity-activity-recognition-dataset-td-td-human-activity-recognition-from-wearable-object-and-ambient-sensors-is-a-dataset-devised-to-benchmark-human-activity-recognition-algorithms-td-td-none-td-td-2551-td-td-text-td-td-classification-td-td-2012-td-td-sup-id-cite-ref-304-class-reference-a-href-cite-note-304-304-a-sup-sup-id-cite-ref-305-class-reference-a-href-cite-note-305-305-a-sup-td-td-d-roggen-et-al-td-tr-tr-td-real-world-activity-recognition-dataset-td-td-human-activity-recognition-from-wearable-devices-distinguishes-between-seven-on-body-device-positions-and-comprises-six-different-kinds-of-sensors-td-td-none-td-td-3150000-per-sensor-td-td-text-td-td-classification-td-td-2016-td-td-sup-id-cite-ref-306-class-reference-a-href-cite-note-306-306-a-sup-td-td-t-sztyler-et-al-td-tr-tr-td-toronto-rehab-stroke-pose-dataset-td-td-3d-human-pose-estimates-kinect-of-stroke-patients-and-healthy-participants-performing-a-set-of-tasks-using-a-stroke-rehabilitation-robot-td-td-none-td-td-10-healthy-person-and-9-stroke-survivors-3500-6000-frames-per-person-td-td-csv-td-td-classification-td-td-2017-td-td-sup-id-cite-ref-307-class-reference-a-href-cite-note-307-307-a-sup-sup-id-cite-ref-308-class-reference-a-href-cite-note-308-308-a-sup-sup-id-cite-ref-309-class-reference-a-href-cite-note-309-309-a-sup-td-td-e-dolatabadi-et-al-td-tr-tbody-table-h3-span-class-mw-headline-id-other-signals-other-signals-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-22-title-edit-section-other-signals-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-wine-dataset-td-td-chemical-analysis-of-wines-grown-in-the-same-region-in-italy-but-derived-from-three-different-cultivars-td-td-13-properties-of-each-wine-are-given-td-td-178-td-td-text-td-td-classification-regression-td-td-1991-td-td-sup-id-cite-ref-310-class-reference-a-href-cite-note-310-310-a-sup-sup-id-cite-ref-311-class-reference-a-href-cite-note-311-311-a-sup-td-td-m-forina-et-al-td-tr-tr-td-combined-cycle-power-plant-data-set-td-td-data-from-various-sensors-within-a-power-plant-running-for-6-years-td-td-none-td-td-9568-td-td-text-td-td-regression-td-td-2014-td-td-sup-id-cite-ref-312-class-reference-a-href-cite-note-312-312-a-sup-sup-id-cite-ref-313-class-reference-a-href-cite-note-313-313-a-sup-td-td-p-tufekci-et-al-td-tr-tbody-table-h2-span-class-mw-headline-id-physical-data-physical-data-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-23-title-edit-section-physical-data-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-datasets-from-physical-systems-p-h3-span-class-mw-headline-id-high-energy-physics-high-energy-physics-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-24-title-edit-section-high-energy-physics-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-higgs-dataset-td-td-monte-carlo-simulations-of-particle-accelerator-collisions-td-td-28-features-of-each-collision-are-given-td-td-11m-td-td-text-td-td-classification-td-td-2014-td-td-sup-id-cite-ref-314-class-reference-a-href-cite-note-314-314-a-sup-sup-id-cite-ref-8-315-0-class-reference-a-href-cite-note-8-315-315-a-sup-sup-id-cite-ref-9-316-0-class-reference-a-href-cite-note-9-316-316-a-sup-td-td-d-whiteson-td-tr-tr-td-hepmass-dataset-td-td-monte-carlo-simulations-of-particle-accelerator-collisions-goal-is-to-separate-the-signal-from-noise-td-td-28-features-of-each-collision-are-given-td-td-10500000-td-td-text-td-td-classification-td-td-2016-td-td-sup-id-cite-ref-8-315-1-class-reference-a-href-cite-note-8-315-315-a-sup-sup-id-cite-ref-9-316-1-class-reference-a-href-cite-note-9-316-316-a-sup-sup-id-cite-ref-317-class-reference-a-href-cite-note-317-317-a-sup-td-td-d-whiteson-td-tr-tbody-table-h3-span-class-mw-headline-id-systems-systems-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-25-title-edit-section-systems-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-yacht-hydrodynamics-dataset-td-td-yacht-performance-based-on-dimensions-td-td-six-features-are-given-for-each-yacht-td-td-308-td-td-text-td-td-regression-td-td-2013-td-td-sup-id-cite-ref-318-class-reference-a-href-cite-note-318-318-a-sup-sup-id-cite-ref-319-class-reference-a-href-cite-note-319-319-a-sup-td-td-r-lopez-td-tr-tr-td-robot-execution-failures-dataset-td-td-5-data-sets-that-center-around-robotic-failure-to-execute-common-tasks-td-td-integer-valued-features-such-as-torque-and-other-sensor-measurements-td-td-463-td-td-text-td-td-classification-td-td-1999-td-td-sup-id-cite-ref-320-class-reference-a-href-cite-note-320-320-a-sup-td-td-l-seabra-et-al-td-tr-tr-td-pittsburgh-bridges-dataset-td-td-design-description-is-given-in-terms-of-several-properties-of-various-bridges-td-td-various-bridge-features-are-given-td-td-108-td-td-text-td-td-classification-td-td-1990-td-td-sup-id-cite-ref-321-class-reference-a-href-cite-note-321-321-a-sup-sup-id-cite-ref-322-class-reference-a-href-cite-note-322-322-a-sup-td-td-y-reich-et-al-td-tr-tr-td-automobile-dataset-td-td-data-about-automobiles-their-insurance-risk-and-their-normalized-losses-td-td-car-features-extracted-td-td-205-td-td-text-td-td-regression-td-td-1987-td-td-sup-id-cite-ref-323-class-reference-a-href-cite-note-323-323-a-sup-sup-id-cite-ref-324-class-reference-a-href-cite-note-324-324-a-sup-td-td-j-schimmer-et-al-td-tr-tr-td-auto-mpg-dataset-td-td-mpg-data-for-cars-td-td-eight-features-of-each-car-given-td-td-398-td-td-text-td-td-regression-td-td-1993-td-td-sup-id-cite-ref-325-class-reference-a-href-cite-note-325-325-a-sup-td-td-a-href-wiki-carnegie-mellon-university-title-carnegie-mellon-university-carnegie-mellon-university-a-td-tr-tr-td-energy-efficiency-dataset-td-td-heating-and-cooling-requirements-given-as-a-function-of-building-parameters-td-td-building-parameters-given-td-td-768-td-td-text-td-td-classification-regression-td-td-2012-td-td-sup-id-cite-ref-326-class-reference-a-href-cite-note-326-326-a-sup-sup-id-cite-ref-327-class-reference-a-href-cite-note-327-327-a-sup-td-td-a-xifara-et-al-td-tr-tr-td-airfoil-self-noise-dataset-td-td-a-series-of-aerodynamic-and-acoustic-tests-of-two-and-three-dimensional-airfoil-blade-sections-td-td-data-about-frequency-angle-of-attack-etc-are-given-td-td-1503-td-td-text-td-td-regression-td-td-2014-td-td-sup-id-cite-ref-328-class-reference-a-href-cite-note-328-328-a-sup-td-td-r-lopez-td-tr-tr-td-challenger-usa-space-shuttle-o-ring-dataset-td-td-attempt-to-predict-o-ring-problems-given-past-challenger-data-td-td-several-features-of-each-flight-such-as-launch-temperature-are-given-td-td-23-td-td-text-td-td-regression-td-td-1993-td-td-sup-id-cite-ref-329-class-reference-a-href-cite-note-329-329-a-sup-sup-id-cite-ref-330-class-reference-a-href-cite-note-330-330-a-sup-td-td-d-draper-et-al-td-tr-tr-td-statlog-shuttle-dataset-td-td-nasa-space-shuttle-datasets-td-td-nine-features-given-td-td-58000-td-td-text-td-td-classification-td-td-2002-td-td-sup-id-cite-ref-331-class-reference-a-href-cite-note-331-331-a-sup-td-td-a-href-wiki-nasa-title-nasa-nasa-a-td-tr-tbody-table-h3-span-class-mw-headline-id-astronomy-astronomy-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-26-title-edit-section-astronomy-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-volcanoes-on-venus-jartool-experiment-dataset-td-td-venus-images-returned-by-the-magellan-spacecraft-td-td-images-are-labeled-by-humans-td-td-not-given-td-td-images-td-td-classification-td-td-1991-td-td-sup-id-cite-ref-332-class-reference-a-href-cite-note-332-332-a-sup-sup-id-cite-ref-10-333-0-class-reference-a-href-cite-note-10-333-333-a-sup-td-td-m-burl-td-tr-tr-td-magic-gamma-telescope-dataset-td-td-monte-carlo-generated-high-energy-gamma-particle-events-td-td-numerous-features-extracted-from-the-simulations-td-td-19020-td-td-text-td-td-classification-td-td-2007-td-td-sup-id-cite-ref-10-333-1-class-reference-a-href-cite-note-10-333-333-a-sup-sup-id-cite-ref-334-class-reference-a-href-cite-note-334-334-a-sup-td-td-r-bock-td-tr-tr-td-solar-flare-dataset-td-td-measurements-of-the-number-of-certain-types-of-solar-flare-events-occurring-in-a-24-hour-period-td-td-many-solar-flare-specific-features-are-given-td-td-1389-td-td-text-td-td-regression-classification-td-td-1989-td-td-sup-id-cite-ref-335-class-reference-a-href-cite-note-335-335-a-sup-td-td-g-bradshaw-td-tr-tbody-table-h3-span-class-mw-headline-id-earth-science-earth-science-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-27-title-edit-section-earth-science-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-volcanoes-of-the-world-td-td-volcanic-eruption-data-for-all-known-volcanic-events-on-earth-td-td-details-such-as-region-subregion-tectonic-setting-dominant-rock-type-are-given-td-td-1535-td-td-text-td-td-regression-classification-td-td-2013-td-td-sup-id-cite-ref-336-class-reference-a-href-cite-note-336-336-a-sup-td-td-e-venzke-et-al-td-tr-tr-td-seismic-bumps-dataset-td-td-seismic-activities-from-a-coal-mine-td-td-seismic-activity-was-classified-as-hazardous-or-not-td-td-2584-td-td-text-td-td-classification-td-td-2013-td-td-sup-id-cite-ref-337-class-reference-a-href-cite-note-337-337-a-sup-sup-id-cite-ref-338-class-reference-a-href-cite-note-338-338-a-sup-td-td-m-sikora-et-al-td-tr-tbody-table-h3-span-class-mw-headline-id-other-physical-other-physical-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-28-title-edit-section-other-physical-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-concrete-compressive-strength-dataset-td-td-dataset-of-concrete-properties-and-compressive-strength-td-td-nine-features-are-given-for-each-sample-td-td-1030-td-td-text-td-td-regression-td-td-2007-td-td-sup-id-cite-ref-339-class-reference-a-href-cite-note-339-339-a-sup-sup-id-cite-ref-340-class-reference-a-href-cite-note-340-340-a-sup-td-td-i-yeh-td-tr-tr-td-concrete-slump-test-dataset-td-td-concrete-slump-flow-given-in-terms-of-properties-td-td-features-of-concrete-given-such-as-fly-ash-water-etc-td-td-103-td-td-text-td-td-regression-td-td-2009-td-td-sup-id-cite-ref-341-class-reference-a-href-cite-note-341-341-a-sup-sup-id-cite-ref-342-class-reference-a-href-cite-note-342-342-a-sup-td-td-i-yeh-td-tr-tr-td-musk-dataset-td-td-predict-if-a-molecule-given-the-features-will-be-a-musk-or-a-non-musk-td-td-168-features-given-for-each-molecule-td-td-6598-td-td-text-td-td-classification-td-td-1994-td-td-sup-id-cite-ref-343-class-reference-a-href-cite-note-343-343-a-sup-td-td-arris-pharmaceutical-corp-td-tr-tr-td-steel-plates-faults-dataset-td-td-steel-plates-of-7-different-types-td-td-27-features-given-for-each-sample-td-td-1941-td-td-text-td-td-classification-td-td-2010-td-td-sup-id-cite-ref-344-class-reference-a-href-cite-note-344-344-a-sup-td-td-semeion-research-center-td-tr-tbody-table-h2-span-class-mw-headline-id-biological-data-biological-data-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-29-title-edit-section-biological-data-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-datasets-from-biological-systems-p-h3-span-class-mw-headline-id-human-human-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-30-title-edit-section-human-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-eeg-database-td-td-study-to-examine-eeg-correlates-of-genetic-predisposition-to-alcoholism-td-td-measurements-from-64-electrodes-placed-on-the-scalp-sampled-at-256-hz-3-9-ms-epoch-for-1-second-td-td-122-td-td-text-td-td-classification-td-td-1999-td-td-sup-id-cite-ref-3-345-0-class-reference-a-href-cite-note-3-345-345-a-sup-td-td-h-begleiter-td-tr-tr-td-p300-interface-dataset-td-td-data-from-nine-subjects-collected-using-p300-based-brain-computer-interface-for-disabled-subjects-td-td-split-into-four-sessions-for-each-subject-a-href-wiki-matlab-title-matlab-matlab-a-code-given-td-td-1224-td-td-text-td-td-classification-td-td-2008-td-td-sup-id-cite-ref-346-class-reference-a-href-cite-note-346-346-a-sup-sup-id-cite-ref-347-class-reference-a-href-cite-note-347-347-a-sup-td-td-u-hoffman-et-al-td-tr-tr-td-heart-disease-data-set-td-td-attributed-of-patients-with-and-without-heart-disease-td-td-75-attributes-given-for-each-patient-with-some-missing-values-td-td-303-td-td-text-td-td-classification-td-td-1988-td-td-sup-id-cite-ref-348-class-reference-a-href-cite-note-348-348-a-sup-sup-id-cite-ref-349-class-reference-a-href-cite-note-349-349-a-sup-td-td-a-janosi-et-al-td-tr-tr-td-breast-cancer-wisconsin-diagnostic-dataset-td-td-dataset-of-features-of-breast-masses-diagnoses-by-physician-is-given-td-td-10-features-for-each-sample-are-given-td-td-569-td-td-text-td-td-classification-td-td-1995-td-td-sup-id-cite-ref-350-class-reference-a-href-cite-note-350-350-a-sup-sup-id-cite-ref-351-class-reference-a-href-cite-note-351-351-a-sup-td-td-w-wolberg-et-al-td-tr-tr-td-national-survey-on-drug-use-and-health-td-td-large-scale-survey-on-health-and-drug-use-in-the-united-states-td-td-none-td-td-55268-td-td-text-td-td-classification-regression-td-td-2012-td-td-sup-id-cite-ref-352-class-reference-a-href-cite-note-352-352-a-sup-td-td-a-href-wiki-united-states-department-of-health-and-human-services-title-united-states-department-of-health-and-human-services-united-states-department-of-health-and-human-services-a-td-tr-tr-td-lung-cancer-dataset-td-td-lung-cancer-dataset-without-attribute-definitions-td-td-56-features-are-given-for-each-case-td-td-32-td-td-text-td-td-classification-td-td-1992-td-td-sup-id-cite-ref-353-class-reference-a-href-cite-note-353-353-a-sup-sup-id-cite-ref-jinyan-2003-354-0-class-reference-a-href-cite-note-jinyan-2003-354-354-a-sup-td-td-z-hong-et-al-td-tr-tr-td-arrhythmia-dataset-td-td-data-for-a-group-of-patients-of-which-some-have-cardiac-arrhythmia-td-td-276-features-for-each-instance-td-td-452-td-td-text-td-td-classification-td-td-1998-td-td-sup-id-cite-ref-355-class-reference-a-href-cite-note-355-355-a-sup-sup-id-cite-ref-356-class-reference-a-href-cite-note-356-356-a-sup-td-td-h-altay-et-al-td-tr-tr-td-diabetes-130-us-hospitals-for-years-1999-2008-dataset-td-td-9-years-of-readmission-data-across-130-us-hospitals-for-patients-with-diabetes-td-td-many-features-of-each-readmission-are-given-td-td-100000-td-td-text-td-td-classification-clustering-td-td-2014-td-td-sup-id-cite-ref-357-class-reference-a-href-cite-note-357-357-a-sup-sup-id-cite-ref-358-class-reference-a-href-cite-note-358-358-a-sup-td-td-j-clore-et-al-td-tr-tr-td-diabetic-retinopathy-debrecen-dataset-td-td-features-extracted-from-images-of-eyes-with-and-without-diabetic-retinopathy-td-td-features-extracted-and-conditions-diagnosed-td-td-1151-td-td-text-td-td-classification-td-td-2014-td-td-sup-id-cite-ref-359-class-reference-a-href-cite-note-359-359-a-sup-sup-id-cite-ref-360-class-reference-a-href-cite-note-360-360-a-sup-td-td-b-antal-et-al-td-tr-tr-td-diabetic-retinopathy-messidor-dataset-td-td-methods-to-evaluate-segmentation-and-indexing-techniques-in-the-field-of-retinal-ophthalmology-messidor-td-td-features-retinopathy-grade-and-risk-of-macular-edema-td-td-1200-td-td-images-text-td-td-classification-segmentation-td-td-2008-td-td-sup-id-cite-ref-361-class-reference-a-href-cite-note-361-361-a-sup-sup-id-cite-ref-362-class-reference-a-href-cite-note-362-362-a-sup-td-td-messidor-project-td-tr-tr-td-liver-disorders-dataset-td-td-data-for-people-with-liver-disorders-td-td-seven-biological-features-given-for-each-patient-td-td-345-td-td-text-td-td-classification-td-td-1990-td-td-sup-id-cite-ref-363-class-reference-a-href-cite-note-363-363-a-sup-sup-id-cite-ref-364-class-reference-a-href-cite-note-364-364-a-sup-td-td-bupa-medical-research-ltd-td-tr-tr-td-thyroid-disease-dataset-td-td-10-databases-of-thyroid-disease-patient-data-td-td-none-td-td-7200-td-td-text-td-td-classification-td-td-1987-td-td-sup-id-cite-ref-365-class-reference-a-href-cite-note-365-365-a-sup-sup-id-cite-ref-zhou-zhi-hua-2004-366-0-class-reference-a-href-cite-note-zhou-zhi-hua-2004-366-366-a-sup-td-td-r-quinlan-td-tr-tr-td-mesothelioma-dataset-td-td-mesothelioma-patient-data-td-td-large-number-of-features-including-asbestos-exposure-are-given-td-td-324-td-td-text-td-td-classification-td-td-2016-td-td-sup-id-cite-ref-367-class-reference-a-href-cite-note-367-367-a-sup-sup-id-cite-ref-368-class-reference-a-href-cite-note-368-368-a-sup-td-td-a-tanrikulu-et-al-td-tr-tr-td-parkinson-s-vision-based-pose-estimation-dataset-td-td-2d-human-pose-estimates-of-parkinson-s-patients-performing-a-variety-of-tasks-td-td-camera-shake-has-been-removed-from-trajectories-td-td-134-td-td-text-td-td-classification-regression-td-td-2017-td-td-sup-id-cite-ref-369-class-reference-a-href-cite-note-369-369-a-sup-sup-id-cite-ref-370-class-reference-a-href-cite-note-370-370-a-sup-sup-id-cite-ref-371-class-reference-a-href-cite-note-371-371-a-sup-td-td-m-li-et-al-td-tr-tr-td-kegg-metabolic-reaction-network-undirected-dataset-td-td-network-of-metabolic-pathways-a-reaction-network-and-a-a-href-wiki-relation-network-title-relation-network-relation-network-a-are-given-td-td-detailed-features-for-each-network-node-and-pathway-are-given-td-td-65554-td-td-text-td-td-classification-clustering-regression-td-td-2011-td-td-sup-id-cite-ref-372-class-reference-a-href-cite-note-372-372-a-sup-td-td-m-naeem-et-al-td-tr-tr-td-modified-human-sperm-morphology-analysis-dataset-mhsma-td-td-human-sperm-images-from-235-patients-with-male-factor-infertility-labeled-for-normal-or-abnormal-sperm-acrosome-head-vacuole-and-tail-td-td-cropped-around-single-sperm-head-magnification-normalized-training-validation-and-test-set-splits-created-td-td-1540-td-td-npy-files-td-td-classification-td-td-2019-td-td-sup-id-cite-ref-373-class-reference-a-href-cite-note-373-373-a-sup-sup-id-cite-ref-374-class-reference-a-href-cite-note-374-374-a-sup-td-td-s-javadi-and-s-a-mirroshandel-td-tr-tbody-table-h3-span-class-mw-headline-id-animal-animal-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-31-title-edit-section-animal-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-abalone-dataset-td-td-physical-measurements-of-abalone-weather-patterns-and-location-are-also-given-td-td-none-td-td-4177-td-td-text-td-td-regression-td-td-1995-td-td-sup-id-cite-ref-375-class-reference-a-href-cite-note-375-375-a-sup-td-td-marine-research-laboratories-taroona-td-tr-tr-td-zoo-dataset-td-td-artificial-dataset-covering-7-classes-of-animals-td-td-animals-are-classed-into-7-categories-and-features-are-given-for-each-td-td-101-td-td-text-td-td-classification-td-td-1990-td-td-sup-id-cite-ref-376-class-reference-a-href-cite-note-376-376-a-sup-td-td-r-forsyth-td-tr-tr-td-demospongiae-dataset-td-td-data-about-marine-sponges-td-td-503-sponges-in-the-a-href-wiki-demosponge-title-demosponge-demosponge-a-class-are-described-by-various-features-td-td-503-td-td-text-td-td-classification-td-td-2010-td-td-sup-id-cite-ref-377-class-reference-a-href-cite-note-377-377-a-sup-td-td-e-armengol-et-al-td-tr-tr-td-splice-junction-gene-sequences-dataset-td-td-primate-splice-junction-gene-sequences-dna-with-associated-imperfect-domain-theory-td-td-none-td-td-3190-td-td-text-td-td-classification-td-td-1992-td-td-sup-id-cite-ref-jinyan-2003-354-1-class-reference-a-href-cite-note-jinyan-2003-354-354-a-sup-td-td-g-towell-et-al-td-tr-tr-td-mice-protein-expression-dataset-td-td-expression-levels-of-77-proteins-measured-in-the-cerebral-cortex-of-mice-td-td-none-td-td-1080-td-td-text-td-td-classification-clustering-td-td-2015-td-td-sup-id-cite-ref-378-class-reference-a-href-cite-note-378-378-a-sup-sup-id-cite-ref-379-class-reference-a-href-cite-note-379-379-a-sup-td-td-c-higuera-et-al-td-tr-tbody-table-h3-span-class-mw-headline-id-plant-plant-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-32-title-edit-section-plant-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-forest-fires-dataset-td-td-forest-fires-and-their-properties-td-td-13-features-of-each-fire-are-extracted-td-td-517-td-td-text-td-td-regression-td-td-2008-td-td-sup-id-cite-ref-380-class-reference-a-href-cite-note-380-380-a-sup-sup-id-cite-ref-381-class-reference-a-href-cite-note-381-381-a-sup-td-td-p-cortez-et-al-td-tr-tr-td-a-href-wiki-iris-flower-data-set-title-iris-flower-data-set-iris-dataset-a-td-td-three-types-of-iris-plants-are-described-by-4-different-attributes-td-td-none-td-td-150-td-td-text-td-td-classification-td-td-1936-td-td-sup-id-cite-ref-382-class-reference-a-href-cite-note-382-382-a-sup-sup-id-cite-ref-383-class-reference-a-href-cite-note-383-383-a-sup-td-td-r-fisher-td-tr-tr-td-plant-species-leaves-dataset-td-td-sixteen-samples-of-leaf-each-of-one-hundred-plant-species-td-td-shape-descriptor-fine-scale-margin-and-texture-histograms-are-given-td-td-1600-td-td-text-td-td-classification-td-td-2012-td-td-sup-id-cite-ref-384-class-reference-a-href-cite-note-384-384-a-sup-sup-id-cite-ref-385-class-reference-a-href-cite-note-385-385-a-sup-td-td-j-cope-et-al-td-tr-tr-td-mushroom-dataset-td-td-mushroom-attributes-and-classification-td-td-many-properties-of-each-mushroom-are-given-td-td-8124-td-td-text-td-td-classification-td-td-1987-td-td-sup-id-cite-ref-386-class-reference-a-href-cite-note-386-386-a-sup-td-td-j-schlimmer-td-tr-tr-td-soybean-dataset-td-td-database-of-diseased-soybean-plants-td-td-35-features-for-each-plant-are-given-plants-are-classified-into-19-categories-td-td-307-td-td-text-td-td-classification-td-td-1988-td-td-sup-id-cite-ref-387-class-reference-a-href-cite-note-387-387-a-sup-td-td-r-michalski-et-al-td-tr-tr-td-seeds-dataset-td-td-measurements-of-geometrical-properties-of-kernels-belonging-to-three-different-varieties-of-wheat-td-td-none-td-td-210-td-td-text-td-td-classification-clustering-td-td-2012-td-td-sup-id-cite-ref-388-class-reference-a-href-cite-note-388-388-a-sup-sup-id-cite-ref-389-class-reference-a-href-cite-note-389-389-a-sup-td-td-charytanowicz-et-al-td-tr-tr-td-covertype-dataset-td-td-data-for-predicting-forest-cover-type-strictly-from-cartographic-variables-td-td-many-geographical-features-given-td-td-581012-td-td-text-td-td-classification-td-td-1998-td-td-sup-id-cite-ref-390-class-reference-a-href-cite-note-390-390-a-sup-sup-id-cite-ref-391-class-reference-a-href-cite-note-391-391-a-sup-td-td-j-blackard-et-al-td-tr-tr-td-abscisic-acid-signaling-network-dataset-td-td-data-for-a-plant-signaling-network-goal-is-to-determine-set-of-rules-that-governs-the-network-td-td-none-td-td-300-td-td-text-td-td-causal-discovery-td-td-2008-td-td-sup-id-cite-ref-392-class-reference-a-href-cite-note-392-392-a-sup-td-td-j-jenkens-et-al-td-tr-tr-td-folio-dataset-td-td-20-photos-of-leaves-for-each-of-32-species-td-td-none-td-td-637-td-td-images-text-td-td-classification-clustering-td-td-2015-td-td-sup-id-cite-ref-393-class-reference-a-href-cite-note-393-393-a-sup-sup-id-cite-ref-394-class-reference-a-href-cite-note-394-394-a-sup-td-td-t-munisami-et-al-td-tr-tr-td-oxford-flower-dataset-td-td-17-category-dataset-of-flowers-td-td-train-test-splits-labeled-images-td-td-1360-td-td-images-text-td-td-classification-td-td-2006-td-td-sup-id-cite-ref-razavian-ali-2014-139-1-class-reference-a-href-cite-note-razavian-ali-2014-139-139-a-sup-sup-id-cite-ref-395-class-reference-a-href-cite-note-395-395-a-sup-td-td-m-e-nilsback-et-al-td-tr-tr-td-plant-seedlings-dataset-td-td-12-category-dataset-of-plant-seedlings-td-td-labelled-images-segmented-images-td-td-5544-td-td-images-td-td-classification-detection-td-td-2017-td-td-sup-id-cite-ref-396-class-reference-a-href-cite-note-396-396-a-sup-td-td-giselsson-et-al-td-tr-tr-td-fruits-360-dataset-td-td-database-with-images-of-100-fruits-td-td-100x100-pixels-white-background-td-td-69277-td-td-images-jpg-td-td-classification-td-td-2017-td-td-sup-id-cite-ref-397-class-reference-a-href-cite-note-397-397-a-sup-sup-id-cite-ref-398-class-reference-a-href-cite-note-398-398-a-sup-td-td-mihai-oltean-horea-muresan-td-tr-tbody-table-h3-span-class-mw-headline-id-microbe-microbe-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-33-title-edit-section-microbe-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-ecoli-dataset-td-td-protein-localization-sites-td-td-various-features-of-the-protein-localizations-sites-are-given-td-td-336-td-td-text-td-td-classification-td-td-1996-td-td-sup-id-cite-ref-399-class-reference-a-href-cite-note-399-399-a-sup-sup-id-cite-ref-400-class-reference-a-href-cite-note-400-400-a-sup-td-td-k-nakai-et-al-td-tr-tr-td-micromass-dataset-td-td-identification-of-microorganisms-from-mass-spectrometry-data-td-td-various-mass-spectrometer-features-td-td-931-td-td-text-td-td-classification-td-td-2013-td-td-sup-id-cite-ref-401-class-reference-a-href-cite-note-401-401-a-sup-sup-id-cite-ref-402-class-reference-a-href-cite-note-402-402-a-sup-td-td-p-mahe-et-al-td-tr-tr-td-yeast-dataset-td-td-predictions-of-cellular-localization-sites-of-proteins-td-td-eight-features-given-per-instance-td-td-1484-td-td-text-td-td-classification-td-td-1996-td-td-sup-id-cite-ref-403-class-reference-a-href-cite-note-403-403-a-sup-sup-id-cite-ref-404-class-reference-a-href-cite-note-404-404-a-sup-td-td-k-nakai-et-al-td-tr-tbody-table-h3-span-class-mw-headline-id-drug-discovery-drug-discovery-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-34-title-edit-section-drug-discovery-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-tox21-dataset-td-td-prediction-of-outcome-of-biological-assays-td-td-chemical-descriptors-of-molecules-are-given-td-td-12707-td-td-text-td-td-classification-td-td-2016-td-td-sup-id-cite-ref-405-class-reference-a-href-cite-note-405-405-a-sup-td-td-a-mayr-et-al-td-tr-tbody-table-h2-span-class-mw-headline-id-anomaly-data-anomaly-data-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-35-title-edit-section-anomaly-data-edit-a-span-class-mw-editsection-bracket-span-span-h2-table-style-width-100-class-wikitable-sortable-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-numenta-anomaly-benchmark-nab-td-td-data-are-ordered-timestamped-single-valued-metrics-all-data-files-contain-anomalies-unless-otherwise-noted-td-td-none-td-td-50-files-td-td-comma-separated-values-td-td-a-href-wiki-anomaly-detection-title-anomaly-detection-anomaly-detection-a-td-td-2016-continually-updated-td-td-sup-id-cite-ref-406-class-reference-a-href-cite-note-406-406-a-sup-td-td-a-href-wiki-numenta-title-numenta-numenta-a-td-tr-tr-td-on-the-evaluation-of-unsupervised-outlier-detection-measures-datasets-and-an-empirical-study-td-td-most-data-files-are-adapted-from-uci-machine-learning-repository-data-some-are-collected-from-the-literature-td-td-treated-for-missing-values-numerical-attributes-only-different-percentages-of-anomalies-labels-td-td-1000-files-td-td-a-href-wiki-attribute-relation-file-format-class-mw-redirect-title-attribute-relation-file-format-arff-a-td-td-a-href-wiki-anomaly-detection-title-anomaly-detection-anomaly-detection-a-td-td-2016-possibly-updated-with-new-datasets-and-or-results-td-td-p-sup-id-cite-ref-camposzimek2016-407-0-class-reference-a-href-cite-note-camposzimek2016-407-407-a-sup-p-td-td-campos-et-al-td-tr-tbody-table-h2-span-class-mw-headline-id-question-answering-data-question-answering-data-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-36-title-edit-section-question-answering-data-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-this-section-includes-datasets-that-deals-with-structured-data-p-table-style-width-100-class-wikitable-sortable-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-dbpedia-neural-question-answering-dbnqa-dataset-td-td-a-large-collection-of-question-to-sparql-specially-design-for-open-domain-neural-question-answering-over-dbpedia-knowledgebase-td-td-this-dataset-contains-a-large-collection-of-open-neural-sparql-templates-and-instances-for-training-neural-sparql-machines-it-was-pre-processed-by-semi-automatic-annotation-tools-as-well-as-by-three-sparql-experts-td-td-894499-td-td-question-query-pairs-td-td-question-answering-td-td-2018-td-td-sup-id-cite-ref-408-class-reference-a-href-cite-note-408-408-a-sup-sup-id-cite-ref-409-class-reference-a-href-cite-note-409-409-a-sup-td-td-hartmann-soru-and-marx-et-al-td-tr-tbody-table-h2-span-class-mw-headline-id-multivariate-data-multivariate-data-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-37-title-edit-section-multivariate-data-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-datasets-consisting-of-rows-of-observations-and-columns-of-attributes-characterizing-those-observations-typically-used-for-a-href-wiki-regression-analysis-title-regression-analysis-regression-analysis-a-or-classification-but-other-types-of-algorithms-can-also-be-used-this-section-includes-datasets-that-do-not-fit-in-the-above-categories-p-h3-span-class-mw-headline-id-financial-financial-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-38-title-edit-section-financial-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-style-width-100-class-wikitable-sortable-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-dow-jones-index-td-td-weekly-data-of-stocks-from-the-first-and-second-quarters-of-2011-td-td-calculated-values-included-such-as-percentage-change-and-a-lags-td-td-750-td-td-comma-separated-values-td-td-classification-regression-a-href-wiki-time-series-title-time-series-time-series-a-td-td-2014-td-td-sup-id-cite-ref-410-class-reference-a-href-cite-note-410-410-a-sup-sup-id-cite-ref-411-class-reference-a-href-cite-note-411-411-a-sup-td-td-m-brown-et-al-td-tr-tr-td-statlog-australian-credit-approval-td-td-credit-card-applications-either-accepted-or-rejected-and-attributes-about-the-application-td-td-attribute-names-are-removed-as-well-as-identifying-information-factors-have-been-relabeled-td-td-690-td-td-comma-separated-values-td-td-classification-td-td-1987-td-td-sup-id-cite-ref-412-class-reference-a-href-cite-note-412-412-a-sup-sup-id-cite-ref-413-class-reference-a-href-cite-note-413-413-a-sup-td-td-r-quinlan-td-tr-tr-td-ebay-auction-data-td-td-auction-data-from-various-ebay-com-objects-over-various-length-auctions-td-td-contains-all-bids-bidderid-bid-times-and-opening-prices-td-td-550-td-td-text-td-td-regression-classification-td-td-2012-td-td-sup-id-cite-ref-414-class-reference-a-href-cite-note-414-414-a-sup-sup-id-cite-ref-415-class-reference-a-href-cite-note-415-415-a-sup-td-td-g-shmueli-et-al-td-tr-tr-td-statlog-german-credit-data-td-td-binary-credit-classification-into-good-or-bad-with-many-features-td-td-various-financial-features-of-each-person-are-given-td-td-690-td-td-text-td-td-classification-td-td-1994-td-td-sup-id-cite-ref-416-class-reference-a-href-cite-note-416-416-a-sup-td-td-h-hofmann-td-tr-tr-td-bank-marketing-dataset-td-td-data-from-a-large-marketing-campaign-carried-out-by-a-large-bank-td-td-many-attributes-of-the-clients-contacted-are-given-if-the-client-subscribed-to-the-bank-is-also-given-td-td-45211-td-td-text-td-td-classification-td-td-2012-td-td-sup-id-cite-ref-417-class-reference-a-href-cite-note-417-417-a-sup-sup-id-cite-ref-418-class-reference-a-href-cite-note-418-418-a-sup-td-td-s-moro-et-al-td-tr-tr-td-istanbul-stock-exchange-dataset-td-td-several-stock-indexes-tracked-for-almost-two-years-td-td-none-td-td-536-td-td-text-td-td-classification-regression-td-td-2013-td-td-sup-id-cite-ref-419-class-reference-a-href-cite-note-419-419-a-sup-sup-id-cite-ref-420-class-reference-a-href-cite-note-420-420-a-sup-td-td-o-akbilgic-td-tr-tr-td-default-of-credit-card-clients-td-td-credit-default-data-for-taiwanese-creditors-td-td-various-features-about-each-account-are-given-td-td-30000-td-td-text-td-td-classification-td-td-2016-td-td-sup-id-cite-ref-421-class-reference-a-href-cite-note-421-421-a-sup-sup-id-cite-ref-422-class-reference-a-href-cite-note-422-422-a-sup-td-td-i-yeh-td-tr-tbody-table-h3-span-class-mw-headline-id-weather-weather-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-39-title-edit-section-weather-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-cloud-dataset-td-td-data-about-1024-different-clouds-td-td-image-features-extracted-td-td-1024-td-td-text-td-td-classification-clustering-td-td-1989-td-td-sup-id-cite-ref-423-class-reference-a-href-cite-note-423-423-a-sup-td-td-p-collard-td-tr-tr-td-el-nino-dataset-td-td-oceanographic-and-surface-meteorological-readings-taken-from-a-series-of-buoys-positioned-throughout-the-equatorial-pacific-td-td-12-weather-attributes-are-measured-at-each-buoy-td-td-178080-td-td-text-td-td-regression-td-td-1999-td-td-sup-id-cite-ref-424-class-reference-a-href-cite-note-424-424-a-sup-td-td-a-href-wiki-pacific-marine-environmental-laboratory-title-pacific-marine-environmental-laboratory-pacific-marine-environmental-laboratory-a-td-tr-tr-td-greenhouse-gas-observing-network-dataset-td-td-time-series-of-greenhouse-gas-concentrations-at-2921-grid-cells-in-california-created-using-simulations-of-the-weather-td-td-none-td-td-2921-td-td-text-td-td-regression-td-td-2015-td-td-sup-id-cite-ref-425-class-reference-a-href-cite-note-425-425-a-sup-td-td-d-lucas-td-tr-tr-td-atmospheric-co2-from-continuous-air-samples-at-mauna-loa-observatory-td-td-continuous-air-samples-in-hawaii-usa-44-years-of-records-td-td-none-td-td-44-years-td-td-text-td-td-regression-td-td-2001-td-td-sup-id-cite-ref-426-class-reference-a-href-cite-note-426-426-a-sup-td-td-a-href-wiki-mauna-loa-observatory-title-mauna-loa-observatory-mauna-loa-observatory-a-td-tr-tr-td-ionosphere-dataset-td-td-radar-data-from-the-ionosphere-task-is-to-classify-into-good-and-bad-radar-returns-td-td-many-radar-features-given-td-td-351-td-td-text-td-td-classification-td-td-1989-td-td-sup-id-cite-ref-zhou-zhi-hua-2004-366-1-class-reference-a-href-cite-note-zhou-zhi-hua-2004-366-366-a-sup-sup-id-cite-ref-427-class-reference-a-href-cite-note-427-427-a-sup-td-td-a-href-wiki-johns-hopkins-university-title-johns-hopkins-university-johns-hopkins-university-a-td-tr-tr-td-ozone-level-detection-dataset-td-td-two-ground-ozone-level-datasets-td-td-many-features-given-including-weather-conditions-at-time-of-measurement-td-td-2536-td-td-text-td-td-classification-td-td-2008-td-td-sup-id-cite-ref-428-class-reference-a-href-cite-note-428-428-a-sup-sup-id-cite-ref-429-class-reference-a-href-cite-note-429-429-a-sup-td-td-k-zhang-et-al-td-tr-tbody-table-h3-span-class-mw-headline-id-census-census-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-40-title-edit-section-census-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-style-width-100-class-wikitable-sortable-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-adult-dataset-td-td-census-data-from-1994-containing-demographic-features-of-adults-and-their-income-td-td-cleaned-and-anonymized-td-td-48842-td-td-comma-separated-values-td-td-classification-td-td-1996-td-td-sup-id-cite-ref-430-class-reference-a-href-cite-note-430-430-a-sup-td-td-united-states-census-bureau-td-tr-tr-td-census-income-kdd-td-td-weighted-census-data-from-the-1994-and-1995-a-href-wiki-current-population-survey-us-class-mw-redirect-title-current-population-survey-us-current-population-surveys-a-td-td-split-into-training-and-test-sets-td-td-299285-td-td-comma-separated-values-td-td-classification-td-td-2000-td-td-sup-id-cite-ref-431-class-reference-a-href-cite-note-431-431-a-sup-sup-id-cite-ref-432-class-reference-a-href-cite-note-432-432-a-sup-td-td-a-href-wiki-united-states-census-bureau-title-united-states-census-bureau-united-states-census-bureau-a-td-tr-tr-td-ipums-census-database-td-td-census-data-from-the-los-angeles-and-long-beach-areas-td-td-none-td-td-256932-td-td-text-td-td-classification-regression-td-td-1999-td-td-sup-id-cite-ref-433-class-reference-a-href-cite-note-433-433-a-sup-td-td-a-href-wiki-ipums-title-ipums-ipums-a-td-tr-tr-td-us-census-data-1990-td-td-partial-data-from-1990-us-census-td-td-results-randomized-and-useful-attributes-selected-td-td-2458285-td-td-text-td-td-classification-regression-td-td-1990-td-td-sup-id-cite-ref-434-class-reference-a-href-cite-note-434-434-a-sup-td-td-a-href-wiki-united-states-census-bureau-title-united-states-census-bureau-united-states-census-bureau-a-td-tr-tbody-table-h3-span-class-mw-headline-id-transit-transit-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-41-title-edit-section-transit-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-bike-sharing-dataset-td-td-hourly-and-daily-count-of-rental-bikes-in-a-large-city-td-td-many-features-including-weather-length-of-trip-etc-are-given-td-td-17389-td-td-text-td-td-regression-td-td-2013-td-td-sup-id-cite-ref-435-class-reference-a-href-cite-note-435-435-a-sup-sup-id-cite-ref-436-class-reference-a-href-cite-note-436-436-a-sup-td-td-h-fanaee-t-td-tr-tr-td-new-york-city-taxi-trip-data-td-td-trip-data-for-yellow-and-green-taxis-in-new-york-city-td-td-gives-pick-up-and-drop-off-locations-fares-and-other-details-of-trips-td-td-6-years-td-td-text-td-td-classification-clustering-td-td-2015-td-td-sup-id-cite-ref-437-class-reference-a-href-cite-note-437-437-a-sup-td-td-a-href-wiki-new-york-city-taxi-and-limousine-commission-title-new-york-city-taxi-and-limousine-commission-new-york-city-taxi-and-limousine-commission-a-td-tr-tr-td-taxi-service-trajectory-ecml-pkdd-td-td-trajectories-of-all-taxis-in-a-large-city-td-td-many-features-given-including-start-and-stop-points-td-td-1710671-td-td-text-td-td-clustering-causal-discovery-td-td-2015-td-td-sup-id-cite-ref-438-class-reference-a-href-cite-note-438-438-a-sup-sup-id-cite-ref-439-class-reference-a-href-cite-note-439-439-a-sup-td-td-m-ferreira-et-al-td-tr-tbody-table-h3-span-class-mw-headline-id-internet-internet-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-42-title-edit-section-internet-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-wikitable-sortable-style-width-100-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-webpages-from-common-crawl-2012-td-td-large-collection-of-webpages-and-how-they-are-connected-via-hyperlinks-td-td-none-td-td-3-5b-td-td-text-td-td-clustering-classification-td-td-2013-td-td-sup-id-cite-ref-440-class-reference-a-href-cite-note-440-440-a-sup-td-td-v-granville-td-tr-tr-td-internet-advertisements-dataset-td-td-dataset-for-predicting-if-a-given-image-is-an-advertisement-or-not-td-td-features-encode-geometry-of-ads-and-phrases-occurring-in-the-url-td-td-3279-td-td-text-td-td-classification-td-td-1998-td-td-sup-id-cite-ref-441-class-reference-a-href-cite-note-441-441-a-sup-sup-id-cite-ref-442-class-reference-a-href-cite-note-442-442-a-sup-td-td-n-kushmerick-td-tr-tr-td-internet-usage-dataset-td-td-general-demographics-of-internet-users-td-td-none-td-td-10104-td-td-text-td-td-classification-clustering-td-td-1999-td-td-sup-id-cite-ref-443-class-reference-a-href-cite-note-443-443-a-sup-td-td-d-cook-td-tr-tr-td-url-dataset-td-td-120-days-of-url-data-from-a-large-conference-td-td-many-features-of-each-url-are-given-td-td-2396130-td-td-text-td-td-classification-td-td-2009-td-td-sup-id-cite-ref-444-class-reference-a-href-cite-note-444-444-a-sup-sup-id-cite-ref-445-class-reference-a-href-cite-note-445-445-a-sup-td-td-j-ma-td-tr-tr-td-phishing-websites-dataset-td-td-dataset-of-phishing-websites-td-td-many-features-of-each-site-are-given-td-td-2456-td-td-text-td-td-classification-td-td-2015-td-td-sup-id-cite-ref-446-class-reference-a-href-cite-note-446-446-a-sup-td-td-r-mustafa-et-al-td-tr-tr-td-online-retail-dataset-td-td-online-transactions-for-a-uk-online-retailer-td-td-details-of-each-transaction-given-td-td-541909-td-td-text-td-td-classification-clustering-td-td-2015-td-td-sup-id-cite-ref-447-class-reference-a-href-cite-note-447-447-a-sup-td-td-d-chen-td-tr-tr-td-freebase-simple-topic-dump-td-td-freebase-is-an-online-effort-to-structure-all-human-knowledge-td-td-topics-from-freebase-have-been-extracted-td-td-large-td-td-text-td-td-classification-clustering-td-td-2011-td-td-sup-id-cite-ref-448-class-reference-a-href-cite-note-448-448-a-sup-sup-id-cite-ref-449-class-reference-a-href-cite-note-449-449-a-sup-td-td-a-href-wiki-freebase-title-freebase-freebase-a-td-tr-tr-td-farm-ads-dataset-td-td-the-text-of-farm-ads-from-websites-binary-approval-or-disapproval-by-content-owners-is-given-td-td-svmlight-sparse-vectors-of-text-words-in-ads-calculated-td-td-4143-td-td-text-td-td-classification-td-td-2011-td-td-sup-id-cite-ref-450-class-reference-a-href-cite-note-450-450-a-sup-sup-id-cite-ref-451-class-reference-a-href-cite-note-451-451-a-sup-td-td-c-masterharm-et-al-td-tr-tbody-table-h3-span-class-mw-headline-id-games-games-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-43-title-edit-section-games-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-style-width-100-class-wikitable-sortable-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-poker-hand-dataset-td-td-5-card-hands-from-a-standard-52-card-deck-td-td-attributes-of-each-hand-are-given-including-the-poker-hands-formed-by-the-cards-it-contains-td-td-1025010-td-td-text-td-td-regression-classification-td-td-2007-td-td-sup-id-cite-ref-452-class-reference-a-href-cite-note-452-452-a-sup-td-td-r-cattral-td-tr-tr-td-connect-4-dataset-td-td-contains-all-legal-8-ply-positions-in-the-game-of-connect-4-in-which-neither-player-has-won-yet-and-in-which-the-next-move-is-not-forced-td-td-none-td-td-67557-td-td-text-td-td-classification-td-td-1995-td-td-sup-id-cite-ref-453-class-reference-a-href-cite-note-453-453-a-sup-td-td-j-tromp-td-tr-tr-td-chess-king-rook-vs-king-dataset-td-td-endgame-database-for-white-king-and-rook-against-black-king-td-td-none-td-td-28056-td-td-text-td-td-classification-td-td-1994-td-td-sup-id-cite-ref-454-class-reference-a-href-cite-note-454-454-a-sup-sup-id-cite-ref-455-class-reference-a-href-cite-note-455-455-a-sup-td-td-m-bain-et-al-td-tr-tr-td-chess-king-rook-vs-king-pawn-dataset-td-td-king-rook-versus-king-pawn-on-a7-td-td-none-td-td-3196-td-td-text-td-td-classification-td-td-1989-td-td-sup-id-cite-ref-456-class-reference-a-href-cite-note-456-456-a-sup-td-td-r-holte-td-tr-tr-td-tic-tac-toe-endgame-dataset-td-td-binary-classification-for-win-conditions-in-tic-tac-toe-td-td-none-td-td-958-td-td-text-td-td-classification-td-td-1991-td-td-sup-id-cite-ref-457-class-reference-a-href-cite-note-457-457-a-sup-td-td-d-aha-td-tr-tbody-table-h3-span-class-mw-headline-id-other-multivariate-other-multivariate-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-44-title-edit-section-other-multivariate-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-style-width-100-class-wikitable-sortable-tbody-tr-th-scope-col-style-width-15-dataset-name-th-th-scope-col-style-width-18-brief-description-th-th-scope-col-style-width-18-preprocessing-th-th-scope-col-style-width-6-instances-th-th-scope-col-style-width-7-format-th-th-scope-col-style-width-7-default-task-th-th-scope-col-style-width-6-created-updated-th-th-scope-col-style-width-6-reference-th-th-scope-col-style-width-11-creator-th-tr-tr-td-housing-data-set-td-td-median-home-values-of-boston-with-associated-home-and-neighborhood-attributes-td-td-none-td-td-506-td-td-text-td-td-regression-td-td-1993-td-td-sup-id-cite-ref-5-458-0-class-reference-a-href-cite-note-5-458-458-a-sup-td-td-d-harrison-et-al-td-tr-tr-td-the-getty-vocabularies-td-td-structured-terminology-for-art-and-other-material-culture-archival-materials-visual-surrogates-and-bibliographic-materials-td-td-none-td-td-large-td-td-text-td-td-classification-td-td-2015-td-td-sup-id-cite-ref-459-class-reference-a-href-cite-note-459-459-a-sup-td-td-a-href-wiki-getty-center-title-getty-center-getty-center-a-td-tr-tr-td-yahoo-front-page-today-module-user-click-log-td-td-user-click-log-for-news-articles-displayed-in-the-featured-tab-of-the-today-module-on-yahoo-front-page-td-td-conjoint-analysis-with-a-bilinear-model-td-td-45811883-user-visits-td-td-text-td-td-regression-clustering-td-td-2009-td-td-sup-id-cite-ref-460-class-reference-a-href-cite-note-460-460-a-sup-sup-id-cite-ref-461-class-reference-a-href-cite-note-461-461-a-sup-td-td-chu-et-al-td-tr-tr-td-british-oceanographic-data-centre-td-td-biological-chemical-physical-and-geophysical-data-for-oceans-22k-variables-tracked-td-td-various-td-td-22k-variables-many-instances-td-td-text-td-td-regression-clustering-td-td-2015-td-td-sup-id-cite-ref-462-class-reference-a-href-cite-note-462-462-a-sup-td-td-a-href-wiki-british-oceanographic-data-centre-title-british-oceanographic-data-centre-british-oceanographic-data-centre-a-td-tr-tr-td-congressional-voting-records-dataset-td-td-voting-data-for-all-usa-representatives-on-16-issues-td-td-beyond-the-raw-voting-data-various-other-features-are-provided-td-td-435-td-td-text-td-td-classification-td-td-1987-td-td-sup-id-cite-ref-463-class-reference-a-href-cite-note-463-463-a-sup-td-td-j-schlimmer-td-tr-tr-td-entree-chicago-recommendation-dataset-td-td-record-of-user-interactions-with-entree-chicago-recommendation-system-td-td-details-of-each-users-usage-of-the-app-are-recorded-in-detail-td-td-50672-td-td-text-td-td-regression-recommendation-td-td-2000-td-td-sup-id-cite-ref-464-class-reference-a-href-cite-note-464-464-a-sup-td-td-r-burke-td-tr-tr-td-insurance-company-benchmark-coil-2000-td-td-information-on-customers-of-an-insurance-company-td-td-many-features-of-each-customer-and-the-services-they-use-td-td-9000-td-td-text-td-td-regression-classification-td-td-2000-td-td-sup-id-cite-ref-465-class-reference-a-href-cite-note-465-465-a-sup-sup-id-cite-ref-466-class-reference-a-href-cite-note-466-466-a-sup-td-td-p-van-der-putten-td-tr-tr-td-nursery-dataset-td-td-data-from-applicants-to-nursery-schools-td-td-data-about-applicant-s-family-and-various-other-factors-included-td-td-12960-td-td-text-td-td-classification-td-td-1997-td-td-sup-id-cite-ref-467-class-reference-a-href-cite-note-467-467-a-sup-sup-id-cite-ref-468-class-reference-a-href-cite-note-468-468-a-sup-td-td-v-rajkovic-et-al-td-tr-tr-td-university-dataset-td-td-data-describing-attributed-of-a-large-number-of-universities-td-td-none-td-td-285-td-td-text-td-td-clustering-classification-td-td-1988-td-td-sup-id-cite-ref-469-class-reference-a-href-cite-note-469-469-a-sup-td-td-s-sounders-et-al-td-tr-tr-td-blood-transfusion-service-center-dataset-td-td-data-from-blood-transfusion-service-center-gives-data-on-donors-return-rate-frequency-etc-td-td-none-td-td-748-td-td-text-td-td-classification-td-td-2008-td-td-sup-id-cite-ref-470-class-reference-a-href-cite-note-470-470-a-sup-sup-id-cite-ref-471-class-reference-a-href-cite-note-471-471-a-sup-td-td-i-yeh-td-tr-tr-td-record-linkage-comparison-patterns-dataset-td-td-large-dataset-of-records-task-is-to-link-relevant-records-together-td-td-blocking-procedure-applied-to-select-only-certain-record-pairs-td-td-5749132-td-td-text-td-td-classification-td-td-2011-td-td-sup-id-cite-ref-472-class-reference-a-href-cite-note-472-472-a-sup-sup-id-cite-ref-473-class-reference-a-href-cite-note-473-473-a-sup-td-td-a-href-wiki-university-of-mainz-class-mw-redirect-title-university-of-mainz-university-of-mainz-a-td-tr-tr-td-nomao-dataset-td-td-nomao-collects-data-about-places-from-many-different-sources-task-is-to-detect-items-that-describe-the-same-place-td-td-duplicates-labeled-td-td-34465-td-td-text-td-td-classification-td-td-2012-td-td-sup-id-cite-ref-474-class-reference-a-href-cite-note-474-474-a-sup-sup-id-cite-ref-475-class-reference-a-href-cite-note-475-475-a-sup-td-td-nomao-labs-td-tr-tr-td-movie-dataset-td-td-data-for-10000-movies-td-td-several-features-for-each-movie-are-given-td-td-10000-td-td-text-td-td-clustering-classification-td-td-1999-td-td-sup-id-cite-ref-476-class-reference-a-href-cite-note-476-476-a-sup-td-td-g-wiederhold-td-tr-tr-td-open-university-learning-analytics-dataset-td-td-information-about-students-and-their-interactions-with-a-virtual-learning-environment-td-td-none-td-td-30000-td-td-text-td-td-classification-clustering-regression-td-td-2015-td-td-sup-id-cite-ref-477-class-reference-a-href-cite-note-477-477-a-sup-sup-id-cite-ref-478-class-reference-a-href-cite-note-478-478-a-sup-td-td-j-kuzilek-et-al-td-tr-tr-td-mobile-phone-records-td-td-telecommunications-activity-and-interactions-td-td-aggregation-per-geographical-grid-cells-and-every-15-minutes-td-td-large-td-td-text-td-td-classification-clustering-regression-td-td-2015-td-td-sup-id-cite-ref-barlacchide-nadai2015-479-0-class-reference-a-href-cite-note-barlacchide-nadai2015-479-479-a-sup-td-td-g-barlacchi-et-al-td-tr-tbody-table-h2-span-class-mw-headline-id-curated-repositories-of-datasets-curated-repositories-of-datasets-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-45-title-edit-section-curated-repositories-of-datasets-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-as-datasets-come-in-myriad-formats-and-can-sometimes-be-difficult-to-use-there-has-been-considerable-work-put-into-curating-and-standardizing-the-format-of-datasets-to-make-them-easier-to-use-for-machine-learning-research-p-ul-li-openml-sup-id-cite-ref-480-class-reference-a-href-cite-note-480-480-a-sup-web-platform-with-python-r-java-and-other-apis-for-downloading-hundreds-of-machine-learning-datasets-evaluating-algorithms-on-datasets-and-benchmarking-algorithm-performance-against-dozens-of-other-algorithms-li-li-pmlb-sup-id-cite-ref-481-class-reference-a-href-cite-note-481-481-a-sup-a-large-curated-repository-of-benchmark-datasets-for-evaluating-supervised-machine-learning-algorithms-provides-classification-and-regression-datasets-in-a-standardized-format-that-are-accessible-through-a-python-api-li-ul-h2-span-class-mw-headline-id-see-also-see-also-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-46-title-edit-section-see-also-edit-a-span-class-mw-editsection-bracket-span-span-h2-ul-li-a-href-wiki-comparison-of-deep-learning-software-class-mw-redirect-title-comparison-of-deep-learning-software-comparison-of-deep-learning-software-a-li-li-a-href-wiki-list-of-manual-image-annotation-tools-title-list-of-manual-image-annotation-tools-list-of-manual-image-annotation-tools-a-li-ul-h2-span-class-mw-headline-id-references-references-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-section-47-title-edit-section-references-edit-a-span-class-mw-editsection-bracket-span-span-h2-div-class-reflist-columns-references-column-width-style-moz-column-width-30em-webkit-column-width-30em-column-width-30em-list-style-type-decimal-ol-class-references-li-id-cite-note-1-span-class-mw-cite-backlink-b-a-href-cite-ref-1-a-b-span-span-class-reference-text-cite-class-citation-web-wissner-gross-a-a-rel-nofollow-class-external-text-href-https-edge-org-response-detail-26587-datasets-over-algorithms-a-edge-com-span-class-reference-accessdate-retrieved-span-class-nowrap-8-january-span-2016-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-datasets-over-algorithms-rft-pub-edge-com-rft-aulast-wissner-gross-rft-aufirst-a-rft-id-https-3a-2f-2fedge-org-2fresponse-detail-2f26587-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-style-data-mw-deduplicate-templatestyles-r886058088-mw-parser-output-cite-citation-font-style-inherit-mw-parser-output-citation-q-quotes-mw-parser-output-citation-cs1-lock-free-a-background-url-upload-wikimedia-org-wikipedia-commons-thumb-6-65-lock-green-svg-9px-lock-green-svg-png-no-repeat-background-position-right-1em-center-mw-parser-output-citation-cs1-lock-limited-a-mw-parser-output-citation-cs1-lock-registration-a-background-url-upload-wikimedia-org-wikipedia-commons-thumb-d-d6-lock-gray-alt-2-svg-9px-lock-gray-alt-2-svg-png-no-repeat-background-position-right-1em-center-mw-parser-output-citation-cs1-lock-subscription-a-background-url-upload-wikimedia-org-wikipedia-commons-thumb-a-aa-lock-red-alt-2-svg-9px-lock-red-alt-2-svg-png-no-repeat-background-position-right-1em-center-mw-parser-output-cs1-subscription-mw-parser-output-cs1-registration-color-555-mw-parser-output-cs1-subscription-span-mw-parser-output-cs1-registration-span-border-bottom-1px-dotted-cursor-help-mw-parser-output-cs1-ws-icon-a-background-url-upload-wikimedia-org-wikipedia-commons-thumb-4-4c-wikisource-logo-svg-12px-wikisource-logo-svg-png-no-repeat-background-position-right-1em-center-mw-parser-output-code-cs1-code-color-inherit-background-inherit-border-inherit-padding-inherit-mw-parser-output-cs1-hidden-error-display-none-font-size-100-mw-parser-output-cs1-visible-error-font-size-100-mw-parser-output-cs1-maint-display-none-color-33aa33-margin-left-0-3em-mw-parser-output-cs1-subscription-mw-parser-output-cs1-registration-mw-parser-output-cs1-format-font-size-95-mw-parser-output-cs1-kern-left-mw-parser-output-cs1-kern-wl-left-padding-left-0-2em-mw-parser-output-cs1-kern-right-mw-parser-output-cs1-kern-wl-right-padding-right-0-2em-style-span-li-li-id-cite-note-2-span-class-mw-cite-backlink-b-a-href-cite-ref-2-a-b-span-span-class-reference-text-weiss-gary-m-and-foster-provost-learning-when-training-data-are-costly-the-effect-of-class-distribution-on-tree-induction-i-journal-of-artificial-intelligence-research-i-2003-315-354-span-li-li-id-cite-note-3-span-class-mw-cite-backlink-b-a-href-cite-ref-3-a-b-span-span-class-reference-text-turney-peter-types-of-cost-in-inductive-concept-learning-2000-span-li-li-id-cite-note-4-span-class-mw-cite-backlink-b-a-href-cite-ref-4-a-b-span-span-class-reference-text-abney-steven-i-semisupervised-learning-for-computational-linguistics-i-crc-press-2007-span-li-li-id-cite-note-5-span-class-mw-cite-backlink-b-a-href-cite-ref-5-a-b-span-span-class-reference-text-zliobaite-indre-et-al-active-learning-with-evolving-streaming-data-i-machine-learning-and-knowledge-discovery-in-databases-i-springer-berlin-heidelberg-2011-597-612-span-li-li-id-cite-note-4-6-span-class-mw-cite-backlink-b-a-href-cite-ref-4-6-0-a-b-span-span-class-reference-text-cite-class-citation-journal-phillips-p-jonathon-et-al-1998-the-feret-database-and-evaluation-procedure-for-face-recognition-algorithms-i-image-and-vision-computing-i-b-16-b-5-295-306-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fs0262-8856-2897-2900070-x-10-1016-s0262-8856-97-00070-x-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-image-and-vision-computing-rft-atitle-the-feret-database-and-evaluation-procedure-for-face-recognition-algorithms-rft-volume-16-rft-issue-5-rft-pages-295-306-rft-date-1998-rft-id-info-3adoi-2f10-1016-2fs0262-8856-2897-2900070-x-rft-aulast-phillips-rft-aufirst-p-jonathon-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-7-span-class-mw-cite-backlink-b-a-href-cite-ref-7-a-b-span-span-class-reference-text-cite-class-citation-journal-wiskott-laurenz-et-al-1997-face-recognition-by-elastic-bunch-graph-matching-i-ieee-transactions-on-pattern-analysis-and-machine-intelligence-i-b-19-b-7-775-779-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-44-2321-10-1-1-44-2321-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2f34-598235-10-1109-34-598235-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-pattern-analysis-and-machine-intelligence-rft-atitle-face-recognition-by-elastic-bunch-graph-matching-rft-volume-19-rft-issue-7-rft-pages-775-779-rft-date-1997-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-44-2321-rft-id-info-3adoi-2f10-1109-2f34-598235-rft-aulast-wiskott-rft-aufirst-laurenz-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-8-span-class-mw-cite-backlink-b-a-href-cite-ref-8-a-b-span-span-class-reference-text-sim-terence-simon-baker-and-maan-bsat-the-cmu-pose-illumination-and-expression-pie-database-i-automatic-face-and-gesture-recognition-2002-proceedings-fifth-ieee-international-conference-on-i-ieee-2002-span-li-li-id-cite-note-9-span-class-mw-cite-backlink-b-a-href-cite-ref-9-a-b-span-span-class-reference-text-schroff-florian-et-al-pose-illumination-and-expression-invariant-pairwise-face-similarity-measure-via-doppelganger-list-comparison-i-computer-vision-iccv-2011-ieee-international-conference-on-i-ieee-2011-span-li-li-id-cite-note-10-span-class-mw-cite-backlink-b-a-href-cite-ref-10-a-b-span-span-class-reference-text-livingstone-russo-2018-the-ryerson-audio-visual-database-of-emotional-speech-and-song-ravdess-a-dynamic-multimodal-set-of-facial-and-vocal-expressions-in-north-american-english-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-https-doi-org-10-1371-2fjournal-pone-0196391-10-1371-journal-pone-0196391-a-span-li-li-id-cite-note-11-span-class-mw-cite-backlink-b-a-href-cite-ref-11-a-b-span-span-class-reference-text-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-https-doi-org-10-5281-2fzenodo-1188976-10-5281-zenodo-1188976-a-span-li-li-id-cite-note-0-12-span-class-mw-cite-backlink-b-a-href-cite-ref-0-12-0-a-b-span-span-class-reference-text-cite-class-citation-journal-grgic-mislav-delac-kresimir-grgic-sonja-2011-scface-surveillance-cameras-face-database-i-multimedia-tools-and-applications-i-b-51-b-3-863-879-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-multimedia-tools-and-applications-rft-atitle-scface-e2-80-93surveillance-cameras-face-database-rft-volume-51-rft-issue-3-rft-pages-863-879-rft-date-2011-rft-aulast-grgic-rft-aufirst-mislav-rft-au-delac-2c-kresimir-rft-au-grgic-2c-sonja-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-13-span-class-mw-cite-backlink-b-a-href-cite-ref-13-a-b-span-span-class-reference-text-wallace-roy-et-al-inter-session-variability-modelling-and-joint-factor-analysis-for-face-authentication-i-biometrics-ijcb-2011-international-joint-conference-on-i-ieee-2011-span-li-li-id-cite-note-14-span-class-mw-cite-backlink-b-a-href-cite-ref-14-a-b-span-span-class-reference-text-schroff-florian-dmitry-kalenichenko-and-james-philbin-facenet-a-unified-embedding-for-face-recognition-and-clustering-i-proceedings-of-the-ieee-conference-on-computer-vision-and-pattern-recognition-i-2015-span-li-li-id-cite-note-15-span-class-mw-cite-backlink-b-a-href-cite-ref-15-a-b-span-span-class-reference-text-wolf-lior-tal-hassner-and-itay-maoz-face-recognition-in-unconstrained-videos-with-matched-background-similarity-i-computer-vision-and-pattern-recognition-cvpr-2011-ieee-conference-on-i-ieee-2011-span-li-li-id-cite-note-16-span-class-mw-cite-backlink-b-a-href-cite-ref-16-a-b-span-span-class-reference-text-shen-jie-et-al-the-first-facial-landmark-tracking-in-the-wild-challenge-benchmark-and-results-2015-ieee-international-conference-on-computer-vision-workshop-iccvw-ieee-2015-span-li-li-id-cite-note-17-span-class-mw-cite-backlink-b-a-href-cite-ref-17-a-b-span-span-class-reference-text-de-almeida-freitas-fernando-et-al-grammatical-facial-expressions-recognition-with-machine-learning-i-flairs-conference-i-2014-span-li-li-id-cite-note-18-span-class-mw-cite-backlink-b-a-href-cite-ref-18-a-b-span-span-class-reference-text-mitchell-tom-m-machine-learning-wcb-1997-span-li-li-id-cite-note-19-span-class-mw-cite-backlink-b-a-href-cite-ref-19-a-b-span-span-class-reference-text-xiaofeng-he-and-partha-niyogi-locality-preserving-projections-nips-2003-span-li-li-id-cite-note-20-span-class-mw-cite-backlink-b-a-href-cite-ref-20-a-b-span-span-class-reference-text-georghiades-a-yale-face-database-i-center-for-computational-vision-and-control-at-yale-university-a-rel-nofollow-class-external-free-href-http-cvc-yale-edu-projects-yalefaces-yalefa-http-cvc-yale-edu-projects-yalefaces-yalefa-a-i-2-1997-span-li-li-id-cite-note-21-span-class-mw-cite-backlink-b-a-href-cite-ref-21-a-b-span-span-class-reference-text-cite-class-citation-journal-nguyen-duy-et-al-2006-real-time-face-detection-and-lip-feature-extraction-using-field-programmable-gate-arrays-i-ieee-transactions-on-systems-man-and-cybernetics-part-b-cybernetics-i-b-36-b-4-902-912-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-156-9848-10-1-1-156-9848-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftsmcb-2005-862728-10-1109-tsmcb-2005-862728-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-systems-2c-man-2c-and-cybernetics-2c-part-b-3a-cybernetics-rft-atitle-real-time-face-detection-and-lip-feature-extraction-using-field-programmable-gate-arrays-rft-volume-36-rft-issue-4-rft-pages-902-912-rft-date-2006-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-156-9848-rft-id-info-3adoi-2f10-1109-2ftsmcb-2005-862728-rft-aulast-nguyen-rft-aufirst-duy-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-22-span-class-mw-cite-backlink-b-a-href-cite-ref-22-a-b-span-span-class-reference-text-kanade-takeo-jeffrey-f-cohn-and-yingli-tian-comprehensive-database-for-facial-expression-analysis-i-automatic-face-and-gesture-recognition-2000-proceedings-fourth-ieee-international-conference-on-i-ieee-2000-span-li-li-id-cite-note-23-span-class-mw-cite-backlink-b-a-href-cite-ref-23-a-b-span-span-class-reference-text-cite-class-citation-journal-zeng-zhihong-et-al-2009-a-survey-of-affect-recognition-methods-audio-visual-and-spontaneous-expressions-i-ieee-transactions-on-pattern-analysis-and-machine-intelligence-i-b-31-b-1-39-58-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-144-217-10-1-1-144-217-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftpami-2008-52-10-1109-tpami-2008-52-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-19029545-19029545-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-pattern-analysis-and-machine-intelligence-rft-atitle-a-survey-of-affect-recognition-methods-3a-audio-2c-visual-2c-and-spontaneous-expressions-rft-volume-31-rft-issue-1-rft-pages-39-58-rft-date-2009-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-144-217-rft-id-info-3apmid-2f19029545-rft-id-info-3adoi-2f10-1109-2ftpami-2008-52-rft-aulast-zeng-rft-aufirst-zhihong-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-24-span-class-mw-cite-backlink-b-a-href-cite-ref-24-a-b-span-span-class-reference-text-ng-hong-wei-and-stefan-winkler-a-data-driven-approach-to-cleaning-large-face-datasets-i-image-processing-icip-2014-ieee-international-conference-on-i-ieee-2014-span-li-li-id-cite-note-25-span-class-mw-cite-backlink-b-a-href-cite-ref-25-a-b-span-span-class-reference-text-cite-class-citation-arxiv-roychowdhury-aruni-lin-tsung-yu-maji-subhransu-learned-miller-erik-2015-one-to-many-face-recognition-with-bilinear-cnns-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1506-01342-1506-01342-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-one-to-many-face-recognition-with-bilinear-cnns-rft-date-2015-rft-id-info-3aarxiv-2f1506-01342-rft-aulast-roychowdhury-rft-aufirst-aruni-rft-au-lin-2c-tsung-yu-rft-au-maji-2c-subhransu-rft-au-learned-miller-2c-erik-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-26-span-class-mw-cite-backlink-b-a-href-cite-ref-26-a-b-span-span-class-reference-text-jesorsky-oliver-klaus-j-kirchberg-and-robert-w-frischholz-robust-face-detection-using-the-hausdorff-distance-i-audio-and-video-based-biometric-person-authentication-i-springer-berlin-heidelberg-2001-span-li-li-id-cite-note-27-span-class-mw-cite-backlink-b-a-href-cite-ref-27-a-b-span-span-class-reference-text-huang-gary-b-et-al-i-labeled-faces-in-the-wild-a-database-for-studying-face-recognition-in-unconstrained-environments-i-vol-1-no-2-technical-report-07-49-university-of-massachusetts-amherst-2007-span-li-li-id-cite-note-28-span-class-mw-cite-backlink-b-a-href-cite-ref-28-a-b-span-span-class-reference-text-bhatt-rajen-b-et-al-efficient-skin-region-segmentation-using-low-complexity-fuzzy-decision-tree-model-i-india-conference-indicon-2009-annual-ieee-i-ieee-2009-span-li-li-id-cite-note-29-span-class-mw-cite-backlink-b-a-href-cite-ref-29-a-b-span-span-class-reference-text-cite-class-citation-journal-lingala-mounika-et-al-2014-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4287461-fuzzy-logic-color-detection-blue-areas-in-melanoma-dermoscopy-images-a-i-computerized-medical-imaging-and-graphics-i-b-38-b-5-403-410-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-compmedimag-2014-03-007-10-1016-j-compmedimag-2014-03-007-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4287461-4287461-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-24786720-24786720-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-computerized-medical-imaging-and-graphics-rft-atitle-fuzzy-logic-color-detection-3a-blue-areas-in-melanoma-dermoscopy-images-rft-volume-38-rft-issue-5-rft-pages-403-410-rft-date-2014-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4287461-rft-id-info-3apmid-2f24786720-rft-id-info-3adoi-2f10-1016-2fj-compmedimag-2014-03-007-rft-aulast-lingala-rft-aufirst-mounika-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4287461-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-30-span-class-mw-cite-backlink-b-a-href-cite-ref-30-a-b-span-span-class-reference-text-maes-chris-et-al-feature-detection-on-3d-face-surfaces-for-pose-normalisation-and-recognition-i-biometrics-theory-applications-and-systems-btas-2010-fourth-ieee-international-conference-on-i-ieee-2010-span-li-li-id-cite-note-31-span-class-mw-cite-backlink-b-a-href-cite-ref-31-a-b-span-span-class-reference-text-savran-arman-et-al-bosphorus-database-for-3d-face-analysis-i-biometrics-and-identity-management-i-springer-berlin-heidelberg-2008-47-56-span-li-li-id-cite-note-32-span-class-mw-cite-backlink-b-a-href-cite-ref-32-a-b-span-span-class-reference-text-heseltine-thomas-nick-pears-and-jim-austin-three-dimensional-face-recognition-an-eigensurface-approach-i-image-processing-2004-icip-04-2004-international-conference-on-i-vol-2-ieee-2004-span-li-li-id-cite-note-33-span-class-mw-cite-backlink-b-a-href-cite-ref-33-a-b-span-span-class-reference-text-cite-class-citation-journal-ge-yun-et-al-2011-3d-novel-face-sample-modeling-for-face-recognition-i-journal-of-multimedia-i-b-6-b-5-467-475-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-461-9710-10-1-1-461-9710-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-4304-2fjmm-6-5-467-475-10-4304-jmm-6-5-467-475-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-multimedia-rft-atitle-3d-novel-face-sample-modeling-for-face-recognition-rft-volume-6-rft-issue-5-rft-pages-467-475-rft-date-2011-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-461-9710-rft-id-info-3adoi-2f10-4304-2fjmm-6-5-467-475-rft-aulast-ge-rft-aufirst-yun-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-34-span-class-mw-cite-backlink-b-a-href-cite-ref-34-a-b-span-span-class-reference-text-cite-class-citation-journal-wang-yueming-liu-jianzhuang-tang-xiaoou-2010-robust-3d-face-recognition-by-local-shape-difference-boosting-i-ieee-transactions-on-pattern-analysis-and-machine-intelligence-i-b-32-b-10-1858-1870-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-471-2424-10-1-1-471-2424-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftpami-2009-200-10-1109-tpami-2009-200-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-20724762-20724762-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-pattern-analysis-and-machine-intelligence-rft-atitle-robust-3d-face-recognition-by-local-shape-difference-boosting-rft-volume-32-rft-issue-10-rft-pages-1858-1870-rft-date-2010-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-471-2424-rft-id-info-3apmid-2f20724762-rft-id-info-3adoi-2f10-1109-2ftpami-2009-200-rft-aulast-wang-rft-aufirst-yueming-rft-au-liu-2c-jianzhuang-rft-au-tang-2c-xiaoou-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-35-span-class-mw-cite-backlink-b-a-href-cite-ref-35-a-b-span-span-class-reference-text-zhong-cheng-zhenan-sun-and-tieniu-tan-robust-3d-face-recognition-using-learned-visual-codebook-i-computer-vision-and-pattern-recognition-2007-cvpr-07-ieee-conference-on-i-ieee-2007-span-li-li-id-cite-note-36-span-class-mw-cite-backlink-b-a-href-cite-ref-36-a-b-span-span-class-reference-text-zhao-g-huang-x-taini-m-li-s-z-pietikainen-m-2011-facial-expression-recognition-from-near-infrared-videos-image-and-vision-computing-29-9-607-619-span-li-li-id-cite-note-37-span-class-mw-cite-backlink-b-a-href-cite-ref-37-a-b-span-span-class-reference-text-soyel-hamit-and-hasan-demirel-facial-expression-recognition-using-3d-facial-feature-distances-i-image-analysis-and-recognition-i-springer-berlin-heidelberg-2007-831-838-span-li-li-id-cite-note-38-span-class-mw-cite-backlink-b-a-href-cite-ref-38-a-b-span-span-class-reference-text-cite-class-citation-journal-bowyer-kevin-w-chang-kyong-flynn-patrick-2006-a-survey-of-approaches-and-challenges-in-3d-and-multi-modal-3d-2d-face-recognition-i-computer-vision-and-image-understanding-i-b-101-b-1-1-15-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-134-8784-10-1-1-134-8784-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-cviu-2005-05-005-10-1016-j-cviu-2005-05-005-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-computer-vision-and-image-understanding-rft-atitle-a-survey-of-approaches-and-challenges-in-3d-and-multi-modal-3d-2b-2d-face-recognition-rft-volume-101-rft-issue-1-rft-pages-1-15-rft-date-2006-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-134-8784-rft-id-info-3adoi-2f10-1016-2fj-cviu-2005-05-005-rft-aulast-bowyer-rft-aufirst-kevin-w-rft-au-chang-2c-kyong-rft-au-flynn-2c-patrick-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-39-span-class-mw-cite-backlink-b-a-href-cite-ref-39-a-b-span-span-class-reference-text-cite-class-citation-journal-tan-xiaoyang-triggs-bill-2010-enhanced-local-texture-feature-sets-for-face-recognition-under-difficult-lighting-conditions-i-ieee-transactions-on-image-processing-i-b-19-b-6-1635-1650-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2010itip-19-1635t-2010itip-19-1635t-a-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-105-3355-10-1-1-105-3355-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftip-2010-2042645-10-1109-tip-2010-2042645-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-20172829-20172829-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-image-processing-rft-atitle-enhanced-local-texture-feature-sets-for-face-recognition-under-difficult-lighting-conditions-rft-volume-19-rft-issue-6-rft-pages-1635-1650-rft-date-2010-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-105-3355-rft-id-info-3apmid-2f20172829-rft-id-info-3adoi-2f10-1109-2ftip-2010-2042645-rft-id-info-3abibcode-2f2010itip-19-1635t-rft-aulast-tan-rft-aufirst-xiaoyang-rft-au-triggs-2c-bill-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-40-span-class-mw-cite-backlink-b-a-href-cite-ref-40-a-b-span-span-class-reference-text-mousavi-mir-hashem-karim-faez-and-amin-asghari-a-rel-nofollow-class-external-text-href-https-ieeexplore-ieee-org-abstract-document-4529822-three-dimensional-face-recognition-using-svm-classifier-a-i-computer-and-information-science-2008-icis-08-seventh-ieee-acis-international-conference-on-i-ieee-2008-span-li-li-id-cite-note-41-span-class-mw-cite-backlink-b-a-href-cite-ref-41-a-b-span-span-class-reference-text-amberg-brian-reinhard-knothe-and-thomas-vetter-expression-invariant-3d-face-recognition-with-a-morphable-model-i-automatic-face-gesture-recognition-2008-fg-08-8th-ieee-international-conference-on-i-ieee-2008-span-li-li-id-cite-note-42-span-class-mw-cite-backlink-b-a-href-cite-ref-42-a-b-span-span-class-reference-text-irfanoglu-m-o-berk-gokberk-and-lale-akarun-3d-shape-based-face-recognition-using-automatically-registered-facial-surfaces-i-pattern-recognition-2004-icpr-2004-proceedings-of-the-17th-international-conference-on-i-vol-4-ieee-2004-span-li-li-id-cite-note-43-span-class-mw-cite-backlink-b-a-href-cite-ref-43-a-b-span-span-class-reference-text-cite-class-citation-journal-beumier-charles-acheroy-marc-2001-face-verification-from-3d-and-grey-level-clues-i-pattern-recognition-letters-i-b-22-b-12-1321-1329-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fs0167-8655-2801-2900077-0-10-1016-s0167-8655-01-00077-0-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-pattern-recognition-letters-rft-atitle-face-verification-from-3d-and-grey-level-clues-rft-volume-22-rft-issue-12-rft-pages-1321-1329-rft-date-2001-rft-id-info-3adoi-2f10-1016-2fs0167-8655-2801-2900077-0-rft-aulast-beumier-rft-aufirst-charles-rft-au-acheroy-2c-marc-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-44-span-class-mw-cite-backlink-b-a-href-cite-ref-44-a-b-span-span-class-reference-text-cite-class-citation-arxiv-afifi-mahmoud-abdelhamed-abdelrahman-13-june-2017-afif4-deep-gender-classification-based-on-adaboost-based-fusion-of-isolated-facial-features-and-foggy-faces-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1706-04277-1706-04277-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-afif4-3a-deep-gender-classification-based-on-adaboost-based-fusion-of-isolated-facial-features-and-foggy-faces-rft-date-2017-06-13-rft-id-info-3aarxiv-2f1706-04277-rft-aulast-afifi-rft-aufirst-mahmoud-rft-au-abdelhamed-2c-abdelrahman-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-45-span-class-mw-cite-backlink-b-a-href-cite-ref-45-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-sites-google-com-view-sof-dataset-sof-dataset-a-i-sites-google-com-i-span-class-reference-accessdate-retrieved-span-class-nowrap-18-november-span-2017-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-sites-google-com-rft-atitle-sof-dataset-rft-id-https-3a-2f-2fsites-google-com-2fview-2fsof-dataset-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-46-span-class-mw-cite-backlink-b-a-href-cite-ref-46-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-data-vision-ee-ethz-ch-cvl-rrothe-imdb-wiki-imdb-wiki-a-i-data-vision-ee-ethz-ch-i-span-class-reference-accessdate-retrieved-span-class-nowrap-13-march-span-2018-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-data-vision-ee-ethz-ch-rft-atitle-imdb-wiki-rft-id-https-3a-2f-2fdata-vision-ee-ethz-ch-2fcvl-2frrothe-2fimdb-wiki-2f-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-47-span-class-mw-cite-backlink-b-a-href-cite-ref-47-a-b-span-span-class-reference-text-h-kuehne-h-jhuang-e-garrote-t-poggio-and-t-serre-hmdb-a-large-video-database-for-human-motion-recognition-iccv-2011-span-li-li-id-cite-note-48-span-class-mw-cite-backlink-b-a-href-cite-ref-48-a-b-span-span-class-reference-text-cite-class-citation-journal-patron-perez-a-marszalek-m-reid-i-zisserman-a-2012-structured-learning-of-human-interactions-in-tv-shows-i-ieee-transactions-on-pattern-analysis-and-machine-intelligence-i-b-34-b-12-2441-2453-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftpami-2012-24-10-1109-tpami-2012-24-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-23079467-23079467-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-pattern-analysis-and-machine-intelligence-rft-atitle-structured-learning-of-human-interactions-in-tv-shows-rft-volume-34-rft-issue-12-rft-pages-2441-2453-rft-date-2012-rft-id-info-3adoi-2f10-1109-2ftpami-2012-24-rft-id-info-3apmid-2f23079467-rft-aulast-patron-perez-rft-aufirst-a-rft-au-marszalek-2c-m-rft-au-reid-2c-i-rft-au-zisserman-2c-a-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-49-span-class-mw-cite-backlink-b-a-href-cite-ref-49-a-b-span-span-class-reference-text-ryoo-m-s-aggarwal-j-k-september-2009-spatio-temporal-relationship-match-video-structure-comparison-for-recognition-of-complex-human-activities-in-i-computer-vision-2009-ieee-12th-international-conference-on-i-pp-1593-1600-ieee-span-li-li-id-cite-note-50-span-class-mw-cite-backlink-b-a-href-cite-ref-50-a-b-span-span-class-reference-text-xia-l-chen-c-c-aggarwal-j-k-june-2012-view-invariant-human-action-recognition-using-histograms-of-3d-joints-in-i-computer-vision-and-pattern-recognition-workshops-cvprw-2012-ieee-computer-society-conference-on-i-pp-20-27-ieee-span-li-li-id-cite-note-51-span-class-mw-cite-backlink-b-a-href-cite-ref-51-a-b-span-span-class-reference-text-yun-k-honorio-j-chattopadhyay-d-berg-t-l-samaras-d-june-2012-two-person-interaction-detection-using-body-pose-features-and-multiple-instance-learning-in-computer-vision-and-pattern-recognition-workshops-cvprw-2012-ieee-computer-society-conference-on-pp-28-35-ieee-span-li-li-id-cite-note-52-span-class-mw-cite-backlink-b-a-href-cite-ref-52-a-b-span-span-class-reference-text-ofli-f-chaudhry-r-kurillo-g-vidal-r-bajcsy-r-january-2013-berkeley-mhad-a-comprehensive-multimodal-human-action-database-in-applications-of-computer-vision-wacv-2013-ieee-workshop-on-pp-53-60-ieee-span-li-li-id-cite-note-53-span-class-mw-cite-backlink-b-a-href-cite-ref-53-a-b-span-span-class-reference-text-cite-class-citation-arxiv-soomro-khurram-amir-roshan-zamir-shah-mubarak-2012-ucf101-a-dataset-of-101-human-actions-classes-from-videos-in-the-wild-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1212-0402-1212-0402-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-ucf101-3a-a-dataset-of-101-human-actions-classes-from-videos-in-the-wild-rft-date-2012-rft-id-info-3aarxiv-2f1212-0402-rft-aulast-soomro-rft-aufirst-khurram-rft-au-amir-roshan-zamir-rft-au-shah-2c-mubarak-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-54-span-class-mw-cite-backlink-b-a-href-cite-ref-54-a-b-span-span-class-reference-text-a-href-wiki-andrej-karpathy-title-andrej-karpathy-karpathy-andrej-a-et-al-large-scale-video-classification-with-convolutional-neural-networks-i-proceedings-of-the-ieee-conference-on-computer-vision-and-pattern-recognition-i-2014-span-li-li-id-cite-note-55-span-class-mw-cite-backlink-b-a-href-cite-ref-55-a-b-span-span-class-reference-text-jiang-y-g-et-al-thumos-challenge-action-recognition-with-a-large-number-of-classes-i-iccv-workshop-on-action-recognition-with-a-large-number-of-classes-a-rel-nofollow-class-external-free-href-http-crcv-ucf-edu-iccv13-action-workshop-http-crcv-ucf-edu-iccv13-action-workshop-a-i-2013-span-li-li-id-cite-note-56-span-class-mw-cite-backlink-b-a-href-cite-ref-56-a-b-span-span-class-reference-text-simonyan-karen-and-andrew-zisserman-two-stream-convolutional-networks-for-action-recognition-in-videos-i-advances-in-neural-information-processing-systems-i-2014-span-li-li-id-cite-note-57-span-class-mw-cite-backlink-b-a-href-cite-ref-57-a-b-span-span-class-reference-text-caba-heilbron-fabian-et-al-activitynet-a-large-scale-video-benchmark-for-human-activity-understanding-proceedings-of-the-ieee-conference-on-computer-vision-and-pattern-recognition-2015-span-li-li-id-cite-note-58-span-class-mw-cite-backlink-b-a-href-cite-ref-58-a-b-span-span-class-reference-text-sadoughi-n-liu-y-busso-c-may-2015-msp-avatar-corpus-motion-capture-recordings-to-study-the-role-of-discourse-functions-in-the-design-of-intelligent-virtual-agents-in-i-automatic-face-and-gesture-recognition-fg-2015-11th-ieee-international-conference-and-workshops-on-i-vol-7-pp-1-6-ieee-span-li-li-id-cite-note-59-span-class-mw-cite-backlink-b-a-href-cite-ref-59-a-b-span-span-class-reference-text-sheerman-chase-t-ong-e-j-bowden-r-november-2011-cultural-factors-in-the-regression-of-non-verbal-communication-perception-in-computer-vision-workshops-iccv-workshops-2011-ieee-international-conference-on-pp-1242-1249-ieee-span-li-li-id-cite-note-60-span-class-mw-cite-backlink-b-a-href-cite-ref-60-a-b-span-span-class-reference-text-cite-class-citation-journal-stoian-andrei-ferecatu-marin-benois-pineau-jenny-crucianu-michel-2016-fast-action-localization-in-large-scale-video-archives-i-ieee-transactions-on-circuits-and-systems-for-video-technology-i-b-26-b-10-1917-1930-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftcsvt-2015-2475835-10-1109-tcsvt-2015-2475835-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-circuits-and-systems-for-video-technology-rft-atitle-fast-action-localization-in-large-scale-video-archives-rft-volume-26-rft-issue-10-rft-pages-1917-1930-rft-date-2016-rft-id-info-3adoi-2f10-1109-2ftcsvt-2015-2475835-rft-aulast-stoian-rft-aufirst-andrei-rft-au-ferecatu-2c-marin-rft-au-benois-pineau-2c-jenny-rft-au-crucianu-2c-michel-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-61-span-class-mw-cite-backlink-b-a-href-cite-ref-61-a-b-span-span-class-reference-text-cite-class-citation-journal-krishna-ranjay-zhu-yuke-groth-oliver-johnson-justin-hata-kenji-kravitz-joshua-chen-stephanie-kalantidis-yannis-li-li-jia-shamma-david-a-bernstein-michael-s-fei-fei-li-2017-visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations-i-international-journal-of-computer-vision-i-b-123-b-32-73-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fs11263-016-0981-7-10-1007-s11263-016-0981-7-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-international-journal-of-computer-vision-rft-atitle-visual-genome-3a-connecting-language-and-vision-using-crowdsourced-dense-image-annotations-rft-volume-123-rft-pages-32-73-rft-date-2017-rft-id-info-3adoi-2f10-1007-2fs11263-016-0981-7-rft-aulast-krishna-rft-aufirst-ranjay-rft-au-zhu-2c-yuke-rft-au-groth-2c-oliver-rft-au-johnson-2c-justin-rft-au-hata-2c-kenji-rft-au-kravitz-2c-joshua-rft-au-chen-2c-stephanie-rft-au-kalantidis-2c-yannis-rft-au-li-2c-li-jia-rft-au-shamma-2c-david-a-rft-au-bernstein-2c-michael-s-rft-au-fei-fei-2c-li-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-62-span-class-mw-cite-backlink-b-a-href-cite-ref-62-a-b-span-span-class-reference-text-cite-class-citation-arxiv-pont-tuset-jordi-perazzi-federico-caelles-sergi-arbelaez-pablo-sorkine-hornung-alex-luc-van-gool-2017-the-2017-davis-challenge-on-video-object-segmentation-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1704-00675-1704-00675-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-the-2017-davis-challenge-on-video-object-segmentation-rft-date-2017-rft-id-info-3aarxiv-2f1704-00675-rft-aulast-pont-tuset-rft-aufirst-jordi-rft-au-perazzi-2c-federico-rft-au-caelles-2c-sergi-rft-au-arbel-c3-a1ez-2c-pablo-rft-au-sorkine-hornung-2c-alex-rft-au-luc-van-gool-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-63-span-class-mw-cite-backlink-b-a-href-cite-ref-63-a-b-span-span-class-reference-text-cite-class-citation-journal-perazzi-federico-pont-tuset-jordi-mcwilliams-brian-van-gool-luc-gross-markus-sorkine-hornung-alex-2016-a-rel-nofollow-class-external-text-href-https-www-cv-foundation-org-openaccess-content-cvpr-2016-papers-perazzi-a-benchmark-dataset-cvpr-2016-paper-pdf-a-benchmark-dataset-and-evaluation-methodology-for-video-object-segmentation-a-span-class-cs1-format-pdf-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-atitle-a-benchmark-dataset-and-evaluation-methodology-for-video-object-segmentation-rft-date-2016-rft-aulast-perazzi-rft-aufirst-federico-rft-au-pont-tuset-2c-jordi-rft-au-mcwilliams-2c-brian-rft-au-van-gool-2c-luc-rft-au-gross-2c-markus-rft-au-sorkine-hornung-2c-alex-rft-id-https-3a-2f-2fwww-cv-foundation-org-2fopenaccess-2fcontent-cvpr-2016-2fpapers-2fperazzi-a-benchmark-dataset-cvpr-2016-paper-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-64-span-class-mw-cite-backlink-b-a-href-cite-ref-64-a-b-span-span-class-reference-text-hodan-t-et-al-t-less-an-rgb-d-dataset-for-6d-pose-estimation-of-texture-less-objects-i-winter-conference-on-applications-of-computer-vision-wacv-2017-i-span-li-li-id-cite-note-6-65-span-class-mw-cite-backlink-b-a-href-cite-ref-6-65-0-a-b-span-span-class-reference-text-karayev-s-et-al-a-category-level-3-d-object-dataset-putting-the-kinect-to-work-i-proceedings-of-the-ieee-international-conference-on-computer-vision-workshops-i-2011-span-li-li-id-cite-note-66-span-class-mw-cite-backlink-b-a-href-cite-ref-66-a-b-span-span-class-reference-text-tighe-joseph-and-svetlana-lazebnik-superparsing-scalable-nonparametric-image-parsing-with-superpixels-i-computer-vision-eccv-2010-i-springer-berlin-heidelberg-2010-352-365-span-li-li-id-cite-note-67-span-class-mw-cite-backlink-b-a-href-cite-ref-67-a-b-span-span-class-reference-text-cite-class-citation-journal-arbelaez-p-maire-m-fowlkes-c-malik-j-may-2011-a-rel-nofollow-class-external-text-href-http-www-eecs-berkeley-edu-research-projects-cs-vision-grouping-papers-amfm-pami2010-pdf-contour-detection-and-hierarchical-image-segmentation-a-span-class-cs1-format-pdf-span-i-ieee-transactions-on-pattern-analysis-and-machine-intelligence-i-b-33-b-5-898-916-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftpami-2010-161-10-1109-tpami-2010-161-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-20733228-20733228-a-span-class-reference-accessdate-retrieved-span-class-nowrap-27-february-span-2016-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-pattern-analysis-and-machine-intelligence-rft-atitle-contour-detection-and-hierarchical-image-segmentation-rft-volume-33-rft-issue-5-rft-pages-898-916-rft-date-2011-05-rft-id-info-3adoi-2f10-1109-2ftpami-2010-161-rft-id-info-3apmid-2f20733228-rft-aulast-arbelaez-rft-aufirst-p-rft-au-maire-2c-m-rft-au-fowlkes-2c-c-rft-au-malik-2c-j-rft-id-http-3a-2f-2fwww-eecs-berkeley-edu-2fresearch-2fprojects-2fcs-2fvision-2fgrouping-2fpapers-2famfm-pami2010-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-68-span-class-mw-cite-backlink-b-a-href-cite-ref-68-a-b-span-span-class-reference-text-lin-tsung-yi-et-al-microsoft-coco-common-objects-in-context-i-computer-vision-eccv-2014-i-springer-international-publishing-2014-740-755-span-li-li-id-cite-note-69-span-class-mw-cite-backlink-b-a-href-cite-ref-69-a-b-span-span-class-reference-text-cite-class-citation-journal-russakovsky-olga-et-al-2015-imagenet-large-scale-visual-recognition-challenge-i-international-journal-of-computer-vision-i-b-115-b-3-211-252-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1409-0575-1409-0575-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fs11263-015-0816-y-10-1007-s11263-015-0816-y-a-a-href-wiki-handle-system-title-handle-system-hdl-a-a-rel-nofollow-class-external-text-href-hdl-handle-net-1721-1-2f104944-1721-1-104944-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-international-journal-of-computer-vision-rft-atitle-imagenet-large-scale-visual-recognition-challenge-rft-volume-115-rft-issue-3-rft-pages-211-252-rft-date-2015-rft-id-info-3aarxiv-2f1409-0575-rft-id-info-3ahdl-2f1721-1-2f104944-rft-id-info-3adoi-2f10-1007-2fs11263-015-0816-y-rft-aulast-russakovsky-rft-aufirst-olga-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-70-span-class-mw-cite-backlink-b-a-href-cite-ref-70-a-b-span-span-class-reference-text-xiao-jianxiong-et-al-sun-database-large-scale-scene-recognition-from-abbey-to-zoo-i-computer-vision-and-pattern-recognition-cvpr-2010-ieee-conference-on-i-ieee-2010-span-li-li-id-cite-note-71-span-class-mw-cite-backlink-b-a-href-cite-ref-71-a-b-span-span-class-reference-text-cite-class-citation-arxiv-donahue-jeff-jia-yangqing-vinyals-oriol-hoffman-judy-zhang-ning-tzeng-eric-darrell-trevor-2013-decaf-a-deep-convolutional-activation-feature-for-generic-visual-recognition-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1310-1531-1310-1531-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-decaf-3a-a-deep-convolutional-activation-feature-for-generic-visual-recognition-rft-date-2013-rft-id-info-3aarxiv-2f1310-1531-rft-aulast-donahue-rft-aufirst-jeff-rft-au-jia-2c-yangqing-rft-au-vinyals-2c-oriol-rft-au-hoffman-2c-judy-rft-au-zhang-2c-ning-rft-au-tzeng-2c-eric-rft-au-darrell-2c-trevor-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-72-span-class-mw-cite-backlink-b-a-href-cite-ref-72-a-b-span-span-class-reference-text-deng-jia-et-al-imagenet-a-large-scale-hierarchical-image-database-i-computer-vision-and-pattern-recognition-2009-cvpr-2009-ieee-conference-on-i-ieee-2009-span-li-li-id-cite-note-02-73-span-class-mw-cite-backlink-a-href-cite-ref-02-73-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-02-73-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-02-73-2-sup-i-b-c-b-i-sup-a-span-span-class-reference-text-krizhevsky-alex-ilya-sutskever-and-geoffrey-e-hinton-imagenet-classification-with-deep-convolutional-neural-networks-i-advances-in-neural-information-processing-systems-i-2012-span-li-li-id-cite-note-74-span-class-mw-cite-backlink-b-a-href-cite-ref-74-a-b-span-span-class-reference-text-cite-class-citation-journal-russakovsky-olga-deng-jia-su-hao-krause-jonathan-satheesh-sanjeev-et-al-11-april-2015-imagenet-large-scale-visual-recognition-challenge-i-international-journal-of-computer-vision-i-b-115-b-3-211-252-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1409-0575-1409-0575-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fs11263-015-0816-y-10-1007-s11263-015-0816-y-a-a-href-wiki-handle-system-title-handle-system-hdl-a-a-rel-nofollow-class-external-text-href-hdl-handle-net-1721-1-2f104944-1721-1-104944-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-international-journal-of-computer-vision-rft-atitle-imagenet-large-scale-visual-recognition-challenge-rft-volume-115-rft-issue-3-rft-pages-211-252-rft-date-2015-04-11-rft-id-info-3aarxiv-2f1409-0575-rft-id-info-3ahdl-2f1721-1-2f104944-rft-id-info-3adoi-2f10-1007-2fs11263-015-0816-y-rft-aulast-russakovsky-rft-aufirst-olga-rft-au-deng-2c-jia-rft-au-su-2c-hao-rft-au-krause-2c-jonathan-rft-au-satheesh-2c-sanjeev-rft-au-ma-2c-sean-rft-au-huang-2c-zhiheng-rft-au-karpathy-2c-andrej-rft-au-khosla-2c-aditya-rft-au-bernstein-2c-michael-rft-au-berg-2c-alexander-c-rft-au-fei-fei-2c-li-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-75-span-class-mw-cite-backlink-b-a-href-cite-ref-75-a-b-span-span-class-reference-text-ivan-krasin-tom-duerig-neil-alldrin-andreas-veit-sami-abu-el-haija-serge-belongie-david-cai-zheyun-feng-vittorio-ferrari-victor-gomes-abhinav-gupta-dhyanesh-narayanan-chen-sun-gal-chechik-kevin-murphy-openimages-a-public-dataset-for-large-scale-multi-label-and-multi-class-image-classification-2017-available-from-a-rel-nofollow-class-external-free-href-https-github-com-openimages-https-github-com-openimages-a-span-li-li-id-cite-note-76-span-class-mw-cite-backlink-b-a-href-cite-ref-76-a-b-span-span-class-reference-text-vyas-apoorv-et-al-commercial-block-detection-in-broadcast-news-videos-i-proceedings-of-the-2014-indian-conference-on-computer-vision-graphics-and-image-processing-i-acm-2014-span-li-li-id-cite-note-77-span-class-mw-cite-backlink-b-a-href-cite-ref-77-a-b-span-span-class-reference-text-hauptmann-alexander-g-and-michael-j-witbrock-story-segmentation-and-detection-of-commercials-in-broadcast-news-video-i-research-and-technology-advances-in-digital-libraries-1998-adl-98-proceedings-ieee-international-forum-on-i-ieee-1998-span-li-li-id-cite-note-78-span-class-mw-cite-backlink-b-a-href-cite-ref-78-a-b-span-span-class-reference-text-tung-anthony-kh-xin-xu-and-beng-chin-ooi-curler-finding-and-visualizing-nonlinear-correlation-clusters-i-proceedings-of-the-2005-acm-sigmod-international-conference-on-management-of-data-i-acm-2005-span-li-li-id-cite-note-79-span-class-mw-cite-backlink-b-a-href-cite-ref-79-a-b-span-span-class-reference-text-jarrett-kevin-et-al-what-is-the-best-multi-stage-architecture-for-object-recognition-i-computer-vision-2009-ieee-12th-international-conference-on-i-ieee-2009-span-li-li-id-cite-note-80-span-class-mw-cite-backlink-b-a-href-cite-ref-80-a-b-span-span-class-reference-text-lazebnik-svetlana-cordelia-schmid-and-jean-ponce-beyond-bags-of-features-spatial-pyramid-matching-for-recognizing-natural-scene-categories-i-computer-vision-and-pattern-recognition-2006-ieee-computer-society-conference-on-i-vol-2-ieee-2006-span-li-li-id-cite-note-81-span-class-mw-cite-backlink-b-a-href-cite-ref-81-a-b-span-span-class-reference-text-griffin-g-a-holub-and-p-perona-i-caltech-256-object-category-dataset-california-inst-i-technol-tech-rep-7694-2007-online-available-a-rel-nofollow-class-external-free-href-http-authors-library-caltech-edu-7694-http-authors-library-caltech-edu-7694-a-2007-span-li-li-id-cite-note-82-span-class-mw-cite-backlink-b-a-href-cite-ref-82-a-b-span-span-class-reference-text-baeza-yates-ricardo-and-berthier-ribeiro-neto-i-modern-information-retrieval-i-vol-463-new-york-acm-press-1999-span-li-li-id-cite-note-83-span-class-mw-cite-backlink-b-a-href-cite-ref-83-a-b-span-span-class-reference-text-fu-xiping-et-al-nokmeans-non-orthogonal-k-means-hashing-i-computer-vision-accv-2014-i-springer-international-publishing-2014-162-177-span-li-li-id-cite-note-84-span-class-mw-cite-backlink-b-a-href-cite-ref-84-a-b-span-span-class-reference-text-cite-class-citation-journal-heitz-geremy-et-al-2009-shape-based-object-localization-for-descriptive-classification-i-international-journal-of-computer-vision-i-b-84-b-1-40-62-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-142-280-10-1-1-142-280-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fs11263-009-0228-y-10-1007-s11263-009-0228-y-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-international-journal-of-computer-vision-rft-atitle-shape-based-object-localization-for-descriptive-classification-rft-volume-84-rft-issue-1-rft-pages-40-62-rft-date-2009-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-142-280-rft-id-info-3adoi-2f10-1007-2fs11263-009-0228-y-rft-aulast-heitz-rft-aufirst-geremy-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-85-span-class-mw-cite-backlink-b-a-href-cite-ref-85-a-b-span-span-class-reference-text-m-cordts-m-omran-s-ramos-t-scharwachter-m-enzweiler-r-benenson-u-franke-s-roth-and-b-schiele-a-rel-nofollow-class-external-text-href-https-www-cityscapes-dataset-com-wordpress-wp-content-papercite-data-pdf-cordts2015cvprw-pdf-the-cityscapes-dataset-a-in-cvpr-workshop-on-the-future-of-datasets-in-vision-2015-span-li-li-id-cite-note-86-span-class-mw-cite-backlink-b-a-href-cite-ref-86-a-b-span-span-class-reference-text-cite-class-citation-journal-everingham-mark-et-al-2010-the-pascal-visual-object-classes-voc-challenge-i-international-journal-of-computer-vision-i-b-88-b-2-303-338-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fs11263-009-0275-4-10-1007-s11263-009-0275-4-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-international-journal-of-computer-vision-rft-atitle-the-pascal-visual-object-classes-28voc-29-challenge-rft-volume-88-rft-issue-2-rft-pages-303-338-rft-date-2010-rft-id-info-3adoi-2f10-1007-2fs11263-009-0275-4-rft-aulast-everingham-rft-aufirst-mark-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-87-span-class-mw-cite-backlink-b-a-href-cite-ref-87-a-b-span-span-class-reference-text-cite-class-citation-journal-felzenszwalb-pedro-f-et-al-2010-object-detection-with-discriminatively-trained-part-based-models-i-ieee-transactions-on-pattern-analysis-and-machine-intelligence-i-b-32-b-9-1627-1645-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-153-2745-10-1-1-153-2745-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftpami-2009-167-10-1109-tpami-2009-167-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-20634557-20634557-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-pattern-analysis-and-machine-intelligence-rft-atitle-object-detection-with-discriminatively-trained-part-based-models-rft-volume-32-rft-issue-9-rft-pages-1627-1645-rft-date-2010-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-153-2745-rft-id-info-3apmid-2f20634557-rft-id-info-3adoi-2f10-1109-2ftpami-2009-167-rft-aulast-felzenszwalb-rft-aufirst-pedro-f-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-12-88-span-class-mw-cite-backlink-a-href-cite-ref-12-88-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-12-88-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-gong-yunchao-and-svetlana-lazebnik-iterative-quantization-a-procrustean-approach-to-learning-binary-codes-i-computer-vision-and-pattern-recognition-cvpr-2011-ieee-conference-on-i-ieee-2011-span-li-li-id-cite-note-89-span-class-mw-cite-backlink-b-a-href-cite-ref-89-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-http-www-bayeswatch-com-2018-10-09-cinic-cinic-10-dataset-a-i-luke-n-darlow-elliot-j-crowley-antreas-antoniou-amos-j-storkey-2018-cinic-10-is-not-imagenet-or-cifar-10-i-9-october-2018-span-class-reference-accessdate-retrieved-span-class-nowrap-13-november-span-2018-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-luke-n-darlow-2c-elliot-j-crowley-2c-antreas-antoniou-2c-amos-j-storkey-282018-29-cinic-10-is-not-imagenet-or-cifar-10-rft-atitle-cinic-10-dataset-rft-date-2018-10-09-rft-id-http-3a-2f-2fwww-bayeswatch-com-2f2018-2f10-2f09-2fcinic-2f-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-90-span-class-mw-cite-backlink-b-a-href-cite-ref-90-a-b-span-span-class-reference-text-cite-class-citation-a-rel-nofollow-class-external-text-href-https-github-com-zalandoresearch-fashion-mnist-i-fashion-mnist-a-mnist-like-fashion-product-database-benchmark-point-right-i-a-zalando-research-7-october-2017-span-class-reference-accessdate-retrieved-span-class-nowrap-7-october-span-2017-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-fashion-mnist-3a-a-mnist-like-fashion-product-database-benchmark-3apoint-right-rft-pub-zalando-research-rft-date-2017-10-07-rft-id-https-3a-2f-2fgithub-com-2fzalandoresearch-2ffashion-mnist-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-91-span-class-mw-cite-backlink-b-a-href-cite-ref-91-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-http-yaroslavvb-blogspot-com-2011-09-notmnist-dataset-html-notmnist-dataset-a-i-machine-learning-etc-i-8-september-2011-span-class-reference-accessdate-retrieved-span-class-nowrap-13-october-span-2017-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-machine-learning-2c-etc-rft-atitle-notmnist-dataset-rft-date-2011-09-08-rft-id-http-3a-2f-2fyaroslavvb-blogspot-com-2f2011-2f09-2fnotmnist-dataset-html-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-92-span-class-mw-cite-backlink-b-a-href-cite-ref-92-a-b-span-span-class-reference-text-houben-sebastian-et-al-detection-of-traffic-signs-in-real-world-images-the-german-traffic-sign-detection-benchmark-i-neural-networks-ijcnn-the-2013-international-joint-conference-on-i-ieee-2013-span-li-li-id-cite-note-93-span-class-mw-cite-backlink-b-a-href-cite-ref-93-a-b-span-span-class-reference-text-mathias-mayeul-et-al-traffic-sign-recognition-how-far-are-we-from-the-solution-i-neural-networks-ijcnn-the-2013-international-joint-conference-on-i-ieee-2013-span-li-li-id-cite-note-94-span-class-mw-cite-backlink-b-a-href-cite-ref-94-a-b-span-span-class-reference-text-geiger-andreas-philip-lenz-and-raquel-urtasun-are-we-ready-for-autonomous-driving-the-kitti-vision-benchmark-suite-i-computer-vision-and-pattern-recognition-cvpr-2012-ieee-conference-on-i-ieee-2012-span-li-li-id-cite-note-95-span-class-mw-cite-backlink-b-a-href-cite-ref-95-a-b-span-span-class-reference-text-sturm-jurgen-et-al-a-benchmark-for-the-evaluation-of-rgb-d-slam-systems-i-intelligent-robots-and-systems-iros-2012-ieee-rsj-international-conference-on-i-ieee-2012-span-li-li-id-cite-note-96-span-class-mw-cite-backlink-b-a-href-cite-ref-96-a-b-span-span-class-reference-text-chaladze-g-kalatozishvili-l-2017-i-linnaeus-5-dataset-i-i-chaladze-com-i-retrieved-13-november-2017-from-a-rel-nofollow-class-external-free-href-http-chaladze-com-l5-http-chaladze-com-l5-a-span-li-li-id-cite-note-97-span-class-mw-cite-backlink-b-a-href-cite-ref-97-a-b-span-span-class-reference-text-cite-class-citation-journal-kragh-mikkel-f-et-al-2017-a-rel-nofollow-class-external-text-href-https-vision-eng-au-dk-fieldsafe-fieldsafe-dataset-for-obstacle-detection-in-agriculture-a-i-sensors-i-b-17-b-11-2579-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-3390-2fs17112579-10-3390-s17112579-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc5713196-5713196-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-29120383-29120383-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-sensors-rft-atitle-fieldsafe-e2-80-93-dataset-for-obstacle-detection-in-agriculture-rft-volume-17-rft-issue-11-rft-pages-2579-rft-date-2017-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc5713196-rft-id-info-3apmid-2f29120383-rft-id-info-3adoi-2f10-3390-2fs17112579-rft-aulast-kragh-rft-aufirst-mikkel-f-rft-id-https-3a-2f-2fvision-eng-au-dk-2ffieldsafe-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-98-span-class-mw-cite-backlink-b-a-href-cite-ref-98-a-b-span-span-class-reference-text-cite-class-citation-arxiv-afifi-mahmoud-12-november-2017-gender-recognition-and-biometric-identification-using-a-large-dataset-of-hand-images-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1711-04322-1711-04322-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-gender-recognition-and-biometric-identification-using-a-large-dataset-of-hand-images-rft-date-2017-11-12-rft-id-info-3aarxiv-2f1711-04322-rft-aulast-afifi-rft-aufirst-mahmoud-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-99-span-class-mw-cite-backlink-b-a-href-cite-ref-99-a-b-span-span-class-reference-text-cite-class-citation-arxiv-lomonaco-vincenzo-maltoni-davide-18-october-2017-core50-a-new-dataset-and-benchmark-for-continuous-object-recognition-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1705-03550-1705-03550-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-core50-3a-a-new-dataset-and-benchmark-for-continuous-object-recognition-rft-date-2017-10-18-rft-id-info-3aarxiv-2f1705-03550-rft-aulast-lomonaco-rft-aufirst-vincenzo-rft-au-maltoni-2c-davide-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-100-span-class-mw-cite-backlink-b-a-href-cite-ref-100-a-b-span-span-class-reference-text-botta-m-a-giordana-and-l-saitta-learning-fuzzy-concept-definitions-i-fuzzy-systems-1993-second-ieee-international-conference-on-i-ieee-1993-span-li-li-id-cite-note-101-span-class-mw-cite-backlink-b-a-href-cite-ref-101-a-b-span-span-class-reference-text-cite-class-citation-journal-frey-peter-w-slate-david-j-1991-letter-recognition-using-holland-style-adaptive-classifiers-i-machine-learning-i-b-6-b-2-161-182-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fbf00114162-10-1007-bf00114162-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-machine-learning-rft-atitle-letter-recognition-using-holland-style-adaptive-classifiers-rft-volume-6-rft-issue-2-rft-pages-161-182-rft-date-1991-rft-id-info-3adoi-2f10-1007-2fbf00114162-rft-aulast-frey-rft-aufirst-peter-w-rft-au-slate-2c-david-j-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-102-span-class-mw-cite-backlink-b-a-href-cite-ref-102-a-b-span-span-class-reference-text-cite-class-citation-journal-peltonen-jaakko-klami-arto-kaski-samuel-2004-improved-learning-of-riemannian-metrics-for-exploratory-analysis-i-neural-networks-i-b-17-b-8-1087-1100-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-59-4865-10-1-1-59-4865-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-neunet-2004-06-008-10-1016-j-neunet-2004-06-008-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-15555853-15555853-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neural-networks-rft-atitle-improved-learning-of-riemannian-metrics-for-exploratory-analysis-rft-volume-17-rft-issue-8-rft-pages-1087-1100-rft-date-2004-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-59-4865-rft-id-info-3apmid-2f15555853-rft-id-info-3adoi-2f10-1016-2fj-neunet-2004-06-008-rft-aulast-peltonen-rft-aufirst-jaakko-rft-au-klami-2c-arto-rft-au-kaski-2c-samuel-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-103-span-class-mw-cite-backlink-b-a-href-cite-ref-103-a-b-span-span-class-reference-text-williams-ben-h-marc-toussaint-and-amos-j-storkey-i-extracting-motion-primitives-from-natural-handwriting-data-i-springer-berlin-heidelberg-2006-span-li-li-id-cite-note-104-span-class-mw-cite-backlink-b-a-href-cite-ref-104-a-b-span-span-class-reference-text-meier-franziska-et-al-movement-segmentation-using-a-primitive-library-i-intelligent-robots-and-systems-iros-2011-ieee-rsj-international-conference-on-i-ieee-2011-span-li-li-id-cite-note-105-span-class-mw-cite-backlink-b-a-href-cite-ref-105-a-b-span-span-class-reference-text-t-e-de-campos-b-r-babu-and-m-varma-a-rel-nofollow-class-external-text-href-http-personal-ee-surrey-ac-uk-personal-t-decampos-papers-decampos-etal-visapp2009-pdf-character-recognition-in-natural-images-a-in-i-proceedings-of-the-international-conference-on-computer-vision-theory-and-applications-visapp-lisbon-portugal-i-february-2009-span-li-li-id-cite-note-106-span-class-mw-cite-backlink-b-a-href-cite-ref-106-a-b-span-span-class-reference-text-llorens-david-et-al-the-ujipenchars-database-a-pen-based-database-of-isolated-handwritten-characters-i-lrec-i-2008-span-li-li-id-cite-note-107-span-class-mw-cite-backlink-b-a-href-cite-ref-107-a-b-span-span-class-reference-text-cite-class-citation-journal-calderara-simone-prati-andrea-cucchiara-rita-2011-mixtures-of-von-mises-distributions-for-people-trajectory-shape-analysis-i-ieee-transactions-on-circuits-and-systems-for-video-technology-i-b-21-b-4-457-471-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftcsvt-2011-2125550-10-1109-tcsvt-2011-2125550-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-circuits-and-systems-for-video-technology-rft-atitle-mixtures-of-von-mises-distributions-for-people-trajectory-shape-analysis-rft-volume-21-rft-issue-4-rft-pages-457-471-rft-date-2011-rft-id-info-3adoi-2f10-1109-2ftcsvt-2011-2125550-rft-aulast-calderara-rft-aufirst-simone-rft-au-prati-2c-andrea-rft-au-cucchiara-2c-rita-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-108-span-class-mw-cite-backlink-b-a-href-cite-ref-108-a-b-span-span-class-reference-text-guyon-isabelle-et-al-result-analysis-of-the-nips-2003-feature-selection-challenge-i-advances-in-neural-information-processing-systems-i-2004-span-li-li-id-cite-note-109-span-class-mw-cite-backlink-b-a-href-cite-ref-109-a-b-span-span-class-reference-text-cite-class-citation-journal-lecun-yann-et-al-1998-gradient-based-learning-applied-to-document-recognition-i-proceedings-of-the-ieee-i-b-86-b-11-2278-2324-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-32-9552-10-1-1-32-9552-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2f5-726791-10-1109-5-726791-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-proceedings-of-the-ieee-rft-atitle-gradient-based-learning-applied-to-document-recognition-rft-volume-86-rft-issue-11-rft-pages-2278-2324-rft-date-1998-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-32-9552-rft-id-info-3adoi-2f10-1109-2f5-726791-rft-aulast-lecun-rft-aufirst-yann-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-110-span-class-mw-cite-backlink-b-a-href-cite-ref-110-a-b-span-span-class-reference-text-kussul-ernst-and-tatiana-baidyk-improved-method-of-handwritten-digit-recognition-tested-on-mnist-database-i-image-and-vision-computing-i-22-12-2004-971-981-span-li-li-id-cite-note-111-span-class-mw-cite-backlink-b-a-href-cite-ref-111-a-b-span-span-class-reference-text-cite-class-citation-journal-xu-lei-krzyzak-adam-suen-ching-y-1992-methods-of-combining-multiple-classifiers-and-their-applications-to-handwriting-recognition-i-ieee-transactions-on-systems-man-and-cybernetics-i-b-22-b-3-418-435-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2f21-155943-10-1109-21-155943-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-systems-2c-man-and-cybernetics-rft-atitle-methods-of-combining-multiple-classifiers-and-their-applications-to-handwriting-recognition-rft-volume-22-rft-issue-3-rft-pages-418-435-rft-date-1992-rft-id-info-3adoi-2f10-1109-2f21-155943-rft-aulast-xu-rft-aufirst-lei-rft-au-krzy-c5-bcak-2c-adam-rft-au-suen-2c-ching-y-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-112-span-class-mw-cite-backlink-b-a-href-cite-ref-112-a-b-span-span-class-reference-text-alimoglu-fevzi-et-al-combining-multiple-classifiers-for-pen-based-handwritten-digit-recognition-1996-span-li-li-id-cite-note-113-span-class-mw-cite-backlink-b-a-href-cite-ref-113-a-b-span-span-class-reference-text-cite-class-citation-journal-tang-e-ke-et-al-2005-linear-dimensionality-reduction-using-relevance-weighted-lda-i-pattern-recognition-i-b-38-b-4-485-493-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-patcog-2004-09-005-10-1016-j-patcog-2004-09-005-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-pattern-recognition-rft-atitle-linear-dimensionality-reduction-using-relevance-weighted-lda-rft-volume-38-rft-issue-4-rft-pages-485-493-rft-date-2005-rft-id-info-3adoi-2f10-1016-2fj-patcog-2004-09-005-rft-aulast-tang-rft-aufirst-e-ke-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-114-span-class-mw-cite-backlink-b-a-href-cite-ref-114-a-b-span-span-class-reference-text-hong-yi-et-al-learning-a-mixture-of-sparse-distance-metrics-for-classification-and-dimensionality-reduction-i-computer-vision-iccv-2011-ieee-international-conference-on-i-ieee-2011-span-li-li-id-cite-note-115-span-class-mw-cite-backlink-b-a-href-cite-ref-115-a-b-span-span-class-reference-text-cite-class-citation-arxiv-thoma-martin-2017-the-hasyv2-dataset-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1701-08380-1701-08380-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-the-hasyv2-dataset-rft-date-2017-rft-id-info-3aarxiv-2f1701-08380-rft-aulast-thoma-rft-aufirst-martin-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-116-span-class-mw-cite-backlink-b-a-href-cite-ref-116-a-b-span-span-class-reference-text-cite-class-citation-arxiv-karki-manohar-liu-qun-dibiano-robert-basu-saikat-mukhopadhyay-supratik-20-june-2018-pixel-level-reconstruction-and-classification-for-noisy-handwritten-bangla-characters-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1806-08037-1806-08037-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-pixel-level-reconstruction-and-classification-for-noisy-handwritten-bangla-characters-rft-date-2018-06-20-rft-id-info-3aarxiv-2f1806-08037-rft-aulast-karki-rft-aufirst-manohar-rft-au-liu-2c-qun-rft-au-dibiano-2c-robert-rft-au-basu-2c-saikat-rft-au-mukhopadhyay-2c-supratik-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-117-span-class-mw-cite-backlink-b-a-href-cite-ref-117-a-b-span-span-class-reference-text-cite-class-citation-journal-yuan-jiangye-gleason-shaun-s-cheriyadat-anil-m-2013-systematic-benchmarking-of-aerial-image-segmentation-i-ieee-geoscience-and-remote-sensing-letters-i-b-10-b-6-1527-1531-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2013igrsl-10-1527y-2013igrsl-10-1527y-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2flgrs-2013-2261453-10-1109-lgrs-2013-2261453-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-geoscience-and-remote-sensing-letters-rft-atitle-systematic-benchmarking-of-aerial-image-segmentation-rft-volume-10-rft-issue-6-rft-pages-1527-1531-rft-date-2013-rft-id-info-3adoi-2f10-1109-2flgrs-2013-2261453-rft-id-info-3abibcode-2f2013igrsl-10-1527y-rft-aulast-yuan-rft-aufirst-jiangye-rft-au-gleason-2c-shaun-s-rft-au-cheriyadat-2c-anil-m-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-118-span-class-mw-cite-backlink-b-a-href-cite-ref-118-a-b-span-span-class-reference-text-vatsavai-ranga-raju-object-based-image-classification-state-of-the-art-and-computational-challenges-i-proceedings-of-the-2nd-acm-sigspatial-international-workshop-on-analytics-for-big-geospatial-data-i-acm-2013-span-li-li-id-cite-note-119-span-class-mw-cite-backlink-b-a-href-cite-ref-119-a-b-span-span-class-reference-text-butenuth-matthias-et-al-integrating-pedestrian-simulation-tracking-and-event-detection-for-crowd-analysis-i-computer-vision-workshops-iccv-workshops-2011-ieee-international-conference-on-i-ieee-2011-span-li-li-id-cite-note-120-span-class-mw-cite-backlink-b-a-href-cite-ref-120-a-b-span-span-class-reference-text-fradi-hajer-and-jean-luc-dugelay-low-level-crowd-analysis-using-frame-wise-normalized-feature-for-people-counting-i-information-forensics-and-security-wifs-2012-ieee-international-workshop-on-i-ieee-2012-span-li-li-id-cite-note-121-span-class-mw-cite-backlink-b-a-href-cite-ref-121-a-b-span-span-class-reference-text-johnson-brian-alan-ryutaro-tateishi-and-nguyen-thanh-hoan-a-hybrid-pansharpening-approach-and-multiscale-object-based-image-analysis-for-mapping-diseased-pine-and-oak-trees-i-international-journal-of-remote-sensing-i-34-20-2013-6969-6982-span-li-li-id-cite-note-122-span-class-mw-cite-backlink-b-a-href-cite-ref-122-a-b-span-span-class-reference-text-mohd-pozi-muhammad-syafiq-et-al-a-new-classification-model-for-a-class-imbalanced-data-set-using-genetic-programming-and-support-vector-machines-case-study-for-wilt-disease-classification-i-remote-sensing-letters-i-6-7-2015-568-577-span-li-li-id-cite-note-123-span-class-mw-cite-backlink-b-a-href-cite-ref-123-a-b-span-span-class-reference-text-cite-class-citation-journal-johnson-brian-tateishi-ryutaro-xie-zhixiao-2012-using-geographically-weighted-variables-for-image-classification-i-remote-sensing-letters-i-b-3-b-6-491-499-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1080-2f01431161-2011-629637-10-1080-01431161-2011-629637-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-remote-sensing-letters-rft-atitle-using-geographically-weighted-variables-for-image-classification-rft-volume-3-rft-issue-6-rft-pages-491-499-rft-date-2012-rft-id-info-3adoi-2f10-1080-2f01431161-2011-629637-rft-aulast-johnson-rft-aufirst-brian-rft-au-tateishi-2c-ryutaro-rft-au-xie-2c-zhixiao-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-124-span-class-mw-cite-backlink-b-a-href-cite-ref-124-a-b-span-span-class-reference-text-chatterjee-sankhadeep-et-al-forest-type-classification-a-hybrid-nn-ga-model-based-approach-i-information-systems-design-and-intelligent-applications-i-springer-india-2016-227-236-span-li-li-id-cite-note-125-span-class-mw-cite-backlink-b-a-href-cite-ref-125-a-b-span-span-class-reference-text-diegert-carl-a-combinatorial-method-for-tracing-objects-using-semantics-of-their-shape-i-applied-imagery-pattern-recognition-workshop-aipr-2010-ieee-39th-i-ieee-2010-span-li-li-id-cite-note-126-span-class-mw-cite-backlink-b-a-href-cite-ref-126-a-b-span-span-class-reference-text-razakarivony-sebastien-and-frederic-jurie-small-target-detection-combining-foreground-and-background-manifolds-i-iapr-international-conference-on-machine-vision-applications-i-2013-span-li-li-id-cite-note-127-span-class-mw-cite-backlink-b-a-href-cite-ref-127-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-http-explore-digitalglobe-com-spacenet-spacenet-a-i-explore-digitalglobe-com-i-span-class-reference-accessdate-retrieved-span-class-nowrap-13-march-span-2018-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-explore-digitalglobe-com-rft-atitle-spacenet-rft-id-http-3a-2f-2fexplore-digitalglobe-com-2fspacenet-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-128-span-class-mw-cite-backlink-b-a-href-cite-ref-128-a-b-span-span-class-reference-text-cite-class-citation-web-etten-adam-van-5-january-2017-a-rel-nofollow-class-external-text-href-https-medium-com-the-downlinq-getting-started-with-spacenet-data-827fd2ec9f53-getting-started-with-spacenet-data-a-i-the-downlinq-i-span-class-reference-accessdate-retrieved-span-class-nowrap-13-march-span-2018-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-the-downlinq-rft-atitle-getting-started-with-spacenet-data-rft-date-2017-01-05-rft-aulast-etten-rft-aufirst-adam-van-rft-id-https-3a-2f-2fmedium-com-2fthe-downlinq-2fgetting-started-with-spacenet-data-827fd2ec9f53-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-129-span-class-mw-cite-backlink-b-a-href-cite-ref-129-a-b-span-span-class-reference-text-cite-class-citation-book-vakalopoulou-m-bus-n-karantzalosa-k-paragios-n-july-2017-a-rel-nofollow-class-external-text-href-http-ieeexplore-ieee-org-80-abstract-document-8127705-reload-true-i-integrating-edge-boundary-priors-with-classification-scores-for-building-detection-in-very-high-resolution-data-i-a-i-2017-ieee-international-geoscience-and-remote-sensing-symposium-igarss-i-pp-3309-3312-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2figarss-2017-8127705-10-1109-igarss-2017-8127705-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-1-5090-4951-6-title-special-booksources-978-1-5090-4951-6-bdi-978-1-5090-4951-6-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-integrating-edge-2fboundary-priors-with-classification-scores-for-building-detection-in-very-high-resolution-data-rft-pages-3309-3312-rft-date-2017-07-rft-id-info-3adoi-2f10-1109-2figarss-2017-8127705-rft-isbn-978-1-5090-4951-6-rft-aulast-vakalopoulou-rft-aufirst-m-rft-au-bus-2c-n-rft-au-karantzalosa-2c-k-rft-au-paragios-2c-n-rft-id-http-3a-2f-2fieeexplore-ieee-org-3a80-2fabstract-2fdocument-2f8127705-2f-3freload-3dtrue-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-130-span-class-mw-cite-backlink-b-a-href-cite-ref-130-a-b-span-span-class-reference-text-cite-class-citation-book-yang-yi-newsam-shawn-2010-i-bag-of-visual-words-and-spatial-extensions-for-land-use-classification-i-i-proceedings-of-the-18th-sigspatial-international-conference-on-advances-in-geographic-information-systems-gis-10-i-new-york-new-york-usa-acm-press-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1145-2f1869790-1869829-10-1145-1869790-1869829-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-9781450304283-title-special-booksources-9781450304283-bdi-9781450304283-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-bag-of-visual-words-and-spatial-extensions-for-land-use-classification-rft-place-new-york-2c-new-york-2c-usa-rft-pub-acm-press-rft-date-2010-rft-id-info-3adoi-2f10-1145-2f1869790-1869829-rft-isbn-9781450304283-rft-aulast-yang-rft-aufirst-yi-rft-au-newsam-2c-shawn-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-1-131-span-class-mw-cite-backlink-a-href-cite-ref-1-131-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-1-131-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-book-basu-saikat-ganguly-sangram-mukhopadhyay-supratik-dibiano-robert-karki-manohar-nemani-ramakrishna-3-november-2015-a-rel-nofollow-class-external-text-href-http-dl-acm-org-citation-cfm-id-2820783-2820816-i-deepsat-a-learning-framework-for-satellite-imagery-i-a-acm-p-37-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1145-2f2820783-2820816-10-1145-2820783-2820816-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-9781450339674-title-special-booksources-9781450339674-bdi-9781450339674-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-deepsat-3a-a-learning-framework-for-satellite-imagery-rft-pages-37-rft-pub-acm-rft-date-2015-11-03-rft-id-info-3adoi-2f10-1145-2f2820783-2820816-rft-isbn-9781450339674-rft-aulast-basu-rft-aufirst-saikat-rft-au-ganguly-2c-sangram-rft-au-mukhopadhyay-2c-supratik-rft-au-dibiano-2c-robert-rft-au-karki-2c-manohar-rft-au-nemani-2c-ramakrishna-rft-id-http-3a-2f-2fdl-acm-org-2fcitation-cfm-3fid-3d2820783-2820816-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-132-span-class-mw-cite-backlink-b-a-href-cite-ref-132-a-b-span-span-class-reference-text-cite-class-citation-journal-quantum-simulations-of-an-electron-in-a-two-dimensional-potential-well-16-may-2018-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-4224-2fphysreva-96-042113-data-10-4224-physreva-96-042113-data-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-atitle-quantum-simulations-of-an-electron-in-a-two-dimensional-potential-well-rft-date-2018-05-16-rft-id-info-3adoi-2f10-4224-2fphysreva-96-042113-data-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-133-span-class-mw-cite-backlink-b-a-href-cite-ref-133-a-b-span-span-class-reference-text-rohrbach-marcus-et-al-a-database-for-fine-grained-activity-detection-of-cooking-activities-i-computer-vision-and-pattern-recognition-cvpr-2012-ieee-conference-on-i-ieee-2012-span-li-li-id-cite-note-134-span-class-mw-cite-backlink-b-a-href-cite-ref-134-a-b-span-span-class-reference-text-kuehne-hilde-ali-arslan-and-thomas-serre-the-language-of-actions-recovering-the-syntax-and-semantics-of-goal-directed-human-activities-i-proceedings-of-the-ieee-conference-on-computer-vision-and-pattern-recognition-i-2014-span-li-li-id-cite-note-135-span-class-mw-cite-backlink-b-a-href-cite-ref-135-a-b-span-span-class-reference-text-sviatoslav-voloshynovskiy-et-al-towards-reproducible-results-in-authentication-based-on-physical-non-cloneable-functions-the-forensic-authentication-microstructure-optical-set-famos-i-proc-proceedings-of-ieee-international-workshop-on-information-forensics-and-security-i-2012-span-li-li-id-cite-note-136-span-class-mw-cite-backlink-b-a-href-cite-ref-136-a-b-span-span-class-reference-text-olga-taran-and-shideh-rezaeifar-et-al-a-rel-nofollow-class-external-text-href-https-archive-ouverte-unige-ch-unige-97444-attachment01-pharmapack-mobile-fine-grained-recognition-of-pharma-packages-a-i-proc-european-signal-processing-conference-eusipco-i-2017-span-li-li-id-cite-note-137-span-class-mw-cite-backlink-b-a-href-cite-ref-137-a-b-span-span-class-reference-text-khosla-aditya-et-al-novel-dataset-for-fine-grained-image-categorization-stanford-dogs-i-proc-cvpr-workshop-on-fine-grained-visual-categorization-fgvc-i-2011-span-li-li-id-cite-note-7-138-span-class-mw-cite-backlink-a-href-cite-ref-7-138-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-7-138-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-parkhi-omkar-m-et-al-cats-and-dogs-i-computer-vision-and-pattern-recognition-cvpr-2012-ieee-conference-on-i-ieee-2012-span-li-li-id-cite-note-razavian-ali-2014-139-span-class-mw-cite-backlink-a-href-cite-ref-razavian-ali-2014-139-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-razavian-ali-2014-139-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-razavian-ali-et-al-cnn-features-off-the-shelf-an-astounding-baseline-for-recognition-i-proceedings-of-the-ieee-conference-on-computer-vision-and-pattern-recognition-workshops-i-2014-span-li-li-id-cite-note-140-span-class-mw-cite-backlink-b-a-href-cite-ref-140-a-b-span-span-class-reference-text-cite-class-citation-journal-ortega-michael-et-al-1998-supporting-ranked-boolean-similarity-queries-in-mars-i-ieee-transactions-on-knowledge-and-data-engineering-i-b-10-b-6-905-925-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-36-6079-10-1-1-36-6079-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2f69-738357-10-1109-69-738357-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-knowledge-and-data-engineering-rft-atitle-supporting-ranked-boolean-similarity-queries-in-mars-rft-volume-10-rft-issue-6-rft-pages-905-925-rft-date-1998-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-36-6079-rft-id-info-3adoi-2f10-1109-2f69-738357-rft-aulast-ortega-rft-aufirst-michael-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-141-span-class-mw-cite-backlink-b-a-href-cite-ref-141-a-b-span-span-class-reference-text-he-xuming-richard-s-zemel-and-miguel-a-carreira-perpinan-multiscale-conditional-random-fields-for-image-labeling-i-computer-vision-and-pattern-recognition-2004-cvpr-2004-proceedings-of-the-2004-ieee-computer-society-conference-on-i-vol-2-ieee-2004-span-li-li-id-cite-note-142-span-class-mw-cite-backlink-b-a-href-cite-ref-142-a-b-span-span-class-reference-text-deneke-tewodros-et-al-video-transcoding-time-prediction-for-proactive-load-balancing-multimedia-and-expo-icme-2014-ieee-international-conference-on-ieee-2014-span-li-li-id-cite-note-143-span-class-mw-cite-backlink-b-a-href-cite-ref-143-a-b-span-span-class-reference-text-cite-class-citation-arxiv-ting-hao-kenneth-huang-francis-ferraro-nasrin-mostafazadeh-ishan-misra-aishwarya-agrawal-jacob-devlin-ross-girshick-xiaodong-he-pushmeet-kohli-dhruv-batra-c-lawrence-zitnick-devi-parikh-lucy-vanderwende-michel-galley-margaret-mitchell-13-april-2016-visual-storytelling-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1604-03968-1604-03968-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cl-cs-cl-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-visual-storytelling-rft-date-2016-04-13-rft-id-info-3aarxiv-2f1604-03968-rft-au-ting-hao-28kenneth-29-huang-2c-francis-ferraro-2c-nasrin-mostafazadeh-2c-ishan-misra-2c-aishwarya-agrawal-2c-jacob-devlin-2c-ross-girshick-2c-xiaodong-he-2c-pushmeet-kohli-2c-dhruv-batra-2c-c-lawrence-zitnick-2c-devi-parikh-2c-lucy-vanderwende-2c-michel-galley-2c-margaret-mitchell-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-span-class-cs1-maint-citation-comment-cs1-maint-multiple-names-authors-list-a-href-wiki-category-cs1-maint-multiple-names-authors-list-title-category-cs1-maint-multiple-names-authors-list-link-a-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-144-span-class-mw-cite-backlink-b-a-href-cite-ref-144-a-b-span-span-class-reference-text-wah-catherine-et-al-the-caltech-ucsd-birds-200-2011-dataset-2011-span-li-li-id-cite-note-145-span-class-mw-cite-backlink-b-a-href-cite-ref-145-a-b-span-span-class-reference-text-duan-kun-et-al-a-rel-nofollow-class-external-text-href-http-vision-soic-indiana-edu-papers-attributes2012cvpr-pdf-discovering-localized-attributes-for-fine-grained-recognition-a-i-computer-vision-and-pattern-recognition-cvpr-2012-ieee-conference-on-i-ieee-2012-span-li-li-id-cite-note-146-span-class-mw-cite-backlink-b-a-href-cite-ref-146-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-research-google-com-youtube8m-youtube-8m-dataset-a-i-research-google-com-i-span-class-reference-accessdate-retrieved-span-class-nowrap-1-october-span-2016-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-research-google-com-rft-atitle-youtube-8m-dataset-rft-id-https-3a-2f-2fresearch-google-com-2fyoutube8m-2f-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-147-span-class-mw-cite-backlink-b-a-href-cite-ref-147-a-b-span-span-class-reference-text-cite-class-citation-arxiv-abu-el-haija-sami-kothari-nisarg-lee-joonseok-natsev-paul-toderici-george-varadarajan-balakrishnan-vijayanarasimhan-sudheendra-27-september-2016-youtube-8m-a-large-scale-video-classification-benchmark-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1609-08675-1609-08675-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-youtube-8m-3a-a-large-scale-video-classification-benchmark-rft-date-2016-09-27-rft-id-info-3aarxiv-2f1609-08675-rft-au-abu-el-haija-2c-sami-rft-au-kothari-2c-nisarg-rft-au-lee-2c-joonseok-rft-au-natsev-2c-paul-rft-au-toderici-2c-george-rft-au-varadarajan-2c-balakrishnan-rft-au-vijayanarasimhan-2c-sudheendra-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-148-span-class-mw-cite-backlink-b-a-href-cite-ref-148-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-http-mmcommons-org-yfcc100m-dataset-a-i-mmcommons-org-i-a-href-w-index-php-title-yahoo-icsi-llnl-action-edit-redlink-1-class-new-title-yahoo-icsi-llnl-page-does-not-exist-yahoo-icsi-llnl-a-span-class-reference-accessdate-retrieved-span-class-nowrap-1-june-span-2017-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-mmcommons-org-rft-atitle-yfcc100m-dataset-rft-id-http-3a-2f-2fmmcommons-org-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-149-span-class-mw-cite-backlink-b-a-href-cite-ref-149-a-b-span-span-class-reference-text-cite-class-citation-journal-bart-thomee-david-a-shamma-gerald-friedland-benjamin-elizalde-karl-ni-douglas-poland-damian-borth-li-jia-li-25-april-2016-yfcc100m-the-new-data-in-multimedia-research-i-communications-of-the-acm-i-b-59-b-2-64-73-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1503-01817-1503-01817-a-span-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-1985cacm-28-22s-1985cacm-28-22s-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1145-2f2812802-10-1145-2812802-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-communications-of-the-acm-rft-atitle-yfcc100m-3a-the-new-data-in-multimedia-research-rft-volume-59-rft-issue-2-rft-pages-64-73-rft-date-2016-04-25-rft-id-info-3aarxiv-2f1503-01817-rft-id-info-3adoi-2f10-1145-2f2812802-rft-id-info-3abibcode-2f1985cacm-28-22s-rft-au-bart-thomee-rft-au-david-a-shamma-rft-au-gerald-friedland-rft-au-benjamin-elizalde-rft-au-karl-ni-rft-au-douglas-poland-rft-au-damian-borth-rft-au-li-jia-li-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-150-span-class-mw-cite-backlink-b-a-href-cite-ref-150-a-b-span-span-class-reference-text-y-baveye-e-dellandrea-c-chamaret-and-l-chen-a-rel-nofollow-class-external-text-href-https-hal-archives-ouvertes-fr-hal-01375518-document-liris-accede-a-video-database-for-affective-content-analysis-a-in-ieee-transactions-on-affective-computing-2015-span-li-li-id-cite-note-151-span-class-mw-cite-backlink-b-a-href-cite-ref-151-a-b-span-span-class-reference-text-y-baveye-e-dellandrea-c-chamaret-and-l-chen-a-rel-nofollow-class-external-text-href-https-hal-archives-ouvertes-fr-hal-01193144-document-deep-learning-vs-kernel-methods-performance-for-emotion-prediction-in-videos-a-in-2015-humaine-association-conference-on-affective-computing-and-intelligent-interaction-acii-2015-span-li-li-id-cite-note-152-span-class-mw-cite-backlink-b-a-href-cite-ref-152-a-b-span-span-class-reference-text-m-sjoberg-y-baveye-h-wang-v-l-quang-b-ionescu-e-dellandrea-m-schedl-c-h-demarty-and-l-chen-a-rel-nofollow-class-external-text-href-https-www-researchgate-net-profile-hanli-wang2-publication-309704559-the-mediaeval-2015-affective-impact-of-movies-task-links-581dada308ae12715af33bc8-the-mediaeval-2015-affective-impact-of-movies-task-pdf-the-mediaeval-2015-affective-impact-of-movies-task-a-in-mediaeval-2015-workshop-2015-span-li-li-id-cite-note-153-span-class-mw-cite-backlink-b-a-href-cite-ref-153-a-b-span-span-class-reference-text-s-johnson-and-m-everingham-a-rel-nofollow-class-external-text-href-http-sam-johnson-io-research-publications-johnson10bmvc-pdf-clustered-pose-and-nonlinear-appearance-models-for-human-pose-estimation-a-in-proceedings-of-the-21st-british-machine-vision-conference-bmvc2010-span-li-li-id-cite-note-154-span-class-mw-cite-backlink-b-a-href-cite-ref-154-a-b-span-span-class-reference-text-s-johnson-and-m-everingham-a-rel-nofollow-class-external-text-href-http-sam-johnson-io-research-publications-johnson11cvpr-pdf-learning-effective-human-pose-estimation-from-inaccurate-annotation-a-in-proceedings-of-ieee-conference-on-computer-vision-and-pattern-recognition-cvpr2011-span-li-li-id-cite-note-155-span-class-mw-cite-backlink-b-a-href-cite-ref-155-a-b-span-span-class-reference-text-cite-class-citation-arxiv-afifi-mahmoud-hussain-khaled-f-2-november-2017-the-achievement-of-higher-flexibility-in-multiple-choice-based-tests-using-image-classification-techniques-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1711-00972-1711-00972-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-the-achievement-of-higher-flexibility-in-multiple-choice-based-tests-using-image-classification-techniques-rft-date-2017-11-02-rft-id-info-3aarxiv-2f1711-00972-rft-aulast-afifi-rft-aufirst-mahmoud-rft-au-hussain-2c-khaled-f-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-156-span-class-mw-cite-backlink-b-a-href-cite-ref-156-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-sites-google-com-view-mcq-dataset-mcqe-dataset-mcq-dataset-a-i-sites-google-com-i-span-class-reference-accessdate-retrieved-span-class-nowrap-18-november-span-2017-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-sites-google-com-rft-atitle-mcq-dataset-rft-id-https-3a-2f-2fsites-google-com-2fview-2fmcq-dataset-2fmcqe-dataset-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-157-span-class-mw-cite-backlink-b-a-href-cite-ref-157-a-b-span-span-class-reference-text-cite-class-citation-book-taj-eddin-i-a-t-f-afifi-m-korashy-m-hamdy-d-nasser-m-derbaz-s-july-2016-a-rel-nofollow-class-external-text-href-http-ieeexplore-ieee-org-abstract-document-7544020-i-a-new-compression-technique-for-surveillance-videos-evaluation-using-new-dataset-i-a-i-2016-sixth-international-conference-on-digital-information-and-communication-technology-and-its-applications-dictap-i-pp-159-164-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2fdictap-2016-7544020-10-1109-dictap-2016-7544020-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-1-4673-9609-7-title-special-booksources-978-1-4673-9609-7-bdi-978-1-4673-9609-7-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-a-new-compression-technique-for-surveillance-videos-3a-evaluation-using-new-dataset-rft-pages-159-164-rft-date-2016-07-rft-id-info-3adoi-2f10-1109-2fdictap-2016-7544020-rft-isbn-978-1-4673-9609-7-rft-aulast-taj-eddin-rft-aufirst-i-a-t-f-rft-au-afifi-2c-m-rft-au-korashy-2c-m-rft-au-hamdy-2c-d-rft-au-nasser-2c-m-rft-au-derbaz-2c-s-rft-id-http-3a-2f-2fieeexplore-ieee-org-2fabstract-2fdocument-2f7544020-2f-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-tabaknorouzzadeh2018-158-span-class-mw-cite-backlink-b-a-href-cite-ref-tabaknorouzzadeh2018-158-0-a-b-span-span-class-reference-text-cite-class-citation-journal-tabak-michael-a-norouzzadeh-mohammad-s-wolfson-david-w-sweeney-steven-j-vercauteren-kurt-c-snow-nathan-p-halseth-joseph-m-di-salvo-paul-a-lewis-jesse-s-white-michael-d-teton-ben-beasley-james-c-schlichting-peter-e-boughton-raoul-k-wight-bethany-newkirk-eric-s-ivan-jacob-s-odell-eric-a-brook-ryan-k-lukacs-paul-m-moeller-anna-k-mandeville-elizabeth-g-clune-jeff-miller-ryan-s-photopoulou-theoni-2018-machine-learning-to-classify-animal-species-in-camera-trap-images-applications-in-ecology-i-methods-in-ecology-and-evolution-i-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1111-2f2041-210x-13120-10-1111-2041-210x-13120-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-2041-210x-2041-210x-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-methods-in-ecology-and-evolution-rft-atitle-machine-learning-to-classify-animal-species-in-camera-trap-images-3a-applications-in-ecology-rft-date-2018-rft-id-info-3adoi-2f10-1111-2f2041-210x-13120-rft-issn-2041-210x-rft-aulast-tabak-rft-aufirst-michael-a-rft-au-norouzzadeh-2c-mohammad-s-rft-au-wolfson-2c-david-w-rft-au-sweeney-2c-steven-j-rft-au-vercauteren-2c-kurt-c-rft-au-snow-2c-nathan-p-rft-au-halseth-2c-joseph-m-rft-au-di-salvo-2c-paul-a-rft-au-lewis-2c-jesse-s-rft-au-white-2c-michael-d-rft-au-teton-2c-ben-rft-au-beasley-2c-james-c-rft-au-schlichting-2c-peter-e-rft-au-boughton-2c-raoul-k-rft-au-wight-2c-bethany-rft-au-newkirk-2c-eric-s-rft-au-ivan-2c-jacob-s-rft-au-odell-2c-eric-a-rft-au-brook-2c-ryan-k-rft-au-lukacs-2c-paul-m-rft-au-moeller-2c-anna-k-rft-au-mandeville-2c-elizabeth-g-rft-au-clune-2c-jeff-rft-au-miller-2c-ryan-s-rft-au-photopoulou-2c-theoni-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-159-span-class-mw-cite-backlink-b-a-href-cite-ref-159-a-b-span-span-class-reference-text-cite-class-citation-journal-taj-eddin-islam-a-t-f-afifi-mahmoud-korashy-mostafa-ahmed-ali-h-ng-yoke-cheng-hernandez-evelyng-abdel-latif-salma-m-november-2017-a-rel-nofollow-class-external-text-href-https-www-spiedigitallibrary-org-journals-journal-of-electronic-imaging-volume-26-issue-6-060501-can-we-see-photosynthesis-magnifying-the-tiny-color-changes-of-10-1117-1-jei-26-6-060501-short-can-we-see-photosynthesis-magnifying-the-tiny-color-changes-of-plant-green-leaves-using-eulerian-video-magnification-a-i-journal-of-electronic-imaging-i-b-26-b-6-060501-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1706-03867-1706-03867-a-span-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2017jei-26f0501t-2017jei-26f0501t-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1117-2f1-jei-26-6-060501-10-1117-1-jei-26-6-060501-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-1017-9909-1017-9909-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-electronic-imaging-rft-atitle-can-we-see-photosynthesis-3f-magnifying-the-tiny-color-changes-of-plant-green-leaves-using-eulerian-video-magnification-rft-volume-26-rft-issue-6-rft-pages-060501-rft-date-2017-11-rft-id-info-3aarxiv-2f1706-03867-rft-issn-1017-9909-rft-id-info-3adoi-2f10-1117-2f1-jei-26-6-060501-rft-id-info-3abibcode-2f2017jei-26f0501t-rft-aulast-taj-eddin-rft-aufirst-islam-a-t-f-rft-au-afifi-2c-mahmoud-rft-au-korashy-2c-mostafa-rft-au-ahmed-2c-ali-h-rft-au-ng-2c-yoke-cheng-rft-au-hernandez-2c-evelyng-rft-au-abdel-latif-2c-salma-m-rft-id-https-3a-2f-2fwww-spiedigitallibrary-org-2fjournals-2fjournal-of-electronic-imaging-2fvolume-26-2fissue-6-2f060501-2fcan-we-see-photosynthesis-magnifying-the-tiny-color-changes-of-2f10-1117-2f1-jei-26-6-060501-short-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-160-span-class-mw-cite-backlink-b-a-href-cite-ref-160-a-b-span-span-class-reference-text-mcauley-julian-et-al-image-based-recommendations-on-styles-and-substitutes-i-proceedings-of-the-38th-international-acm-sigir-conference-on-research-and-development-in-information-retrieval-i-acm-2015-span-li-li-id-cite-note-161-span-class-mw-cite-backlink-b-a-href-cite-ref-161-a-b-span-span-class-reference-text-cite-class-citation-journal-ganesan-kavita-zhai-chengxiang-2012-opinion-based-entity-ranking-i-information-retrieval-i-b-15-b-2-116-150-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fs10791-011-9174-8-10-1007-s10791-011-9174-8-a-a-href-wiki-handle-system-title-handle-system-hdl-a-a-rel-nofollow-class-external-text-href-hdl-handle-net-2142-2f15252-2142-15252-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-information-retrieval-rft-atitle-opinion-based-entity-ranking-rft-volume-15-rft-issue-2-rft-pages-116-150-rft-date-2012-rft-id-info-3ahdl-2f2142-2f15252-rft-id-info-3adoi-2f10-1007-2fs10791-011-9174-8-rft-aulast-ganesan-rft-aufirst-kavita-rft-au-zhai-2c-chengxiang-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-162-span-class-mw-cite-backlink-b-a-href-cite-ref-162-a-b-span-span-class-reference-text-lv-yuanhua-dimitrios-lymberopoulos-and-qiang-wu-an-exploration-of-ranking-heuristics-in-mobile-local-search-i-proceedings-of-the-35th-international-acm-sigir-conference-on-research-and-development-in-information-retrieval-i-acm-2012-span-li-li-id-cite-note-163-span-class-mw-cite-backlink-b-a-href-cite-ref-163-a-b-span-span-class-reference-text-cite-class-citation-journal-harper-f-maxwell-konstan-joseph-a-2015-the-movielens-datasets-history-and-context-i-acm-transactions-on-interactive-intelligent-systems-tiis-i-b-5-b-4-19-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-acm-transactions-on-interactive-intelligent-systems-28tiis-29-rft-atitle-the-movielens-datasets-3a-history-and-context-rft-volume-5-rft-issue-4-rft-pages-19-rft-date-2015-rft-aulast-harper-rft-aufirst-f-maxwell-rft-au-konstan-2c-joseph-a-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-164-span-class-mw-cite-backlink-b-a-href-cite-ref-164-a-b-span-span-class-reference-text-koenigstein-noam-gideon-dror-and-yehuda-koren-yahoo-music-recommendations-modeling-music-ratings-with-temporal-dynamics-and-item-taxonomy-i-proceedings-of-the-fifth-acm-conference-on-recommender-systems-i-acm-2011-span-li-li-id-cite-note-165-span-class-mw-cite-backlink-b-a-href-cite-ref-165-a-b-span-span-class-reference-text-mcfee-brian-et-al-the-million-song-dataset-challenge-i-proceedings-of-the-21st-international-conference-companion-on-world-wide-web-i-acm-2012-span-li-li-id-cite-note-166-span-class-mw-cite-backlink-b-a-href-cite-ref-166-a-b-span-span-class-reference-text-bohanec-marko-and-vladislav-rajkovic-knowledge-acquisition-and-explanation-for-multi-attribute-decision-making-i-8th-intl-workshop-on-expert-systems-and-their-applications-i-1988-span-li-li-id-cite-note-167-span-class-mw-cite-backlink-b-a-href-cite-ref-167-a-b-span-span-class-reference-text-tan-peter-j-and-david-l-dowe-mml-inference-of-decision-graphs-with-multi-way-joins-i-australian-joint-conference-on-artificial-intelligence-i-2002-span-li-li-id-cite-note-168-span-class-mw-cite-backlink-b-a-href-cite-ref-168-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-http-googleresearch-blogspot-com-2012-02-quantifying-comedy-on-youtube-why-html-quantifying-comedy-on-youtube-why-the-number-of-o-s-in-your-lol-matter-a-i-google-research-blog-i-span-class-reference-accessdate-retrieved-span-class-nowrap-26-february-span-2016-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-google-research-blog-rft-atitle-quantifying-comedy-on-youtube-3a-why-the-number-of-o-27s-in-your-lol-matter-rft-id-http-3a-2f-2fgoogleresearch-blogspot-com-2f2012-2f02-2fquantifying-comedy-on-youtube-why-html-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-169-span-class-mw-cite-backlink-b-a-href-cite-ref-169-a-b-span-span-class-reference-text-kim-byung-joo-a-classifier-for-big-data-i-convergence-and-hybrid-information-technology-i-springer-berlin-heidelberg-2012-505-512-span-li-li-id-cite-note-170-span-class-mw-cite-backlink-b-a-href-cite-ref-170-a-b-span-span-class-reference-text-cite-class-citation-journal-perezgonzalez-jose-d-gilbey-andrew-2011-predicting-skytrax-airport-rankings-from-customer-reviews-i-journal-of-airport-management-i-b-5-b-4-335-339-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-airport-management-rft-atitle-predicting-skytrax-airport-rankings-from-customer-reviews-rft-volume-5-rft-issue-4-rft-pages-335-339-rft-date-2011-rft-aulast-p-c3-a9rezgonz-c3-a1lez-rft-aufirst-jose-d-rft-au-gilbey-2c-andrew-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-171-span-class-mw-cite-backlink-b-a-href-cite-ref-171-a-b-span-span-class-reference-text-loh-wei-yin-and-yu-shan-shih-split-selection-methods-for-classification-trees-i-statistica-sinica-i-1997-815-840-span-li-li-id-cite-note-172-span-class-mw-cite-backlink-b-a-href-cite-ref-172-a-b-span-span-class-reference-text-cite-class-citation-journal-lim-tjen-sien-loh-wei-yin-shih-yu-shan-2000-a-comparison-of-prediction-accuracy-complexity-and-training-time-of-thirty-three-old-and-new-classification-algorithms-i-machine-learning-i-b-40-b-3-203-228-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1023-2fa-3a1007608224229-10-1023-a-1007608224229-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-machine-learning-rft-atitle-a-comparison-of-prediction-accuracy-2c-complexity-2c-and-training-time-of-thirty-three-old-and-new-classification-algorithms-rft-volume-40-rft-issue-3-rft-pages-203-228-rft-date-2000-rft-id-info-3adoi-2f10-1023-2fa-3a1007608224229-rft-aulast-lim-rft-aufirst-tjen-sien-rft-au-loh-2c-wei-yin-rft-au-shih-2c-yu-shan-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-173-span-class-mw-cite-backlink-b-a-href-cite-ref-173-a-b-span-span-class-reference-text-dermouche-mohamed-et-al-a-joint-model-for-topic-sentiment-evolution-over-time-i-data-mining-icdm-2014-ieee-international-conference-on-i-ieee-2014-span-li-li-id-cite-note-174-span-class-mw-cite-backlink-b-a-href-cite-ref-174-a-b-span-span-class-reference-text-cite-class-citation-journal-rose-tony-stevenson-mark-whitehead-miles-2002-the-reuters-corpus-volume-1-from-yesterday-s-news-to-tomorrow-s-language-resources-i-lrec-i-b-2-b-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-lrec-rft-atitle-the-reuters-corpus-volume-1-from-yesterday-27s-news-to-tomorrow-27s-language-resources-rft-volume-2-rft-date-2002-rft-aulast-rose-rft-aufirst-tony-rft-au-stevenson-2c-mark-rft-au-whitehead-2c-miles-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-175-span-class-mw-cite-backlink-b-a-href-cite-ref-175-a-b-span-span-class-reference-text-amini-massih-nicolas-usunier-and-cyril-goutte-learning-from-multiple-partially-observed-views-an-application-to-multilingual-text-categorization-i-advances-in-neural-information-processing-systems-i-2009-span-li-li-id-cite-note-176-span-class-mw-cite-backlink-b-a-href-cite-ref-176-a-b-span-span-class-reference-text-liu-ming-et-al-vrca-a-clustering-algorithm-for-massive-amount-of-texts-i-proceedings-of-the-24th-international-conference-on-artificial-intelligence-i-aaai-press-2015-span-li-li-id-cite-note-177-span-class-mw-cite-backlink-b-a-href-cite-ref-177-a-b-span-span-class-reference-text-al-harbi-s-almuhareb-a-al-thubaity-a-khorsheed-m-s-and-al-rajeh-a-2008-automatic-arabic-text-classification-in-i-proceedings-of-the-9th-international-conference-on-the-statistical-analysis-of-textual-data-lyon-france-i-span-li-li-id-cite-note-178-span-class-mw-cite-backlink-b-a-href-cite-ref-178-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-github-com-dstl-re3d-relationship-and-entity-extraction-evaluation-dataset-dstl-re3d-a-17-december-2018-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-relationship-and-entity-extraction-evaluation-dataset-3a-dstl-2fre3d-rft-date-2018-12-17-rft-id-https-3a-2f-2fgithub-com-2fdstl-2fre3d-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-179-span-class-mw-cite-backlink-b-a-href-cite-ref-179-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-kaggle-com-therohk-examine-the-examiner-the-examiner-spamclickbait-news-dataset-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-the-examiner-spamclickbait-news-dataset-rft-id-https-3a-2f-2fwww-kaggle-com-2ftherohk-2fexamine-the-examiner-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-180-span-class-mw-cite-backlink-b-a-href-cite-ref-180-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-kaggle-com-therohk-million-headlines-a-million-news-headlines-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-a-million-news-headlines-rft-id-https-3a-2f-2fwww-kaggle-com-2ftherohk-2fmillion-headlines-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-181-span-class-mw-cite-backlink-b-a-href-cite-ref-181-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-kaggle-com-therohk-global-news-week-one-week-of-global-news-feeds-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-one-week-of-global-news-feeds-rft-id-https-3a-2f-2fwww-kaggle-com-2ftherohk-2fglobal-news-week-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-182-span-class-mw-cite-backlink-b-a-href-cite-ref-182-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-doi-org-10-7910-dvn-xdb74w-reuters-news-wire-archive-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-reuters-news-wire-archive-rft-id-https-3a-2f-2fdoi-org-2f10-7910-2fdvn-2fxdb74w-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-183-span-class-mw-cite-backlink-b-a-href-cite-ref-183-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-kaggle-com-therohk-ireland-historical-news-irishtimes-the-waxy-wany-news-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-irishtimes-the-waxy-wany-news-rft-id-https-3a-2f-2fwww-kaggle-com-2ftherohk-2fireland-historical-news-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-184-span-class-mw-cite-backlink-b-a-href-cite-ref-184-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-kaggle-com-rmisra-news-headlines-dataset-for-sarcasm-detection-news-headlines-dataset-for-sarcasm-detection-a-i-kaggle-com-i-span-class-reference-accessdate-retrieved-span-class-nowrap-27-april-span-2019-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-kaggle-com-rft-atitle-news-headlines-dataset-for-sarcasm-detection-rft-id-https-3a-2f-2fkaggle-com-2frmisra-2fnews-headlines-dataset-for-sarcasm-detection-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-185-span-class-mw-cite-backlink-b-a-href-cite-ref-185-a-b-span-span-class-reference-text-klimt-bryan-and-yiming-yang-introducing-the-enron-corpus-i-ceas-i-2004-span-li-li-id-cite-note-186-span-class-mw-cite-backlink-b-a-href-cite-ref-186-a-b-span-span-class-reference-text-kossinets-gueorgi-jon-kleinberg-and-duncan-watts-the-structure-of-information-pathways-in-a-social-communication-network-i-proceedings-of-the-14th-acm-sigkdd-international-conference-on-knowledge-discovery-and-data-mining-i-acm-2008-span-li-li-id-cite-note-187-span-class-mw-cite-backlink-b-a-href-cite-ref-187-a-b-span-span-class-reference-text-cite-class-citation-conference-androutsopoulos-ion-koutsias-john-chandrinos-konstantinos-v-paliouras-george-spyropoulos-constantine-d-2000-an-evaluation-of-naive-bayesian-anti-spam-filtering-in-potamias-g-moustakis-v-van-someren-m-eds-i-proceedings-of-the-workshop-on-machine-learning-in-the-new-information-age-i-11th-european-conference-on-machine-learning-barcelona-spain-b-11-b-pp-9-17-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-cs-0006013-cs-0006013-a-span-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2000cs-6013a-2000cs-6013a-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-conference-rft-atitle-an-evaluation-of-naive-bayesian-anti-spam-filtering-rft-btitle-proceedings-of-the-workshop-on-machine-learning-in-the-new-information-age-rft-pages-9-17-rft-date-2000-rft-id-info-3aarxiv-2fcs-2f0006013-rft-id-info-3abibcode-2f2000cs-6013a-rft-aulast-androutsopoulos-rft-aufirst-ion-rft-au-koutsias-2c-john-rft-au-chandrinos-2c-konstantinos-v-rft-au-paliouras-2c-george-rft-au-spyropoulos-2c-constantine-d-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-188-span-class-mw-cite-backlink-b-a-href-cite-ref-188-a-b-span-span-class-reference-text-cite-class-citation-journal-bratko-andrej-et-al-2006-spam-filtering-using-statistical-data-compression-models-i-the-journal-of-machine-learning-research-i-b-7-b-2673-2698-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-the-journal-of-machine-learning-research-rft-atitle-spam-filtering-using-statistical-data-compression-models-rft-volume-7-rft-pages-2673-2698-rft-date-2006-rft-aulast-bratko-rft-aufirst-andrej-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-189-span-class-mw-cite-backlink-b-a-href-cite-ref-189-a-b-span-span-class-reference-text-almeida-tiago-a-jose-maria-g-hidalgo-and-akebo-yamakami-contributions-to-the-study-of-sms-spam-filtering-new-collection-and-results-i-proceedings-of-the-11th-acm-symposium-on-document-engineering-i-acm-2011-span-li-li-id-cite-note-190-span-class-mw-cite-backlink-b-a-href-cite-ref-190-a-b-span-span-class-reference-text-cite-class-citation-journal-delany-jane-sarah-buckley-mark-greene-derek-2012-a-rel-nofollow-class-external-text-href-https-arrow-dit-ie-cgi-viewcontent-cgi-article-1022-context-scschcomart-sms-spam-filtering-methods-and-data-a-i-expert-systems-with-applications-i-b-39-b-10-9899-9908-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-eswa-2012-02-053-10-1016-j-eswa-2012-02-053-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-expert-systems-with-applications-rft-atitle-sms-spam-filtering-3a-methods-and-data-rft-volume-39-rft-issue-10-rft-pages-9899-9908-rft-date-2012-rft-id-info-3adoi-2f10-1016-2fj-eswa-2012-02-053-rft-au-delany-rft-au-jane-2c-sarah-rft-au-buckley-2c-mark-rft-au-greene-2c-derek-rft-id-https-3a-2f-2farrow-dit-ie-2fcgi-2fviewcontent-cgi-3farticle-3d1022-26context-3dscschcomart-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-191-span-class-mw-cite-backlink-b-a-href-cite-ref-191-a-b-span-span-class-reference-text-joachims-thorsten-i-a-probabilistic-analysis-of-the-rocchio-algorithm-with-tfidf-for-text-categorization-i-no-cmu-cs-96-118-carnegie-mellon-univ-pittsburgh-pa-dept-of-computer-science-1996-span-li-li-id-cite-note-192-span-class-mw-cite-backlink-b-a-href-cite-ref-192-a-b-span-span-class-reference-text-dimitrakakis-christos-and-samy-bengio-i-online-policy-adaptation-for-ensemble-algorithms-i-no-epfl-report-82788-idiap-2002-span-li-li-id-cite-note-193-span-class-mw-cite-backlink-b-a-href-cite-ref-193-a-b-span-span-class-reference-text-dooms-s-et-al-movietweetings-a-movie-rating-dataset-collected-from-twitter-2013-available-from-a-rel-nofollow-class-external-free-href-https-github-com-sidooms-movietweetings-https-github-com-sidooms-movietweetings-a-span-li-li-id-cite-note-194-span-class-mw-cite-backlink-b-a-href-cite-ref-194-a-b-span-span-class-reference-text-cite-class-citation-arxiv-roychowdhury-aruni-lin-tsung-yu-maji-subhransu-learned-miller-erik-2017-twitter100k-a-real-world-dataset-for-weakly-supervised-cross-media-retrieval-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1703-06618-1703-06618-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-twitter100k-3a-a-real-world-dataset-for-weakly-supervised-cross-media-retrieval-rft-date-2017-rft-id-info-3aarxiv-2f1703-06618-rft-aulast-roychowdhury-rft-aufirst-aruni-rft-au-lin-2c-tsung-yu-rft-au-maji-2c-subhransu-rft-au-learned-miller-2c-erik-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-195-span-class-mw-cite-backlink-b-a-href-cite-ref-195-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-github-com-huyt16-twitter100k-huyt16-twitter100k-a-i-github-i-span-class-reference-accessdate-retrieved-span-class-nowrap-26-march-span-2018-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-github-rft-atitle-huyt16-2ftwitter100k-rft-id-https-3a-2f-2fgithub-com-2fhuyt16-2ftwitter100k-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-196-span-class-mw-cite-backlink-b-a-href-cite-ref-196-a-b-span-span-class-reference-text-cite-class-citation-journal-go-alec-bhayani-richa-huang-lei-2009-twitter-sentiment-classification-using-distant-supervision-i-cs224n-project-report-stanford-i-b-1-b-12-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-cs224n-project-report-2c-stanford-rft-atitle-twitter-sentiment-classification-using-distant-supervision-rft-volume-1-rft-pages-12-rft-date-2009-rft-aulast-go-rft-aufirst-alec-rft-au-bhayani-2c-richa-rft-au-huang-2c-lei-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-197-span-class-mw-cite-backlink-b-a-href-cite-ref-197-a-b-span-span-class-reference-text-chikersal-prerna-soujanya-poria-and-erik-cambria-sentu-sentiment-analysis-of-tweets-by-combining-a-rule-based-classifier-with-supervised-learning-i-proceedings-of-the-international-workshop-on-semantic-evaluation-semeval-i-2015-span-li-li-id-cite-note-198-span-class-mw-cite-backlink-b-a-href-cite-ref-198-a-b-span-span-class-reference-text-zafarani-reza-and-a-href-wiki-huan-liu-title-huan-liu-huan-liu-a-social-computing-data-repository-at-asu-i-school-of-computing-informatics-and-decision-systems-engineering-arizona-state-university-i-2009-span-li-li-id-cite-note-199-span-class-mw-cite-backlink-b-a-href-cite-ref-199-a-b-span-span-class-reference-text-bisgin-halil-nitin-agarwal-and-xiaowei-xu-investigating-homophily-in-online-social-networks-i-web-intelligence-and-intelligent-agent-technology-wi-iat-2010-ieee-wic-acm-international-conference-on-i-vol-1-ieee-2010-span-li-li-id-cite-note-200-span-class-mw-cite-backlink-b-a-href-cite-ref-200-a-b-span-span-class-reference-text-cite-class-citation-journal-mcauley-julian-j-leskovec-jure-learning-to-discover-social-circles-in-ego-networks-i-nips-i-b-2012-b-2012-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-nips-rft-atitle-learning-to-discover-social-circles-in-ego-networks-rft-volume-2012-rft-pages-2012-rft-aulast-mcauley-rft-aufirst-julian-j-rft-au-leskovec-2c-jure-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-201-span-class-mw-cite-backlink-b-a-href-cite-ref-201-a-b-span-span-class-reference-text-cite-class-citation-journal-subelj-lovro-fiala-dalibor-bajec-marko-2014-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4178292-network-based-statistical-comparison-of-citation-topology-of-bibliographic-databases-a-i-scientific-reports-i-b-4-b-6496-6496-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1502-05061-1502-05061-a-span-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2014natsr-4e6496s-2014natsr-4e6496s-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1038-2fsrep06496-10-1038-srep06496-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4178292-4178292-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-25263231-25263231-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-scientific-reports-rft-atitle-network-based-statistical-comparison-of-citation-topology-of-bibliographic-databases-rft-volume-4-rft-issue-6496-rft-pages-6496-rft-date-2014-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4178292-rft-id-info-3abibcode-2f2014natsr-4e6496s-rft-id-info-3aarxiv-2f1502-05061-rft-id-info-3apmid-2f25263231-rft-id-info-3adoi-2f10-1038-2fsrep06496-rft-aulast-c5-a0ubelj-rft-aufirst-lovro-rft-au-fiala-2c-dalibor-rft-au-bajec-2c-marko-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4178292-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-202-span-class-mw-cite-backlink-b-a-href-cite-ref-202-a-b-span-span-class-reference-text-abdulla-n-et-al-arabic-sentiment-analysis-corpus-based-and-lexicon-based-i-proceedings-of-the-ieee-conference-on-applied-electrical-engineering-and-computing-technologies-aeect-i-2013-span-li-li-id-cite-note-203-span-class-mw-cite-backlink-b-a-href-cite-ref-203-a-b-span-span-class-reference-text-abooraig-raddad-et-al-on-the-automatic-categorization-of-arabic-articles-based-on-their-political-orientation-i-third-international-conference-on-informatics-engineering-and-information-science-icieis2014-i-2014-span-li-li-id-cite-note-204-span-class-mw-cite-backlink-b-a-href-cite-ref-204-a-b-span-span-class-reference-text-kawala-francois-et-al-a-rel-nofollow-class-external-text-href-https-hal-archives-ouvertes-fr-hal-00881395-document-predictions-d-activite-dans-les-reseaux-sociaux-en-ligne-a-i-4ieme-conference-sur-les-modeles-et-l-analyse-des-reseaux-approches-mathematiques-et-informatiques-i-2013-span-li-li-id-cite-note-205-span-class-mw-cite-backlink-b-a-href-cite-ref-205-a-b-span-span-class-reference-text-cite-class-citation-arxiv-sabharwal-ashish-samulowitz-horst-tesauro-gerald-2015-selecting-near-optimal-learners-via-incremental-data-allocation-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1601-00024-1601-00024-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-lg-cs-lg-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-selecting-near-optimal-learners-via-incremental-data-allocation-rft-date-2015-rft-id-info-3aarxiv-2f1601-00024-rft-aulast-sabharwal-rft-aufirst-ashish-rft-au-samulowitz-2c-horst-rft-au-tesauro-2c-gerald-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-206-span-class-mw-cite-backlink-b-a-href-cite-ref-206-a-b-span-span-class-reference-text-xu-et-al-semeval-2015-task-1-paraphrase-and-semantic-similarity-in-twitter-pit-i-proceedings-of-the-9th-international-workshop-on-semantic-evaluation-i-2015-span-li-li-id-cite-note-207-span-class-mw-cite-backlink-b-a-href-cite-ref-207-a-b-span-span-class-reference-text-xu-et-al-a-rel-nofollow-class-external-text-href-https-transacl-org-ojs-index-php-tacl-article-viewfile-498-64-extracting-lexically-divergent-paraphrases-from-twitter-a-i-transactions-of-the-association-for-computational-tacl-i-2014-span-li-li-id-cite-note-208-span-class-mw-cite-backlink-b-a-href-cite-ref-208-a-b-span-span-class-reference-text-cite-class-citation-journal-middleton-stuart-e-middleton-lee-modafferi-stefano-2014-a-rel-nofollow-class-external-text-href-https-eprints-soton-ac-uk-370581-1-ieee-is2014-pdf-real-time-crisis-mapping-of-natural-disasters-using-social-media-a-span-class-cs1-format-pdf-span-i-ieee-intelligent-systems-i-b-29-b-2-9-17-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2fmis-2013-126-10-1109-mis-2013-126-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-intelligent-systems-rft-atitle-real-time-crisis-mapping-of-natural-disasters-using-social-media-rft-volume-29-rft-issue-2-rft-pages-9-17-rft-date-2014-rft-id-info-3adoi-2f10-1109-2fmis-2013-126-rft-aulast-middleton-rft-aufirst-stuart-e-rft-au-middleton-2c-lee-rft-au-modafferi-2c-stefano-rft-id-https-3a-2f-2feprints-soton-ac-uk-2f370581-2f1-2fieee-is2014-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-209-span-class-mw-cite-backlink-b-a-href-cite-ref-209-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-pypi-org-project-geoparsepy-geoparsepy-a-2016-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-geoparsepy-rft-date-2016-rft-id-https-3a-2f-2fpypi-org-2fproject-2fgeoparsepy-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-python-pypi-library-span-li-li-id-cite-note-210-span-class-mw-cite-backlink-b-a-href-cite-ref-210-a-b-span-span-class-reference-text-forsyth-e-lin-j-martell-c-2008-june-25-the-nps-chat-corpus-retrieved-from-a-rel-nofollow-class-external-free-href-http-faculty-nps-edu-cmartell-npschat-htm-http-faculty-nps-edu-cmartell-npschat-htm-a-span-li-li-id-cite-note-211-span-class-mw-cite-backlink-b-a-href-cite-ref-211-a-b-span-span-class-reference-text-alessandro-sordoni-michel-galley-michael-auli-chris-brockett-yangfeng-ji-meg-mitchell-jian-yun-nie-jianfeng-gao-and-bill-dolan-a-neural-network-approach-to-context-sensitive-generation-of-conversational-responses-conference-of-the-north-american-chapter-of-the-association-for-computational-linguistics-human-language-technologies-naacl-hlt-2015-june-2015-span-li-li-id-cite-note-212-span-class-mw-cite-backlink-b-a-href-cite-ref-212-a-b-span-span-class-reference-text-shaoul-c-westbury-c-2013-a-reduced-redundancy-usenet-corpus-2005-2011-edmonton-ab-university-of-alberta-downloaded-from-a-rel-nofollow-class-external-free-href-http-www-psych-ualberta-ca-westburylab-downloads-usenetcorpus-download-html-http-www-psych-ualberta-ca-westburylab-downloads-usenetcorpus-download-html-a-span-li-li-id-cite-note-213-span-class-mw-cite-backlink-b-a-href-cite-ref-213-a-b-span-span-class-reference-text-kan-m-2011-january-nus-short-message-service-sms-corpus-retrieved-from-a-rel-nofollow-class-external-free-href-http-www-comp-nus-edu-sg-entrepreneurship-innovation-osr-corpus-http-www-comp-nus-edu-sg-entrepreneurship-innovation-osr-corpus-a-span-li-li-id-cite-note-214-span-class-mw-cite-backlink-b-a-href-cite-ref-214-a-b-span-span-class-reference-text-stuck-in-the-matrix-2015-july-3-i-have-every-publicly-available-reddit-comment-for-research-1-7-billion-comments-250-gb-compressed-any-interest-in-this-original-post-message-posted-to-a-rel-nofollow-class-external-free-href-https-www-reddit-com-r-datasets-comments-3bxlg7-i-have-every-publicly-available-reddit-comment-https-www-reddit-com-r-datasets-comments-3bxlg7-i-have-every-publicly-available-reddit-comment-a-span-li-li-id-cite-note-215-span-class-mw-cite-backlink-b-a-href-cite-ref-215-a-b-span-span-class-reference-text-ryan-lowe-nissan-pow-iulian-v-serban-and-joelle-pineau-the-ubuntu-dialogue-corpus-a-large-dataset-for-research-in-unstructure-multi-turn-dialogue-systems-sigdial-2015-span-li-li-id-cite-note-kow2017-216-span-class-mw-cite-backlink-b-a-href-cite-ref-kow2017-216-0-a-b-span-span-class-reference-text-k-kowsari-d-e-brown-m-heidarysafa-k-jafari-meimandi-m-s-gerber-and-l-e-barnes-hdltex-hierarchical-deep-learning-for-text-classification-2017-16th-ieee-international-conference-on-machine-learning-and-applications-icmla-pp-364-371-doi-a-rel-nofollow-class-external-text-href-https-doi-org-10-1109-icmla-2017-0-134-10-1109-icmla-2017-0-134-a-span-li-li-id-cite-note-kow2017wos-217-span-class-mw-cite-backlink-b-a-href-cite-ref-kow2017wos-217-0-a-b-span-span-class-reference-text-k-kowsari-d-e-brown-m-heidarysafa-k-jafari-meimandi-m-s-gerber-and-l-e-barnes-web-of-science-dataset-doi-a-rel-nofollow-class-external-text-href-https-dx-doi-org-10-17632-9rw3vkcfy4-6-10-17632-9rw3vkcfy4-6-a-span-li-li-id-cite-note-218-span-class-mw-cite-backlink-b-a-href-cite-ref-218-a-b-span-span-class-reference-text-galgani-filippo-paul-compton-and-achim-hoffmann-combining-different-summarization-techniques-for-legal-text-i-proceedings-of-the-workshop-on-innovative-hybrid-approaches-to-the-processing-of-textual-data-i-association-for-computational-linguistics-2012-span-li-li-id-cite-note-219-span-class-mw-cite-backlink-b-a-href-cite-ref-219-a-b-span-span-class-reference-text-cite-class-citation-journal-nagwani-n-k-2015-summarizing-large-text-collection-using-topic-modeling-and-clustering-based-on-mapreduce-framework-i-journal-of-big-data-i-b-2-b-1-1-18-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1186-2fs40537-015-0020-5-10-1186-s40537-015-0020-5-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-big-data-rft-atitle-summarizing-large-text-collection-using-topic-modeling-and-clustering-based-on-mapreduce-framework-rft-volume-2-rft-issue-1-rft-pages-1-18-rft-date-2015-rft-id-info-3adoi-2f10-1186-2fs40537-015-0020-5-rft-aulast-nagwani-rft-aufirst-n-k-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-220-span-class-mw-cite-backlink-b-a-href-cite-ref-220-a-b-span-span-class-reference-text-cite-class-citation-journal-schler-jonathan-et-al-2006-effects-of-age-and-gender-on-blogging-i-aaai-spring-symposium-computational-approaches-to-analyzing-weblogs-i-b-6-b-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-aaai-spring-symposium-3a-computational-approaches-to-analyzing-weblogs-rft-atitle-effects-of-age-and-gender-on-blogging-rft-volume-6-rft-date-2006-rft-aulast-schler-rft-aufirst-jonathan-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-221-span-class-mw-cite-backlink-b-a-href-cite-ref-221-a-b-span-span-class-reference-text-anand-pranav-et-al-believe-me-we-can-do-this-annotating-persuasive-acts-in-blog-text-i-computational-models-of-natural-argument-i-2011-span-li-li-id-cite-note-222-span-class-mw-cite-backlink-b-a-href-cite-ref-222-a-b-span-span-class-reference-text-traud-amanda-l-peter-j-mucha-and-mason-a-porter-social-structure-of-facebook-networks-i-physica-a-statistical-mechanics-and-its-applications-i-391-16-2012-4165-4180-span-li-li-id-cite-note-223-span-class-mw-cite-backlink-b-a-href-cite-ref-223-a-b-span-span-class-reference-text-cite-class-citation-arxiv-richard-emile-savalle-pierre-andre-vayatis-nicolas-2012-estimation-of-simultaneously-sparse-and-low-rank-matrices-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1206-6474-1206-6474-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-ds-cs-ds-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-estimation-of-simultaneously-sparse-and-low-rank-matrices-rft-date-2012-rft-id-info-3aarxiv-2f1206-6474-rft-aulast-richard-rft-aufirst-emile-rft-au-savalle-2c-pierre-andre-rft-au-vayatis-2c-nicolas-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-224-span-class-mw-cite-backlink-b-a-href-cite-ref-224-a-b-span-span-class-reference-text-cite-class-citation-journal-richardson-matthew-burges-christopher-jc-renshaw-erin-2013-mctest-a-challenge-dataset-for-the-open-domain-machine-comprehension-of-text-i-emnlp-i-b-1-b-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-emnlp-rft-atitle-mctest-3a-a-challenge-dataset-for-the-open-domain-machine-comprehension-of-text-rft-volume-1-rft-date-2013-rft-aulast-richardson-rft-aufirst-matthew-rft-au-burges-2c-christopher-jc-rft-au-renshaw-2c-erin-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-225-span-class-mw-cite-backlink-b-a-href-cite-ref-225-a-b-span-span-class-reference-text-cite-class-citation-arxiv-weston-jason-bordes-antoine-chopra-sumit-rush-alexander-m-bart-van-merrienboer-joulin-armand-mikolov-tomas-2015-towards-ai-complete-question-answering-a-set-of-prerequisite-toy-tasks-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1502-05698-1502-05698-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-ai-cs-ai-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-towards-ai-complete-question-answering-3a-a-set-of-prerequisite-toy-tasks-rft-date-2015-rft-id-info-3aarxiv-2f1502-05698-rft-aulast-weston-rft-aufirst-jason-rft-au-bordes-2c-antoine-rft-au-chopra-2c-sumit-rft-au-rush-2c-alexander-m-rft-au-bart-van-merri-c3-abnboer-rft-au-joulin-2c-armand-rft-au-mikolov-2c-tomas-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-226-span-class-mw-cite-backlink-b-a-href-cite-ref-226-a-b-span-span-class-reference-text-cite-class-citation-journal-marcus-mitchell-p-ann-marcinkiewicz-mary-santorini-beatrice-1993-a-rel-nofollow-class-external-text-href-http-repository-upenn-edu-cgi-viewcontent-cgi-article-1246-context-cis-reports-building-a-large-annotated-corpus-of-english-the-penn-treebank-a-i-computational-linguistics-i-b-19-b-2-313-330-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-computational-linguistics-rft-atitle-building-a-large-annotated-corpus-of-english-3a-the-penn-treebank-rft-volume-19-rft-issue-2-rft-pages-313-330-rft-date-1993-rft-aulast-marcus-rft-aufirst-mitchell-p-rft-au-ann-marcinkiewicz-2c-mary-rft-au-santorini-2c-beatrice-rft-id-http-3a-2f-2frepository-upenn-edu-2fcgi-2fviewcontent-cgi-3farticle-3d1246-26context-3dcis-reports-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-227-span-class-mw-cite-backlink-b-a-href-cite-ref-227-a-b-span-span-class-reference-text-cite-class-citation-journal-collins-michael-2003-head-driven-statistical-models-for-natural-language-parsing-i-computational-linguistics-i-b-29-b-4-589-637-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1162-2f089120103322753356-10-1162-089120103322753356-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-computational-linguistics-rft-atitle-head-driven-statistical-models-for-natural-language-parsing-rft-volume-29-rft-issue-4-rft-pages-589-637-rft-date-2003-rft-id-info-3adoi-2f10-1162-2f089120103322753356-rft-aulast-collins-rft-aufirst-michael-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-228-span-class-mw-cite-backlink-b-a-href-cite-ref-228-a-b-span-span-class-reference-text-guyon-isabelle-et-al-eds-i-feature-extraction-foundations-and-applications-i-vol-207-springer-2008-span-li-li-id-cite-note-229-span-class-mw-cite-backlink-b-a-href-cite-ref-229-a-b-span-span-class-reference-text-lin-yuri-et-al-syntactic-annotations-for-the-google-books-ngram-corpus-i-proceedings-of-the-acl-2012-system-demonstrations-i-association-for-computational-linguistics-2012-span-li-li-id-cite-note-230-span-class-mw-cite-backlink-b-a-href-cite-ref-230-a-b-span-span-class-reference-text-cite-class-citation-journal-krishnamoorthy-niveda-et-al-2013-generating-natural-language-video-descriptions-using-text-mined-knowledge-i-aaai-i-b-1-b-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-aaai-rft-atitle-generating-natural-language-video-descriptions-using-text-mined-knowledge-rft-volume-1-rft-date-2013-rft-aulast-krishnamoorthy-rft-aufirst-niveda-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-231-span-class-mw-cite-backlink-b-a-href-cite-ref-231-a-b-span-span-class-reference-text-luyckx-kim-and-walter-daelemans-personae-a-corpus-for-author-and-personality-prediction-from-text-i-lrec-i-2008-span-li-li-id-cite-note-232-span-class-mw-cite-backlink-b-a-href-cite-ref-232-a-b-span-span-class-reference-text-solorio-thamar-ragib-hasan-and-mainul-mizan-a-case-study-of-sockpuppet-detection-in-wikipedia-i-workshop-on-language-analysis-in-social-media-lasm-at-naacl-hlt-i-2013-span-li-li-id-cite-note-233-span-class-mw-cite-backlink-b-a-href-cite-ref-233-a-b-span-span-class-reference-text-ciarelli-patrick-marques-and-elias-oliveira-agglomeration-and-elimination-of-terms-for-dimensionality-reduction-i-intelligent-systems-design-and-applications-2009-isda-09-ninth-international-conference-on-i-ieee-2009-span-li-li-id-cite-note-234-span-class-mw-cite-backlink-b-a-href-cite-ref-234-a-b-span-span-class-reference-text-zhou-mingyuan-oscar-hernan-madrid-padilla-and-james-g-scott-priors-for-random-count-matrices-derived-from-a-family-of-negative-binomial-processes-i-journal-of-the-american-statistical-association-i-just-accepted-2015-00-00-span-li-li-id-cite-note-235-span-class-mw-cite-backlink-b-a-href-cite-ref-235-a-b-span-span-class-reference-text-kotzias-dimitrios-et-al-from-group-to-individual-labels-using-deep-features-proceedings-of-the-21th-acm-sigkdd-international-conference-on-knowledge-discovery-and-data-mining-acm-2015-span-li-li-id-cite-note-236-span-class-mw-cite-backlink-b-a-href-cite-ref-236-a-b-span-span-class-reference-text-cite-class-citation-arxiv-ning-yue-muthiah-sathappan-rangwala-huzefa-ramakrishnan-naren-2016-modeling-precursors-for-event-forecasting-via-nested-multi-instance-learning-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1602-08033-1602-08033-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-si-cs-si-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-modeling-precursors-for-event-forecasting-via-nested-multi-instance-learning-rft-date-2016-rft-id-info-3aarxiv-2f1602-08033-rft-aulast-ning-rft-aufirst-yue-rft-au-muthiah-2c-sathappan-rft-au-rangwala-2c-huzefa-rft-au-ramakrishnan-2c-naren-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-237-span-class-mw-cite-backlink-b-a-href-cite-ref-237-a-b-span-span-class-reference-text-buza-krisztian-feedback-prediction-for-blogs-i-data-analysis-machine-learning-and-knowledge-discovery-i-springer-international-publishing-2014-145-152-span-li-li-id-cite-note-238-span-class-mw-cite-backlink-b-a-href-cite-ref-238-a-b-span-span-class-reference-text-cite-class-citation-journal-soysal-omer-m-2015-association-rule-mining-with-mostly-associated-sequential-patterns-i-expert-systems-with-applications-i-b-42-b-5-2582-2592-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-eswa-2014-10-049-10-1016-j-eswa-2014-10-049-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-expert-systems-with-applications-rft-atitle-association-rule-mining-with-mostly-associated-sequential-patterns-rft-volume-42-rft-issue-5-rft-pages-2582-2592-rft-date-2015-rft-id-info-3adoi-2f10-1016-2fj-eswa-2014-10-049-rft-aulast-soysal-rft-aufirst-c3-96mer-m-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-239-span-class-mw-cite-backlink-b-a-href-cite-ref-239-a-b-span-span-class-reference-text-bowman-samuel-et-al-a-large-annotated-corpus-for-learning-natural-language-inference-proceedings-of-the-2015-conference-on-empirical-methods-in-natural-language-processing-emnlp-acl-2015-span-li-li-id-cite-note-240-span-class-mw-cite-backlink-b-a-href-cite-ref-240-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-http-ttg-uni-saarland-de-resources-dslcc-dsl-corpus-collection-a-i-ttg-uni-saarland-de-i-span-class-reference-accessdate-retrieved-span-class-nowrap-22-september-span-2017-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-ttg-uni-saarland-de-rft-atitle-dsl-corpus-collection-rft-id-http-3a-2f-2fttg-uni-saarland-de-2fresources-2fdslcc-2f-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-241-span-class-mw-cite-backlink-b-a-href-cite-ref-241-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-kaggle-com-therohk-urban-dictionary-words-dataset-urban-dictionary-words-and-definitions-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-urban-dictionary-words-and-definitions-rft-id-https-3a-2f-2fwww-kaggle-com-2ftherohk-2furban-dictionary-words-dataset-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-242-span-class-mw-cite-backlink-b-a-href-cite-ref-242-a-b-span-span-class-reference-text-h-elsahar-p-vougiouklis-a-remaci-c-gravier-j-hare-f-laforest-e-simperl-t-rex-a-large-scale-alignment-of-natural-language-with-knowledge-base-triples-proceedings-of-the-eleventh-international-conference-on-language-resources-and-evaluation-lrec-2018-span-li-li-id-cite-note-243-span-class-mw-cite-backlink-b-a-href-cite-ref-243-a-b-span-span-class-reference-text-m-versteegh-r-thiolliere-t-schatz-x-n-cao-x-anguera-a-jansen-and-e-dupoux-2015-the-zero-resource-speech-challenge-2015-in-interspeech-2015-span-li-li-id-cite-note-244-span-class-mw-cite-backlink-b-a-href-cite-ref-244-a-b-span-span-class-reference-text-m-versteegh-x-anguera-a-jansen-and-e-dupoux-2016-the-zero-resource-speech-challenge-2015-proposed-approaches-and-results-in-sltu-2016-span-li-li-id-cite-note-245-span-class-mw-cite-backlink-b-a-href-cite-ref-245-a-b-span-span-class-reference-text-cite-class-citation-journal-sakar-betul-erdogdu-et-al-2013-collection-and-analysis-of-a-parkinson-speech-dataset-with-multiple-types-of-sound-recordings-i-ieee-journal-of-biomedical-and-health-informatics-i-b-17-b-4-828-834-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2fjbhi-2013-2245674-10-1109-jbhi-2013-2245674-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-25055311-25055311-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-journal-of-biomedical-and-health-informatics-rft-atitle-collection-and-analysis-of-a-parkinson-speech-dataset-with-multiple-types-of-sound-recordings-rft-volume-17-rft-issue-4-rft-pages-828-834-rft-date-2013-rft-id-info-3adoi-2f10-1109-2fjbhi-2013-2245674-rft-id-info-3apmid-2f25055311-rft-aulast-sakar-rft-aufirst-betul-erdogdu-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-246-span-class-mw-cite-backlink-b-a-href-cite-ref-246-a-b-span-span-class-reference-text-zhao-shunan-et-al-automatic-detection-of-expressed-emotion-in-parkinson-s-disease-i-acoustics-speech-and-signal-processing-icassp-2014-ieee-international-conference-on-i-ieee-2014-span-li-li-id-cite-note-2-247-span-class-mw-cite-backlink-b-a-href-cite-ref-2-247-0-a-b-span-span-class-reference-text-used-in-hammami-nacereddine-and-mouldi-bedda-improved-tree-model-for-arabic-speech-recognition-i-computer-science-and-information-technology-iccsit-2010-3rd-ieee-international-conference-on-i-vol-5-ieee-2010-span-li-li-id-cite-note-248-span-class-mw-cite-backlink-b-a-href-cite-ref-248-a-b-span-span-class-reference-text-maaten-laurens-learning-discriminative-fisher-kernels-i-proceedings-of-the-28th-international-conference-on-machine-learning-icml-11-i-2011-span-li-li-id-cite-note-249-span-class-mw-cite-backlink-b-a-href-cite-ref-249-a-b-span-span-class-reference-text-cole-ronald-and-mark-fanty-spoken-letter-recognition-i-proc-third-darpa-speech-and-natural-language-workshop-i-1990-span-li-li-id-cite-note-250-span-class-mw-cite-backlink-b-a-href-cite-ref-250-a-b-span-span-class-reference-text-cite-class-citation-journal-chapelle-olivier-sindhwani-vikas-keerthi-sathiya-s-2008-optimization-techniques-for-semi-supervised-support-vector-machines-i-the-journal-of-machine-learning-research-i-b-9-b-203-233-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-the-journal-of-machine-learning-research-rft-atitle-optimization-techniques-for-semi-supervised-support-vector-machines-rft-volume-9-rft-pages-203-233-rft-date-2008-rft-aulast-chapelle-rft-aufirst-olivier-rft-au-sindhwani-2c-vikas-rft-au-keerthi-2c-sathiya-s-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-251-span-class-mw-cite-backlink-b-a-href-cite-ref-251-a-b-span-span-class-reference-text-cite-class-citation-journal-kudo-mineichi-toyama-jun-shimbo-masaru-1999-multidimensional-curve-classification-using-passing-through-regions-i-pattern-recognition-letters-i-b-20-b-11-1103-1111-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-46-2515-10-1-1-46-2515-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fs0167-8655-2899-2900077-x-10-1016-s0167-8655-99-00077-x-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-pattern-recognition-letters-rft-atitle-multidimensional-curve-classification-using-passing-through-regions-rft-volume-20-rft-issue-11-rft-pages-1103-1111-rft-date-1999-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-46-2515-rft-id-info-3adoi-2f10-1016-2fs0167-8655-2899-2900077-x-rft-aulast-kudo-rft-aufirst-mineichi-rft-au-toyama-2c-jun-rft-au-shimbo-2c-masaru-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-252-span-class-mw-cite-backlink-b-a-href-cite-ref-252-a-b-span-span-class-reference-text-cite-class-citation-journal-jaeger-herbert-et-al-2007-optimization-and-applications-of-echo-state-networks-with-leaky-integrator-neurons-i-neural-networks-i-b-20-b-3-335-352-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-neunet-2007-04-016-10-1016-j-neunet-2007-04-016-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-17517495-17517495-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neural-networks-rft-atitle-optimization-and-applications-of-echo-state-networks-with-leaky-integrator-neurons-rft-volume-20-rft-issue-3-rft-pages-335-352-rft-date-2007-rft-id-info-3adoi-2f10-1016-2fj-neunet-2007-04-016-rft-id-info-3apmid-2f17517495-rft-aulast-jaeger-rft-aufirst-herbert-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-253-span-class-mw-cite-backlink-b-a-href-cite-ref-253-a-b-span-span-class-reference-text-cite-class-citation-journal-tsanas-athanasios-et-al-2010-a-rel-nofollow-class-external-text-href-http-precedings-nature-com-documents-3920-version-1-accurate-telemonitoring-of-parkinson-s-disease-progression-by-noninvasive-speech-tests-a-i-ieee-transactions-on-biomedical-engineering-i-submitted-manuscript-b-57-b-4-884-893-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftbme-2009-2036000-10-1109-tbme-2009-2036000-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-19932995-19932995-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-biomedical-engineering-rft-atitle-accurate-telemonitoring-of-parkinson-27s-disease-progression-by-noninvasive-speech-tests-rft-volume-57-rft-issue-4-rft-pages-884-893-rft-date-2010-rft-id-info-3adoi-2f10-1109-2ftbme-2009-2036000-rft-id-info-3apmid-2f19932995-rft-aulast-tsanas-rft-aufirst-athanasios-rft-id-http-3a-2f-2fprecedings-nature-com-2fdocuments-2f3920-2fversion-2f1-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-254-span-class-mw-cite-backlink-b-a-href-cite-ref-254-a-b-span-span-class-reference-text-cite-class-citation-journal-clifford-gari-d-clifton-david-2012-wireless-technology-in-disease-management-and-medicine-i-annual-review-of-medicine-i-b-63-b-479-492-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1146-2fannurev-med-051210-114650-10-1146-annurev-med-051210-114650-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-22053737-22053737-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-annual-review-of-medicine-rft-atitle-wireless-technology-in-disease-management-and-medicine-rft-volume-63-rft-pages-479-492-rft-date-2012-rft-id-info-3adoi-2f10-1146-2fannurev-med-051210-114650-rft-id-info-3apmid-2f22053737-rft-aulast-clifford-rft-aufirst-gari-d-rft-au-clifton-2c-david-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-255-span-class-mw-cite-backlink-b-a-href-cite-ref-255-a-b-span-span-class-reference-text-cite-class-citation-journal-zue-victor-seneff-stephanie-glass-james-1990-speech-database-development-at-mit-timit-and-beyond-i-speech-communication-i-b-9-b-4-351-356-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2f0167-6393-2890-2990010-7-10-1016-0167-6393-90-90010-7-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-speech-communication-rft-atitle-speech-database-development-at-mit-3a-timit-and-beyond-rft-volume-9-rft-issue-4-rft-pages-351-356-rft-date-1990-rft-id-info-3adoi-2f10-1016-2f0167-6393-2890-2990010-7-rft-aulast-zue-rft-aufirst-victor-rft-au-seneff-2c-stephanie-rft-au-glass-2c-james-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-256-span-class-mw-cite-backlink-b-a-href-cite-ref-256-a-b-span-span-class-reference-text-kapadia-sadik-valtcho-valtchev-and-s-j-young-mmi-training-for-continuous-phoneme-recognition-on-the-timit-database-i-acoustics-speech-and-signal-processing-1993-icassp-93-1993-ieee-international-conference-on-i-vol-2-ieee-1993-span-li-li-id-cite-note-halabi2016-257-span-class-mw-cite-backlink-b-a-href-cite-ref-halabi2016-257-0-a-b-span-span-class-reference-text-cite-class-citation-thesis-halabi-nawar-2016-a-rel-nofollow-class-external-text-href-http-en-arabicspeechcorpus-com-nawar-20halabi-20phd-20thesis-20revised-pdf-i-modern-standard-arabic-phonetics-for-speech-synthesis-i-a-span-class-cs1-format-pdf-span-phd-thesis-a-href-wiki-university-of-southampton-title-university-of-southampton-university-of-southampton-a-school-of-electronics-and-computer-science-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3adissertation-rft-title-modern-standard-arabic-phonetics-for-speech-synthesis-rft-inst-university-of-southampton-2c-school-of-electronics-and-computer-science-rft-date-2016-rft-aulast-halabi-rft-aufirst-nawar-rft-id-http-3a-2f-2fen-arabicspeechcorpus-com-2fnawar-2520halabi-2520phd-2520thesis-2520revised-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-258-span-class-mw-cite-backlink-b-a-href-cite-ref-258-a-b-span-span-class-reference-text-zhou-fang-q-claire-and-ross-d-king-predicting-the-geographical-origin-of-music-i-data-mining-icdm-2014-ieee-international-conference-on-i-ieee-2014-span-li-li-id-cite-note-259-span-class-mw-cite-backlink-b-a-href-cite-ref-259-a-b-span-span-class-reference-text-cite-class-citation-journal-saccenti-edoardo-camacho-jose-2015-on-the-use-of-the-observation-wise-k-fold-operation-in-pca-cross-validation-i-journal-of-chemometrics-i-b-29-b-8-467-478-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1002-2fcem-2726-10-1002-cem-2726-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-chemometrics-rft-atitle-on-the-use-of-the-observation-e2-80-90wise-k-e2-80-90fold-operation-in-pca-cross-e2-80-90validation-rft-volume-29-rft-issue-8-rft-pages-467-478-rft-date-2015-rft-id-info-3adoi-2f10-1002-2fcem-2726-rft-aulast-saccenti-rft-aufirst-edoardo-rft-au-camacho-2c-jos-c3-a9-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-260-span-class-mw-cite-backlink-b-a-href-cite-ref-260-a-b-span-span-class-reference-text-bertin-mahieux-thierry-et-al-the-million-song-dataset-i-ismir-2011-proceedings-of-the-12th-international-society-for-music-information-retrieval-conference-24-28-october-2011-miami-florida-i-university-of-miami-2011-span-li-li-id-cite-note-261-span-class-mw-cite-backlink-b-a-href-cite-ref-261-a-b-span-span-class-reference-text-cite-class-citation-journal-henaff-mikael-et-al-2011-unsupervised-learning-of-sparse-features-for-scalable-audio-classification-i-ismir-i-b-11-b-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ismir-rft-atitle-unsupervised-learning-of-sparse-features-for-scalable-audio-classification-rft-volume-11-rft-date-2011-rft-aulast-henaff-rft-aufirst-mikael-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-262-span-class-mw-cite-backlink-b-a-href-cite-ref-262-a-b-span-span-class-reference-text-cite-class-citation-arxiv-defferrard-michael-benzi-kirell-vandergheynst-pierre-bresson-xavier-6-december-2016-fma-a-dataset-for-music-analysis-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1612-01840-1612-01840-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-sd-cs-sd-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-fma-3a-a-dataset-for-music-analysis-rft-date-2016-12-06-rft-id-info-3aarxiv-2f1612-01840-rft-aulast-defferrard-rft-aufirst-micha-c3-abl-rft-au-benzi-2c-kirell-rft-au-vandergheynst-2c-pierre-rft-au-bresson-2c-xavier-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-263-span-class-mw-cite-backlink-b-a-href-cite-ref-263-a-b-span-span-class-reference-text-cite-class-citation-journal-esposito-roberto-radicioni-daniele-p-2009-carpediem-optimizing-the-viterbi-algorithm-and-applications-to-supervised-sequential-learning-i-the-journal-of-machine-learning-research-i-b-10-b-1851-1880-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-the-journal-of-machine-learning-research-rft-atitle-carpediem-3a-optimizing-the-viterbi-algorithm-and-applications-to-supervised-sequential-learning-rft-volume-10-rft-pages-1851-1880-rft-date-2009-rft-aulast-esposito-rft-aufirst-roberto-rft-au-radicioni-2c-daniele-p-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-264-span-class-mw-cite-backlink-b-a-href-cite-ref-264-a-b-span-span-class-reference-text-cite-class-citation-journal-sourati-jamshid-et-al-2016-classification-active-learning-based-on-mutual-information-i-entropy-i-b-18-b-2-51-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2016entrp-18-51s-2016entrp-18-51s-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-3390-2fe18020051-10-3390-e18020051-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-entropy-rft-atitle-classification-active-learning-based-on-mutual-information-rft-volume-18-rft-issue-2-rft-pages-51-rft-date-2016-rft-id-info-3adoi-2f10-3390-2fe18020051-rft-id-info-3abibcode-2f2016entrp-18-51s-rft-aulast-sourati-rft-aufirst-jamshid-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-265-span-class-mw-cite-backlink-b-a-href-cite-ref-265-a-b-span-span-class-reference-text-salamon-justin-jacoby-christopher-bello-juan-pablo-a-dataset-and-taxonomy-for-urban-sound-research-i-proceedings-of-the-acm-international-conference-on-multimedia-i-acm-2014-span-li-li-id-cite-note-266-span-class-mw-cite-backlink-b-a-href-cite-ref-266-a-b-span-span-class-reference-text-cite-class-citation-arxiv-lagrange-mathieu-lafay-gregoire-rossignol-mathias-benetos-emmanouil-roebel-axel-2015-an-evaluation-framework-for-event-detection-using-a-morphological-model-of-acoustic-scenes-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1502-00141-1502-00141-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-stat-ml-stat-ml-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-an-evaluation-framework-for-event-detection-using-a-morphological-model-of-acoustic-scenes-rft-date-2015-rft-id-info-3aarxiv-2f1502-00141-rft-aulast-lagrange-rft-aufirst-mathieu-rft-au-lafay-2c-gr-c3-a9goire-rft-au-rossignol-2c-mathias-rft-au-benetos-2c-emmanouil-rft-au-roebel-2c-axel-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-267-span-class-mw-cite-backlink-b-a-href-cite-ref-267-a-b-span-span-class-reference-text-gemmeke-jort-f-et-al-audio-set-an-ontology-and-human-labeled-dataset-for-audio-events-a-href-wiki-ieee-class-mw-redirect-title-ieee-ieee-a-a-href-wiki-international-conference-on-acoustics-speech-and-signal-processing-title-international-conference-on-acoustics-speech-and-signal-processing-international-conference-on-acoustics-speech-and-signal-processing-a-icassp-2017-span-li-li-id-cite-note-268-span-class-mw-cite-backlink-b-a-href-cite-ref-268-a-b-span-span-class-reference-text-cite-class-citation-news-a-rel-nofollow-class-external-text-href-http-www-sciencemag-org-news-2018-07-watch-out-birders-artificial-intelligence-has-learned-spot-birds-their-songs-watch-out-birders-artificial-intelligence-has-learned-to-spot-birds-from-their-songs-a-i-science-aaas-i-18-july-2018-span-class-reference-accessdate-retrieved-span-class-nowrap-22-july-span-2018-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-science-7c-aaas-rft-atitle-watch-out-2c-birders-3a-artificial-intelligence-has-learned-to-spot-birds-from-their-songs-rft-date-2018-07-18-rft-id-http-3a-2f-2fwww-sciencemag-org-2fnews-2f2018-2f07-2fwatch-out-birders-artificial-intelligence-has-learned-spot-birds-their-songs-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-269-span-class-mw-cite-backlink-b-a-href-cite-ref-269-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-http-machine-listening-eecs-qmul-ac-uk-bird-audio-detection-challenge-bird-audio-detection-challenge-a-i-machine-listening-lab-at-a-href-wiki-queen-mary-university-class-mw-redirect-title-queen-mary-university-queen-mary-university-a-i-3-may-2016-span-class-reference-accessdate-retrieved-span-class-nowrap-22-july-span-2018-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-machine-listening-lab-at-queen-mary-university-rft-atitle-bird-audio-detection-challenge-rft-date-2016-05-03-rft-id-http-3a-2f-2fmachine-listening-eecs-qmul-ac-uk-2fbird-audio-detection-challenge-2f-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-270-span-class-mw-cite-backlink-b-a-href-cite-ref-270-a-b-span-span-class-reference-text-the-caida-ucsd-dataset-on-the-witty-worm-19-24-march-2004-a-rel-nofollow-class-external-free-href-http-www-caida-org-data-passive-witty-worm-dataset-xml-http-www-caida-org-data-passive-witty-worm-dataset-xml-a-span-li-li-id-cite-note-271-span-class-mw-cite-backlink-b-a-href-cite-ref-271-a-b-span-span-class-reference-text-chen-zesheng-and-chuanyi-ji-optimal-worm-scanning-method-using-vulnerable-host-distributions-i-international-journal-of-security-and-networks-i-2-1-2-2007-71-80-span-li-li-id-cite-note-272-span-class-mw-cite-backlink-b-a-href-cite-ref-272-a-b-span-span-class-reference-text-kachuee-mohamad-et-al-cuff-less-high-accuracy-calibration-free-blood-pressure-estimation-using-pulse-transit-time-i-circuits-and-systems-iscas-2015-ieee-international-symposium-on-i-ieee-2015-span-li-li-id-cite-note-273-span-class-mw-cite-backlink-b-a-href-cite-ref-273-a-b-span-span-class-reference-text-physiobank-physiotoolkit-physionet-components-of-a-new-research-resource-for-complex-physiologic-signals-i-circulation-v101-i23-e215-e220-i-span-li-li-id-cite-note-274-span-class-mw-cite-backlink-b-a-href-cite-ref-274-a-b-span-span-class-reference-text-cite-class-citation-journal-vergara-alexander-et-al-2012-chemical-gas-sensor-drift-compensation-using-classifier-ensembles-i-sensors-and-actuators-b-chemical-i-b-166-b-320-329-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-snb-2012-01-074-10-1016-j-snb-2012-01-074-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-sensors-and-actuators-b-3a-chemical-rft-atitle-chemical-gas-sensor-drift-compensation-using-classifier-ensembles-rft-volume-166-rft-pages-320-329-rft-date-2012-rft-id-info-3adoi-2f10-1016-2fj-snb-2012-01-074-rft-aulast-vergara-rft-aufirst-alexander-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-275-span-class-mw-cite-backlink-b-a-href-cite-ref-275-a-b-span-span-class-reference-text-cite-class-citation-journal-korotcenkov-g-cho-b-k-2014-engineering-approaches-to-improvement-of-conductometric-gas-sensor-parameters-part-2-decrease-of-dissipated-consumable-power-and-improvement-stability-and-reliability-i-sensors-and-actuators-b-chemical-i-b-198-b-316-341-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-snb-2014-03-069-10-1016-j-snb-2014-03-069-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-sensors-and-actuators-b-3a-chemical-rft-atitle-engineering-approaches-to-improvement-of-conductometric-gas-sensor-parameters-part-2-3a-decrease-of-dissipated-28consumable-29-power-and-improvement-stability-and-reliability-rft-volume-198-rft-pages-316-341-rft-date-2014-rft-id-info-3adoi-2f10-1016-2fj-snb-2014-03-069-rft-aulast-korotcenkov-rft-aufirst-g-rft-au-cho-2c-b-k-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-276-span-class-mw-cite-backlink-b-a-href-cite-ref-276-a-b-span-span-class-reference-text-cite-class-citation-journal-quinlan-john-r-1992-learning-with-continuous-classes-i-5th-australian-joint-conference-on-artificial-intelligence-i-b-92-b-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-5th-australian-joint-conference-on-artificial-intelligence-rft-atitle-learning-with-continuous-classes-rft-volume-92-rft-date-1992-rft-aulast-quinlan-rft-aufirst-john-r-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-277-span-class-mw-cite-backlink-b-a-href-cite-ref-277-a-b-span-span-class-reference-text-cite-class-citation-journal-merz-christopher-j-pazzani-michael-j-1999-a-principal-components-approach-to-combining-regression-estimates-i-machine-learning-i-b-36-b-1-2-9-32-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1023-2fa-3a1007507221352-10-1023-a-1007507221352-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-machine-learning-rft-atitle-a-principal-components-approach-to-combining-regression-estimates-rft-volume-36-rft-issue-1-e2-80-932-rft-pages-9-32-rft-date-1999-rft-id-info-3adoi-2f10-1023-2fa-3a1007507221352-rft-aulast-merz-rft-aufirst-christopher-j-rft-au-pazzani-2c-michael-j-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-278-span-class-mw-cite-backlink-b-a-href-cite-ref-278-a-b-span-span-class-reference-text-torres-sospedra-joaquin-et-al-ujiindoorloc-mag-a-new-database-for-magnetic-field-based-localization-problems-i-indoor-positioning-and-indoor-navigation-ipin-2015-international-conference-on-i-ieee-2015-span-li-li-id-cite-note-279-span-class-mw-cite-backlink-b-a-href-cite-ref-279-a-b-span-span-class-reference-text-berkvens-rafael-maarten-weyn-and-herbert-peremans-mean-mutual-information-of-probabilistic-wi-fi-localization-i-indoor-positioning-and-indoor-navigation-ipin-2015-international-conference-on-banff-canada-ipin-i-2015-span-li-li-id-cite-note-280-span-class-mw-cite-backlink-b-a-href-cite-ref-280-a-b-span-span-class-reference-text-paschke-fabian-et-al-sensorlose-zustandsuberwachung-an-synchronmotoren-i-proceedings-23-workshop-computational-intelligence-dortmund-5-6-dezember-2013-i-kit-scientific-publishing-2013-span-li-li-id-cite-note-281-span-class-mw-cite-backlink-b-a-href-cite-ref-281-a-b-span-span-class-reference-text-lessmeier-christian-et-al-data-acquisition-and-signal-analysis-from-measured-motor-currents-for-defect-detection-in-electromechanical-drive-systems-span-li-li-id-cite-note-282-span-class-mw-cite-backlink-b-a-href-cite-ref-282-a-b-span-span-class-reference-text-ugulino-wallace-et-al-wearable-computing-accelerometers-data-classification-of-body-postures-and-movements-i-advances-in-artificial-intelligence-sbia-2012-i-springer-berlin-heidelberg-2012-52-61-span-li-li-id-cite-note-283-span-class-mw-cite-backlink-b-a-href-cite-ref-283-a-b-span-span-class-reference-text-cite-class-citation-journal-schneider-jan-et-al-2015-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4367401-augmenting-the-senses-a-review-on-sensor-based-learning-support-a-i-sensors-i-b-15-b-2-4097-4133-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-3390-2fs150204097-10-3390-s150204097-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4367401-4367401-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-25679313-25679313-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-sensors-rft-atitle-augmenting-the-senses-3a-a-review-on-sensor-based-learning-support-rft-volume-15-rft-issue-2-rft-pages-4097-4133-rft-date-2015-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4367401-rft-id-info-3apmid-2f25679313-rft-id-info-3adoi-2f10-3390-2fs150204097-rft-aulast-schneider-rft-aufirst-jan-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4367401-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-284-span-class-mw-cite-backlink-b-a-href-cite-ref-284-a-b-span-span-class-reference-text-madeo-renata-cb-clodoaldo-am-lima-and-sarajane-m-peres-gesture-unit-segmentation-using-support-vector-machines-segmenting-gestures-from-rest-positions-i-proceedings-of-the-28th-annual-acm-symposium-on-applied-computing-i-acm-2013-span-li-li-id-cite-note-285-span-class-mw-cite-backlink-b-a-href-cite-ref-285-a-b-span-span-class-reference-text-cite-class-citation-journal-lun-roanna-zhao-wenbing-2015-a-survey-of-applications-and-human-motion-recognition-with-microsoft-kinect-i-international-journal-of-pattern-recognition-and-artificial-intelligence-i-b-29-b-5-1555008-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1142-2fs0218001415550083-10-1142-s0218001415550083-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-international-journal-of-pattern-recognition-and-artificial-intelligence-rft-atitle-a-survey-of-applications-and-human-motion-recognition-with-microsoft-kinect-rft-volume-29-rft-issue-5-rft-pages-1555008-rft-date-2015-rft-id-info-3adoi-2f10-1142-2fs0218001415550083-rft-aulast-lun-rft-aufirst-roanna-rft-au-zhao-2c-wenbing-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-286-span-class-mw-cite-backlink-b-a-href-cite-ref-286-a-b-span-span-class-reference-text-theodoridis-theodoros-and-huosheng-hu-action-classification-of-3d-human-models-using-dynamic-anns-for-mobile-robot-surveillance-i-robotics-and-biomimetics-2007-robio-2007-ieee-international-conference-on-i-ieee-2007-span-li-li-id-cite-note-287-span-class-mw-cite-backlink-b-a-href-cite-ref-287-a-b-span-span-class-reference-text-etemad-seyed-ali-and-ali-arya-3d-human-action-recognition-and-style-transformation-using-resilient-backpropagation-neural-networks-i-intelligent-computing-and-intelligent-systems-2009-icis-2009-ieee-international-conference-on-i-vol-4-ieee-2009-span-li-li-id-cite-note-288-span-class-mw-cite-backlink-b-a-href-cite-ref-288-a-b-span-span-class-reference-text-cite-class-citation-journal-altun-kerem-barshan-billur-tuncel-orkun-2010-comparative-study-on-classifying-human-activities-with-miniature-inertial-and-magnetic-sensors-i-pattern-recognition-i-b-43-b-10-3605-3620-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-patcog-2010-04-019-10-1016-j-patcog-2010-04-019-a-a-href-wiki-handle-system-title-handle-system-hdl-a-a-rel-nofollow-class-external-text-href-hdl-handle-net-11693-2f11947-11693-11947-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-pattern-recognition-rft-atitle-comparative-study-on-classifying-human-activities-with-miniature-inertial-and-magnetic-sensors-rft-volume-43-rft-issue-10-rft-pages-3605-3620-rft-date-2010-rft-id-info-3ahdl-2f11693-2f11947-rft-id-info-3adoi-2f10-1016-2fj-patcog-2010-04-019-rft-aulast-altun-rft-aufirst-kerem-rft-au-barshan-2c-billur-rft-au-tun-c3-a7el-2c-orkun-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-289-span-class-mw-cite-backlink-b-a-href-cite-ref-289-a-b-span-span-class-reference-text-cite-class-citation-journal-a-href-wiki-ran-nathan-title-ran-nathan-nathan-ran-a-et-al-2012-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc3284320-using-tri-axial-acceleration-data-to-identify-behavioral-modes-of-free-ranging-animals-general-concepts-and-tools-illustrated-for-griffon-vultures-a-i-the-journal-of-experimental-biology-i-b-215-b-6-986-996-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1242-2fjeb-058602-10-1242-jeb-058602-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc3284320-3284320-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-22357592-22357592-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-the-journal-of-experimental-biology-rft-atitle-using-tri-axial-acceleration-data-to-identify-behavioral-modes-of-free-ranging-animals-3a-general-concepts-and-tools-illustrated-for-griffon-vultures-rft-volume-215-rft-issue-6-rft-pages-986-996-rft-date-2012-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc3284320-rft-id-info-3apmid-2f22357592-rft-id-info-3adoi-2f10-1242-2fjeb-058602-rft-aulast-nathan-rft-aufirst-ran-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc3284320-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-290-span-class-mw-cite-backlink-b-a-href-cite-ref-290-a-b-span-span-class-reference-text-anguita-davide-et-al-human-activity-recognition-on-smartphones-using-a-multiclass-hardware-friendly-support-vector-machine-i-ambient-assisted-living-and-home-care-i-springer-berlin-heidelberg-2012-216-223-span-li-li-id-cite-note-291-span-class-mw-cite-backlink-b-a-href-cite-ref-291-a-b-span-span-class-reference-text-cite-class-citation-journal-su-xing-tong-hanghang-ji-ping-2014-activity-recognition-with-smartphone-sensors-i-tsinghua-science-and-technology-i-b-19-b-3-235-249-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftst-2014-6838194-10-1109-tst-2014-6838194-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-tsinghua-science-and-technology-rft-atitle-activity-recognition-with-smartphone-sensors-rft-volume-19-rft-issue-3-rft-pages-235-249-rft-date-2014-rft-id-info-3adoi-2f10-1109-2ftst-2014-6838194-rft-aulast-su-rft-aufirst-xing-rft-au-tong-2c-hanghang-rft-au-ji-2c-ping-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-292-span-class-mw-cite-backlink-b-a-href-cite-ref-292-a-b-span-span-class-reference-text-kadous-mohammed-waleed-i-temporal-classification-extending-the-classification-paradigm-to-multivariate-time-series-i-diss-the-university-of-new-south-wales-2002-span-li-li-id-cite-note-293-span-class-mw-cite-backlink-b-a-href-cite-ref-293-a-b-span-span-class-reference-text-graves-alex-et-al-connectionist-temporal-classification-labelling-unsegmented-sequence-data-with-recurrent-neural-networks-i-proceedings-of-the-23rd-international-conference-on-machine-learning-i-acm-2006-span-li-li-id-cite-note-294-span-class-mw-cite-backlink-b-a-href-cite-ref-294-a-b-span-span-class-reference-text-velloso-eduardo-et-al-qualitative-activity-recognition-of-weight-lifting-exercises-i-proceedings-of-the-4th-augmented-human-international-conference-i-acm-2013-span-li-li-id-cite-note-295-span-class-mw-cite-backlink-b-a-href-cite-ref-295-a-b-span-span-class-reference-text-mortazavi-bobak-jack-et-al-determining-the-single-best-axis-for-exercise-repetition-recognition-and-counting-on-smartwatches-i-wearable-and-implantable-body-sensor-networks-bsn-2014-11th-international-conference-on-i-ieee-2014-span-li-li-id-cite-note-296-span-class-mw-cite-backlink-b-a-href-cite-ref-296-a-b-span-span-class-reference-text-sapsanis-christos-et-al-improving-emg-based-classification-of-basic-hand-movements-using-emd-i-engineering-in-medicine-and-biology-society-embc-2013-35th-annual-international-conference-of-the-ieee-i-ieee-2013-span-li-li-id-cite-note-andrianesis-konstantinos-2015-297-span-class-mw-cite-backlink-a-href-cite-ref-andrianesis-konstantinos-2015-297-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-andrianesis-konstantinos-2015-297-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-andrianesis-konstantinos-tzes-anthony-2015-development-and-control-of-a-multifunctional-prosthetic-hand-with-shape-memory-alloy-actuators-i-journal-of-intelligent-robotic-systems-i-b-78-b-2-257-289-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fs10846-014-0061-6-10-1007-s10846-014-0061-6-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-intelligent-26-robotic-systems-rft-atitle-development-and-control-of-a-multifunctional-prosthetic-hand-with-shape-memory-alloy-actuators-rft-volume-78-rft-issue-2-rft-pages-257-289-rft-date-2015-rft-id-info-3adoi-2f10-1007-2fs10846-014-0061-6-rft-aulast-andrianesis-rft-aufirst-konstantinos-rft-au-tzes-2c-anthony-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-298-span-class-mw-cite-backlink-b-a-href-cite-ref-298-a-b-span-span-class-reference-text-cite-class-citation-journal-banos-oresti-et-al-2014-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4118358-dealing-with-the-effects-of-sensor-displacement-in-wearable-activity-recognition-a-i-sensors-i-b-14-b-6-9995-10023-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-3390-2fs140609995-10-3390-s140609995-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4118358-4118358-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-24915181-24915181-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-sensors-rft-atitle-dealing-with-the-effects-of-sensor-displacement-in-wearable-activity-recognition-rft-volume-14-rft-issue-6-rft-pages-9995-10023-rft-date-2014-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4118358-rft-id-info-3apmid-2f24915181-rft-id-info-3adoi-2f10-3390-2fs140609995-rft-aulast-banos-rft-aufirst-oresti-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4118358-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-299-span-class-mw-cite-backlink-b-a-href-cite-ref-299-a-b-span-span-class-reference-text-stisen-allan-et-al-smart-devices-are-different-assessing-and-mitigatingmobile-sensing-heterogeneities-for-activity-recognition-i-proceedings-of-the-13th-acm-conference-on-embedded-networked-sensor-systems-i-acm-2015-span-li-li-id-cite-note-300-span-class-mw-cite-backlink-b-a-href-cite-ref-300-a-b-span-span-class-reference-text-bhattacharya-sourav-and-nicholas-d-lane-from-smart-to-deep-robust-activity-recognition-on-smartwatches-using-deep-learning-span-li-li-id-cite-note-301-span-class-mw-cite-backlink-b-a-href-cite-ref-301-a-b-span-span-class-reference-text-cite-class-citation-journal-bacciu-davide-et-al-2014-an-experimental-characterization-of-reservoir-computing-in-ambient-assisted-living-applications-i-neural-computing-and-applications-i-b-24-b-6-1451-1464-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fs00521-013-1364-4-10-1007-s00521-013-1364-4-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neural-computing-and-applications-rft-atitle-an-experimental-characterization-of-reservoir-computing-in-ambient-assisted-living-applications-rft-volume-24-rft-issue-6-rft-pages-1451-1464-rft-date-2014-rft-id-info-3adoi-2f10-1007-2fs00521-013-1364-4-rft-aulast-bacciu-rft-aufirst-davide-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-302-span-class-mw-cite-backlink-b-a-href-cite-ref-302-a-b-span-span-class-reference-text-palumbo-filippo-et-al-a-rel-nofollow-class-external-text-href-https-link-springer-com-chapter-10-1007-978-3-642-41043-7-3-multisensor-data-fusion-for-activity-recognition-based-on-reservoir-computing-a-i-evaluating-aal-systems-through-competitive-benchmarking-i-springer-berlin-heidelberg-2013-24-35-span-li-li-id-cite-note-303-span-class-mw-cite-backlink-b-a-href-cite-ref-303-a-b-span-span-class-reference-text-reiss-attila-and-didier-stricker-introducing-a-new-benchmarked-dataset-for-activity-monitoring-i-wearable-computers-iswc-2012-16th-international-symposium-on-i-ieee-2012-span-li-li-id-cite-note-304-span-class-mw-cite-backlink-b-a-href-cite-ref-304-a-b-span-span-class-reference-text-roggen-daniel-et-al-opportunity-towards-opportunistic-activity-and-context-recognition-systems-i-world-of-wireless-mobile-and-multimedia-networks-workshops-2009-wowmom-2009-ieee-international-symposium-on-a-i-ieee-2009-span-li-li-id-cite-note-305-span-class-mw-cite-backlink-b-a-href-cite-ref-305-a-b-span-span-class-reference-text-kurz-marc-et-al-dynamic-quantification-of-activity-recognition-capabilities-in-opportunistic-systems-i-vehicular-technology-conference-vtc-spring-2011-ieee-73rd-i-ieee-2011-span-li-li-id-cite-note-306-span-class-mw-cite-backlink-b-a-href-cite-ref-306-a-b-span-span-class-reference-text-sztyler-timo-and-heiner-stuckenschmidt-on-body-localization-of-wearable-devices-an-investigation-of-position-aware-activity-recognition-i-pervasive-computing-and-communications-percom-2016-ieee-international-conference-on-i-ieee-2016-span-li-li-id-cite-note-307-span-class-mw-cite-backlink-b-a-href-cite-ref-307-a-b-span-span-class-reference-text-cite-class-citation-journal-zhi-ying-xuan-lukasik-michelle-li-michael-h-dolatabadi-elham-wang-rosalie-h-taati-babak-2018-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc5788403-automatic-detection-of-compensation-during-robotic-stroke-rehabilitation-therapy-a-i-ieee-journal-of-translational-engineering-in-health-and-medicine-i-b-6-b-1-7-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2fjtehm-2017-2780836-10-1109-jtehm-2017-2780836-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-2168-2372-2168-2372-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc5788403-5788403-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-29404226-29404226-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-journal-of-translational-engineering-in-health-and-medicine-rft-atitle-automatic-detection-of-compensation-during-robotic-stroke-rehabilitation-therapy-rft-volume-6-rft-pages-1-7-rft-date-2018-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc5788403-rft-issn-2168-2372-rft-id-info-3apmid-2f29404226-rft-id-info-3adoi-2f10-1109-2fjtehm-2017-2780836-rft-aulast-zhi-rft-aufirst-ying-xuan-rft-au-lukasik-2c-michelle-rft-au-li-2c-michael-h-rft-au-dolatabadi-2c-elham-rft-au-wang-2c-rosalie-h-rft-au-taati-2c-babak-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc5788403-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-308-span-class-mw-cite-backlink-b-a-href-cite-ref-308-a-b-span-span-class-reference-text-cite-class-citation-book-dolatabadi-elham-zhi-ying-xuan-ye-bing-coahran-marge-lupinacci-giorgia-mihailidis-alex-wang-rosalie-taati-babak-23-may-2017-a-rel-nofollow-class-external-text-href-http-dl-acm-org-citation-cfm-id-3154862-3154925-i-the-toronto-rehab-stroke-pose-dataset-to-detect-compensation-during-stroke-rehabilitation-therapy-i-a-acm-pp-375-381-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1145-2f3154862-3154925-10-1145-3154862-3154925-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-9781450363631-title-special-booksources-9781450363631-bdi-9781450363631-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-the-toronto-rehab-stroke-pose-dataset-to-detect-compensation-during-stroke-rehabilitation-therapy-rft-pages-375-381-rft-pub-acm-rft-date-2017-05-23-rft-id-info-3adoi-2f10-1145-2f3154862-3154925-rft-isbn-9781450363631-rft-aulast-dolatabadi-rft-aufirst-elham-rft-au-zhi-2c-ying-xuan-rft-au-ye-2c-bing-rft-au-coahran-2c-marge-rft-au-lupinacci-2c-giorgia-rft-au-mihailidis-2c-alex-rft-au-wang-2c-rosalie-rft-au-taati-2c-babak-rft-id-http-3a-2f-2fdl-acm-org-2fcitation-cfm-3fid-3d3154862-3154925-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-309-span-class-mw-cite-backlink-b-a-href-cite-ref-309-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-kaggle-com-derekdb-toronto-robot-stroke-posture-dataset-toronto-rehab-stroke-pose-dataset-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-toronto-rehab-stroke-pose-dataset-rft-id-https-3a-2f-2fwww-kaggle-com-2fderekdb-2ftoronto-robot-stroke-posture-dataset-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-310-span-class-mw-cite-backlink-b-a-href-cite-ref-310-a-b-span-span-class-reference-text-aeberhard-s-d-coomans-and-o-de-vel-comparison-of-classifiers-in-high-dimensional-settings-i-dept-math-statist-james-cook-univ-north-queensland-australia-tech-rep-i-92-02-1992-span-li-li-id-cite-note-311-span-class-mw-cite-backlink-b-a-href-cite-ref-311-a-b-span-span-class-reference-text-basu-sugato-a-rel-nofollow-class-external-text-href-http-www-aaai-org-papers-aaai-2004-aaai04-138-pdf-semi-supervised-clustering-with-limited-background-knowledge-a-i-aaai-i-2004-span-li-li-id-cite-note-312-span-class-mw-cite-backlink-b-a-href-cite-ref-312-a-b-span-span-class-reference-text-cite-class-citation-journal-tufekci-pinar-2014-prediction-of-full-load-electrical-power-output-of-a-base-load-operated-combined-cycle-power-plant-using-machine-learning-methods-i-international-journal-of-electrical-power-energy-systems-i-b-60-b-126-140-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-ijepes-2014-02-027-10-1016-j-ijepes-2014-02-027-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-international-journal-of-electrical-power-26-energy-systems-rft-atitle-prediction-of-full-load-electrical-power-output-of-a-base-load-operated-combined-cycle-power-plant-using-machine-learning-methods-rft-volume-60-rft-pages-126-140-rft-date-2014-rft-id-info-3adoi-2f10-1016-2fj-ijepes-2014-02-027-rft-aulast-t-c3-bcfekci-rft-aufirst-p-c4-b1nar-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-313-span-class-mw-cite-backlink-b-a-href-cite-ref-313-a-b-span-span-class-reference-text-kaya-heysem-pinar-tufekci-and-fikret-s-gurgen-local-and-global-learning-methods-for-predicting-power-of-a-combined-gas-steam-turbine-i-international-conference-on-emerging-trends-in-computer-and-electronics-engineering-icetcee-2012-dubai-i-2012-span-li-li-id-cite-note-314-span-class-mw-cite-backlink-b-a-href-cite-ref-314-a-b-span-span-class-reference-text-cite-class-citation-journal-baldi-pierre-sadowski-peter-whiteson-daniel-2014-searching-for-exotic-particles-in-high-energy-physics-with-deep-learning-i-nature-communications-i-b-5-b-2014-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1402-4735-1402-4735-a-span-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2014natco-5e4308b-2014natco-5e4308b-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1038-2fncomms5308-10-1038-ncomms5308-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-24986233-24986233-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-nature-communications-rft-atitle-searching-for-exotic-particles-in-high-energy-physics-with-deep-learning-rft-volume-5-rft-pages-2014-rft-date-2014-rft-id-info-3aarxiv-2f1402-4735-rft-id-info-3apmid-2f24986233-rft-id-info-3adoi-2f10-1038-2fncomms5308-rft-id-info-3abibcode-2f2014natco-5e4308b-rft-aulast-baldi-rft-aufirst-pierre-rft-au-sadowski-2c-peter-rft-au-whiteson-2c-daniel-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-8-315-span-class-mw-cite-backlink-a-href-cite-ref-8-315-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-8-315-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-baldi-pierre-sadowski-peter-whiteson-daniel-2015-enhanced-higgs-boson-to-t-t-search-with-deep-learning-i-physical-review-letters-i-b-114-b-11-111801-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1410-3469-1410-3469-a-span-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2015phrvl-114k1801b-2015phrvl-114k1801b-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1103-2fphysrevlett-114-111801-10-1103-physrevlett-114-111801-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-25839260-25839260-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-physical-review-letters-rft-atitle-enhanced-higgs-boson-to-cf-84-2b-cf-84-e2-88-92-search-with-deep-learning-rft-volume-114-rft-issue-11-rft-pages-111801-rft-date-2015-rft-id-info-3aarxiv-2f1410-3469-rft-id-info-3apmid-2f25839260-rft-id-info-3adoi-2f10-1103-2fphysrevlett-114-111801-rft-id-info-3abibcode-2f2015phrvl-114k1801b-rft-aulast-baldi-rft-aufirst-pierre-rft-au-sadowski-2c-peter-rft-au-whiteson-2c-daniel-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-9-316-span-class-mw-cite-backlink-a-href-cite-ref-9-316-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-9-316-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-adam-bourdarios-c-cowan-g-germain-renaud-c-guyon-i-kegl-b-rousseau-d-2015-a-rel-nofollow-class-external-text-href-https-higgsml-lal-in2p3-fr-the-higgs-machine-learning-challenge-a-i-journal-of-physics-conference-series-i-b-664-b-7-072015-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2015jphcs-664g2015a-2015jphcs-664g2015a-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1088-2f1742-6596-2f664-2f7-2f072015-10-1088-1742-6596-664-7-072015-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-physics-conference-series-rft-atitle-the-higgs-machine-learning-challenge-rft-volume-664-rft-issue-7-rft-pages-072015-rft-date-2015-rft-id-info-3adoi-2f10-1088-2f1742-6596-2f664-2f7-2f072015-rft-id-info-3abibcode-2f2015jphcs-664g2015a-rft-aulast-adam-bourdarios-rft-aufirst-c-rft-au-cowan-2c-g-rft-au-germain-renaud-2c-c-rft-au-guyon-2c-i-rft-au-k-c3-a9gl-2c-b-rft-au-rousseau-2c-d-rft-id-https-3a-2f-2fhiggsml-lal-in2p3-fr-2f-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-317-span-class-mw-cite-backlink-b-a-href-cite-ref-317-a-b-span-span-class-reference-text-pierre-baldi-kyle-cranmer-taylor-faucett-peter-sadowski-and-daniel-whiteson-parameterized-machine-learning-for-high-energy-physics-in-submission-span-li-li-id-cite-note-318-span-class-mw-cite-backlink-b-a-href-cite-ref-318-a-b-span-span-class-reference-text-cite-class-citation-journal-ortigosa-i-lopez-r-garcia-j-a-neural-networks-approach-to-residuary-resistance-of-sailing-yachts-prediction-i-proceedings-of-the-international-conference-on-marine-engineering-marine-i-b-2007-b-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-proceedings-of-the-international-conference-on-marine-engineering-marine-rft-atitle-a-neural-networks-approach-to-residuary-resistance-of-sailing-yachts-prediction-rft-volume-2007-rft-aulast-ortigosa-rft-aufirst-i-rft-au-lopez-2c-r-rft-au-garcia-2c-j-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-319-span-class-mw-cite-backlink-b-a-href-cite-ref-319-a-b-span-span-class-reference-text-gerritsma-j-r-onnink-and-a-versluis-i-geometry-resistance-and-stability-of-the-delft-systematic-yacht-hull-series-i-delft-university-of-technology-1981-span-li-li-id-cite-note-320-span-class-mw-cite-backlink-b-a-href-cite-ref-320-a-b-span-span-class-reference-text-liu-huan-and-hiroshi-motoda-i-a-rel-nofollow-class-external-text-href-https-books-google-com-books-id-zi-0edww5fyc-printsec-frontcover-v-onepage-q-f-false-feature-extraction-construction-and-selection-a-data-mining-perspective-a-i-springer-science-business-media-1998-span-li-li-id-cite-note-321-span-class-mw-cite-backlink-b-a-href-cite-ref-321-a-b-span-span-class-reference-text-reich-yoram-i-converging-to-ideal-design-knowledge-by-learning-i-carnegie-mellon-university-engineering-design-research-center-1989-span-li-li-id-cite-note-322-span-class-mw-cite-backlink-b-a-href-cite-ref-322-a-b-span-span-class-reference-text-todorovski-ljupco-and-saso-dzeroski-i-a-rel-nofollow-class-external-text-href-https-link-springer-com-chapter-10-1007-978-3-540-48247-5-11-experiments-in-meta-level-learning-with-ilp-a-i-springer-berlin-heidelberg-1999-span-li-li-id-cite-note-323-span-class-mw-cite-backlink-b-a-href-cite-ref-323-a-b-span-span-class-reference-text-wang-yong-i-a-new-approach-to-fitting-linear-models-in-high-dimensional-spaces-i-diss-the-university-of-waikato-2000-span-li-li-id-cite-note-324-span-class-mw-cite-backlink-b-a-href-cite-ref-324-a-b-span-span-class-reference-text-cite-class-citation-journal-kibler-dennis-aha-david-w-albert-marc-k-1989-instance-based-prediction-of-real-valued-attributes-i-computational-intelligence-i-b-5-b-2-51-57-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1111-2fj-1467-8640-1989-tb00315-x-10-1111-j-1467-8640-1989-tb00315-x-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-computational-intelligence-rft-atitle-instance-e2-80-90based-prediction-of-real-e2-80-90valued-attributes-rft-volume-5-rft-issue-2-rft-pages-51-57-rft-date-1989-rft-id-info-3adoi-2f10-1111-2fj-1467-8640-1989-tb00315-x-rft-aulast-kibler-rft-aufirst-dennis-rft-au-aha-2c-david-w-rft-au-albert-2c-marc-k-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-325-span-class-mw-cite-backlink-b-a-href-cite-ref-325-a-b-span-span-class-reference-text-palmer-christopher-r-and-christos-faloutsos-a-rel-nofollow-class-external-text-href-http-citeseerx-ist-psu-edu-viewdoc-download-doi-10-1-1-469-989-rep-rep1-type-pdf-electricity-based-external-similarity-of-categorical-attributes-a-i-advances-in-knowledge-discovery-and-data-mining-i-springer-berlin-heidelberg-2003-486-500-span-li-li-id-cite-note-326-span-class-mw-cite-backlink-b-a-href-cite-ref-326-a-b-span-span-class-reference-text-cite-class-citation-journal-tsanas-athanasios-xifara-angeliki-2012-accurate-quantitative-estimation-of-energy-performance-of-residential-buildings-using-statistical-machine-learning-tools-i-energy-and-buildings-i-b-49-b-560-567-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-enbuild-2012-03-003-10-1016-j-enbuild-2012-03-003-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-energy-and-buildings-rft-atitle-accurate-quantitative-estimation-of-energy-performance-of-residential-buildings-using-statistical-machine-learning-tools-rft-volume-49-rft-pages-560-567-rft-date-2012-rft-id-info-3adoi-2f10-1016-2fj-enbuild-2012-03-003-rft-aulast-tsanas-rft-aufirst-athanasios-rft-au-xifara-2c-angeliki-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-327-span-class-mw-cite-backlink-b-a-href-cite-ref-327-a-b-span-span-class-reference-text-cite-class-citation-journal-de-wilde-pieter-2014-the-gap-between-predicted-and-measured-energy-performance-of-buildings-a-framework-for-investigation-i-automation-in-construction-i-b-41-b-40-49-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-autcon-2014-02-009-10-1016-j-autcon-2014-02-009-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-automation-in-construction-rft-atitle-the-gap-between-predicted-and-measured-energy-performance-of-buildings-3a-a-framework-for-investigation-rft-volume-41-rft-pages-40-49-rft-date-2014-rft-id-info-3adoi-2f10-1016-2fj-autcon-2014-02-009-rft-aulast-de-wilde-rft-aufirst-pieter-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-328-span-class-mw-cite-backlink-b-a-href-cite-ref-328-a-b-span-span-class-reference-text-brooks-thomas-f-d-stuart-pope-and-michael-a-marcolini-i-airfoil-self-noise-and-prediction-i-vol-1218-national-aeronautics-and-space-administration-office-of-management-scientific-and-technical-information-division-1989-span-li-li-id-cite-note-329-span-class-mw-cite-backlink-b-a-href-cite-ref-329-a-b-span-span-class-reference-text-draper-david-assessment-and-propagation-of-model-uncertainty-i-journal-of-the-royal-statistical-society-series-b-methodological-i-1995-45-97-span-li-li-id-cite-note-330-span-class-mw-cite-backlink-b-a-href-cite-ref-330-a-b-span-span-class-reference-text-cite-class-citation-journal-lavine-michael-1991-problems-in-extrapolation-illustrated-with-space-shuttle-o-ring-data-i-journal-of-the-american-statistical-association-i-b-86-b-416-919-921-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1080-2f01621459-1991-10475132-10-1080-01621459-1991-10475132-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-the-american-statistical-association-rft-atitle-problems-in-extrapolation-illustrated-with-space-shuttle-o-ring-data-rft-volume-86-rft-issue-416-rft-pages-919-921-rft-date-1991-rft-id-info-3adoi-2f10-1080-2f01621459-1991-10475132-rft-aulast-lavine-rft-aufirst-michael-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-331-span-class-mw-cite-backlink-b-a-href-cite-ref-331-a-b-span-span-class-reference-text-wang-jun-bei-yu-and-les-gasser-concept-tree-based-clustering-visualization-with-shaded-similarity-matrices-i-data-mining-2002-icdm-2003-proceedings-2002-ieee-international-conference-on-i-ieee-2002-span-li-li-id-cite-note-332-span-class-mw-cite-backlink-b-a-href-cite-ref-332-a-b-span-span-class-reference-text-pettengill-gordon-h-et-al-magellan-radar-performance-and-data-products-i-science-i-252-5003-1991-260-265-span-li-li-id-cite-note-10-333-span-class-mw-cite-backlink-a-href-cite-ref-10-333-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-10-333-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-aharonian-f-et-al-2008-energy-spectrum-of-cosmic-ray-electrons-at-tev-energies-i-physical-review-letters-i-b-101-b-26-261104-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-0811-3894-0811-3894-a-span-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2008phrvl-101z1104a-2008phrvl-101z1104a-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1103-2fphysrevlett-101-261104-10-1103-physrevlett-101-261104-a-a-href-wiki-handle-system-title-handle-system-hdl-a-a-rel-nofollow-class-external-text-href-hdl-handle-net-2440-2f51450-2440-51450-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-19437632-19437632-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-physical-review-letters-rft-atitle-energy-spectrum-of-cosmic-ray-electrons-at-tev-energies-rft-volume-101-rft-issue-26-rft-pages-261104-rft-date-2008-rft-id-info-3ahdl-2f2440-2f51450-rft-id-info-3abibcode-2f2008phrvl-101z1104a-rft-id-info-3aarxiv-2f0811-3894-rft-id-info-3apmid-2f19437632-rft-id-info-3adoi-2f10-1103-2fphysrevlett-101-261104-rft-aulast-aharonian-rft-aufirst-f-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-334-span-class-mw-cite-backlink-b-a-href-cite-ref-334-a-b-span-span-class-reference-text-cite-class-citation-journal-bock-r-k-et-al-2004-methods-for-multidimensional-event-classification-a-case-study-using-images-from-a-cherenkov-gamma-ray-telescope-i-nuclear-instruments-and-methods-in-physics-research-section-a-accelerators-spectrometers-detectors-and-associated-equipment-i-b-516-b-2-511-528-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2004nimpa-516-511b-2004nimpa-516-511b-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-nima-2003-08-157-10-1016-j-nima-2003-08-157-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-nuclear-instruments-and-methods-in-physics-research-section-a-3a-accelerators-2c-spectrometers-2c-detectors-and-associated-equipment-rft-atitle-methods-for-multidimensional-event-classification-3a-a-case-study-using-images-from-a-cherenkov-gamma-ray-telescope-rft-volume-516-rft-issue-2-rft-pages-511-528-rft-date-2004-rft-id-info-3adoi-2f10-1016-2fj-nima-2003-08-157-rft-id-info-3abibcode-2f2004nimpa-516-511b-rft-aulast-bock-rft-aufirst-r-k-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-335-span-class-mw-cite-backlink-b-a-href-cite-ref-335-a-b-span-span-class-reference-text-cite-class-citation-journal-li-jinyan-et-al-2004-deeps-a-new-instance-based-lazy-discovery-and-classification-system-i-machine-learning-i-b-54-b-2-99-124-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1023-2fb-3amach-0000011804-08528-7d-10-1023-b-mach-0000011804-08528-7d-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-machine-learning-rft-atitle-deeps-3a-a-new-instance-based-lazy-discovery-and-classification-system-rft-volume-54-rft-issue-2-rft-pages-99-124-rft-date-2004-rft-id-info-3adoi-2f10-1023-2fb-3amach-0000011804-08528-7d-rft-aulast-li-rft-aufirst-jinyan-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-336-span-class-mw-cite-backlink-b-a-href-cite-ref-336-a-b-span-span-class-reference-text-siebert-lee-and-tom-simkin-volcanoes-of-the-world-an-illustrated-catalog-of-holocene-volcanoes-and-their-eruptions-2014-span-li-li-id-cite-note-337-span-class-mw-cite-backlink-b-a-href-cite-ref-337-a-b-span-span-class-reference-text-cite-class-citation-journal-sikora-marek-wrobel-lukasz-2010-application-of-rule-induction-algorithms-for-analysis-of-data-collected-by-seismic-hazard-monitoring-systems-in-coal-mines-i-archives-of-mining-sciences-i-b-55-b-1-91-114-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-archives-of-mining-sciences-rft-atitle-application-of-rule-induction-algorithms-for-analysis-of-data-collected-by-seismic-hazard-monitoring-systems-in-coal-mines-rft-volume-55-rft-issue-1-rft-pages-91-114-rft-date-2010-rft-aulast-sikora-rft-aufirst-marek-rft-au-wr-c3-b3bel-2c-c5-81ukasz-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-338-span-class-mw-cite-backlink-b-a-href-cite-ref-338-a-b-span-span-class-reference-text-sikora-marek-and-beata-sikora-rough-natural-hazards-monitoring-i-rough-sets-selected-methods-and-applications-in-management-and-engineering-i-springer-london-2012-163-179-span-li-li-id-cite-note-339-span-class-mw-cite-backlink-b-a-href-cite-ref-339-a-b-span-span-class-reference-text-cite-class-citation-journal-yeh-i-c-1998-modeling-of-strength-of-high-performance-concrete-using-artificial-neural-networks-i-cement-and-concrete-research-i-b-28-b-12-1797-1808-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fs0008-8846-2898-2900165-3-10-1016-s0008-8846-98-00165-3-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-cement-and-concrete-research-rft-atitle-modeling-of-strength-of-high-performance-concrete-using-artificial-neural-networks-rft-volume-28-rft-issue-12-rft-pages-1797-1808-rft-date-1998-rft-id-info-3adoi-2f10-1016-2fs0008-8846-2898-2900165-3-rft-aulast-yeh-rft-aufirst-i-e2-80-93c-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-340-span-class-mw-cite-backlink-b-a-href-cite-ref-340-a-b-span-span-class-reference-text-cite-class-citation-journal-zarandi-mh-fazel-et-al-2008-fuzzy-polynomial-neural-networks-for-approximation-of-the-compressive-strength-of-concrete-i-applied-soft-computing-i-b-8-b-1-488-498-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2008apsoc-8-79s-2008apsoc-8-79s-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-asoc-2007-02-010-10-1016-j-asoc-2007-02-010-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-applied-soft-computing-rft-atitle-fuzzy-polynomial-neural-networks-for-approximation-of-the-compressive-strength-of-concrete-rft-volume-8-rft-issue-1-rft-pages-488-498-rft-date-2008-rft-id-info-3adoi-2f10-1016-2fj-asoc-2007-02-010-rft-id-info-3abibcode-2f2008apsoc-8-79s-rft-aulast-zarandi-rft-aufirst-mh-fazel-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-341-span-class-mw-cite-backlink-b-a-href-cite-ref-341-a-b-span-span-class-reference-text-yeh-i-modeling-slump-of-concrete-with-fly-ash-and-superplasticizer-i-computers-and-concrete-i-5-6-2008-559-572-span-li-li-id-cite-note-342-span-class-mw-cite-backlink-b-a-href-cite-ref-342-a-b-span-span-class-reference-text-cite-class-citation-journal-gencel-osman-et-al-2011-comparison-of-artificial-neural-networks-and-general-linear-model-approaches-for-the-analysis-of-abrasive-wear-of-concrete-i-construction-and-building-materials-i-b-25-b-8-3486-3494-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-conbuildmat-2011-03-040-10-1016-j-conbuildmat-2011-03-040-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-construction-and-building-materials-rft-atitle-comparison-of-artificial-neural-networks-and-general-linear-model-approaches-for-the-analysis-of-abrasive-wear-of-concrete-rft-volume-25-rft-issue-8-rft-pages-3486-3494-rft-date-2011-rft-id-info-3adoi-2f10-1016-2fj-conbuildmat-2011-03-040-rft-aulast-gencel-rft-aufirst-osman-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-343-span-class-mw-cite-backlink-b-a-href-cite-ref-343-a-b-span-span-class-reference-text-dietterich-thomas-g-et-al-a-comparison-of-dynamic-reposing-and-tangent-distance-for-drug-activity-prediction-i-advances-in-neural-information-processing-systems-i-1994-216-216-span-li-li-id-cite-note-344-span-class-mw-cite-backlink-b-a-href-cite-ref-344-a-b-span-span-class-reference-text-buscema-massimo-william-j-tastle-and-stefano-terzi-meta-net-a-new-meta-classifier-family-i-data-mining-applications-using-artificial-adaptive-systems-i-springer-new-york-2013-141-182-span-li-li-id-cite-note-3-345-span-class-mw-cite-backlink-b-a-href-cite-ref-3-345-0-a-b-span-span-class-reference-text-cite-class-citation-journal-ingber-lester-1997-statistical-mechanics-of-neocortical-interactions-canonical-momenta-indicatorsof-electroencephalography-i-physical-review-e-i-b-55-b-4-4578-4593-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-physics-0001052-physics-0001052-a-span-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-1997phrve-55-4578i-1997phrve-55-4578i-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1103-2fphysreve-55-4578-10-1103-physreve-55-4578-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-physical-review-e-rft-atitle-statistical-mechanics-of-neocortical-interactions-3a-canonical-momenta-indicatorsof-electroencephalography-rft-volume-55-rft-issue-4-rft-pages-4578-4593-rft-date-1997-rft-id-info-3aarxiv-2fphysics-2f0001052-rft-id-info-3adoi-2f10-1103-2fphysreve-55-4578-rft-id-info-3abibcode-2f1997phrve-55-4578i-rft-aulast-ingber-rft-aufirst-lester-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-346-span-class-mw-cite-backlink-b-a-href-cite-ref-346-a-b-span-span-class-reference-text-cite-class-citation-journal-hoffmann-ulrich-vesin-jean-marc-ebrahimi-touradj-diserens-karin-2008-an-efficient-p300-based-brain-computer-interface-for-disabled-subjects-i-journal-of-neuroscience-methods-i-b-167-b-1-115-125-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-352-4630-10-1-1-352-4630-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-jneumeth-2007-03-005-10-1016-j-jneumeth-2007-03-005-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-17445904-17445904-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-neuroscience-methods-rft-atitle-an-efficient-p300-based-brain-e2-80-93computer-interface-for-disabled-subjects-rft-volume-167-rft-issue-1-rft-pages-115-125-rft-date-2008-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-352-4630-rft-id-info-3apmid-2f17445904-rft-id-info-3adoi-2f10-1016-2fj-jneumeth-2007-03-005-rft-aulast-hoffmann-rft-aufirst-ulrich-rft-au-vesin-2c-jean-marc-rft-au-ebrahimi-2c-touradj-rft-au-diserens-2c-karin-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-347-span-class-mw-cite-backlink-b-a-href-cite-ref-347-a-b-span-span-class-reference-text-cite-class-citation-journal-donchin-emanuel-spencer-kevin-m-wijesinghe-ranjith-2000-the-mental-prosthesis-assessing-the-speed-of-a-p300-based-brain-computer-interface-i-ieee-transactions-on-rehabilitation-engineering-i-b-8-b-2-174-179-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2f86-847808-10-1109-86-847808-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-10896179-10896179-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-rehabilitation-engineering-rft-atitle-the-mental-prosthesis-3a-assessing-the-speed-of-a-p300-based-brain-computer-interface-rft-volume-8-rft-issue-2-rft-pages-174-179-rft-date-2000-rft-id-info-3adoi-2f10-1109-2f86-847808-rft-id-info-3apmid-2f10896179-rft-aulast-donchin-rft-aufirst-emanuel-rft-au-spencer-2c-kevin-m-rft-au-wijesinghe-2c-ranjith-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-348-span-class-mw-cite-backlink-b-a-href-cite-ref-348-a-b-span-span-class-reference-text-cite-class-citation-journal-detrano-robert-et-al-1989-international-application-of-a-new-probability-algorithm-for-the-diagnosis-of-coronary-artery-disease-i-the-american-journal-of-cardiology-i-b-64-b-5-304-310-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2f0002-9149-2889-2990524-9-10-1016-0002-9149-89-90524-9-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-the-american-journal-of-cardiology-rft-atitle-international-application-of-a-new-probability-algorithm-for-the-diagnosis-of-coronary-artery-disease-rft-volume-64-rft-issue-5-rft-pages-304-310-rft-date-1989-rft-id-info-3adoi-2f10-1016-2f0002-9149-2889-2990524-9-rft-aulast-detrano-rft-aufirst-robert-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-349-span-class-mw-cite-backlink-b-a-href-cite-ref-349-a-b-span-span-class-reference-text-cite-class-citation-journal-bradley-andrew-p-1997-the-use-of-the-area-under-the-roc-curve-in-the-evaluation-of-machine-learning-algorithms-i-pattern-recognition-i-b-30-b-7-1145-1159-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fs0031-3203-2896-2900142-2-10-1016-s0031-3203-96-00142-2-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-pattern-recognition-rft-atitle-the-use-of-the-area-under-the-roc-curve-in-the-evaluation-of-machine-learning-algorithms-rft-volume-30-rft-issue-7-rft-pages-1145-1159-rft-date-1997-rft-id-info-3adoi-2f10-1016-2fs0031-3203-2896-2900142-2-rft-aulast-bradley-rft-aufirst-andrew-p-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-350-span-class-mw-cite-backlink-b-a-href-cite-ref-350-a-b-span-span-class-reference-text-street-w-nick-william-h-wolberg-and-olvi-l-mangasarian-a-rel-nofollow-class-external-text-href-https-www-spiedigitallibrary-org-conference-proceedings-of-spie-1905-0000-nuclear-feature-extraction-for-breast-tumor-diagnosis-10-1117-12-148698-short-nuclear-feature-extraction-for-breast-tumor-diagnosis-a-i-is-t-spie-s-symposium-on-electronic-imaging-science-and-technology-i-international-society-for-optics-and-photonics-1993-span-li-li-id-cite-note-351-span-class-mw-cite-backlink-b-a-href-cite-ref-351-a-b-span-span-class-reference-text-demir-cigdem-and-bulent-yener-automated-cancer-diagnosis-based-on-histopathological-images-a-systematic-survey-i-rensselaer-polytechnic-institute-tech-rep-i-2005-span-li-li-id-cite-note-352-span-class-mw-cite-backlink-b-a-href-cite-ref-352-a-b-span-span-class-reference-text-abuse-substance-mental-health-services-administration-results-from-the-2010-national-survey-on-drug-use-and-health-summary-of-national-findings-nsduh-series-h-41-hhs-publication-no-sma-11-4658-i-rockville-md-substance-abuse-and-mental-health-services-administration-i-201-2011-span-li-li-id-cite-note-353-span-class-mw-cite-backlink-b-a-href-cite-ref-353-a-b-span-span-class-reference-text-cite-class-citation-journal-hong-zi-quan-yang-jing-yu-1991-optimal-discriminant-plane-for-a-small-number-of-samples-and-design-method-of-classifier-on-the-plane-i-pattern-recognition-i-b-24-b-4-317-324-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2f0031-3203-2891-2990074-f-10-1016-0031-3203-91-90074-f-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-pattern-recognition-rft-atitle-optimal-discriminant-plane-for-a-small-number-of-samples-and-design-method-of-classifier-on-the-plane-rft-volume-24-rft-issue-4-rft-pages-317-324-rft-date-1991-rft-id-info-3adoi-2f10-1016-2f0031-3203-2891-2990074-f-rft-aulast-hong-rft-aufirst-zi-quan-rft-au-yang-2c-jing-yu-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-jinyan-2003-354-span-class-mw-cite-backlink-a-href-cite-ref-jinyan-2003-354-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-jinyan-2003-354-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-li-jinyan-and-limsoon-wong-using-rules-to-analyse-bio-medical-data-a-comparison-between-c4-5-and-pcl-i-advances-in-web-age-information-management-i-springer-berlin-heidelberg-2003-254-265-span-li-li-id-cite-note-355-span-class-mw-cite-backlink-b-a-href-cite-ref-355-a-b-span-span-class-reference-text-guvenir-h-altay-et-al-a-supervised-machine-learning-algorithm-for-arrhythmia-analysis-i-computers-in-cardiology-1997-i-ieee-1997-span-li-li-id-cite-note-356-span-class-mw-cite-backlink-b-a-href-cite-ref-356-a-b-span-span-class-reference-text-lagus-krista-et-al-independent-variable-group-analysis-in-learning-compact-representations-for-data-i-proceedings-of-the-international-and-interdisciplinary-conference-on-adaptive-knowledge-representation-and-reasoning-akrr-05-t-honkela-v-kononen-m-polla-and-o-simula-eds-espoo-finland-i-2005-span-li-li-id-cite-note-357-span-class-mw-cite-backlink-b-a-href-cite-ref-357-a-b-span-span-class-reference-text-strack-beata-et-al-impact-of-hba1c-measurement-on-hospital-readmission-rates-analysis-of-70000-clinical-database-patient-records-i-biomed-research-international-i-2014-2014-span-li-li-id-cite-note-358-span-class-mw-cite-backlink-b-a-href-cite-ref-358-a-b-span-span-class-reference-text-cite-class-citation-journal-rubin-daniel-j-2015-hospital-readmission-of-patients-with-diabetes-i-current-diabetes-reports-i-b-15-b-4-1-9-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fs11892-015-0584-7-10-1007-s11892-015-0584-7-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-25712258-25712258-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-current-diabetes-reports-rft-atitle-hospital-readmission-of-patients-with-diabetes-rft-volume-15-rft-issue-4-rft-pages-1-9-rft-date-2015-rft-id-info-3adoi-2f10-1007-2fs11892-015-0584-7-rft-id-info-3apmid-2f25712258-rft-aulast-rubin-rft-aufirst-daniel-j-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-359-span-class-mw-cite-backlink-b-a-href-cite-ref-359-a-b-span-span-class-reference-text-cite-class-citation-journal-antal-balint-hajdu-andras-2014-an-ensemble-based-system-for-automatic-screening-of-diabetic-retinopathy-i-knowledge-based-systems-i-b-60-b-2014-20-27-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1410-8576-1410-8576-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-knosys-2013-12-023-10-1016-j-knosys-2013-12-023-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-knowledge-based-systems-rft-atitle-an-ensemble-based-system-for-automatic-screening-of-diabetic-retinopathy-rft-volume-60-rft-issue-2014-rft-pages-20-27-rft-date-2014-rft-id-info-3aarxiv-2f1410-8576-rft-id-info-3adoi-2f10-1016-2fj-knosys-2013-12-023-rft-aulast-antal-rft-aufirst-b-c3-a1lint-rft-au-hajdu-2c-andr-c3-a1s-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-360-span-class-mw-cite-backlink-b-a-href-cite-ref-360-a-b-span-span-class-reference-text-cite-class-citation-arxiv-haloi-mrinal-2015-improved-microaneurysm-detection-using-deep-neural-networks-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1505-04424-1505-04424-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-improved-microaneurysm-detection-using-deep-neural-networks-rft-date-2015-rft-id-info-3aarxiv-2f1505-04424-rft-aulast-haloi-rft-aufirst-mrinal-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-361-span-class-mw-cite-backlink-b-a-href-cite-ref-361-a-b-span-span-class-reference-text-cite-class-citation-web-elie-guillaume-patry-gervais-gauthier-bruno-lay-julien-roger-damien-a-rel-nofollow-class-external-text-href-http-www-adcis-net-en-download-third-party-messidor-htmldownload-php-adcis-download-third-party-messidor-database-a-i-www-adcis-net-i-span-class-reference-accessdate-retrieved-span-class-nowrap-25-february-span-2018-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-www-adcis-net-rft-atitle-adcis-download-third-party-3a-messidor-database-rft-aulast-elie-rft-aufirst-guillaume-patry-2c-gervais-gauthier-2c-bruno-lay-2c-julien-roger-2c-damien-rft-id-http-3a-2f-2fwww-adcis-net-2fen-2fdownload-third-party-2fmessidor-htmldownload-php-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-362-span-class-mw-cite-backlink-b-a-href-cite-ref-362-a-b-span-span-class-reference-text-cite-class-citation-journal-decenciere-etienne-zhang-xiwei-cazuguel-guy-lay-bruno-cochener-beatrice-trone-caroline-gain-philippe-ordonez-richard-massin-pascale-26-august-2014-a-rel-nofollow-class-external-text-href-https-www-ias-iss-org-ojs-ias-article-view-1155-feedback-on-a-publicly-distributed-image-database-the-messidor-database-a-i-image-analysis-stereology-i-b-33-b-3-231-234-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-5566-2fias-1155-10-5566-ias-1155-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-1854-5165-1854-5165-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-image-analysis-26-stereology-rft-atitle-feedback-on-a-publicly-distributed-image-database-3a-the-messidor-database-rft-volume-33-rft-issue-3-rft-pages-231-234-rft-date-2014-08-26-rft-id-info-3adoi-2f10-5566-2fias-1155-rft-issn-1854-5165-rft-aulast-decenci-c3-a8re-rft-aufirst-etienne-rft-au-zhang-2c-xiwei-rft-au-cazuguel-2c-guy-rft-au-lay-2c-bruno-rft-au-cochener-2c-b-c3-a9atrice-rft-au-trone-2c-caroline-rft-au-gain-2c-philippe-rft-au-ordonez-2c-richard-rft-au-massin-2c-pascale-rft-id-https-3a-2f-2fwww-ias-iss-org-2fojs-2fias-2farticle-2fview-2f1155-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-363-span-class-mw-cite-backlink-b-a-href-cite-ref-363-a-b-span-span-class-reference-text-cite-class-citation-journal-bagirov-a-m-et-al-2003-unsupervised-and-supervised-data-classification-via-nonsmooth-and-global-optimization-i-top-i-b-11-b-1-1-75-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-1-6429-10-1-1-1-6429-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fbf02578945-10-1007-bf02578945-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-top-rft-atitle-unsupervised-and-supervised-data-classification-via-nonsmooth-and-global-optimization-rft-volume-11-rft-issue-1-rft-pages-1-75-rft-date-2003-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-1-6429-rft-id-info-3adoi-2f10-1007-2fbf02578945-rft-aulast-bagirov-rft-aufirst-a-m-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-364-span-class-mw-cite-backlink-b-a-href-cite-ref-364-a-b-span-span-class-reference-text-fung-glenn-et-al-a-fast-iterative-algorithm-for-fisher-discriminant-using-heterogeneous-kernels-i-proceedings-of-the-twenty-first-international-conference-on-machine-learning-i-acm-2004-span-li-li-id-cite-note-365-span-class-mw-cite-backlink-b-a-href-cite-ref-365-a-b-span-span-class-reference-text-quinlan-john-ross-et-al-inductive-knowledge-acquisition-a-case-study-i-proceedings-of-the-second-australian-conference-on-applications-of-expert-systems-i-addison-wesley-longman-publishing-co-inc-1987-span-li-li-id-cite-note-zhou-zhi-hua-2004-366-span-class-mw-cite-backlink-a-href-cite-ref-zhou-zhi-hua-2004-366-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-zhou-zhi-hua-2004-366-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-zhou-zhi-hua-jiang-yuan-2004-nec4-5-neural-ensemble-based-c4-5-i-ieee-transactions-on-knowledge-and-data-engineering-i-b-16-b-6-770-773-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-1-8430-10-1-1-1-8430-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftkde-2004-11-10-1109-tkde-2004-11-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-knowledge-and-data-engineering-rft-atitle-nec4-5-3a-neural-ensemble-based-c4-5-rft-volume-16-rft-issue-6-rft-pages-770-773-rft-date-2004-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-1-8430-rft-id-info-3adoi-2f10-1109-2ftkde-2004-11-rft-aulast-zhou-rft-aufirst-zhi-hua-rft-au-jiang-2c-yuan-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-367-span-class-mw-cite-backlink-b-a-href-cite-ref-367-a-b-span-span-class-reference-text-cite-class-citation-journal-er-orhan-et-al-2012-an-approach-based-on-probabilistic-neural-network-for-diagnosis-of-mesothelioma-s-disease-i-computers-electrical-engineering-i-b-38-b-1-75-81-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-compeleceng-2011-09-001-10-1016-j-compeleceng-2011-09-001-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-computers-26-electrical-engineering-rft-atitle-an-approach-based-on-probabilistic-neural-network-for-diagnosis-of-mesothelioma-27s-disease-rft-volume-38-rft-issue-1-rft-pages-75-81-rft-date-2012-rft-id-info-3adoi-2f10-1016-2fj-compeleceng-2011-09-001-rft-aulast-er-rft-aufirst-orhan-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-368-span-class-mw-cite-backlink-b-a-href-cite-ref-368-a-b-span-span-class-reference-text-er-orhan-a-cetin-tanrikulu-and-abdurrahman-abakay-use-of-artificial-intelligence-techniques-for-diagnosis-of-malignant-pleural-mesothelioma-i-dicle-tip-dergisi-i-42-1-2015-span-li-li-id-cite-note-369-span-class-mw-cite-backlink-b-a-href-cite-ref-369-a-b-span-span-class-reference-text-cite-class-citation-journal-li-michael-h-mestre-tiago-a-fox-susan-h-taati-babak-25-july-2017-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc6219082-vision-based-assessment-of-parkinsonism-and-levodopa-induced-dyskinesia-with-deep-learning-pose-estimation-a-i-journal-of-neuroengineering-and-rehabilitation-i-b-15-b-1-97-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1707-09416-1707-09416-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1186-2fs12984-018-0446-z-10-1186-s12984-018-0446-z-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc6219082-6219082-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-30400914-30400914-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-neuroengineering-and-rehabilitation-rft-atitle-vision-based-assessment-of-parkinsonism-and-levodopa-induced-dyskinesia-with-deep-learning-pose-estimation-rft-volume-15-rft-issue-1-rft-pages-97-rft-date-2017-07-25-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc6219082-rft-id-info-3apmid-2f30400914-rft-id-info-3aarxiv-2f1707-09416-rft-id-info-3adoi-2f10-1186-2fs12984-018-0446-z-rft-aulast-li-rft-aufirst-michael-h-rft-au-mestre-2c-tiago-a-rft-au-fox-2c-susan-h-rft-au-taati-2c-babak-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc6219082-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-370-span-class-mw-cite-backlink-b-a-href-cite-ref-370-a-b-span-span-class-reference-text-cite-class-citation-journal-li-michael-h-mestre-tiago-a-fox-susan-h-taati-babak-may-2018-a-rel-nofollow-class-external-text-href-https-linkinghub-elsevier-com-retrieve-pii-s1353802018302220-automated-assessment-of-levodopa-induced-dyskinesia-evaluating-the-responsiveness-of-video-based-features-a-i-parkinsonism-related-disorders-i-b-53-b-42-45-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-parkreldis-2018-04-036-10-1016-j-parkreldis-2018-04-036-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-1353-8020-1353-8020-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-29748112-29748112-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-parkinsonism-26-related-disorders-rft-atitle-automated-assessment-of-levodopa-induced-dyskinesia-3a-evaluating-the-responsiveness-of-video-based-features-rft-volume-53-rft-pages-42-45-rft-date-2018-05-rft-issn-1353-8020-rft-id-info-3apmid-2f29748112-rft-id-info-3adoi-2f10-1016-2fj-parkreldis-2018-04-036-rft-aulast-li-rft-aufirst-michael-h-rft-au-mestre-2c-tiago-a-rft-au-fox-2c-susan-h-rft-au-taati-2c-babak-rft-id-https-3a-2f-2flinkinghub-elsevier-com-2fretrieve-2fpii-2fs1353802018302220-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-371-span-class-mw-cite-backlink-b-a-href-cite-ref-371-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-kaggle-com-limi44-parkinsons-visionbased-pose-estimation-dataset-home-parkinson-s-vision-based-pose-estimation-dataset-kaggle-a-i-www-kaggle-com-i-span-class-reference-accessdate-retrieved-span-class-nowrap-22-august-span-2018-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-www-kaggle-com-rft-atitle-parkinson-27s-vision-based-pose-estimation-dataset-7c-kaggle-rft-id-https-3a-2f-2fwww-kaggle-com-2flimi44-2fparkinsons-visionbased-pose-estimation-dataset-2fhome-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-372-span-class-mw-cite-backlink-b-a-href-cite-ref-372-a-b-span-span-class-reference-text-cite-class-citation-journal-shannon-paul-et-al-2003-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc403769-cytoscape-a-software-environment-for-integrated-models-of-biomolecular-interaction-networks-a-i-genome-research-i-b-13-b-11-2498-2504-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1101-2fgr-1239303-10-1101-gr-1239303-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc403769-403769-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-14597658-14597658-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-genome-research-rft-atitle-cytoscape-3a-a-software-environment-for-integrated-models-of-biomolecular-interaction-networks-rft-volume-13-rft-issue-11-rft-pages-2498-2504-rft-date-2003-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc403769-rft-id-info-3apmid-2f14597658-rft-id-info-3adoi-2f10-1101-2fgr-1239303-rft-aulast-shannon-rft-aufirst-paul-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc403769-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-373-span-class-mw-cite-backlink-b-a-href-cite-ref-373-a-b-span-span-class-reference-text-cite-class-citation-journal-javadi-soroush-mirroshandel-seyed-abolghasem-2019-a-novel-deep-learning-method-for-automatic-assessment-of-human-sperm-images-i-computers-in-biology-and-medicine-i-b-109-b-182-194-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-compbiomed-2019-04-030-10-1016-j-compbiomed-2019-04-030-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-0010-4825-0010-4825-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-computers-in-biology-and-medicine-rft-atitle-a-novel-deep-learning-method-for-automatic-assessment-of-human-sperm-images-rft-volume-109-rft-pages-182-194-rft-date-2019-rft-id-info-3adoi-2f10-1016-2fj-compbiomed-2019-04-030-rft-issn-0010-4825-rft-aulast-javadi-rft-aufirst-soroush-rft-au-mirroshandel-2c-seyed-abolghasem-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-374-span-class-mw-cite-backlink-b-a-href-cite-ref-374-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-github-com-soroushj-mhsma-dataset-soroushj-mhsma-dataset-mhsma-the-modified-human-sperm-morphology-analysis-dataset-a-i-github-com-i-span-class-reference-accessdate-retrieved-span-class-nowrap-3-may-span-2019-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-github-com-rft-atitle-soroushj-2fmhsma-dataset-3a-mhsma-3a-the-modified-human-sperm-morphology-analysis-dataset-rft-id-https-3a-2f-2fgithub-com-2fsoroushj-2fmhsma-dataset-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-375-span-class-mw-cite-backlink-b-a-href-cite-ref-375-a-b-span-span-class-reference-text-clark-david-zoltan-schreter-and-anthony-adams-a-quantitative-comparison-of-dystal-and-backpropagation-i-proceedings-of-1996-australian-conference-on-neural-networks-i-1996-span-li-li-id-cite-note-376-span-class-mw-cite-backlink-b-a-href-cite-ref-376-a-b-span-span-class-reference-text-jiang-yuan-and-zhi-hua-zhou-editing-training-data-for-knn-classifiers-with-neural-network-ensemble-i-advances-in-neural-networks-isnn-2004-i-springer-berlin-heidelberg-2004-356-361-span-li-li-id-cite-note-377-span-class-mw-cite-backlink-b-a-href-cite-ref-377-a-b-span-span-class-reference-text-ontanon-santiago-and-enric-plaza-on-similarity-measures-based-on-a-refinement-lattice-i-case-based-reasoning-research-and-development-i-springer-berlin-heidelberg-2009-240-255-span-li-li-id-cite-note-378-span-class-mw-cite-backlink-b-a-href-cite-ref-378-a-b-span-span-class-reference-text-cite-class-citation-journal-higuera-clara-gardiner-katheleen-j-cios-krzysztof-j-2015-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4482027-self-organizing-feature-maps-identify-proteins-critical-to-learning-in-a-mouse-model-of-down-syndrome-a-i-plos-one-i-b-10-b-6-e0129126-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2015ploso-1029126h-2015ploso-1029126h-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1371-2fjournal-pone-0129126-10-1371-journal-pone-0129126-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4482027-4482027-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-26111164-26111164-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-plos-one-rft-atitle-self-organizing-feature-maps-identify-proteins-critical-to-learning-in-a-mouse-model-of-down-syndrome-rft-volume-10-rft-issue-6-rft-pages-e0129126-rft-date-2015-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4482027-rft-id-info-3apmid-2f26111164-rft-id-info-3adoi-2f10-1371-2fjournal-pone-0129126-rft-id-info-3abibcode-2f2015ploso-1029126h-rft-aulast-higuera-rft-aufirst-clara-rft-au-gardiner-2c-katheleen-j-rft-au-cios-2c-krzysztof-j-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4482027-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-379-span-class-mw-cite-backlink-b-a-href-cite-ref-379-a-b-span-span-class-reference-text-cite-class-citation-journal-ahmed-md-mahiuddin-et-al-2015-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4368539-protein-dynamics-associated-with-failed-and-rescued-learning-in-the-ts65dn-mouse-model-of-down-syndrome-a-i-plos-one-i-b-10-b-3-e0119491-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2015ploso-1019491a-2015ploso-1019491a-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1371-2fjournal-pone-0119491-10-1371-journal-pone-0119491-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4368539-4368539-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-25793384-25793384-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-plos-one-rft-atitle-protein-dynamics-associated-with-failed-and-rescued-learning-in-the-ts65dn-mouse-model-of-down-syndrome-rft-volume-10-rft-issue-3-rft-pages-e0119491-rft-date-2015-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4368539-rft-id-info-3apmid-2f25793384-rft-id-info-3adoi-2f10-1371-2fjournal-pone-0119491-rft-id-info-3abibcode-2f2015ploso-1019491a-rft-aulast-ahmed-rft-aufirst-md-mahiuddin-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4368539-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-380-span-class-mw-cite-backlink-b-a-href-cite-ref-380-a-b-span-span-class-reference-text-cortez-paulo-and-anibal-de-jesus-raimundo-morais-a-data-mining-approach-to-predict-forest-fires-using-meteorological-data-2007-span-li-li-id-cite-note-381-span-class-mw-cite-backlink-b-a-href-cite-ref-381-a-b-span-span-class-reference-text-cite-class-citation-journal-farquad-m-a-h-ravi-v-raju-s-bapi-2010-support-vector-regression-based-hybrid-rule-extraction-methods-for-forecasting-i-expert-systems-with-applications-i-b-37-b-8-5577-5589-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-eswa-2010-02-055-10-1016-j-eswa-2010-02-055-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-expert-systems-with-applications-rft-atitle-support-vector-regression-based-hybrid-rule-extraction-methods-for-forecasting-rft-volume-37-rft-issue-8-rft-pages-5577-5589-rft-date-2010-rft-id-info-3adoi-2f10-1016-2fj-eswa-2010-02-055-rft-aulast-farquad-rft-aufirst-m-a-h-rft-au-ravi-2c-v-rft-au-raju-2c-s-bapi-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-382-span-class-mw-cite-backlink-b-a-href-cite-ref-382-a-b-span-span-class-reference-text-cite-class-citation-journal-fisher-ronald-a-1936-the-use-of-multiple-measurements-in-taxonomic-problems-i-annals-of-eugenics-i-b-7-b-2-179-188-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1111-2fj-1469-1809-1936-tb02137-x-10-1111-j-1469-1809-1936-tb02137-x-a-a-href-wiki-handle-system-title-handle-system-hdl-a-a-rel-nofollow-class-external-text-href-hdl-handle-net-2440-2f15227-2440-15227-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-annals-of-eugenics-rft-atitle-the-use-of-multiple-measurements-in-taxonomic-problems-rft-volume-7-rft-issue-2-rft-pages-179-188-rft-date-1936-rft-id-info-3ahdl-2f2440-2f15227-rft-id-info-3adoi-2f10-1111-2fj-1469-1809-1936-tb02137-x-rft-aulast-fisher-rft-aufirst-ronald-a-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-383-span-class-mw-cite-backlink-b-a-href-cite-ref-383-a-b-span-span-class-reference-text-ghahramani-zoubin-and-michael-i-jordan-supervised-learning-from-incomplete-data-via-an-em-approach-i-advances-in-neural-information-processing-systems-6-i-1994-span-li-li-id-cite-note-384-span-class-mw-cite-backlink-b-a-href-cite-ref-384-a-b-span-span-class-reference-text-cite-class-citation-journal-mallah-charles-cope-james-orwell-james-2013-plant-leaf-classification-using-probabilistic-integration-of-shape-texture-and-margin-features-i-signal-processing-pattern-recognition-and-applications-i-b-5-b-1-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-signal-processing-2c-pattern-recognition-and-applications-rft-atitle-plant-leaf-classification-using-probabilistic-integration-of-shape-2c-texture-and-margin-features-rft-volume-5-rft-pages-1-rft-date-2013-rft-aulast-mallah-rft-aufirst-charles-rft-au-cope-2c-james-rft-au-orwell-2c-james-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-385-span-class-mw-cite-backlink-b-a-href-cite-ref-385-a-b-span-span-class-reference-text-yahiaoui-itheri-olfa-mzoughi-and-nozha-boujemaa-leaf-shape-descriptor-for-tree-species-identification-i-multimedia-and-expo-icme-2012-ieee-international-conference-on-i-ieee-2012-span-li-li-id-cite-note-386-span-class-mw-cite-backlink-b-a-href-cite-ref-386-a-b-span-span-class-reference-text-cite-class-citation-journal-langley-pat-2014-trading-off-simplicity-and-coverage-in-incremental-concept-learning-i-machine-learning-proceedings-i-b-1988-b-73-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-machine-learning-proceedings-rft-atitle-trading-off-simplicity-and-coverage-in-incremental-concept-learning-rft-volume-1988-rft-pages-73-rft-date-2014-rft-aulast-langley-rft-aufirst-pat-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-387-span-class-mw-cite-backlink-b-a-href-cite-ref-387-a-b-span-span-class-reference-text-tan-ming-and-larry-eshelman-using-weighted-networks-to-represent-classification-knowledge-in-noisy-domains-i-proceedings-of-the-fifth-international-conference-on-machine-learning-i-2014-span-li-li-id-cite-note-388-span-class-mw-cite-backlink-b-a-href-cite-ref-388-a-b-span-span-class-reference-text-charytanowicz-malgorzata-et-al-complete-gradient-clustering-algorithm-for-features-analysis-of-x-ray-images-i-information-technologies-in-biomedicine-i-springer-berlin-heidelberg-2010-15-24-span-li-li-id-cite-note-389-span-class-mw-cite-backlink-b-a-href-cite-ref-389-a-b-span-span-class-reference-text-cite-class-citation-journal-sanchez-mauricio-a-et-al-2014-fuzzy-granular-gravitational-clustering-algorithm-for-multivariate-data-i-information-sciences-i-b-279-b-498-511-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-ins-2014-04-005-10-1016-j-ins-2014-04-005-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-information-sciences-rft-atitle-fuzzy-granular-gravitational-clustering-algorithm-for-multivariate-data-rft-volume-279-rft-pages-498-511-rft-date-2014-rft-id-info-3adoi-2f10-1016-2fj-ins-2014-04-005-rft-aulast-sanchez-rft-aufirst-mauricio-a-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-390-span-class-mw-cite-backlink-b-a-href-cite-ref-390-a-b-span-span-class-reference-text-cite-class-citation-journal-blackard-jock-a-dean-denis-j-1999-comparative-accuracies-of-artificial-neural-networks-and-discriminant-analysis-in-predicting-forest-cover-types-from-cartographic-variables-i-computers-and-electronics-in-agriculture-i-b-24-b-3-131-151-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-128-2475-10-1-1-128-2475-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fs0168-1699-2899-2900046-0-10-1016-s0168-1699-99-00046-0-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-computers-and-electronics-in-agriculture-rft-atitle-comparative-accuracies-of-artificial-neural-networks-and-discriminant-analysis-in-predicting-forest-cover-types-from-cartographic-variables-rft-volume-24-rft-issue-3-rft-pages-131-151-rft-date-1999-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-128-2475-rft-id-info-3adoi-2f10-1016-2fs0168-1699-2899-2900046-0-rft-aulast-blackard-rft-aufirst-jock-a-rft-au-dean-2c-denis-j-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-391-span-class-mw-cite-backlink-b-a-href-cite-ref-391-a-b-span-span-class-reference-text-furnkranz-johannes-round-robin-rule-learning-i-proceedings-of-the-18th-international-conference-on-machine-learning-icml-01-146-153-i-2001-span-li-li-id-cite-note-392-span-class-mw-cite-backlink-b-a-href-cite-ref-392-a-b-span-span-class-reference-text-cite-class-citation-journal-li-song-assmann-sarah-m-albert-reka-2006-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc1564158-predicting-essential-components-of-signal-transduction-networks-a-dynamic-model-of-guard-cell-abscisic-acid-signaling-a-i-plos-biol-i-b-4-b-10-e312-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1371-2fjournal-pbio-0040312-10-1371-journal-pbio-0040312-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc1564158-1564158-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-16968132-16968132-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-plos-biol-rft-atitle-predicting-essential-components-of-signal-transduction-networks-3a-a-dynamic-model-of-guard-cell-abscisic-acid-signaling-rft-volume-4-rft-issue-10-rft-pages-e312-rft-date-2006-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc1564158-rft-id-info-3apmid-2f16968132-rft-id-info-3adoi-2f10-1371-2fjournal-pbio-0040312-rft-aulast-li-rft-aufirst-song-rft-au-assmann-2c-sarah-m-rft-au-albert-2c-r-c3-a9ka-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc1564158-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-393-span-class-mw-cite-backlink-b-a-href-cite-ref-393-a-b-span-span-class-reference-text-cite-class-citation-journal-munisami-trishen-et-al-2015-plant-leaf-recognition-using-shape-features-and-colour-histogram-with-k-nearest-neighbour-classifiers-i-procedia-computer-science-i-b-58-b-740-747-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-procs-2015-08-095-10-1016-j-procs-2015-08-095-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-procedia-computer-science-rft-atitle-plant-leaf-recognition-using-shape-features-and-colour-histogram-with-k-nearest-neighbour-classifiers-rft-volume-58-rft-pages-740-747-rft-date-2015-rft-id-info-3adoi-2f10-1016-2fj-procs-2015-08-095-rft-aulast-munisami-rft-aufirst-trishen-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-394-span-class-mw-cite-backlink-b-a-href-cite-ref-394-a-b-span-span-class-reference-text-cite-class-citation-journal-li-bai-2016-atomic-potential-matching-an-evolutionary-target-recognition-approach-based-on-edge-features-i-optik-international-journal-for-light-and-electron-optics-i-b-127-b-5-3162-3168-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2016optik-127-3162l-2016optik-127-3162l-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-ijleo-2015-11-186-10-1016-j-ijleo-2015-11-186-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-optik-international-journal-for-light-and-electron-optics-rft-atitle-atomic-potential-matching-3a-an-evolutionary-target-recognition-approach-based-on-edge-features-rft-volume-127-rft-issue-5-rft-pages-3162-3168-rft-date-2016-rft-id-info-3adoi-2f10-1016-2fj-ijleo-2015-11-186-rft-id-info-3abibcode-2f2016optik-127-3162l-rft-aulast-li-rft-aufirst-bai-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-395-span-class-mw-cite-backlink-b-a-href-cite-ref-395-a-b-span-span-class-reference-text-nilsback-maria-elena-and-andrew-zisserman-a-visual-vocabulary-for-flower-classification-i-computer-vision-and-pattern-recognition-2006-ieee-computer-society-conference-on-i-vol-2-ieee-2006-span-li-li-id-cite-note-396-span-class-mw-cite-backlink-b-a-href-cite-ref-396-a-b-span-span-class-reference-text-cite-class-citation-arxiv-giselsson-thomas-m-et-al-2017-a-public-image-database-for-benchmark-of-plant-seedling-classification-algorithms-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1711-05458-1711-05458-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-a-public-image-database-for-benchmark-of-plant-seedling-classification-algorithms-rft-date-2017-rft-id-info-3aarxiv-2f1711-05458-rft-aulast-giselsson-rft-aufirst-thomas-m-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-397-span-class-mw-cite-backlink-b-a-href-cite-ref-397-a-b-span-span-class-reference-text-cite-class-citation-journal-muresan-horea-oltean-mihai-2018-a-rel-nofollow-class-external-text-href-https-www-researchgate-net-publication-321475443-fruit-recognition-from-images-using-deep-learning-a-i-acta-univ-sapientiae-informatica-i-b-10-b-1-26-42-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-13140-2frg-2-2-22059-95527-10-13140-rg-2-2-22059-95527-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-acta-univ-sapientiae-2c-informatica-rft-atitle-fruit-recognition-from-images-using-deep-learning-rft-volume-10-rft-issue-1-rft-pages-26-42-rft-date-2018-rft-id-info-3adoi-2f10-13140-2frg-2-2-22059-95527-rft-aulast-muresan-rft-aufirst-horea-rft-au-oltean-2c-mihai-rft-id-https-3a-2f-2fwww-researchgate-net-2fpublication-2f321475443-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-398-span-class-mw-cite-backlink-b-a-href-cite-ref-398-a-b-span-span-class-reference-text-cite-class-citation-web-muresan-horea-oltean-mihai-2017-a-rel-nofollow-class-external-text-href-https-www-kaggle-com-moltean-fruits-a-dataset-with-fruit-images-on-kaggle-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-a-dataset-with-fruit-images-on-kaggle-rft-date-2017-rft-aulast-muresan-rft-aufirst-horea-rft-au-oltean-2c-mihai-rft-id-https-3a-2f-2fwww-kaggle-com-2fmoltean-2ffruits-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-399-span-class-mw-cite-backlink-b-a-href-cite-ref-399-a-b-span-span-class-reference-text-cite-class-citation-journal-nakai-kenta-kanehisa-minoru-1991-expert-system-for-predicting-protein-localization-sites-in-gram-negative-bacteria-i-proteins-structure-function-and-bioinformatics-i-b-11-b-2-95-110-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1002-2fprot-340110203-10-1002-prot-340110203-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-1946347-1946347-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-proteins-3a-structure-2c-function-2c-and-bioinformatics-rft-atitle-expert-system-for-predicting-protein-localization-sites-in-gram-e2-80-90negative-bacteria-rft-volume-11-rft-issue-2-rft-pages-95-110-rft-date-1991-rft-id-info-3adoi-2f10-1002-2fprot-340110203-rft-id-info-3apmid-2f1946347-rft-aulast-nakai-rft-aufirst-kenta-rft-au-kanehisa-2c-minoru-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-400-span-class-mw-cite-backlink-b-a-href-cite-ref-400-a-b-span-span-class-reference-text-ling-charles-x-et-al-decision-trees-with-minimal-costs-i-proceedings-of-the-twenty-first-international-conference-on-machine-learning-i-acm-2004-span-li-li-id-cite-note-401-span-class-mw-cite-backlink-b-a-href-cite-ref-401-a-b-span-span-class-reference-text-mahe-pierre-et-al-automatic-identification-of-mixed-bacterial-species-fingerprints-in-a-maldi-tof-mass-spectrum-i-bioinformatics-i-2014-btu022-span-li-li-id-cite-note-402-span-class-mw-cite-backlink-b-a-href-cite-ref-402-a-b-span-span-class-reference-text-cite-class-citation-journal-barbano-duane-et-al-2015-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4536233-rapid-characterization-of-microalgae-and-microalgae-mixtures-using-matrix-assisted-laser-desorption-ionization-time-of-flight-mass-spectrometry-maldi-tof-ms-a-i-plos-one-i-b-10-b-8-e0135337-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2015ploso-1035337b-2015ploso-1035337b-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1371-2fjournal-pone-0135337-10-1371-journal-pone-0135337-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4536233-4536233-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-26271045-26271045-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-plos-one-rft-atitle-rapid-characterization-of-microalgae-and-microalgae-mixtures-using-matrix-assisted-laser-desorption-ionization-time-of-flight-mass-spectrometry-28maldi-tof-ms-29-rft-volume-10-rft-issue-8-rft-pages-e0135337-rft-date-2015-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4536233-rft-id-info-3apmid-2f26271045-rft-id-info-3adoi-2f10-1371-2fjournal-pone-0135337-rft-id-info-3abibcode-2f2015ploso-1035337b-rft-aulast-barbano-rft-aufirst-duane-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4536233-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-403-span-class-mw-cite-backlink-b-a-href-cite-ref-403-a-b-span-span-class-reference-text-cite-class-citation-journal-horton-paul-nakai-kenta-a-probabilistic-classification-system-for-predicting-the-cellular-localization-sites-of-proteins-i-ismb-96-proceedings-i-b-4-b-1996-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ismb-96-proceedings-rft-atitle-a-probabilistic-classification-system-for-predicting-the-cellular-localization-sites-of-proteins-rft-volume-4-rft-pages-1996-rft-aulast-horton-rft-aufirst-paul-rft-au-nakai-2c-kenta-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-404-span-class-mw-cite-backlink-b-a-href-cite-ref-404-a-b-span-span-class-reference-text-cite-class-citation-journal-allwein-erin-l-schapire-robert-e-singer-yoram-2001-reducing-multiclass-to-binary-a-unifying-approach-for-margin-classifiers-i-the-journal-of-machine-learning-research-i-b-1-b-113-141-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-the-journal-of-machine-learning-research-rft-atitle-reducing-multiclass-to-binary-3a-a-unifying-approach-for-margin-classifiers-rft-volume-1-rft-pages-113-141-rft-date-2001-rft-aulast-allwein-rft-aufirst-erin-l-rft-au-schapire-2c-robert-e-rft-au-singer-2c-yoram-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-405-span-class-mw-cite-backlink-b-a-href-cite-ref-405-a-b-span-span-class-reference-text-cite-class-citation-journal-mayr-andreas-klambauer-guenter-unterthiner-thomas-hochreiter-sepp-2016-a-rel-nofollow-class-external-text-href-http-bioinf-jku-at-research-deeptox-tox21-html-deeptox-toxicity-prediction-using-deep-learning-a-i-frontiers-in-environmental-science-i-b-3-b-80-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-3389-2ffenvs-2015-00080-10-3389-fenvs-2015-00080-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-frontiers-in-environmental-science-rft-atitle-deeptox-3a-toxicity-prediction-using-deep-learning-rft-volume-3-rft-pages-80-rft-date-2016-rft-id-info-3adoi-2f10-3389-2ffenvs-2015-00080-rft-aulast-mayr-rft-aufirst-andreas-rft-au-klambauer-2c-guenter-rft-au-unterthiner-2c-thomas-rft-au-hochreiter-2c-sepp-rft-id-http-3a-2f-2fbioinf-jku-at-2fresearch-2fdeeptox-2ftox21-html-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-406-span-class-mw-cite-backlink-b-a-href-cite-ref-406-a-b-span-span-class-reference-text-cite-class-citation-book-lavin-alexander-ahmad-subutai-12-october-2015-evaluating-real-time-anomaly-detection-algorithms-the-numenta-anomaly-benchmark-i-evaluating-real-time-anomaly-detection-algorithms-the-numenta-anomaly-benchmark-i-p-38-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1510-03336-1510-03336-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ficmla-2015-141-10-1109-icmla-2015-141-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-1-5090-0287-0-title-special-booksources-978-1-5090-0287-0-bdi-978-1-5090-0287-0-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-bookitem-rft-atitle-evaluating-real-time-anomaly-detection-algorithms-the-numenta-anomaly-benchmark-rft-btitle-evaluating-real-time-anomaly-detection-algorithms-e2-80-93-the-numenta-anomaly-benchmark-rft-pages-38-rft-date-2015-10-12-rft-id-info-3aarxiv-2f1510-03336-rft-id-info-3adoi-2f10-1109-2ficmla-2015-141-rft-isbn-978-1-5090-0287-0-rft-aulast-lavin-rft-aufirst-alexander-rft-au-ahmad-2c-subutai-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-camposzimek2016-407-span-class-mw-cite-backlink-b-a-href-cite-ref-camposzimek2016-407-0-a-b-span-span-class-reference-text-cite-class-citation-journal-campos-guilherme-o-a-href-wiki-arthur-zimek-title-arthur-zimek-zimek-arthur-a-sander-jorg-campello-ricardo-j-g-b-micenkova-barbora-schubert-erich-assent-ira-houle-michael-e-2016-on-the-evaluation-of-unsupervised-outlier-detection-measures-datasets-and-an-empirical-study-i-data-mining-and-knowledge-discovery-i-b-30-b-4-891-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fs10618-015-0444-8-10-1007-s10618-015-0444-8-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-1384-5810-1384-5810-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-data-mining-and-knowledge-discovery-rft-atitle-on-the-evaluation-of-unsupervised-outlier-detection-3a-measures-2c-datasets-2c-and-an-empirical-study-rft-volume-30-rft-issue-4-rft-pages-891-rft-date-2016-rft-id-info-3adoi-2f10-1007-2fs10618-015-0444-8-rft-issn-1384-5810-rft-aulast-campos-rft-aufirst-guilherme-o-rft-au-zimek-2c-arthur-rft-au-sander-2c-j-c3-b6rg-rft-au-campello-2c-ricardo-j-g-b-rft-au-micenkov-c3-a1-2c-barbora-rft-au-schubert-2c-erich-rft-au-assent-2c-ira-rft-au-houle-2c-michael-e-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-408-span-class-mw-cite-backlink-b-a-href-cite-ref-408-a-b-span-span-class-reference-text-ann-kathrin-hartmann-tommaso-soru-edgard-marx-a-rel-nofollow-class-external-text-href-https-www-researchgate-net-publication-324482598-generating-a-large-dataset-for-neural-question-answering-over-the-dbpedia-knowledge-base-i-generating-a-large-dataset-for-neural-question-answering-over-the-dbpedia-knowledge-base-i-a-2018-span-li-li-id-cite-note-409-span-class-mw-cite-backlink-b-a-href-cite-ref-409-a-b-span-span-class-reference-text-tommaso-soru-edgard-marx-diego-moussallem-andre-valdestilhas-diego-esteves-ciro-baron-a-rel-nofollow-class-external-text-href-https-arxiv-org-abs-1708-07624-i-sparql-as-a-foreign-language-i-a-2018-span-li-li-id-cite-note-410-span-class-mw-cite-backlink-b-a-href-cite-ref-410-a-b-span-span-class-reference-text-brown-michael-scott-michael-j-pelosi-and-henry-dirska-dynamic-radius-species-conserving-genetic-algorithm-for-the-financial-forecasting-of-dow-jones-index-stocks-i-machine-learning-and-data-mining-in-pattern-recognition-i-springer-berlin-heidelberg-2013-27-41-span-li-li-id-cite-note-411-span-class-mw-cite-backlink-b-a-href-cite-ref-411-a-b-span-span-class-reference-text-cite-class-citation-journal-shen-kao-yi-tzeng-gwo-hshiung-2015-fuzzy-inference-enhanced-vc-drsa-model-for-technical-analysis-investment-decision-aid-i-international-journal-of-fuzzy-systems-i-b-17-b-3-375-389-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fs40815-015-0058-8-10-1007-s40815-015-0058-8-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-international-journal-of-fuzzy-systems-rft-atitle-fuzzy-inference-enhanced-vc-drsa-model-for-technical-analysis-3a-investment-decision-aid-rft-volume-17-rft-issue-3-rft-pages-375-389-rft-date-2015-rft-id-info-3adoi-2f10-1007-2fs40815-015-0058-8-rft-aulast-shen-rft-aufirst-kao-yi-rft-au-tzeng-2c-gwo-hshiung-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-412-span-class-mw-cite-backlink-b-a-href-cite-ref-412-a-b-span-span-class-reference-text-cite-class-citation-journal-quinlan-j-ross-1987-simplifying-decision-trees-i-international-journal-of-man-machine-studies-i-b-27-b-3-221-234-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-18-4267-10-1-1-18-4267-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fs0020-7373-2887-2980053-6-10-1016-s0020-7373-87-80053-6-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-international-journal-of-man-machine-studies-rft-atitle-simplifying-decision-trees-rft-volume-27-rft-issue-3-rft-pages-221-234-rft-date-1987-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-18-4267-rft-id-info-3adoi-2f10-1016-2fs0020-7373-2887-2980053-6-rft-aulast-quinlan-rft-aufirst-j-ross-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-413-span-class-mw-cite-backlink-b-a-href-cite-ref-413-a-b-span-span-class-reference-text-cite-class-citation-journal-hamers-bart-suykens-johan-ak-de-moor-bart-2003-coupled-transductive-ensemble-learning-of-kernel-models-i-journal-of-machine-learning-research-i-b-1-b-1-48-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-machine-learning-research-rft-atitle-coupled-transductive-ensemble-learning-of-kernel-models-rft-volume-1-rft-pages-1-48-rft-date-2003-rft-aulast-hamers-rft-aufirst-bart-rft-au-suykens-2c-johan-ak-rft-au-de-moor-2c-bart-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-414-span-class-mw-cite-backlink-b-a-href-cite-ref-414-a-b-span-span-class-reference-text-shmueli-galit-ralph-p-russo-and-wolfgang-jank-the-barista-a-model-for-bid-arrivals-in-online-auctions-i-the-annals-of-applied-statistics-i-2007-412-441-span-li-li-id-cite-note-415-span-class-mw-cite-backlink-b-a-href-cite-ref-415-a-b-span-span-class-reference-text-peng-jie-and-hans-georg-muller-distance-based-clustering-of-sparsely-observed-stochastic-processes-with-applications-to-online-auctions-i-the-annals-of-applied-statistics-i-2008-1056-1077-span-li-li-id-cite-note-416-span-class-mw-cite-backlink-b-a-href-cite-ref-416-a-b-span-span-class-reference-text-eggermont-jeroen-joost-n-kok-and-walter-a-kosters-genetic-programming-for-data-classification-partitioning-the-search-space-i-proceedings-of-the-2004-acm-symposium-on-applied-computing-i-acm-2004-span-li-li-id-cite-note-417-span-class-mw-cite-backlink-b-a-href-cite-ref-417-a-b-span-span-class-reference-text-cite-class-citation-journal-moro-sergio-cortez-paulo-rita-paulo-2014-a-data-driven-approach-to-predict-the-success-of-bank-telemarketing-i-decision-support-systems-i-b-62-b-22-31-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-dss-2014-03-001-10-1016-j-dss-2014-03-001-a-a-href-wiki-handle-system-title-handle-system-hdl-a-a-rel-nofollow-class-external-text-href-hdl-handle-net-10071-2f9499-10071-9499-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-decision-support-systems-rft-atitle-a-data-driven-approach-to-predict-the-success-of-bank-telemarketing-rft-volume-62-rft-pages-22-31-rft-date-2014-rft-id-info-3ahdl-2f10071-2f9499-rft-id-info-3adoi-2f10-1016-2fj-dss-2014-03-001-rft-aulast-moro-rft-aufirst-s-c3-a9rgio-rft-au-cortez-2c-paulo-rft-au-rita-2c-paulo-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-418-span-class-mw-cite-backlink-b-a-href-cite-ref-418-a-b-span-span-class-reference-text-cite-class-citation-arxiv-payne-richard-d-mallick-bani-k-2014-bayesian-big-data-classification-a-review-with-complements-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1411-5653-1411-5653-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-stat-me-stat-me-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-bayesian-big-data-classification-3a-a-review-with-complements-rft-date-2014-rft-id-info-3aarxiv-2f1411-5653-rft-aulast-payne-rft-aufirst-richard-d-rft-au-mallick-2c-bani-k-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-419-span-class-mw-cite-backlink-b-a-href-cite-ref-419-a-b-span-span-class-reference-text-cite-class-citation-journal-akbilgic-oguz-bozdogan-hamparsum-balaban-m-erdal-2014-a-novel-hybrid-rbf-neural-networks-model-as-a-forecaster-i-statistics-and-computing-i-b-24-b-3-365-375-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fs11222-013-9375-7-10-1007-s11222-013-9375-7-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-statistics-and-computing-rft-atitle-a-novel-hybrid-rbf-neural-networks-model-as-a-forecaster-rft-volume-24-rft-issue-3-rft-pages-365-375-rft-date-2014-rft-id-info-3adoi-2f10-1007-2fs11222-013-9375-7-rft-aulast-akbilgic-rft-aufirst-oguz-rft-au-bozdogan-2c-hamparsum-rft-au-balaban-2c-m-erdal-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-420-span-class-mw-cite-backlink-b-a-href-cite-ref-420-a-b-span-span-class-reference-text-jabin-suraiya-stock-market-prediction-using-feed-forward-artificial-neural-network-i-int-j-comput-appl-ijca-i-99-9-2014-span-li-li-id-cite-note-421-span-class-mw-cite-backlink-b-a-href-cite-ref-421-a-b-span-span-class-reference-text-cite-class-citation-journal-yeh-i-cheng-che-hui-lien-2009-the-comparisons-of-data-mining-techniques-for-the-predictive-accuracy-of-probability-of-default-of-credit-card-clients-i-expert-systems-with-applications-i-b-36-b-2-2473-2480-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-eswa-2007-12-020-10-1016-j-eswa-2007-12-020-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-expert-systems-with-applications-rft-atitle-the-comparisons-of-data-mining-techniques-for-the-predictive-accuracy-of-probability-of-default-of-credit-card-clients-rft-volume-36-rft-issue-2-rft-pages-2473-2480-rft-date-2009-rft-id-info-3adoi-2f10-1016-2fj-eswa-2007-12-020-rft-aulast-yeh-rft-aufirst-i-cheng-rft-au-che-hui-2c-lien-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-422-span-class-mw-cite-backlink-b-a-href-cite-ref-422-a-b-span-span-class-reference-text-cite-class-citation-journal-lin-shu-ling-2009-a-new-two-stage-hybrid-approach-of-credit-risk-in-banking-industry-i-expert-systems-with-applications-i-b-36-b-4-8333-8341-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-eswa-2008-10-015-10-1016-j-eswa-2008-10-015-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-expert-systems-with-applications-rft-atitle-a-new-two-stage-hybrid-approach-of-credit-risk-in-banking-industry-rft-volume-36-rft-issue-4-rft-pages-8333-8341-rft-date-2009-rft-id-info-3adoi-2f10-1016-2fj-eswa-2008-10-015-rft-aulast-lin-rft-aufirst-shu-ling-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-423-span-class-mw-cite-backlink-b-a-href-cite-ref-423-a-b-span-span-class-reference-text-cite-class-citation-journal-pelckmans-kristiaan-et-al-2005-the-differogram-non-parametric-noise-variance-estimation-and-its-use-for-model-selection-i-neurocomputing-i-b-69-b-1-100-122-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-neucom-2005-02-015-10-1016-j-neucom-2005-02-015-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neurocomputing-rft-atitle-the-differogram-3a-non-parametric-noise-variance-estimation-and-its-use-for-model-selection-rft-volume-69-rft-issue-1-rft-pages-100-122-rft-date-2005-rft-id-info-3adoi-2f10-1016-2fj-neucom-2005-02-015-rft-aulast-pelckmans-rft-aufirst-kristiaan-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-424-span-class-mw-cite-backlink-b-a-href-cite-ref-424-a-b-span-span-class-reference-text-cite-class-citation-journal-bay-stephen-d-et-al-2000-the-uci-kdd-archive-of-large-data-sets-for-data-mining-research-and-experimentation-i-acm-sigkdd-explorations-newsletter-i-b-2-b-2-81-85-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-15-9776-10-1-1-15-9776-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1145-2f380995-381030-10-1145-380995-381030-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-acm-sigkdd-explorations-newsletter-rft-atitle-the-uci-kdd-archive-of-large-data-sets-for-data-mining-research-and-experimentation-rft-volume-2-rft-issue-2-rft-pages-81-85-rft-date-2000-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-15-9776-rft-id-info-3adoi-2f10-1145-2f380995-381030-rft-aulast-bay-rft-aufirst-stephen-d-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-425-span-class-mw-cite-backlink-b-a-href-cite-ref-425-a-b-span-span-class-reference-text-cite-class-citation-journal-lucas-d-d-et-al-2015-designing-optimal-greenhouse-gas-observing-networks-that-consider-performance-and-cost-i-geoscientific-instrumentation-methods-and-data-systems-i-b-4-b-1-121-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2015gi-4-121l-2015gi-4-121l-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-5194-2fgi-4-121-2015-10-5194-gi-4-121-2015-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-geoscientific-instrumentation-2c-methods-and-data-systems-rft-atitle-designing-optimal-greenhouse-gas-observing-networks-that-consider-performance-and-cost-rft-volume-4-rft-issue-1-rft-pages-121-rft-date-2015-rft-id-info-3adoi-2f10-5194-2fgi-4-121-2015-rft-id-info-3abibcode-2f2015gi-4-121l-rft-aulast-lucas-rft-aufirst-d-d-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-426-span-class-mw-cite-backlink-b-a-href-cite-ref-426-a-b-span-span-class-reference-text-cite-class-citation-journal-pales-jack-c-keeling-charles-d-1965-the-concentration-of-atmospheric-carbon-dioxide-in-hawaii-i-journal-of-geophysical-research-i-b-70-b-24-6053-6076-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-1965jgr-70-6053p-1965jgr-70-6053p-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1029-2fjz070i024p06053-10-1029-jz070i024p06053-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-geophysical-research-rft-atitle-the-concentration-of-atmospheric-carbon-dioxide-in-hawaii-rft-volume-70-rft-issue-24-rft-pages-6053-6076-rft-date-1965-rft-id-info-3adoi-2f10-1029-2fjz070i024p06053-rft-id-info-3abibcode-2f1965jgr-70-6053p-rft-aulast-pales-rft-aufirst-jack-c-rft-au-keeling-2c-charles-d-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-427-span-class-mw-cite-backlink-b-a-href-cite-ref-427-a-b-span-span-class-reference-text-sigillito-vincent-g-et-al-classification-of-radar-returns-from-the-ionosphere-using-neural-networks-i-johns-hopkins-apl-technical-digest-i-10-3-1989-262-266-span-li-li-id-cite-note-428-span-class-mw-cite-backlink-b-a-href-cite-ref-428-a-b-span-span-class-reference-text-zhang-kun-and-wei-fan-forecasting-skewed-biased-stochastic-ozone-days-analyses-solutions-and-beyond-i-knowledge-and-information-systems-i-14-3-2008-299-326-span-li-li-id-cite-note-429-span-class-mw-cite-backlink-b-a-href-cite-ref-429-a-b-span-span-class-reference-text-reich-brian-j-montserrat-fuentes-and-david-b-dunson-bayesian-spatial-quantile-regression-i-journal-of-the-american-statistical-association-i-2012-span-li-li-id-cite-note-430-span-class-mw-cite-backlink-b-a-href-cite-ref-430-a-b-span-span-class-reference-text-cite-class-citation-journal-kohavi-ron-1996-scaling-up-the-accuracy-of-naive-bayes-classifiers-a-decision-tree-hybrid-i-kdd-i-b-96-b-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-kdd-rft-atitle-scaling-up-the-accuracy-of-naive-bayes-classifiers-3a-a-decision-tree-hybrid-rft-volume-96-rft-date-1996-rft-aulast-kohavi-rft-aufirst-ron-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-431-span-class-mw-cite-backlink-b-a-href-cite-ref-431-a-b-span-span-class-reference-text-oza-nikunj-c-and-stuart-russell-experimental-comparisons-of-online-and-batch-versions-of-bagging-and-boosting-i-proceedings-of-the-seventh-acm-sigkdd-international-conference-on-knowledge-discovery-and-data-mining-i-acm-2001-span-li-li-id-cite-note-432-span-class-mw-cite-backlink-b-a-href-cite-ref-432-a-b-span-span-class-reference-text-cite-class-citation-journal-bay-stephen-d-2001-multivariate-discretization-for-set-mining-i-knowledge-and-information-systems-i-b-3-b-4-491-512-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-217-921-10-1-1-217-921-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fpl00011680-10-1007-pl00011680-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-knowledge-and-information-systems-rft-atitle-multivariate-discretization-for-set-mining-rft-volume-3-rft-issue-4-rft-pages-491-512-rft-date-2001-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-217-921-rft-id-info-3adoi-2f10-1007-2fpl00011680-rft-aulast-bay-rft-aufirst-stephen-d-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-433-span-class-mw-cite-backlink-b-a-href-cite-ref-433-a-b-span-span-class-reference-text-cite-class-citation-journal-ruggles-steven-1995-sample-designs-and-sampling-errors-i-historical-methods-a-journal-of-quantitative-and-interdisciplinary-history-i-b-28-b-1-40-46-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1080-2f01615440-1995-9955312-10-1080-01615440-1995-9955312-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-historical-methods-3a-a-journal-of-quantitative-and-interdisciplinary-history-rft-atitle-sample-designs-and-sampling-errors-rft-volume-28-rft-issue-1-rft-pages-40-46-rft-date-1995-rft-id-info-3adoi-2f10-1080-2f01615440-1995-9955312-rft-aulast-ruggles-rft-aufirst-steven-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-434-span-class-mw-cite-backlink-b-a-href-cite-ref-434-a-b-span-span-class-reference-text-meek-christopher-bo-thiesson-and-david-heckerman-the-learning-curve-method-applied-to-clustering-i-aistats-i-2001-span-li-li-id-cite-note-435-span-class-mw-cite-backlink-b-a-href-cite-ref-435-a-b-span-span-class-reference-text-cite-class-citation-journal-fanaee-t-hadi-gama-joao-2013-event-labeling-combining-ensemble-detectors-and-background-knowledge-i-progress-in-artificial-intelligence-i-b-2-b-2-3-113-127-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fs13748-013-0040-3-10-1007-s13748-013-0040-3-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-progress-in-artificial-intelligence-rft-atitle-event-labeling-combining-ensemble-detectors-and-background-knowledge-rft-volume-2-rft-issue-2-e2-80-933-rft-pages-113-127-rft-date-2013-rft-id-info-3adoi-2f10-1007-2fs13748-013-0040-3-rft-aulast-fanaee-t-rft-aufirst-hadi-rft-au-gama-2c-joao-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-436-span-class-mw-cite-backlink-b-a-href-cite-ref-436-a-b-span-span-class-reference-text-giot-romain-and-raphael-cherrier-predicting-bikeshare-system-usage-up-to-one-day-ahead-i-computational-intelligence-in-vehicles-and-transportation-systems-civts-2014-ieee-symposium-on-i-ieee-2014-span-li-li-id-cite-note-437-span-class-mw-cite-backlink-b-a-href-cite-ref-437-a-b-span-span-class-reference-text-cite-class-citation-journal-zhan-xianyuan-et-al-2013-urban-link-travel-time-estimation-using-large-scale-taxi-data-with-partial-information-i-transportation-research-part-c-emerging-technologies-i-b-33-b-37-49-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-trc-2013-04-001-10-1016-j-trc-2013-04-001-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-transportation-research-part-c-3a-emerging-technologies-rft-atitle-urban-link-travel-time-estimation-using-large-scale-taxi-data-with-partial-information-rft-volume-33-rft-pages-37-49-rft-date-2013-rft-id-info-3adoi-2f10-1016-2fj-trc-2013-04-001-rft-aulast-zhan-rft-aufirst-xianyuan-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-438-span-class-mw-cite-backlink-b-a-href-cite-ref-438-a-b-span-span-class-reference-text-cite-class-citation-journal-moreira-matias-luis-et-al-2013-predicting-taxi-passenger-demand-using-streaming-data-i-ieee-transactions-on-intelligent-transportation-systems-i-b-14-b-3-1393-1402-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftits-2013-2262376-10-1109-tits-2013-2262376-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-intelligent-transportation-systems-rft-atitle-predicting-taxi-e2-80-93passenger-demand-using-streaming-data-rft-volume-14-rft-issue-3-rft-pages-1393-1402-rft-date-2013-rft-id-info-3adoi-2f10-1109-2ftits-2013-2262376-rft-aulast-moreira-matias-rft-aufirst-luis-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-439-span-class-mw-cite-backlink-b-a-href-cite-ref-439-a-b-span-span-class-reference-text-cite-class-citation-journal-hwang-ren-hung-hsueh-yu-ling-chen-yu-ting-2015-an-effective-taxi-recommender-system-based-on-a-spatio-temporal-factor-analysis-model-i-information-sciences-i-b-314-b-28-40-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-ins-2015-03-068-10-1016-j-ins-2015-03-068-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-information-sciences-rft-atitle-an-effective-taxi-recommender-system-based-on-a-spatio-temporal-factor-analysis-model-rft-volume-314-rft-pages-28-40-rft-date-2015-rft-id-info-3adoi-2f10-1016-2fj-ins-2015-03-068-rft-aulast-hwang-rft-aufirst-ren-hung-rft-au-hsueh-2c-yu-ling-rft-au-chen-2c-yu-ting-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-440-span-class-mw-cite-backlink-b-a-href-cite-ref-440-a-b-span-span-class-reference-text-meusel-robert-et-al-the-graph-structure-in-the-web-analyzed-on-different-aggregation-levels-i-the-journal-of-web-science-i-1-1-2015-span-li-li-id-cite-note-441-span-class-mw-cite-backlink-b-a-href-cite-ref-441-a-b-span-span-class-reference-text-kushmerick-nicholas-learning-to-remove-internet-advertisements-i-proceedings-of-the-third-annual-conference-on-autonomous-agents-i-acm-1999-span-li-li-id-cite-note-442-span-class-mw-cite-backlink-b-a-href-cite-ref-442-a-b-span-span-class-reference-text-fradkin-dmitriy-and-david-madigan-experiments-with-random-projections-for-machine-learning-i-proceedings-of-the-ninth-acm-sigkdd-international-conference-on-knowledge-discovery-and-data-mining-i-acm-2003-span-li-li-id-cite-note-443-span-class-mw-cite-backlink-b-a-href-cite-ref-443-a-b-span-span-class-reference-text-this-data-was-used-in-the-american-statistical-association-statistical-graphics-and-computing-sections-1999-data-exposition-span-li-li-id-cite-note-444-span-class-mw-cite-backlink-b-a-href-cite-ref-444-a-b-span-span-class-reference-text-ma-justin-et-al-identifying-suspicious-urls-an-application-of-large-scale-online-learning-i-proceedings-of-the-26th-annual-international-conference-on-machine-learning-i-acm-2009-span-li-li-id-cite-note-445-span-class-mw-cite-backlink-b-a-href-cite-ref-445-a-b-span-span-class-reference-text-levchenko-kirill-et-al-click-trajectories-end-to-end-analysis-of-the-spam-value-chain-i-security-and-privacy-sp-2011-ieee-symposium-on-i-ieee-2011-span-li-li-id-cite-note-446-span-class-mw-cite-backlink-b-a-href-cite-ref-446-a-b-span-span-class-reference-text-mohammad-rami-m-fadi-thabtah-and-lee-mccluskey-an-assessment-of-features-related-to-phishing-websites-using-an-automated-technique-i-internet-technology-and-secured-transactions-2012-international-conference-for-i-ieee-2012-span-li-li-id-cite-note-447-span-class-mw-cite-backlink-b-a-href-cite-ref-447-a-b-span-span-class-reference-text-singh-ashishkumar-et-al-clustering-experiments-on-big-transaction-data-for-market-segmentation-i-proceedings-of-the-2014-international-conference-on-big-data-science-and-computing-i-acm-2014-span-li-li-id-cite-note-448-span-class-mw-cite-backlink-b-a-href-cite-ref-448-a-b-span-span-class-reference-text-bollacker-kurt-et-al-freebase-a-collaboratively-created-graph-database-for-structuring-human-knowledge-i-proceedings-of-the-2008-acm-sigmod-international-conference-on-management-of-data-i-acm-2008-span-li-li-id-cite-note-449-span-class-mw-cite-backlink-b-a-href-cite-ref-449-a-b-span-span-class-reference-text-mintz-mike-et-al-a-rel-nofollow-class-external-text-href-https-www-aclweb-org-anthology-p09-1113-distant-supervision-for-relation-extraction-without-labeled-data-a-i-proceedings-of-the-joint-conference-of-the-47th-annual-meeting-of-the-acl-and-the-4th-international-joint-conference-on-natural-language-processing-of-the-afnlp-volume-2-volume-2-i-association-for-computational-linguistics-2009-span-li-li-id-cite-note-450-span-class-mw-cite-backlink-b-a-href-cite-ref-450-a-b-span-span-class-reference-text-mesterharm-chris-and-michael-j-pazzani-active-learning-using-on-line-algorithms-i-proceedings-of-the-17th-acm-sigkdd-international-conference-on-knowledge-discovery-and-data-mining-i-acm-2011-span-li-li-id-cite-note-451-span-class-mw-cite-backlink-b-a-href-cite-ref-451-a-b-span-span-class-reference-text-cite-class-citation-journal-wang-shusen-zhang-zhihua-2013-improving-cur-matrix-decomposition-and-the-nystrom-approximation-via-adaptive-sampling-i-the-journal-of-machine-learning-research-i-b-14-b-1-2729-2769-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-the-journal-of-machine-learning-research-rft-atitle-improving-cur-matrix-decomposition-and-the-nystr-c3-b6m-approximation-via-adaptive-sampling-rft-volume-14-rft-issue-1-rft-pages-2729-2769-rft-date-2013-rft-aulast-wang-rft-aufirst-shusen-rft-au-zhang-2c-zhihua-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-452-span-class-mw-cite-backlink-b-a-href-cite-ref-452-a-b-span-span-class-reference-text-cattral-robert-franz-oppacher-and-dwight-deugo-evolutionary-data-mining-with-automatic-rule-generalization-i-recent-advances-in-computers-computing-and-communications-i-2002-296-300-span-li-li-id-cite-note-453-span-class-mw-cite-backlink-b-a-href-cite-ref-453-a-b-span-span-class-reference-text-burton-ariel-n-and-paul-hj-kelly-performance-prediction-of-paging-workloads-using-lightweight-tracing-i-future-generation-computer-systems-i-22-7-2006-784-793-span-li-li-id-cite-note-454-span-class-mw-cite-backlink-b-a-href-cite-ref-454-a-b-span-span-class-reference-text-bain-michael-and-stephen-muggleton-learning-optimal-chess-strategies-i-machine-intelligence-13-i-oxford-university-press-inc-1994-span-li-li-id-cite-note-455-span-class-mw-cite-backlink-b-a-href-cite-ref-455-a-b-span-span-class-reference-text-cite-class-citation-journal-quilan-j-r-1983-learning-efficient-classification-procedures-and-their-application-to-chess-end-games-i-machine-learning-an-artificial-intelligence-approach-i-b-1-b-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-machine-learning-3a-an-artificial-intelligence-approach-rft-atitle-learning-efficient-classification-procedures-and-their-application-to-chess-end-games-rft-volume-1-rft-date-1983-rft-aulast-quilan-rft-aufirst-j-r-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-456-span-class-mw-cite-backlink-b-a-href-cite-ref-456-a-b-span-span-class-reference-text-shapiro-alen-d-i-structured-induction-in-expert-systems-i-addison-wesley-longman-publishing-co-inc-1987-span-li-li-id-cite-note-457-span-class-mw-cite-backlink-b-a-href-cite-ref-457-a-b-span-span-class-reference-text-cite-class-citation-journal-matheus-christopher-j-rendell-larry-a-1989-constructive-induction-on-decision-trees-i-ijcai-i-b-89-b-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ijcai-rft-atitle-constructive-induction-on-decision-trees-rft-volume-89-rft-date-1989-rft-aulast-matheus-rft-aufirst-christopher-j-rft-au-rendell-2c-larry-a-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-5-458-span-class-mw-cite-backlink-b-a-href-cite-ref-5-458-0-a-b-span-span-class-reference-text-belsley-david-a-edwin-kuh-and-roy-e-welsch-i-regression-diagnostics-identifying-influential-data-and-sources-of-collinearity-i-vol-571-john-wiley-sons-2005-span-li-li-id-cite-note-459-span-class-mw-cite-backlink-b-a-href-cite-ref-459-a-b-span-span-class-reference-text-cite-class-citation-journal-ruotsalo-tuukka-aroyo-lora-schreiber-guus-2009-a-rel-nofollow-class-external-text-href-http-dare-ubvu-vu-nl-bitstream-handle-1871-24407-243319-pdf-sequence-3-knowledge-based-linguistic-annotation-of-digital-cultural-heritage-collections-a-span-class-cs1-format-pdf-span-i-ieee-intelligent-systems-i-b-2-b-64-75-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-intelligent-systems-rft-atitle-knowledge-based-linguistic-annotation-of-digital-cultural-heritage-collections-rft-volume-2-rft-pages-64-75-rft-date-2009-rft-aulast-ruotsalo-rft-aufirst-tuukka-rft-au-aroyo-2c-lora-rft-au-schreiber-2c-guus-rft-id-http-3a-2f-2fdare-ubvu-vu-nl-2fbitstream-2fhandle-2f1871-2f24407-2f243319-pdf-3fsequence-3d3-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-460-span-class-mw-cite-backlink-b-a-href-cite-ref-460-a-b-span-span-class-reference-text-li-lihong-et-al-a-rel-nofollow-class-external-text-href-https-arxiv-org-pdf-1003-5956-unbiased-offline-evaluation-of-contextual-bandit-based-news-article-recommendation-algorithms-a-i-proceedings-of-the-fourth-acm-international-conference-on-web-search-and-data-mining-i-acm-2011-span-li-li-id-cite-note-461-span-class-mw-cite-backlink-b-a-href-cite-ref-461-a-b-span-span-class-reference-text-yeung-kam-fung-and-yanyan-yang-a-rel-nofollow-class-external-text-href-https-ieeexplore-ieee-org-abstract-document-5633837-a-proactive-personalized-mobile-news-recommendation-system-a-i-developments-in-e-systems-engineering-dese-2010-i-ieee-2010-span-li-li-id-cite-note-462-span-class-mw-cite-backlink-b-a-href-cite-ref-462-a-b-span-span-class-reference-text-cite-class-citation-journal-gass-susan-e-roberts-j-murray-2006-the-occurrence-of-the-cold-water-coral-lophelia-pertusa-scleractinia-on-oil-and-gas-platforms-in-the-north-sea-colony-growth-recruitment-and-environmental-controls-on-distribution-i-marine-pollution-bulletin-i-b-52-b-5-549-559-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-marpolbul-2005-10-002-10-1016-j-marpolbul-2005-10-002-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-16300800-16300800-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-marine-pollution-bulletin-rft-atitle-the-occurrence-of-the-cold-water-coral-lophelia-pertusa-28scleractinia-29-on-oil-and-gas-platforms-in-the-north-sea-3a-colony-growth-2c-recruitment-and-environmental-controls-on-distribution-rft-volume-52-rft-issue-5-rft-pages-549-559-rft-date-2006-rft-id-info-3adoi-2f10-1016-2fj-marpolbul-2005-10-002-rft-id-info-3apmid-2f16300800-rft-aulast-gass-rft-aufirst-susan-e-rft-au-roberts-2c-j-murray-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-463-span-class-mw-cite-backlink-b-a-href-cite-ref-463-a-b-span-span-class-reference-text-cite-class-citation-journal-gionis-aristides-mannila-heikki-tsaparas-panayiotis-2007-clustering-aggregation-i-acm-transactions-on-knowledge-discovery-from-data-tkdd-i-b-1-b-1-4-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-709-528-10-1-1-709-528-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1145-2f1217299-1217303-10-1145-1217299-1217303-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-acm-transactions-on-knowledge-discovery-from-data-28tkdd-29-rft-atitle-clustering-aggregation-rft-volume-1-rft-issue-1-rft-pages-4-rft-date-2007-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-709-528-rft-id-info-3adoi-2f10-1145-2f1217299-1217303-rft-aulast-gionis-rft-aufirst-aristides-rft-au-mannila-2c-heikki-rft-au-tsaparas-2c-panayiotis-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-464-span-class-mw-cite-backlink-b-a-href-cite-ref-464-a-b-span-span-class-reference-text-obradovic-zoran-and-slobodan-vucetic-i-challenges-in-scientific-data-mining-heterogeneous-biased-and-large-samples-i-technical-report-center-for-information-science-and-technology-temple-university-2004-span-li-li-id-cite-note-465-span-class-mw-cite-backlink-b-a-href-cite-ref-465-a-b-span-span-class-reference-text-cite-class-citation-journal-van-der-putten-peter-van-someren-maarten-2000-coil-challenge-2000-the-insurance-company-case-i-published-by-sentient-machine-research-amsterdam-also-a-leiden-institute-of-advanced-computer-science-technical-report-i-b-9-b-1-43-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-published-by-sentient-machine-research-2c-amsterdam-also-a-leiden-institute-of-advanced-computer-science-technical-report-rft-atitle-coil-challenge-2000-3a-the-insurance-company-case-rft-volume-9-rft-pages-1-43-rft-date-2000-rft-aulast-van-der-putten-rft-aufirst-peter-rft-au-van-someren-2c-maarten-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-466-span-class-mw-cite-backlink-b-a-href-cite-ref-466-a-b-span-span-class-reference-text-cite-class-citation-journal-mao-k-z-2002-rbf-neural-network-center-selection-based-on-fisher-ratio-class-separability-measure-i-ieee-transactions-on-neural-networks-i-b-13-b-5-1211-1217-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftnn-2002-1031953-10-1109-tnn-2002-1031953-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-18244518-18244518-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-neural-networks-rft-atitle-rbf-neural-network-center-selection-based-on-fisher-ratio-class-separability-measure-rft-volume-13-rft-issue-5-rft-pages-1211-1217-rft-date-2002-rft-id-info-3adoi-2f10-1109-2ftnn-2002-1031953-rft-id-info-3apmid-2f18244518-rft-aulast-mao-rft-aufirst-k-z-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-467-span-class-mw-cite-backlink-b-a-href-cite-ref-467-a-b-span-span-class-reference-text-cite-class-citation-journal-olave-manuel-rajkovic-vladislav-bohanec-marko-1989-an-application-for-admission-in-public-school-systems-i-expert-systems-in-public-administration-i-b-1-b-145-160-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-expert-systems-in-public-administration-rft-atitle-an-application-for-admission-in-public-school-systems-rft-volume-1-rft-pages-145-160-rft-date-1989-rft-aulast-olave-rft-aufirst-manuel-rft-au-rajkovic-2c-vladislav-rft-au-bohanec-2c-marko-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-468-span-class-mw-cite-backlink-b-a-href-cite-ref-468-a-b-span-span-class-reference-text-lizotte-daniel-j-omid-madani-and-russell-greiner-a-rel-nofollow-class-external-text-href-https-arxiv-org-pdf-1212-2472-budgeted-learning-of-nailve-bayes-classifiers-a-i-proceedings-of-the-nineteenth-conference-on-uncertainty-in-artificial-intelligence-i-morgan-kaufmann-publishers-inc-2002-span-li-li-id-cite-note-469-span-class-mw-cite-backlink-b-a-href-cite-ref-469-a-b-span-span-class-reference-text-cite-class-citation-book-lebowitz-michael-1986-a-rel-nofollow-class-external-text-href-https-books-google-com-id-f9rylgkphzsc-pg-pa193-dq-22concept-learning-in-a-rich-input-domain-generalization-based-memory-22-v-onepage-q-22concept-20learning-20in-20a-20rich-20input-20domain-3a-20generalization-based-20memory-22-f-false-i-concept-learning-in-a-rich-input-domain-generalization-based-memory-i-a-i-machine-learning-an-artificial-intelligence-approach-i-b-2-b-pp-193-214-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-9780934613002-title-special-booksources-9780934613002-bdi-9780934613002-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-concept-learning-in-a-rich-input-domain-3a-generalization-based-memory-rft-pages-193-214-rft-date-1986-rft-isbn-9780934613002-rft-aulast-lebowitz-rft-aufirst-michael-rft-id-https-3a-2f-2fbooks-google-com-2f-3fid-3df9rylgkphzsc-26pg-3dpa193-26dq-3d-2522concept-2blearning-2bin-2ba-2brich-2binput-2bdomain-3a-2bgeneralization-based-2bmemory-2522-23v-3donepage-26q-3d-2522concept-2520learning-2520in-2520a-2520rich-2520input-2520domain-253a-2520generalization-based-2520memory-2522-26f-3dfalse-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-470-span-class-mw-cite-backlink-b-a-href-cite-ref-470-a-b-span-span-class-reference-text-cite-class-citation-journal-yeh-i-cheng-yang-king-jang-ting-tao-ming-2009-knowledge-discovery-on-rfm-model-using-bernoulli-sequence-i-expert-systems-with-applications-i-b-36-b-3-5866-5871-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-eswa-2008-07-018-10-1016-j-eswa-2008-07-018-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-expert-systems-with-applications-rft-atitle-knowledge-discovery-on-rfm-model-using-bernoulli-sequence-rft-volume-36-rft-issue-3-rft-pages-5866-5871-rft-date-2009-rft-id-info-3adoi-2f10-1016-2fj-eswa-2008-07-018-rft-aulast-yeh-rft-aufirst-i-cheng-rft-au-yang-2c-king-jang-rft-au-ting-2c-tao-ming-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-471-span-class-mw-cite-backlink-b-a-href-cite-ref-471-a-b-span-span-class-reference-text-cite-class-citation-journal-lee-wen-chen-cheng-bor-wen-2011-an-intelligent-system-for-improving-performance-of-blood-donation-i-journal-of-quality-vol-i-b-18-b-2-173-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-quality-vol-rft-atitle-an-intelligent-system-for-improving-performance-of-blood-donation-rft-volume-18-rft-issue-2-rft-pages-173-rft-date-2011-rft-aulast-lee-rft-aufirst-wen-chen-rft-au-cheng-2c-bor-wen-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-472-span-class-mw-cite-backlink-b-a-href-cite-ref-472-a-b-span-span-class-reference-text-schmidtmann-irene-et-al-a-rel-nofollow-class-external-text-href-http-www-krebsregister-nrw-de-fileadmin-user-upload-dokumente-evaluation-ekr-nrw-evaluation-abschlussbericht-2009-06-11-pdf-evaluation-des-krebsregisters-nrw-schwerpunkt-record-linkage-a-i-abschlussbericht-vom-i-11-2009-span-li-li-id-cite-note-473-span-class-mw-cite-backlink-b-a-href-cite-ref-473-a-b-span-span-class-reference-text-cite-class-citation-journal-sariyar-murat-borg-andreas-pommerening-klaus-2011-controlling-false-match-rates-in-record-linkage-using-extreme-value-theory-i-journal-of-biomedical-informatics-i-b-44-b-4-648-654-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-jbi-2011-02-008-10-1016-j-jbi-2011-02-008-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-21352952-21352952-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-biomedical-informatics-rft-atitle-controlling-false-match-rates-in-record-linkage-using-extreme-value-theory-rft-volume-44-rft-issue-4-rft-pages-648-654-rft-date-2011-rft-id-info-3adoi-2f10-1016-2fj-jbi-2011-02-008-rft-id-info-3apmid-2f21352952-rft-aulast-sariyar-rft-aufirst-murat-rft-au-borg-2c-andreas-rft-au-pommerening-2c-klaus-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-474-span-class-mw-cite-backlink-b-a-href-cite-ref-474-a-b-span-span-class-reference-text-candillier-laurent-and-vincent-lemaire-a-rel-nofollow-class-external-text-href-https-pdfs-semanticscholar-org-1647-fc91cfe3e68ef3c41d727b7292ce20482b11-pdf-design-and-analysis-of-the-nomao-challenge-active-learning-in-the-real-world-a-i-proceedings-of-the-alra-active-learning-in-real-world-applications-workshop-ecml-pkdd-i-2012-span-li-li-id-cite-note-475-span-class-mw-cite-backlink-b-a-href-cite-ref-475-a-b-span-span-class-reference-text-marquez-ivan-garrido-a-rel-nofollow-class-external-text-href-http-ccc-inaoep-mx-mmontesg-tesis-20estudiantes-tesismaestria-ivangarrido-pdf-a-domain-adaptation-method-for-text-classification-based-on-self-adjusted-training-approach-a-2013-span-li-li-id-cite-note-476-span-class-mw-cite-backlink-b-a-href-cite-ref-476-a-b-span-span-class-reference-text-nagesh-harsha-s-sanjay-goil-and-alok-n-choudhary-adaptive-grids-for-clustering-massive-data-sets-sdm-2001-span-li-li-id-cite-note-477-span-class-mw-cite-backlink-b-a-href-cite-ref-477-a-b-span-span-class-reference-text-kuzilek-jakub-et-al-a-rel-nofollow-class-external-text-href-http-oro-open-ac-uk-42529-1-userdata-documents4-ctb44-desktop-analysing-at-risk-students-at-open-university-pdf-ou-analyse-analysing-at-risk-students-at-the-open-university-a-i-learning-analytics-review-i-2015-1-16-span-li-li-id-cite-note-478-span-class-mw-cite-backlink-b-a-href-cite-ref-478-a-b-span-span-class-reference-text-siemens-george-et-al-i-a-rel-nofollow-class-external-text-href-http-search-ror-unisa-edu-au-record-unisa-alma11143300720001831-media-digital-open-9915909179101831-12143300710001831-13143328550001831-pdf-open-learning-analytics-an-integrated-modularized-platform-a-i-diss-open-university-press-2011-span-li-li-id-cite-note-barlacchide-nadai2015-479-span-class-mw-cite-backlink-b-a-href-cite-ref-barlacchide-nadai2015-479-0-a-b-span-span-class-reference-text-cite-class-citation-journal-barlacchi-gianni-de-nadai-marco-larcher-roberto-casella-antonio-chitic-cristiana-torrisi-giovanni-antonelli-fabrizio-vespignani-alessandro-pentland-alex-lepri-bruno-2015-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4622222-a-multi-source-dataset-of-urban-life-in-the-city-of-milan-and-the-province-of-trentino-a-i-scientific-data-i-b-2-b-150055-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2015natsd-250055b-2015natsd-250055b-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1038-2fsdata-2015-55-10-1038-sdata-2015-55-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-2052-4463-2052-4463-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4622222-4622222-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-26528394-26528394-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-scientific-data-rft-atitle-a-multi-source-dataset-of-urban-life-in-the-city-of-milan-and-the-province-of-trentino-rft-volume-2-rft-pages-150055-rft-date-2015-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4622222-rft-id-info-3abibcode-2f2015natsd-250055b-rft-id-info-3apmid-2f26528394-rft-id-info-3adoi-2f10-1038-2fsdata-2015-55-rft-issn-2052-4463-rft-aulast-barlacchi-rft-aufirst-gianni-rft-au-de-nadai-2c-marco-rft-au-larcher-2c-roberto-rft-au-casella-2c-antonio-rft-au-chitic-2c-cristiana-rft-au-torrisi-2c-giovanni-rft-au-antonelli-2c-fabrizio-rft-au-vespignani-2c-alessandro-rft-au-pentland-2c-alex-rft-au-lepri-2c-bruno-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4622222-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-480-span-class-mw-cite-backlink-b-a-href-cite-ref-480-a-b-span-span-class-reference-text-cite-class-citation-journal-vanschoren-j-van-rijn-jn-bischl-b-torgo-l-2013-a-rel-nofollow-class-external-text-href-https-dl-acm-org-citation-cfm-id-2641198-openml-networked-science-in-machine-learning-a-i-sigkdd-explorations-i-b-15-b-2-49-60-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1407-7722-1407-7722-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1145-2f2641190-2641198-10-1145-2641190-2641198-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-sigkdd-explorations-rft-atitle-openml-3a-networked-science-in-machine-learning-rft-volume-15-rft-issue-2-rft-pages-49-60-rft-date-2013-rft-id-info-3aarxiv-2f1407-7722-rft-id-info-3adoi-2f10-1145-2f2641190-2641198-rft-aulast-vanschoren-rft-aufirst-j-rft-au-van-rijn-2c-jn-rft-au-bischl-2c-b-rft-au-torgo-2c-l-rft-id-https-3a-2f-2fdl-acm-org-2fcitation-cfm-3fid-3d2641198-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-481-span-class-mw-cite-backlink-b-a-href-cite-ref-481-a-b-span-span-class-reference-text-cite-class-citation-journal-olson-rs-la-cava-w-orzechowski-p-urbanowicz-rj-moore-jh-2017-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc5725843-pmlb-a-large-benchmark-suite-for-machine-learning-evaluation-and-comparison-a-i-biodata-mining-i-b-10-b-36-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1186-2fs13040-017-0154-4-10-1186-s13040-017-0154-4-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc5725843-5725843-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-29238404-29238404-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-biodata-mining-rft-atitle-pmlb-3a-a-large-benchmark-suite-for-machine-learning-evaluation-and-comparison-rft-volume-10-rft-pages-36-rft-date-2017-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc5725843-rft-id-info-3apmid-2f29238404-rft-id-info-3adoi-2f10-1186-2fs13040-017-0154-4-rft-aulast-olson-rft-aufirst-rs-rft-au-la-cava-2c-w-rft-au-orzechowski-2c-p-rft-au-urbanowicz-2c-rj-rft-au-moore-2c-jh-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc5725843-rfr-id-info-3asid-2fen-wikipedia-org-3alist-of-datasets-for-machine-learning-research-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-ol-div-newpp-limit-report-parsed-by-mw1333-cached-time-20190618150240-cache-expiry-2592000-dynamic-content-false-complications-vary-revision-cpu-time-usage-3-120-seconds-real-time-usage-3-281-seconds-preprocessor-visited-node-count-13536-1000000-preprocessor-generated-node-count-0-1500000-post-expand-include-size-469285-2097152-bytes-template-argument-size-3179-2097152-bytes-highest-expansion-depth-12-40-expensive-parser-function-count-9-500-unstrip-recursion-depth-1-20-unstrip-post-expand-size-818642-5000000-bytes-number-of-wikibase-entities-loaded-7-400-lua-time-usage-1-856-10-000-seconds-lua-memory-usage-5-9-mb-50-mb-transclusion-expansion-time-report-ms-calls-template-100-00-2709-467-1-total-87-91-2381-795-1-template-reflist-54-46-1475-563-160-template-cite-journal-7-82-211-933-28-template-cite-web-4-93-133-561-11-template-cite-arxiv-2-95-79-991-11-template-cite-arxiv-2-56-69-363-7-template-cite-book-2-49-67-415-1-template-machine-learning-bar-2-33-63-177-1-template-sidebar-with-collapsible-lists-1-57-42-568-1-template-use-dmy-dates-saved-in-parser-cache-with-key-enwiki-pcache-idhash-49082762-0-canonical-and-timestamp-20190618150237-and-revision-id-902152298-div-noscript-img-src-en-wikipedia-org-wiki-special-centralautologin-start-type-1x1-alt-title-width-1-height-1-style-border-none-position-absolute-noscript-div-div-class-printfooter-retrieved-from-a-dir-ltr-href-https-en-wikipedia-org-w-index-php-title-list-of-datasets-for-machine-learning-research-oldid-902152298-https-en-wikipedia-org-w-index-php-title-list-of-datasets-for-machine-learning-research-oldid-902152298-a-div-div-id-catlinks-class-catlinks-data-mw-interface-div-id-mw-normal-catlinks-class-mw-normal-catlinks-a-href-wiki-help-category-title-help-category-categories-a-ul-li-a-href-wiki-category-datasets-in-machine-learning-title-category-datasets-in-machine-learning-datasets-in-machine-learning-a-li-li-a-href-wiki-category-machine-learning-title-category-machine-learning-machine-learning-a-li-li-a-href-wiki-category-artificial-intelligence-title-category-artificial-intelligence-artificial-intelligence-a-li-ul-div-div-id-mw-hidden-catlinks-class-mw-hidden-catlinks-mw-hidden-cats-hidden-hidden-categories-ul-li-a-href-wiki-category-cs1-maint-multiple-names-authors-list-title-category-cs1-maint-multiple-names-authors-list-cs1-maint-multiple-names-authors-list-a-li-li-a-href-wiki-category-use-dmy-dates-from-september-2017-title-category-use-dmy-dates-from-september-2017-use-dmy-dates-from-september-2017-a-li-ul-div-div-div-class-visualclear-div-div-div-div-id-mw-navigation-h2-navigation-menu-h2-div-id-mw-head-div-id-p-personal-role-navigation-aria-labelledby-p-personal-label-h3-id-p-personal-label-personal-tools-h3-ul-li-id-pt-anonuserpage-not-logged-in-li-li-id-pt-anontalk-a-href-wiki-special-mytalk-title-discussion-about-edits-from-this-ip-address-n-accesskey-n-talk-a-li-li-id-pt-anoncontribs-a-href-wiki-special-mycontributions-title-a-list-of-edits-made-from-this-ip-address-y-accesskey-y-contributions-a-li-li-id-pt-createaccount-a-href-w-index-php-title-special-createaccount-returnto-list-of-datasets-for-machine-learning-research-title-you-are-encouraged-to-create-an-account-and-log-in-however-it-is-not-mandatory-create-account-a-li-li-id-pt-login-a-href-w-index-php-title-special-userlogin-returnto-list-of-datasets-for-machine-learning-research-title-youre-encouraged-to-log-in-however-its-not-mandatory-o-accesskey-o-log-in-a-li-ul-div-div-id-left-navigation-div-id-p-namespaces-role-navigation-class-vectortabs-aria-labelledby-p-namespaces-label-h3-id-p-namespaces-label-namespaces-h3-ul-li-id-ca-nstab-main-class-selected-span-a-href-wiki-list-of-datasets-for-machine-learning-research-title-view-the-content-page-c-accesskey-c-article-a-span-li-li-id-ca-talk-span-a-href-wiki-talk-list-of-datasets-for-machine-learning-research-rel-discussion-title-discussion-about-the-content-page-t-accesskey-t-talk-a-span-li-ul-div-div-id-p-variants-role-navigation-class-vectormenu-emptyportlet-aria-labelledby-p-variants-label-input-type-checkbox-class-vectormenucheckbox-aria-labelledby-p-variants-label-h3-id-p-variants-label-span-variants-span-h3-ul-class-menu-ul-div-div-div-id-right-navigation-div-id-p-views-role-navigation-class-vectortabs-aria-labelledby-p-views-label-h3-id-p-views-label-views-h3-ul-li-id-ca-view-class-collapsible-selected-span-a-href-wiki-list-of-datasets-for-machine-learning-research-read-a-span-li-li-id-ca-edit-class-collapsible-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-edit-title-edit-this-page-e-accesskey-e-edit-a-span-li-li-id-ca-history-class-collapsible-span-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-history-title-past-revisions-of-this-page-h-accesskey-h-view-history-a-span-li-ul-div-div-id-p-cactions-role-navigation-class-vectormenu-emptyportlet-aria-labelledby-p-cactions-label-input-type-checkbox-class-vectormenucheckbox-aria-labelledby-p-cactions-label-h3-id-p-cactions-label-span-more-span-h3-ul-class-menu-ul-div-div-id-p-search-role-search-h3-label-for-searchinput-search-label-h3-form-action-w-index-php-id-searchform-div-id-simplesearch-input-type-search-name-search-placeholder-search-wikipedia-title-search-wikipedia-f-accesskey-f-id-searchinput-input-type-hidden-value-special-search-name-title-input-type-submit-name-fulltext-value-search-title-search-wikipedia-for-this-text-id-mw-searchbutton-class-searchbutton-mw-fallbacksearchbutton-input-type-submit-name-go-value-go-title-go-to-a-page-with-this-exact-name-if-it-exists-id-searchbutton-class-searchbutton-div-form-div-div-div-div-id-mw-panel-div-id-p-logo-role-banner-a-class-mw-wiki-logo-href-wiki-main-page-title-visit-the-main-page-a-div-div-class-portal-role-navigation-id-p-navigation-aria-labelledby-p-navigation-label-h3-id-p-navigation-label-navigation-h3-div-class-body-ul-li-id-n-mainpage-description-a-href-wiki-main-page-title-visit-the-main-page-z-accesskey-z-main-page-a-li-li-id-n-contents-a-href-wiki-portal-contents-title-guides-to-browsing-wikipedia-contents-a-li-li-id-n-featuredcontent-a-href-wiki-portal-featured-content-title-featured-content-the-best-of-wikipedia-featured-content-a-li-li-id-n-currentevents-a-href-wiki-portal-current-events-title-find-background-information-on-current-events-current-events-a-li-li-id-n-randompage-a-href-wiki-special-random-title-load-a-random-article-x-accesskey-x-random-article-a-li-li-id-n-sitesupport-a-href-https-donate-wikimedia-org-wiki-special-fundraiserredirector-utm-source-donate-utm-medium-sidebar-utm-campaign-c13-en-wikipedia-org-uselang-en-title-support-us-donate-to-wikipedia-a-li-li-id-n-shoplink-a-href-shop-wikimedia-org-title-visit-the-wikipedia-store-wikipedia-store-a-li-ul-div-div-div-class-portal-role-navigation-id-p-interaction-aria-labelledby-p-interaction-label-h3-id-p-interaction-label-interaction-h3-div-class-body-ul-li-id-n-help-a-href-wiki-help-contents-title-guidance-on-how-to-use-and-edit-wikipedia-help-a-li-li-id-n-aboutsite-a-href-wiki-wikipedia-about-title-find-out-about-wikipedia-about-wikipedia-a-li-li-id-n-portal-a-href-wiki-wikipedia-community-portal-title-about-the-project-what-you-can-do-where-to-find-things-community-portal-a-li-li-id-n-recentchanges-a-href-wiki-special-recentchanges-title-a-list-of-recent-changes-in-the-wiki-r-accesskey-r-recent-changes-a-li-li-id-n-contactpage-a-href-en-wikipedia-org-wiki-wikipedia-contact-us-title-how-to-contact-wikipedia-contact-page-a-li-ul-div-div-div-class-portal-role-navigation-id-p-tb-aria-labelledby-p-tb-label-h3-id-p-tb-label-tools-h3-div-class-body-ul-li-id-t-whatlinkshere-a-href-wiki-special-whatlinkshere-list-of-datasets-for-machine-learning-research-title-list-of-all-english-wikipedia-pages-containing-links-to-this-page-j-accesskey-j-what-links-here-a-li-li-id-t-recentchangeslinked-a-href-wiki-special-recentchangeslinked-list-of-datasets-for-machine-learning-research-rel-nofollow-title-recent-changes-in-pages-linked-from-this-page-k-accesskey-k-related-changes-a-li-li-id-t-upload-a-href-wiki-wikipedia-file-upload-wizard-title-upload-files-u-accesskey-u-upload-file-a-li-li-id-t-specialpages-a-href-wiki-special-specialpages-title-a-list-of-all-special-pages-q-accesskey-q-special-pages-a-li-li-id-t-permalink-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-oldid-902152298-title-permanent-link-to-this-revision-of-the-page-permanent-link-a-li-li-id-t-info-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-action-info-title-more-information-about-this-page-page-information-a-li-li-id-t-wikibase-a-href-https-www-wikidata-org-wiki-special-entitypage-q23038294-title-link-to-connected-data-repository-item-g-accesskey-g-wikidata-item-a-li-li-id-t-cite-a-href-w-index-php-title-special-citethispage-page-list-of-datasets-for-machine-learning-research-id-902152298-title-information-on-how-to-cite-this-page-cite-this-page-a-li-ul-div-div-div-class-portal-role-navigation-id-p-coll-print-export-aria-labelledby-p-coll-print-export-label-h3-id-p-coll-print-export-label-print-export-h3-div-class-body-ul-li-id-coll-create-a-book-a-href-w-index-php-title-special-book-bookcmd-book-creator-referer-list-of-datasets-for-machine-learning-research-create-a-book-a-li-li-id-coll-download-as-rl-a-href-w-index-php-title-special-electronpdf-page-list-of-datasets-for-machine-learning-research-action-show-download-screen-download-as-pdf-a-li-li-id-t-print-a-href-w-index-php-title-list-of-datasets-for-machine-learning-research-printable-yes-title-printable-version-of-this-page-p-accesskey-p-printable-version-a-li-ul-div-div-div-class-portal-role-navigation-id-p-lang-aria-labelledby-p-lang-label-h3-id-p-lang-label-languages-h3-div-class-body-ul-li-class-interlanguage-link-interwiki-uk-a-href-https-uk-wikipedia-org-wiki-d0-a1-d0-bf-d0-b8-d1-81-d0-be-d0-ba-d0-bd-d0-b0-d0-b1-d0-be-d1-80-d1-96-d0-b2-d0-b4-d0-b0-d0-bd-d0-b8-d1-85-d0-b4-d0-bb-d1-8f-d0-b4-d0-be-d1-81-d0-bb-d1-96-d0-b4-d0-b6-d0-b5-d0-bd-d1-8c-d0-b7-d0-bc-d0-b0-d1-88-d0-b8-d0-bd-d0-bd-d0-be-d0-b3-d0-be-d0-bd-d0-b0-d0-b2-d1-87-d0-b0-d0-bd-d0-bd-d1-8f-title-spisok-naboriv-danikh-dlia-doslidzhen-z-mashinnogo-navchannia-ukrainian-lang-uk-hreflang-uk-class-interlanguage-link-target-ukrayinska-a-li-ul-div-class-after-portlet-after-portlet-lang-span-class-wb-langlinks-edit-wb-langlinks-link-a-href-https-www-wikidata-org-wiki-special-entitypage-q23038294-sitelinks-wikipedia-title-edit-interlanguage-links-class-wbc-editpage-edit-links-a-span-div-div-div-div-div-div-id-footer-role-contentinfo-ul-id-footer-info-li-id-footer-info-lastmod-this-page-was-last-edited-on-16-june-2019-at-23-00-span-class-anonymous-show-utc-span-li-li-id-footer-info-copyright-text-is-available-under-the-a-rel-license-href-en-wikipedia-org-wiki-wikipedia-text-of-creative-commons-attribution-sharealike-3-0-unported-license-creative-commons-attribution-sharealike-license-a-a-rel-license-href-creativecommons-org-licenses-by-sa-3-0-style-display-none-a-additional-terms-may-apply-by-using-this-site-you-agree-to-the-a-href-foundation-wikimedia-org-wiki-terms-of-use-terms-of-use-a-and-a-href-foundation-wikimedia-org-wiki-privacy-policy-privacy-policy-a-wikipedia-r-is-a-registered-trademark-of-the-a-href-www-wikimediafoundation-org-wikimedia-foundation-inc-a-a-non-profit-organization-li-ul-ul-id-footer-places-li-id-footer-places-privacy-a-href-https-foundation-wikimedia-org-wiki-privacy-policy-class-extiw-title-wmf-privacy-policy-privacy-policy-a-li-li-id-footer-places-about-a-href-wiki-wikipedia-about-title-wikipedia-about-about-wikipedia-a-li-li-id-footer-places-disclaimer-a-href-wiki-wikipedia-general-disclaimer-title-wikipedia-general-disclaimer-disclaimers-a-li-li-id-footer-places-contact-a-href-en-wikipedia-org-wiki-wikipedia-contact-us-contact-wikipedia-a-li-li-id-footer-places-developers-a-href-https-www-mediawiki-org-wiki-special-mylanguage-how-to-contribute-developers-a-li-li-id-footer-places-cookiestatement-a-href-https-foundation-wikimedia-org-wiki-cookie-statement-cookie-statement-a-li-li-id-footer-places-mobileview-a-href-en-m-wikipedia-org-w-index-php-title-list-of-datasets-for-machine-learning-research-mobileaction-toggle-view-mobile-class-noprint-stopmobileredirecttoggle-mobile-view-a-li-ul-ul-id-footer-icons-class-noprint-li-id-footer-copyrightico-a-href-https-wikimediafoundation-org-img-src-static-images-wikimedia-button-png-srcset-static-images-wikimedia-button-1-5x-png-1-5x-static-images-wikimedia-button-2x-png-2x-width-88-height-31-alt-wikimedia-foundation-a-li-li-id-footer-poweredbyico-a-href-https-www-mediawiki-org-img-src-static-images-poweredby-mediawiki-88x31-png-alt-powered-by-mediawiki-srcset-static-images-poweredby-mediawiki-132x47-png-1-5x-static-images-poweredby-mediawiki-176x62-png-2x-width-88-height-31-a-li-ul-div-style-clear-both-div-div-script-rlq-window-rlq-push-function-mw-config-set-wgpageparsereport-limitreport-cputime-3-120-walltime-3-281-ppvisitednodes-value-13536-limit-1000000-ppgeneratednodes-value-0-limit-1500000-postexpandincludesize-value-469285-limit-2097152-templateargumentsize-value-3179-limit-2097152-expansiondepth-value-12-limit-40-expensivefunctioncount-value-9-limit-500-unstrip-depth-value-1-limit-20-unstrip-size-value-818642-limit-5000000-entityaccesscount-value-7-limit-400-timingprofile-100-00-2709-467-1-total-87-91-2381-795-1-template-reflist-54-46-1475-563-160-template-cite-journal-7-82-211-933-28-template-cite-web-4-93-133-561-11-template-cite-arxiv-2-95-79-991-11-template-cite-arxiv-2-56-69-363-7-template-cite-book-2-49-67-415-1-template-machine-learning-bar-2-33-63-177-1-template-sidebar-with-collapsible-lists-1-57-42-568-1-template-use-dmy-dates-scribunto-limitreport-timeusage-value-1-856-limit-10-000-limitreport-memusage-value-6191614-limit-52428800-limitreport-logs-table-1-n-size-tiny-n-n-cachereport-origin-mw1333-timestamp-20190618150240-ttl-2592000-transientcontent-false-script-script-type-application-ld-json-context-https-schema-org-type-article-name-list-of-datasets-for-machine-learning-research-url-https-en-wikipedia-org-wiki-list-of-datasets-for-machine-learning-research-sameas-http-www-wikidata-org-entity-q23038294-mainentity-http-www-wikidata-org-entity-q23038294-author-type-organization-name-contributors-to-wikimedia-projects-publisher-type-organization-name-wikimedia-foundation-inc-logo-type-imageobject-url-https-www-wikimedia-org-static-images-wmf-hor-googpub-png-datepublished-2016-01-12t21-54-17z-datemodified-2019-06-16t23-00-13z-image-https-upload-wikimedia-org-wikipedia-commons-f-fe-kernel-machine-svg-headline-wikimedia-list-article-script-script-rlq-window-rlq-push-function-mw-config-set-wgbackendresponsetime-110-wghostname-mw1321-script-body-html