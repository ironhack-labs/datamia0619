doctype-html-html-class-client-nojs-lang-en-dir-ltr-head-meta-charset-utf-8-title-deep-learning-wikipedia-title-script-document-documentelement-classname-document-documentelement-classname-replace-s-client-nojs-s-1client-js-2-rlconf-wgcanonicalnamespace-wgcanonicalspecialpagename-1-wgnamespacenumber-0-wgpagename-deep-learning-wgtitle-deep-learning-wgcurrevisionid-902979782-wgrevisionid-902979782-wgarticleid-32472154-wgisarticle-0-wgisredirect-1-wgaction-view-wgusername-null-wgusergroups-wgcategories-cs1-maint-archived-copy-as-title-cs1-long-volume-value-cs1-maint-bot-original-url-status-unknown-all-articles-with-unsourced-statements-articles-with-unsourced-statements-from-april-2018-wikipedia-articles-needing-clarification-from-september-2017-articles-with-unsourced-statements-from-september-2017-wikipedia-articles-that-are-too-technical-from-july-2016-all-articles-that-are-too-technical-articles-needing-expert-attention-from-july-2016-all-articles-needing-expert-attention-articles-with-unsourced-statements-from-july-2016-articles-prone-to-spam-from-june-2015-deep-learning-artificial-neural-networks-artificial-intelligence-emerging-technologies-wgbreakframes-1-wgpagecontentlanguage-en-wgpagecontentmodel-wikitext-wgseparatortransformtable-wgdigittransformtable-wgdefaultdateformat-dmy-wgmonthnames-january-february-march-april-may-june-july-august-september-october-november-december-wgmonthnamesshort-jan-feb-mar-apr-may-jun-jul-aug-sep-oct-nov-dec-wgrelevantpagename-deep-learning-wgrelevantarticleid-32472154-wgrequestid-xq5u5qpaadoaabahg80aaacd-wgcspnonce-1-wgisprobablyeditable-0-wgrelevantpageisprobablyeditable-0-wgrestrictionedit-wgrestrictionmove-wgmediavieweronclick-0-wgmediaviewerenabledbydefault-0-wgpopupsreferencepreviews-1-wgpopupsconflictswithnavpopupgadget-1-wgvisualeditor-pagelanguagecode-en-pagelanguagedir-ltr-pagevariantfallbacks-en-wgmfdisplaywikibasedescriptions-search-0-nearby-0-watchlist-0-tagline-1-wgwmeschemaeditattemptstepoversample-1-wgpoweredbyhhvm-0-wgulscurrentautonym-english-wgnoticeproject-wikipedia-wgcentralnoticecategoriesusinglegacy-fundraising-fundraising-wgwikibaseitemid-q197536-wgcentralauthmobiledomain-1-wgeditsubmitbuttonlabelpublish-0-rlstate-ext-gadget-charinsert-styles-ready-ext-globalcssjs-user-styles-ready-ext-globalcssjs-site-styles-ready-site-styles-ready-noscript-ready-user-styles-ready-ext-globalcssjs-user-ready-ext-globalcssjs-site-ready-user-ready-user-options-ready-user-tokens-loading-ext-cite-styles-ready-ext-math-styles-ready-mediawiki-legacy-shared-ready-mediawiki-legacy-commonprint-ready-mediawiki-toc-styles-ready-wikibase-client-init-ready-ext-visualeditor-desktoparticletarget-noscript-ready-ext-uls-interlanguage-ready-ext-wikimediabadges-ready-ext-3d-styles-ready-mediawiki-skinning-interface-ready-skins-vector-styles-ready-rlpagemodules-ext-cite-ux-enhancements-ext-math-scripts-ext-scribunto-logs-site-mediawiki-page-startup-mediawiki-page-ready-mediawiki-toc-mediawiki-searchsuggest-ext-gadget-teahouse-ext-gadget-referencetooltips-ext-gadget-watchlist-notice-ext-gadget-drn-wizard-ext-gadget-charinsert-ext-gadget-reftoolbar-ext-gadget-extra-toolbar-buttons-ext-gadget-switcher-ext-centralauth-centralautologin-mmv-head-mmv-bootstrap-autostart-ext-popups-ext-visualeditor-desktoparticletarget-init-ext-visualeditor-targetloader-ext-eventlogging-ext-wikimediaevents-ext-navigationtiming-ext-uls-compactlinks-ext-uls-interface-ext-quicksurveys-init-ext-centralnotice-geoip-ext-centralnotice-startup-skins-vector-js-script-script-rlq-window-rlq-push-function-mw-loader-implement-user-tokens-0tffind-function-jquery-require-module-nomin-mw-user-tokens-set-edittoken-patroltoken-watchtoken-csrftoken-script-link-rel-stylesheet-href-w-load-php-lang-en-modules-ext-3d-styles-7cext-cite-styles-7cext-math-styles-7cext-uls-interlanguage-7cext-visualeditor-desktoparticletarget-noscript-7cext-wikimediabadges-7cmediawiki-legacy-commonprint-2cshared-7cmediawiki-skinning-interface-7cmediawiki-toc-styles-7cskins-vector-styles-7cwikibase-client-init-only-styles-skin-vector-script-async-src-w-load-php-lang-en-modules-startup-only-scripts-skin-vector-script-meta-name-resourceloaderdynamicstyles-content-link-rel-stylesheet-href-w-load-php-lang-en-modules-ext-gadget-charinsert-styles-only-styles-skin-vector-link-rel-stylesheet-href-w-load-php-lang-en-modules-site-styles-only-styles-skin-vector-meta-name-generator-content-mediawiki-1-34-0-wmf-8-meta-name-referrer-content-origin-meta-name-referrer-content-origin-when-crossorigin-meta-name-referrer-content-origin-when-cross-origin-meta-property-og-image-content-https-upload-wikimedia-org-wikipedia-commons-thumb-f-fe-kernel-machine-svg-1200px-kernel-machine-svg-png-link-rel-alternate-href-android-app-org-wikipedia-http-en-m-wikipedia-org-wiki-deep-learning-link-rel-alternate-type-application-x-wiki-title-edit-this-page-href-w-index-php-title-deep-learning-action-edit-link-rel-edit-title-edit-this-page-href-w-index-php-title-deep-learning-action-edit-link-rel-apple-touch-icon-href-static-apple-touch-wikipedia-png-link-rel-shortcut-icon-href-static-favicon-wikipedia-ico-link-rel-search-type-application-opensearchdescription-xml-href-w-opensearch-desc-php-title-wikipedia-en-link-rel-edituri-type-application-rsd-xml-href-en-wikipedia-org-w-api-php-action-rsd-link-rel-license-href-creativecommons-org-licenses-by-sa-3-0-link-rel-canonical-href-https-en-wikipedia-org-wiki-deep-learning-link-rel-dns-prefetch-href-login-wikimedia-org-link-rel-dns-prefetch-href-meta-wikimedia-org-if-lt-ie-9-script-src-w-load-php-lang-qqx-modules-html5shiv-only-scripts-skin-fallback-sync-1-script-endif-head-body-class-mediawiki-ltr-sitedir-ltr-mw-hide-empty-elt-ns-0-ns-subject-mw-editable-page-deep-learning-rootpage-deep-learning-skin-vector-action-view-div-id-mw-page-base-class-noprint-div-div-id-mw-head-base-class-noprint-div-div-id-content-class-mw-body-role-main-a-id-top-a-div-id-sitenotice-class-mw-body-content-centralnotice-div-div-class-mw-indicators-mw-body-content-div-h1-id-firstheading-class-firstheading-lang-en-deep-learning-h1-div-id-bodycontent-class-mw-body-content-div-id-sitesub-class-noprint-from-wikipedia-the-free-encyclopedia-div-div-id-contentsub-div-div-id-jump-to-nav-div-a-class-mw-jump-link-href-mw-head-jump-to-navigation-a-a-class-mw-jump-link-href-p-search-jump-to-search-a-div-id-mw-content-text-lang-en-dir-ltr-class-mw-content-ltr-div-class-mw-parser-output-div-role-note-class-hatnote-navigation-not-searchable-for-deep-versus-shallow-learning-in-educational-psychology-see-a-href-wiki-student-approaches-to-learning-title-student-approaches-to-learning-student-approaches-to-learning-a-for-more-information-see-a-href-wiki-artificial-neural-network-title-artificial-neural-network-artificial-neural-network-a-div-table-class-vertical-navbox-nowraplinks-style-float-right-clear-right-width-22-0em-margin-0-0-1-0em-1-0em-background-f9f9f9-border-1px-solid-aaa-padding-0-2em-border-spacing-0-4em-0-text-align-center-line-height-1-4em-font-size-88-tbody-tr-th-style-padding-0-2em-0-4em-0-2em-font-size-145-line-height-1-2em-a-href-wiki-machine-learning-title-machine-learning-machine-learning-a-and-br-a-href-wiki-data-mining-title-data-mining-data-mining-a-th-tr-tr-td-style-padding-0-2em-0-0-4em-padding-0-25em-0-25em-0-75em-a-href-wiki-file-kernel-machine-svg-class-image-img-alt-kernel-machine-svg-src-upload-wikimedia-org-wikipedia-commons-thumb-f-fe-kernel-machine-svg-220px-kernel-machine-svg-png-decoding-async-width-220-height-100-srcset-upload-wikimedia-org-wikipedia-commons-thumb-f-fe-kernel-machine-svg-330px-kernel-machine-svg-png-1-5x-upload-wikimedia-org-wikipedia-commons-thumb-f-fe-kernel-machine-svg-440px-kernel-machine-svg-png-2x-data-file-width-512-data-file-height-233-a-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-problems-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-statistical-classification-title-statistical-classification-classification-a-li-li-a-href-wiki-cluster-analysis-title-cluster-analysis-clustering-a-li-li-a-href-wiki-regression-analysis-title-regression-analysis-regression-a-li-li-a-href-wiki-anomaly-detection-title-anomaly-detection-anomaly-detection-a-li-li-a-href-wiki-automated-machine-learning-title-automated-machine-learning-automl-a-li-li-a-href-wiki-association-rule-learning-title-association-rule-learning-association-rules-a-li-li-a-href-wiki-reinforcement-learning-title-reinforcement-learning-reinforcement-learning-a-li-li-a-href-wiki-structured-prediction-title-structured-prediction-structured-prediction-a-li-li-a-href-wiki-feature-engineering-title-feature-engineering-feature-engineering-a-li-li-a-href-wiki-feature-learning-title-feature-learning-feature-learning-a-li-li-a-href-wiki-online-machine-learning-title-online-machine-learning-online-learning-a-li-li-a-href-wiki-semi-supervised-learning-title-semi-supervised-learning-semi-supervised-learning-a-li-li-a-href-wiki-unsupervised-learning-title-unsupervised-learning-unsupervised-learning-a-li-li-a-href-wiki-learning-to-rank-title-learning-to-rank-learning-to-rank-a-li-li-a-href-wiki-grammar-induction-title-grammar-induction-grammar-induction-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-div-style-padding-0-1em-0-line-height-1-2em-a-href-wiki-supervised-learning-title-supervised-learning-supervised-learning-a-br-style-data-mw-deduplicate-templatestyles-r886047488-mw-parser-output-nobold-font-weight-normal-style-span-class-nobold-span-style-font-size-85-b-a-href-wiki-statistical-classification-title-statistical-classification-classification-a-b-b-a-href-wiki-regression-analysis-title-regression-analysis-regression-a-b-span-span-div-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-decision-tree-learning-title-decision-tree-learning-decision-trees-a-li-li-a-href-wiki-ensemble-learning-title-ensemble-learning-ensembles-a-ul-li-a-href-wiki-bootstrap-aggregating-title-bootstrap-aggregating-bagging-a-li-li-a-href-wiki-boosting-machine-learning-title-boosting-machine-learning-boosting-a-li-li-a-href-wiki-random-forest-title-random-forest-random-forest-a-li-ul-li-li-a-href-wiki-k-nearest-neighbors-algorithm-title-k-nearest-neighbors-algorithm-i-k-i-nn-a-li-li-a-href-wiki-linear-regression-title-linear-regression-linear-regression-a-li-li-a-href-wiki-naive-bayes-classifier-title-naive-bayes-classifier-naive-bayes-a-li-li-a-href-wiki-artificial-neural-network-title-artificial-neural-network-artificial-neural-networks-a-li-li-a-href-wiki-logistic-regression-title-logistic-regression-logistic-regression-a-li-li-a-href-wiki-perceptron-title-perceptron-perceptron-a-li-li-a-href-wiki-relevance-vector-machine-title-relevance-vector-machine-relevance-vector-machine-rvm-a-li-li-a-href-wiki-support-vector-machine-title-support-vector-machine-support-vector-machine-svm-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-a-href-wiki-cluster-analysis-title-cluster-analysis-clustering-a-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-birch-title-birch-birch-a-li-li-a-href-wiki-cure-data-clustering-algorithm-class-mw-redirect-title-cure-data-clustering-algorithm-cure-a-li-li-a-href-wiki-hierarchical-clustering-title-hierarchical-clustering-hierarchical-a-li-li-a-href-wiki-k-means-clustering-title-k-means-clustering-i-k-i-means-a-li-li-a-href-wiki-expectation-e2-80-93maximization-algorithm-title-expectation-maximization-algorithm-expectation-maximization-em-a-li-li-br-a-href-wiki-dbscan-title-dbscan-dbscan-a-li-li-a-href-wiki-optics-algorithm-title-optics-algorithm-optics-a-li-li-a-href-wiki-mean-shift-class-mw-redirect-title-mean-shift-mean-shift-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-a-href-wiki-dimensionality-reduction-title-dimensionality-reduction-dimensionality-reduction-a-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-factor-analysis-title-factor-analysis-factor-analysis-a-li-li-a-href-wiki-canonical-correlation-analysis-class-mw-redirect-title-canonical-correlation-analysis-cca-a-li-li-a-href-wiki-independent-component-analysis-title-independent-component-analysis-ica-a-li-li-a-href-wiki-linear-discriminant-analysis-title-linear-discriminant-analysis-lda-a-li-li-a-href-wiki-non-negative-matrix-factorization-title-non-negative-matrix-factorization-nmf-a-li-li-a-href-wiki-principal-component-analysis-title-principal-component-analysis-pca-a-li-li-a-href-wiki-t-distributed-stochastic-neighbor-embedding-title-t-distributed-stochastic-neighbor-embedding-t-sne-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-a-href-wiki-structured-prediction-title-structured-prediction-structured-prediction-a-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-graphical-model-title-graphical-model-graphical-models-a-ul-li-a-href-wiki-bayesian-network-title-bayesian-network-bayes-net-a-li-li-a-href-wiki-conditional-random-field-title-conditional-random-field-conditional-random-field-a-li-li-a-href-wiki-hidden-markov-model-title-hidden-markov-model-hidden-markov-a-li-ul-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-a-href-wiki-anomaly-detection-title-anomaly-detection-anomaly-detection-a-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-k-nearest-neighbors-classification-class-mw-redirect-title-k-nearest-neighbors-classification-i-k-i-nn-a-li-li-a-href-wiki-local-outlier-factor-title-local-outlier-factor-local-outlier-factor-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-a-href-wiki-artificial-neural-networks-class-mw-redirect-title-artificial-neural-networks-artificial-neural-networks-a-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-autoencoder-title-autoencoder-autoencoder-a-li-li-a-class-mw-selflink-selflink-deep-learning-a-li-li-a-href-wiki-deepdream-title-deepdream-deepdream-a-li-li-a-href-wiki-multilayer-perceptron-title-multilayer-perceptron-multilayer-perceptron-a-li-li-a-href-wiki-recurrent-neural-network-title-recurrent-neural-network-rnn-a-ul-li-a-href-wiki-long-short-term-memory-title-long-short-term-memory-lstm-a-li-li-a-href-wiki-gated-recurrent-unit-title-gated-recurrent-unit-gru-a-li-ul-li-li-a-href-wiki-restricted-boltzmann-machine-title-restricted-boltzmann-machine-restricted-boltzmann-machine-a-li-li-a-href-wiki-generative-adversarial-network-title-generative-adversarial-network-gan-a-li-li-a-href-wiki-self-organizing-map-title-self-organizing-map-som-a-li-li-a-href-wiki-convolutional-neural-network-title-convolutional-neural-network-convolutional-neural-network-a-ul-li-a-href-wiki-u-net-title-u-net-u-net-a-li-ul-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-a-href-wiki-reinforcement-learning-title-reinforcement-learning-reinforcement-learning-a-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-q-learning-title-q-learning-q-learning-a-li-li-a-href-wiki-state-e2-80-93action-e2-80-93reward-e2-80-93state-e2-80-93action-title-state-action-reward-state-action-sarsa-a-li-li-a-href-wiki-temporal-difference-learning-title-temporal-difference-learning-temporal-difference-td-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-theory-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-bias-e2-80-93variance-dilemma-class-mw-redirect-title-bias-variance-dilemma-bias-variance-dilemma-a-li-li-a-href-wiki-computational-learning-theory-title-computational-learning-theory-computational-learning-theory-a-li-li-a-href-wiki-empirical-risk-minimization-title-empirical-risk-minimization-empirical-risk-minimization-a-li-li-a-href-wiki-occam-learning-title-occam-learning-occam-learning-a-li-li-a-href-wiki-probably-approximately-correct-learning-title-probably-approximately-correct-learning-pac-learning-a-li-li-a-href-wiki-statistical-learning-theory-title-statistical-learning-theory-statistical-learning-a-li-li-a-href-wiki-vapnik-e2-80-93chervonenkis-theory-title-vapnik-chervonenkis-theory-vc-theory-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-machine-learning-venues-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-conference-on-neural-information-processing-systems-title-conference-on-neural-information-processing-systems-nips-a-li-li-a-href-wiki-international-conference-on-machine-learning-title-international-conference-on-machine-learning-icml-a-li-li-a-href-wiki-machine-learning-journal-title-machine-learning-journal-ml-a-li-li-a-href-wiki-journal-of-machine-learning-research-title-journal-of-machine-learning-research-jmlr-a-li-li-a-rel-nofollow-class-external-text-href-https-arxiv-org-list-cs-lg-recent-arxiv-cs-lg-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-a-href-wiki-glossary-of-artificial-intelligence-title-glossary-of-artificial-intelligence-glossary-of-artificial-intelligence-a-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-glossary-of-artificial-intelligence-title-glossary-of-artificial-intelligence-glossary-of-artificial-intelligence-a-li-ul-div-div-div-td-tr-tr-td-style-padding-0-0-1em-0-4em-div-class-navframe-collapsed-style-border-none-padding-0-div-class-navhead-style-font-size-105-background-transparent-text-align-left-related-articles-div-div-class-navcontent-style-font-size-105-padding-0-2em-0-0-4em-text-align-center-div-class-hlist-ul-li-a-href-wiki-list-of-datasets-for-machine-learning-research-title-list-of-datasets-for-machine-learning-research-list-of-datasets-for-machine-learning-research-a-li-li-a-href-wiki-outline-of-machine-learning-title-outline-of-machine-learning-outline-of-machine-learning-a-li-ul-div-div-div-td-tr-tr-td-class-plainlist-style-padding-0-3em-0-4em-0-3em-font-weight-bold-border-top-1px-solid-aaa-border-bottom-1px-solid-aaa-border-top-1px-solid-aaa-border-bottom-1px-solid-aaa-ul-li-a-href-wiki-file-portal-puzzle-svg-class-image-img-alt-portal-puzzle-svg-src-upload-wikimedia-org-wikipedia-en-thumb-f-fd-portal-puzzle-svg-16px-portal-puzzle-svg-png-decoding-async-width-16-height-14-class-noviewer-srcset-upload-wikimedia-org-wikipedia-en-thumb-f-fd-portal-puzzle-svg-24px-portal-puzzle-svg-png-1-5x-upload-wikimedia-org-wikipedia-en-thumb-f-fd-portal-puzzle-svg-32px-portal-puzzle-svg-png-2x-data-file-width-32-data-file-height-28-a-a-href-wiki-portal-machine-learning-title-portal-machine-learning-machine-learning-portal-a-li-ul-td-tr-tr-td-style-text-align-right-font-size-115-padding-top-0-6em-div-class-plainlinks-hlist-navbar-mini-ul-li-class-nv-view-a-href-wiki-template-machine-learning-bar-title-template-machine-learning-bar-abbr-title-view-this-template-v-abbr-a-li-li-class-nv-talk-a-href-wiki-template-talk-machine-learning-bar-title-template-talk-machine-learning-bar-abbr-title-discuss-this-template-t-abbr-a-li-li-class-nv-edit-a-class-external-text-href-en-wikipedia-org-w-index-php-title-template-machine-learning-bar-action-edit-abbr-title-edit-this-template-e-abbr-a-li-ul-div-td-tr-tbody-table-p-b-deep-learning-b-also-known-as-b-deep-structured-learning-b-or-b-hierarchical-learning-b-is-part-of-a-broader-family-of-a-href-wiki-machine-learning-title-machine-learning-machine-learning-a-methods-based-on-artificial-neural-networks-learning-can-be-a-href-wiki-supervised-learning-title-supervised-learning-supervised-a-a-href-wiki-semi-supervised-learning-title-semi-supervised-learning-semi-supervised-a-or-a-href-wiki-unsupervised-learning-title-unsupervised-learning-unsupervised-a-sup-id-cite-ref-bengio2012-1-0-class-reference-a-href-cite-note-bengio2012-1-1-a-sup-sup-id-cite-ref-schidhub-2-0-class-reference-a-href-cite-note-schidhub-2-2-a-sup-sup-id-cite-ref-naturebengio-3-0-class-reference-a-href-cite-note-naturebengio-3-3-a-sup-p-p-deep-learning-architectures-such-as-a-href-deep-neural-networks-deep-neural-networks-a-a-href-wiki-deep-belief-network-title-deep-belief-network-deep-belief-networks-a-a-href-wiki-recurrent-neural-networks-class-mw-redirect-title-recurrent-neural-networks-recurrent-neural-networks-a-and-a-href-wiki-convolutional-neural-networks-class-mw-redirect-title-convolutional-neural-networks-convolutional-neural-networks-a-have-been-applied-to-fields-including-a-href-wiki-computer-vision-title-computer-vision-computer-vision-a-a-href-wiki-automatic-speech-recognition-class-mw-redirect-title-automatic-speech-recognition-speech-recognition-a-a-href-wiki-natural-language-processing-title-natural-language-processing-natural-language-processing-a-audio-recognition-social-network-filtering-a-href-wiki-machine-translation-title-machine-translation-machine-translation-a-a-href-wiki-bioinformatics-title-bioinformatics-bioinformatics-a-a-href-wiki-drug-design-title-drug-design-drug-design-a-medical-image-analysis-material-inspection-and-a-href-wiki-board-game-title-board-game-board-game-a-programs-where-they-have-produced-results-comparable-to-and-in-some-cases-superior-to-human-experts-sup-id-cite-ref-9-4-0-class-reference-a-href-cite-note-9-4-4-a-sup-sup-id-cite-ref-krizhevsky2012-5-0-class-reference-a-href-cite-note-krizhevsky2012-5-5-a-sup-sup-id-cite-ref-6-class-reference-a-href-cite-note-6-6-a-sup-p-p-artificial-neural-networks-anns-were-inspired-by-information-processing-and-distributed-communication-nodes-in-biological-systems-anns-have-various-differences-from-biological-a-href-wiki-brain-title-brain-brains-a-specifically-neural-networks-tend-to-be-static-and-symbolic-while-the-biological-brain-of-most-living-organisms-is-dynamic-plastic-and-analog-sup-id-cite-ref-7-class-reference-a-href-cite-note-7-7-a-sup-sup-id-cite-ref-8-class-reference-a-href-cite-note-8-8-a-sup-sup-id-cite-ref-9-class-reference-a-href-cite-note-9-9-a-sup-p-style-data-mw-deduplicate-templatestyles-r886046785-mw-parser-output-toclimit-2-toclevel-1-ul-mw-parser-output-toclimit-3-toclevel-2-ul-mw-parser-output-toclimit-4-toclevel-3-ul-mw-parser-output-toclimit-5-toclevel-4-ul-mw-parser-output-toclimit-6-toclevel-5-ul-mw-parser-output-toclimit-7-toclevel-6-ul-display-none-style-div-class-toclimit-3-div-id-toc-class-toc-input-type-checkbox-role-button-id-toctogglecheckbox-class-toctogglecheckbox-style-display-none-div-class-toctitle-lang-en-dir-ltr-h2-contents-h2-span-class-toctogglespan-label-class-toctogglelabel-for-toctogglecheckbox-label-span-div-ul-li-class-toclevel-1-tocsection-1-a-href-definition-span-class-tocnumber-1-span-span-class-toctext-definition-span-a-li-li-class-toclevel-1-tocsection-2-a-href-overview-span-class-tocnumber-2-span-span-class-toctext-overview-span-a-li-li-class-toclevel-1-tocsection-3-a-href-interpretations-span-class-tocnumber-3-span-span-class-toctext-interpretations-span-a-li-li-class-toclevel-1-tocsection-4-a-href-history-span-class-tocnumber-4-span-span-class-toctext-history-span-a-ul-li-class-toclevel-2-tocsection-5-a-href-deep-learning-revolution-span-class-tocnumber-4-1-span-span-class-toctext-deep-learning-revolution-span-a-li-ul-li-li-class-toclevel-1-tocsection-6-a-href-neural-networks-span-class-tocnumber-5-span-span-class-toctext-neural-networks-span-a-ul-li-class-toclevel-2-tocsection-7-a-href-artificial-neural-networks-span-class-tocnumber-5-1-span-span-class-toctext-artificial-neural-networks-span-a-li-li-class-toclevel-2-tocsection-8-a-href-deep-neural-networks-span-class-tocnumber-5-2-span-span-class-toctext-deep-neural-networks-span-a-ul-li-class-toclevel-3-tocsection-9-a-href-challenges-span-class-tocnumber-5-2-1-span-span-class-toctext-challenges-span-a-li-ul-li-ul-li-li-class-toclevel-1-tocsection-10-a-href-applications-span-class-tocnumber-6-span-span-class-toctext-applications-span-a-ul-li-class-toclevel-2-tocsection-11-a-href-automatic-speech-recognition-span-class-tocnumber-6-1-span-span-class-toctext-automatic-speech-recognition-span-a-li-li-class-toclevel-2-tocsection-12-a-href-image-recognition-span-class-tocnumber-6-2-span-span-class-toctext-image-recognition-span-a-li-li-class-toclevel-2-tocsection-13-a-href-visual-art-processing-span-class-tocnumber-6-3-span-span-class-toctext-visual-art-processing-span-a-li-li-class-toclevel-2-tocsection-14-a-href-natural-language-processing-span-class-tocnumber-6-4-span-span-class-toctext-natural-language-processing-span-a-li-li-class-toclevel-2-tocsection-15-a-href-drug-discovery-and-toxicology-span-class-tocnumber-6-5-span-span-class-toctext-drug-discovery-and-toxicology-span-a-li-li-class-toclevel-2-tocsection-16-a-href-customer-relationship-management-span-class-tocnumber-6-6-span-span-class-toctext-customer-relationship-management-span-a-li-li-class-toclevel-2-tocsection-17-a-href-recommendation-systems-span-class-tocnumber-6-7-span-span-class-toctext-recommendation-systems-span-a-li-li-class-toclevel-2-tocsection-18-a-href-bioinformatics-span-class-tocnumber-6-8-span-span-class-toctext-bioinformatics-span-a-li-li-class-toclevel-2-tocsection-19-a-href-medical-image-analysis-span-class-tocnumber-6-9-span-span-class-toctext-medical-image-analysis-span-a-li-li-class-toclevel-2-tocsection-20-a-href-mobile-advertising-span-class-tocnumber-6-10-span-span-class-toctext-mobile-advertising-span-a-li-li-class-toclevel-2-tocsection-21-a-href-image-restoration-span-class-tocnumber-6-11-span-span-class-toctext-image-restoration-span-a-li-li-class-toclevel-2-tocsection-22-a-href-financial-fraud-detection-span-class-tocnumber-6-12-span-span-class-toctext-financial-fraud-detection-span-a-li-li-class-toclevel-2-tocsection-23-a-href-military-span-class-tocnumber-6-13-span-span-class-toctext-military-span-a-li-ul-li-li-class-toclevel-1-tocsection-24-a-href-relation-to-human-cognitive-and-brain-development-span-class-tocnumber-7-span-span-class-toctext-relation-to-human-cognitive-and-brain-development-span-a-li-li-class-toclevel-1-tocsection-25-a-href-commercial-activity-span-class-tocnumber-8-span-span-class-toctext-commercial-activity-span-a-li-li-class-toclevel-1-tocsection-26-a-href-criticism-and-comment-span-class-tocnumber-9-span-span-class-toctext-criticism-and-comment-span-a-ul-li-class-toclevel-2-tocsection-27-a-href-theory-span-class-tocnumber-9-1-span-span-class-toctext-theory-span-a-li-li-class-toclevel-2-tocsection-28-a-href-errors-span-class-tocnumber-9-2-span-span-class-toctext-errors-span-a-li-li-class-toclevel-2-tocsection-29-a-href-cyber-threat-span-class-tocnumber-9-3-span-span-class-toctext-cyber-threat-span-a-li-ul-li-li-class-toclevel-1-tocsection-30-a-href-see-also-span-class-tocnumber-10-span-span-class-toctext-see-also-span-a-li-li-class-toclevel-1-tocsection-31-a-href-references-span-class-tocnumber-11-span-span-class-toctext-references-span-a-li-li-class-toclevel-1-tocsection-32-a-href-further-reading-span-class-tocnumber-12-span-span-class-toctext-further-reading-span-a-li-ul-div-div-h2-span-class-mw-headline-id-definition-definition-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-1-title-edit-section-definition-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-deep-learning-is-a-class-of-a-href-wiki-machine-learning-title-machine-learning-machine-learning-a-a-href-wiki-algorithm-title-algorithm-algorithms-a-that-sup-id-cite-ref-book2014-10-0-class-reference-a-href-cite-note-book2014-10-10-a-sup-sup-class-reference-style-white-space-nowrap-span-pp199-200-span-sup-use-multiple-layers-to-progressively-extract-higher-level-features-from-raw-input-for-example-in-image-processing-lower-layers-may-identify-edges-while-higher-layer-may-identify-human-meaningful-items-such-as-digits-letters-or-faces-p-h2-span-class-mw-headline-id-overview-overview-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-2-title-edit-section-overview-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-most-modern-deep-learning-models-are-based-on-artificial-neural-networks-specifically-a-href-wiki-convolutional-neural-network-class-mw-redirect-title-convolutional-neural-network-convolutional-neural-networks-a-cnn-s-although-they-can-also-include-a-href-wiki-propositional-formula-title-propositional-formula-propositional-formulas-a-or-latent-variables-organized-layer-wise-in-deep-a-href-wiki-generative-model-title-generative-model-generative-models-a-such-as-the-nodes-in-a-href-wiki-deep-belief-network-title-deep-belief-network-deep-belief-networks-a-and-deep-a-href-wiki-boltzmann-machine-title-boltzmann-machine-boltzmann-machines-a-sup-id-cite-ref-bengiodeep-11-0-class-reference-a-href-cite-note-bengiodeep-11-11-a-sup-p-p-in-deep-learning-each-level-learns-to-transform-its-input-data-into-a-slightly-more-abstract-and-composite-representation-in-an-image-recognition-application-the-raw-input-may-be-a-a-href-wiki-matrix-mathematics-title-matrix-mathematics-matrix-a-of-pixels-the-first-representational-layer-may-abstract-the-pixels-and-encode-edges-the-second-layer-may-compose-and-encode-arrangements-of-edges-the-third-layer-may-encode-a-nose-and-eyes-and-the-fourth-layer-may-recognize-that-the-image-contains-a-face-importantly-a-deep-learning-process-can-learn-which-features-to-optimally-place-in-which-level-i-on-its-own-i-of-course-this-does-not-completely-obviate-the-need-for-hand-tuning-for-example-varying-numbers-of-layers-and-layer-sizes-can-provide-different-degrees-of-abstraction-sup-id-cite-ref-bengio2012-1-1-class-reference-a-href-cite-note-bengio2012-1-1-a-sup-sup-id-cite-ref-12-class-reference-a-href-cite-note-12-12-a-sup-p-p-the-deep-in-deep-learning-refers-to-the-number-of-layers-through-which-the-data-is-transformed-more-precisely-deep-learning-systems-have-a-substantial-i-credit-assignment-path-i-cap-depth-the-cap-is-the-chain-of-transformations-from-input-to-output-caps-describe-potentially-causal-connections-between-input-and-output-for-a-a-href-wiki-feedforward-neural-network-title-feedforward-neural-network-feedforward-neural-network-a-the-depth-of-the-caps-is-that-of-the-network-and-is-the-number-of-hidden-layers-plus-one-as-the-output-layer-is-also-parameterized-for-a-href-wiki-recurrent-neural-network-title-recurrent-neural-network-recurrent-neural-networks-a-in-which-a-signal-may-propagate-through-a-layer-more-than-once-the-cap-depth-is-potentially-unlimited-sup-id-cite-ref-schidhub-2-1-class-reference-a-href-cite-note-schidhub-2-2-a-sup-no-universally-agreed-upon-threshold-of-depth-divides-shallow-learning-from-deep-learning-but-most-researchers-agree-that-deep-learning-involves-cap-depth-2-cap-of-depth-2-has-been-shown-to-be-a-universal-approximator-in-the-sense-that-it-can-emulate-any-function-sup-class-noprint-inline-template-template-fact-style-white-space-nowrap-i-a-href-wiki-wikipedia-citation-needed-title-wikipedia-citation-needed-span-title-this-claim-needs-references-to-reliable-sources-april-2018-citation-needed-span-a-i-sup-beyond-that-more-layers-do-not-add-to-the-function-approximator-ability-of-the-network-deep-models-cap-2-are-able-to-extract-better-features-than-shallow-models-and-hence-extra-layers-help-in-learning-features-p-p-deep-learning-architectures-are-often-constructed-with-a-a-href-wiki-greedy-algorithm-title-greedy-algorithm-greedy-a-layer-by-layer-method-sup-class-noprint-inline-template-style-margin-left-0-1em-white-space-nowrap-i-a-href-wiki-wikipedia-please-clarify-title-wikipedia-please-clarify-span-title-the-text-near-this-tag-may-need-clarification-or-removal-of-jargon-september-2017-clarification-needed-span-a-i-sup-sup-class-noprint-inline-template-style-white-space-nowrap-i-a-href-wiki-wikipedia-please-clarify-title-wikipedia-please-clarify-span-title-the-text-near-this-tag-needs-further-explanation-september-2017-further-explanation-needed-span-a-i-sup-sup-class-noprint-inline-template-template-fact-style-white-space-nowrap-i-a-href-wiki-wikipedia-citation-needed-title-wikipedia-citation-needed-span-title-this-claim-needs-references-to-reliable-sources-september-2017-citation-needed-span-a-i-sup-deep-learning-helps-to-disentangle-these-abstractions-and-pick-out-which-features-improve-performance-sup-id-cite-ref-bengio2012-1-2-class-reference-a-href-cite-note-bengio2012-1-1-a-sup-p-p-for-a-href-wiki-supervised-learning-title-supervised-learning-supervised-learning-a-tasks-deep-learning-methods-obviate-a-href-wiki-feature-engineering-title-feature-engineering-feature-engineering-a-by-translating-the-data-into-compact-intermediate-representations-akin-to-a-href-wiki-principal-component-analysis-class-mw-redirect-title-principal-component-analysis-principal-components-a-and-derive-layered-structures-that-remove-redundancy-in-representation-p-p-deep-learning-algorithms-can-be-applied-to-unsupervised-learning-tasks-this-is-an-important-benefit-because-unlabeled-data-are-more-abundant-than-labeled-data-examples-of-deep-structures-that-can-be-trained-in-an-unsupervised-manner-are-neural-history-compressors-sup-id-cite-ref-scholarpedia-13-0-class-reference-a-href-cite-note-scholarpedia-13-13-a-sup-and-a-href-wiki-deep-belief-network-title-deep-belief-network-deep-belief-networks-a-sup-id-cite-ref-bengio2012-1-3-class-reference-a-href-cite-note-bengio2012-1-1-a-sup-sup-id-cite-ref-scholardbns-14-0-class-reference-a-href-cite-note-scholardbns-14-14-a-sup-p-h2-span-class-mw-headline-id-interpretations-interpretations-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-3-title-edit-section-interpretations-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-deep-neural-networks-are-generally-interpreted-in-terms-of-the-a-href-wiki-universal-approximation-theorem-title-universal-approximation-theorem-universal-approximation-theorem-a-sup-id-cite-ref-referenceb-15-0-class-reference-a-href-cite-note-referenceb-15-15-a-sup-sup-id-cite-ref-cyb-16-0-class-reference-a-href-cite-note-cyb-16-16-a-sup-sup-id-cite-ref-horn-17-0-class-reference-a-href-cite-note-horn-17-17-a-sup-sup-id-cite-ref-haykin-simon-1998-18-0-class-reference-a-href-cite-note-haykin-simon-1998-18-18-a-sup-sup-id-cite-ref-hassoun-m-1995-p-48-19-0-class-reference-a-href-cite-note-hassoun-m-1995-p-48-19-19-a-sup-sup-id-cite-ref-zhoulu-20-0-class-reference-a-href-cite-note-zhoulu-20-20-a-sup-or-a-href-wiki-bayesian-inference-title-bayesian-inference-probabilistic-inference-a-sup-id-cite-ref-book2014-10-1-class-reference-a-href-cite-note-book2014-10-10-a-sup-sup-id-cite-ref-bengiodeep-11-1-class-reference-a-href-cite-note-bengiodeep-11-11-a-sup-sup-id-cite-ref-bengio2012-1-4-class-reference-a-href-cite-note-bengio2012-1-1-a-sup-sup-id-cite-ref-schidhub-2-2-class-reference-a-href-cite-note-schidhub-2-2-a-sup-sup-id-cite-ref-scholardbns-14-1-class-reference-a-href-cite-note-scholardbns-14-14-a-sup-sup-id-cite-ref-murphy-21-0-class-reference-a-href-cite-note-murphy-21-21-a-sup-sup-id-cite-ref-patel-nips-2016-22-0-class-reference-a-href-cite-note-patel-nips-2016-22-22-a-sup-p-p-the-classic-universal-approximation-theorem-concerns-the-capacity-of-a-href-wiki-feedforward-neural-networks-class-mw-redirect-title-feedforward-neural-networks-feedforward-neural-networks-a-with-a-single-hidden-layer-of-finite-size-to-approximate-a-href-wiki-continuous-functions-class-mw-redirect-title-continuous-functions-continuous-functions-a-sup-id-cite-ref-referenceb-15-1-class-reference-a-href-cite-note-referenceb-15-15-a-sup-sup-id-cite-ref-cyb-16-1-class-reference-a-href-cite-note-cyb-16-16-a-sup-sup-id-cite-ref-horn-17-1-class-reference-a-href-cite-note-horn-17-17-a-sup-sup-id-cite-ref-haykin-simon-1998-18-1-class-reference-a-href-cite-note-haykin-simon-1998-18-18-a-sup-sup-id-cite-ref-hassoun-m-1995-p-48-19-1-class-reference-a-href-cite-note-hassoun-m-1995-p-48-19-19-a-sup-in-1989-the-first-proof-was-published-by-a-href-wiki-george-cybenko-title-george-cybenko-george-cybenko-a-for-a-href-wiki-sigmoid-function-title-sigmoid-function-sigmoid-a-activation-functions-sup-id-cite-ref-cyb-16-2-class-reference-a-href-cite-note-cyb-16-16-a-sup-and-was-generalised-to-feed-forward-multi-layer-architectures-in-1991-by-kurt-hornik-sup-id-cite-ref-horn-17-2-class-reference-a-href-cite-note-horn-17-17-a-sup-p-p-the-universal-approximation-theorem-for-a-href-wiki-deep-neural-network-class-mw-redirect-title-deep-neural-network-deep-neural-networks-a-concerns-the-capacity-of-networks-with-bounded-width-but-the-depth-is-allowed-to-grow-lu-et-al-sup-id-cite-ref-zhoulu-20-1-class-reference-a-href-cite-note-zhoulu-20-20-a-sup-proved-that-if-the-width-of-a-a-href-wiki-deep-neural-network-class-mw-redirect-title-deep-neural-network-deep-neural-network-a-with-a-href-wiki-relu-class-mw-redirect-title-relu-relu-a-activation-is-strictly-larger-than-the-input-dimension-then-the-network-can-approximate-any-a-href-wiki-lebesgue-integration-title-lebesgue-integration-lebesgue-integrable-function-a-if-the-width-is-smaller-or-equal-to-the-input-dimension-then-a-href-wiki-deep-neural-network-class-mw-redirect-title-deep-neural-network-deep-neural-network-a-is-not-a-universal-approximator-p-p-the-a-href-wiki-probabilistic-class-mw-redirect-title-probabilistic-probabilistic-a-interpretation-sup-id-cite-ref-murphy-21-1-class-reference-a-href-cite-note-murphy-21-21-a-sup-derives-from-the-field-of-a-href-wiki-machine-learning-title-machine-learning-machine-learning-a-it-features-inference-sup-id-cite-ref-book2014-10-2-class-reference-a-href-cite-note-book2014-10-10-a-sup-sup-id-cite-ref-bengiodeep-11-2-class-reference-a-href-cite-note-bengiodeep-11-11-a-sup-sup-id-cite-ref-bengio2012-1-5-class-reference-a-href-cite-note-bengio2012-1-1-a-sup-sup-id-cite-ref-schidhub-2-3-class-reference-a-href-cite-note-schidhub-2-2-a-sup-sup-id-cite-ref-scholardbns-14-2-class-reference-a-href-cite-note-scholardbns-14-14-a-sup-sup-id-cite-ref-murphy-21-2-class-reference-a-href-cite-note-murphy-21-21-a-sup-as-well-as-the-a-href-wiki-optimization-class-mw-redirect-title-optimization-optimization-a-concepts-of-a-href-wiki-training-title-training-training-a-and-a-href-wiki-test-assessment-title-test-assessment-testing-a-related-to-fitting-and-a-href-wiki-generalization-title-generalization-generalization-a-respectively-more-specifically-the-probabilistic-interpretation-considers-the-activation-nonlinearity-as-a-a-href-wiki-cumulative-distribution-function-title-cumulative-distribution-function-cumulative-distribution-function-a-sup-id-cite-ref-murphy-21-3-class-reference-a-href-cite-note-murphy-21-21-a-sup-the-probabilistic-interpretation-led-to-the-introduction-of-a-href-wiki-dropout-neural-networks-title-dropout-neural-networks-dropout-a-as-a-href-wiki-regularization-mathematics-title-regularization-mathematics-regularizer-a-in-neural-networks-sup-id-cite-ref-dropout-23-0-class-reference-a-href-cite-note-dropout-23-23-a-sup-the-probabilistic-interpretation-was-introduced-by-researchers-including-a-href-wiki-john-hopfield-title-john-hopfield-hopfield-a-a-href-wiki-bernard-widrow-title-bernard-widrow-widrow-a-and-a-href-wiki-kumpati-s-narendra-title-kumpati-s-narendra-narendra-a-and-popularized-in-surveys-such-as-the-one-by-a-href-wiki-christopher-bishop-title-christopher-bishop-bishop-a-sup-id-cite-ref-prml-24-0-class-reference-a-href-cite-note-prml-24-24-a-sup-p-h2-span-class-mw-headline-id-history-history-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-4-title-edit-section-history-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-the-term-i-deep-learning-i-was-introduced-to-the-machine-learning-community-by-a-href-wiki-rina-dechter-title-rina-dechter-rina-dechter-a-in-1986-sup-id-cite-ref-dechter1986-25-0-class-reference-a-href-cite-note-dechter1986-25-25-a-sup-sup-id-cite-ref-scholarpedia-13-1-class-reference-a-href-cite-note-scholarpedia-13-13-a-sup-and-to-a-href-wiki-artificial-neural-networks-class-mw-redirect-title-artificial-neural-networks-artificial-neural-networks-a-by-igor-aizenberg-and-colleagues-in-2000-in-the-context-of-boolean-threshold-neurons-sup-id-cite-ref-aizenberg2000-26-0-class-reference-a-href-cite-note-aizenberg2000-26-26-a-sup-sup-id-cite-ref-27-class-reference-a-href-cite-note-27-27-a-sup-p-p-the-first-general-working-learning-algorithm-for-supervised-deep-feedforward-multilayer-a-href-wiki-perceptron-title-perceptron-perceptrons-a-was-published-by-a-href-wiki-alexey-grigorevich-ivakhnenko-class-mw-redirect-title-alexey-grigorevich-ivakhnenko-alexey-ivakhnenko-a-and-lapa-in-1965-sup-id-cite-ref-ivak1965-28-0-class-reference-a-href-cite-note-ivak1965-28-28-a-sup-a-1971-paper-described-a-deep-network-with-8-layers-trained-by-the-a-href-wiki-group-method-of-data-handling-title-group-method-of-data-handling-group-method-of-data-handling-a-algorithm-sup-id-cite-ref-ivak1971-29-0-class-reference-a-href-cite-note-ivak1971-29-29-a-sup-p-p-other-deep-learning-working-architectures-specifically-those-built-for-a-href-wiki-computer-vision-title-computer-vision-computer-vision-a-began-with-the-a-href-wiki-neocognitron-title-neocognitron-neocognitron-a-introduced-by-a-href-wiki-kunihiko-fukushima-title-kunihiko-fukushima-kunihiko-fukushima-a-in-1980-sup-id-cite-ref-fuku1980-30-0-class-reference-a-href-cite-note-fuku1980-30-30-a-sup-in-1989-a-href-wiki-yann-lecun-title-yann-lecun-yann-lecun-a-et-al-applied-the-standard-backpropagation-algorithm-which-had-been-around-as-the-reverse-mode-of-a-href-wiki-automatic-differentiation-title-automatic-differentiation-automatic-differentiation-a-since-1970-sup-id-cite-ref-lin1970-31-0-class-reference-a-href-cite-note-lin1970-31-31-a-sup-sup-id-cite-ref-grie2012-32-0-class-reference-a-href-cite-note-grie2012-32-32-a-sup-sup-id-cite-ref-werbos1974-33-0-class-reference-a-href-cite-note-werbos1974-33-33-a-sup-sup-id-cite-ref-werbos1982-34-0-class-reference-a-href-cite-note-werbos1982-34-34-a-sup-to-a-deep-neural-network-with-the-purpose-of-recognizing-handwritten-a-href-wiki-zip-code-class-mw-redirect-title-zip-code-zip-codes-a-on-mail-while-the-algorithm-worked-training-required-3-days-sup-id-cite-ref-lecun1989-35-0-class-reference-a-href-cite-note-lecun1989-35-35-a-sup-p-p-by-1991-such-systems-were-used-for-recognizing-isolated-2-d-hand-written-digits-while-recognizing-3-d-objects-was-done-by-matching-2-d-images-with-a-handcrafted-3-d-object-model-weng-i-et-al-i-suggested-that-a-human-brain-does-not-use-a-monolithic-3-d-object-model-and-in-1992-they-published-cresceptron-sup-id-cite-ref-weng1992-36-0-class-reference-a-href-cite-note-weng1992-36-36-a-sup-sup-id-cite-ref-weng1993-37-0-class-reference-a-href-cite-note-weng1993-37-37-a-sup-sup-id-cite-ref-weng1997-38-0-class-reference-a-href-cite-note-weng1997-38-38-a-sup-a-method-for-performing-3-d-object-recognition-in-cluttered-scenes-because-it-directly-used-natural-images-cresceptron-started-the-beginning-of-general-purpose-visual-learning-for-natural-3d-worlds-cresceptron-is-a-cascade-of-layers-similar-to-neocognitron-but-while-neocognitron-required-a-human-programmer-to-hand-merge-features-cresceptron-learned-an-open-number-of-features-in-each-layer-without-supervision-where-each-feature-is-represented-by-a-a-href-wiki-convolution-title-convolution-convolution-kernel-a-cresceptron-segmented-each-learned-object-from-a-cluttered-scene-through-back-analysis-through-the-network-a-href-wiki-max-pooling-class-mw-redirect-title-max-pooling-max-pooling-a-now-often-adopted-by-deep-neural-networks-e-g-a-href-wiki-imagenet-title-imagenet-imagenet-a-tests-was-first-used-in-cresceptron-to-reduce-the-position-resolution-by-a-factor-of-2x2-to-1-through-the-cascade-for-better-generalization-p-p-in-1994-andre-de-carvalho-together-with-mike-fairhurst-and-david-bisset-published-experimental-results-of-a-multi-layer-a-href-wiki-boolean-algebra-title-boolean-algebra-boolean-a-neural-network-also-known-as-a-weightless-neural-network-composed-of-a-3-layers-self-organising-feature-extraction-neural-network-module-soft-followed-by-a-multi-layer-classification-neural-network-module-gsn-which-were-independently-trained-each-layer-in-the-feature-extraction-module-extracted-features-with-growing-complexity-regarding-the-previous-layer-sup-id-cite-ref-39-class-reference-a-href-cite-note-39-39-a-sup-p-p-in-1995-a-href-wiki-brendan-frey-title-brendan-frey-brendan-frey-a-demonstrated-that-it-was-possible-to-train-over-two-days-a-network-containing-six-fully-connected-layers-and-several-hundred-hidden-units-using-the-a-href-wiki-wake-sleep-algorithm-title-wake-sleep-algorithm-wake-sleep-algorithm-a-co-developed-with-a-href-wiki-peter-dayan-title-peter-dayan-peter-dayan-a-and-a-href-wiki-geoffrey-hinton-title-geoffrey-hinton-hinton-a-sup-id-cite-ref-40-class-reference-a-href-cite-note-40-40-a-sup-many-factors-contribute-to-the-slow-speed-including-the-a-href-wiki-vanishing-gradient-problem-title-vanishing-gradient-problem-vanishing-gradient-problem-a-analyzed-in-1991-by-a-href-wiki-sepp-hochreiter-title-sepp-hochreiter-sepp-hochreiter-a-sup-id-cite-ref-hoch1991-41-0-class-reference-a-href-cite-note-hoch1991-41-41-a-sup-sup-id-cite-ref-hoch2001-42-0-class-reference-a-href-cite-note-hoch2001-42-42-a-sup-p-p-simpler-models-that-use-task-specific-handcrafted-features-such-as-a-href-wiki-gabor-filter-title-gabor-filter-gabor-filters-a-and-a-href-wiki-support-vector-machine-class-mw-redirect-title-support-vector-machine-support-vector-machines-a-svms-were-a-popular-choice-in-the-1990s-and-2000s-because-of-a-href-wiki-artificial-neural-network-title-artificial-neural-network-artificial-neural-network-a-s-ann-computational-cost-and-a-lack-of-understanding-of-how-the-brain-wires-its-biological-networks-p-p-both-shallow-and-deep-learning-e-g-recurrent-nets-of-anns-have-been-explored-for-many-years-sup-id-cite-ref-43-class-reference-a-href-cite-note-43-43-a-sup-sup-id-cite-ref-robinson1992-44-0-class-reference-a-href-cite-note-robinson1992-44-44-a-sup-sup-id-cite-ref-45-class-reference-a-href-cite-note-45-45-a-sup-these-methods-never-outperformed-non-uniform-internal-handcrafting-gaussian-a-href-wiki-mixture-model-title-mixture-model-mixture-model-a-a-href-wiki-hidden-markov-model-title-hidden-markov-model-hidden-markov-model-a-gmm-hmm-technology-based-on-generative-models-of-speech-trained-discriminatively-sup-id-cite-ref-baker2009-46-0-class-reference-a-href-cite-note-baker2009-46-46-a-sup-key-difficulties-have-been-analyzed-including-gradient-diminishing-sup-id-cite-ref-hoch1991-41-1-class-reference-a-href-cite-note-hoch1991-41-41-a-sup-and-weak-temporal-correlation-structure-in-neural-predictive-models-sup-id-cite-ref-bengio1991-47-0-class-reference-a-href-cite-note-bengio1991-47-47-a-sup-sup-id-cite-ref-deng1994-48-0-class-reference-a-href-cite-note-deng1994-48-48-a-sup-additional-difficulties-were-the-lack-of-training-data-and-limited-computing-power-p-p-most-a-href-wiki-speech-recognition-title-speech-recognition-speech-recognition-a-researchers-moved-away-from-neural-nets-to-pursue-generative-modeling-an-exception-was-at-a-href-wiki-sri-international-title-sri-international-sri-international-a-in-the-late-1990s-funded-by-the-us-government-s-a-href-wiki-national-security-agency-title-national-security-agency-nsa-a-and-a-href-wiki-darpa-title-darpa-darpa-a-sri-studied-deep-neural-networks-in-speech-and-speaker-recognition-heck-s-speaker-recognition-team-achieved-the-first-significant-success-with-deep-neural-networks-in-speech-processing-in-the-1998-a-href-wiki-national-institute-of-standards-and-technology-title-national-institute-of-standards-and-technology-national-institute-of-standards-and-technology-a-speaker-recognition-evaluation-sup-id-cite-ref-heck2000-49-0-class-reference-a-href-cite-note-heck2000-49-49-a-sup-while-sri-experienced-success-with-deep-neural-networks-in-speaker-recognition-they-were-unsuccessful-in-demonstrating-similar-success-in-speech-recognition-the-principle-of-elevating-raw-features-over-hand-crafted-optimization-was-first-explored-successfully-in-the-architecture-of-deep-autoencoder-on-the-raw-spectrogram-or-linear-filter-bank-features-in-the-late-1990s-sup-id-cite-ref-heck2000-49-1-class-reference-a-href-cite-note-heck2000-49-49-a-sup-showing-its-superiority-over-the-mel-cepstral-features-that-contain-stages-of-fixed-transformation-from-spectrograms-the-raw-features-of-speech-a-href-wiki-waveform-title-waveform-waveforms-a-later-produced-excellent-larger-scale-results-sup-id-cite-ref-50-class-reference-a-href-cite-note-50-50-a-sup-p-p-many-aspects-of-speech-recognition-were-taken-over-by-a-deep-learning-method-called-a-href-wiki-long-short-term-memory-title-long-short-term-memory-long-short-term-memory-a-lstm-a-recurrent-neural-network-published-by-hochreiter-and-a-href-wiki-j-c3-bcrgen-schmidhuber-title-jurgen-schmidhuber-schmidhuber-a-in-1997-sup-id-cite-ref-0-51-0-class-reference-a-href-cite-note-0-51-51-a-sup-lstm-rnns-avoid-the-vanishing-gradient-problem-and-can-learn-very-deep-learning-tasks-sup-id-cite-ref-schidhub-2-4-class-reference-a-href-cite-note-schidhub-2-2-a-sup-that-require-memories-of-events-that-happened-thousands-of-discrete-time-steps-before-which-is-important-for-speech-in-2003-lstm-started-to-become-competitive-with-traditional-speech-recognizers-on-certain-tasks-sup-id-cite-ref-graves2003-52-0-class-reference-a-href-cite-note-graves2003-52-52-a-sup-later-it-was-combined-with-connectionist-temporal-classification-ctc-sup-id-cite-ref-1-53-0-class-reference-a-href-cite-note-1-53-53-a-sup-in-stacks-of-lstm-rnns-sup-id-cite-ref-fernandez2007keyword-54-0-class-reference-a-href-cite-note-fernandez2007keyword-54-54-a-sup-in-2015-google-s-speech-recognition-reportedly-experienced-a-dramatic-performance-jump-of-49-through-ctc-trained-lstm-which-they-made-available-through-a-href-wiki-google-voice-search-title-google-voice-search-google-voice-search-a-sup-id-cite-ref-sak2015-55-0-class-reference-a-href-cite-note-sak2015-55-55-a-sup-p-p-in-2006-publications-by-a-href-wiki-geoffrey-hinton-title-geoffrey-hinton-geoff-hinton-a-a-href-wiki-russ-salakhutdinov-title-russ-salakhutdinov-ruslan-salakhutdinov-a-osindero-and-a-href-wiki-yee-whye-teh-title-yee-whye-teh-teh-a-sup-id-cite-ref-56-class-reference-a-href-cite-note-56-56-a-sup-sup-id-cite-ref-hinton06-57-0-class-reference-a-href-cite-note-hinton06-57-57-a-sup-sup-id-cite-ref-bengio2012-58-0-class-reference-a-href-cite-note-bengio2012-58-58-a-sup-showed-how-a-many-layered-a-href-wiki-feedforward-neural-network-title-feedforward-neural-network-feedforward-neural-network-a-could-be-effectively-pre-trained-one-layer-at-a-time-treating-each-layer-in-turn-as-an-unsupervised-a-href-wiki-restricted-boltzmann-machine-title-restricted-boltzmann-machine-restricted-boltzmann-machine-a-then-fine-tuning-it-using-supervised-a-href-wiki-backpropagation-title-backpropagation-backpropagation-a-sup-id-cite-ref-hinton2007-59-0-class-reference-a-href-cite-note-hinton2007-59-59-a-sup-the-papers-referred-to-i-learning-i-for-i-deep-belief-nets-i-p-p-deep-learning-is-part-of-state-of-the-art-systems-in-various-disciplines-particularly-computer-vision-and-a-href-wiki-automatic-speech-recognition-class-mw-redirect-title-automatic-speech-recognition-automatic-speech-recognition-a-asr-results-on-commonly-used-evaluation-sets-such-as-a-href-wiki-timit-title-timit-timit-a-asr-and-a-href-wiki-mnist-database-title-mnist-database-mnist-a-a-href-wiki-image-classification-class-mw-redirect-title-image-classification-image-classification-a-as-well-as-a-range-of-large-vocabulary-speech-recognition-tasks-have-steadily-improved-sup-id-cite-ref-hintondengyu2012-60-0-class-reference-a-href-cite-note-hintondengyu2012-60-60-a-sup-sup-id-cite-ref-61-class-reference-a-href-cite-note-61-61-a-sup-sup-id-cite-ref-62-class-reference-a-href-cite-note-62-62-a-sup-a-href-wiki-convolutional-neural-network-title-convolutional-neural-network-convolutional-neural-networks-a-cnns-were-superseded-for-asr-by-ctc-sup-id-cite-ref-1-53-1-class-reference-a-href-cite-note-1-53-53-a-sup-for-lstm-sup-id-cite-ref-0-51-1-class-reference-a-href-cite-note-0-51-51-a-sup-sup-id-cite-ref-sak2015-55-1-class-reference-a-href-cite-note-sak2015-55-55-a-sup-sup-id-cite-ref-sak2014-63-0-class-reference-a-href-cite-note-sak2014-63-63-a-sup-sup-id-cite-ref-liwu2015-64-0-class-reference-a-href-cite-note-liwu2015-64-64-a-sup-sup-id-cite-ref-zen2015-65-0-class-reference-a-href-cite-note-zen2015-65-65-a-sup-sup-id-cite-ref-cnnspeech2013-66-0-class-reference-a-href-cite-note-cnnspeech2013-66-66-a-sup-sup-id-cite-ref-2-67-0-class-reference-a-href-cite-note-2-67-67-a-sup-but-are-more-successful-in-computer-vision-p-p-the-impact-of-deep-learning-in-industry-began-in-the-early-2000s-when-cnns-already-processed-an-estimated-10-to-20-of-all-the-checks-written-in-the-us-according-to-yann-lecun-sup-id-cite-ref-lecun2016slides-68-0-class-reference-a-href-cite-note-lecun2016slides-68-68-a-sup-industrial-applications-of-deep-learning-to-large-scale-speech-recognition-started-around-2010-p-p-the-2009-nips-workshop-on-deep-learning-for-speech-recognition-sup-id-cite-ref-nips2009-69-0-class-reference-a-href-cite-note-nips2009-69-69-a-sup-was-motivated-by-the-limitations-of-deep-generative-models-of-speech-and-the-possibility-that-given-more-capable-hardware-and-large-scale-data-sets-that-deep-neural-nets-dnn-might-become-practical-it-was-believed-that-pre-training-dnns-using-generative-models-of-deep-belief-nets-dbn-would-overcome-the-main-difficulties-of-neural-nets-sup-id-cite-ref-hintonkeynoteicassp2013-70-0-class-reference-a-href-cite-note-hintonkeynoteicassp2013-70-70-a-sup-however-it-was-discovered-that-replacing-pre-training-with-large-amounts-of-training-data-for-straightforward-backpropagation-when-using-dnns-with-large-context-dependent-output-layers-produced-error-rates-dramatically-lower-than-then-state-of-the-art-gaussian-mixture-model-gmm-hidden-markov-model-hmm-and-also-than-more-advanced-generative-model-based-systems-sup-id-cite-ref-hintondengyu2012-60-1-class-reference-a-href-cite-note-hintondengyu2012-60-60-a-sup-sup-id-cite-ref-patent2011-71-0-class-reference-a-href-cite-note-patent2011-71-71-a-sup-the-nature-of-the-recognition-errors-produced-by-the-two-types-of-systems-was-characteristically-different-sup-id-cite-ref-referenceicassp2013-72-0-class-reference-a-href-cite-note-referenceicassp2013-72-72-a-sup-sup-id-cite-ref-nips2009-69-1-class-reference-a-href-cite-note-nips2009-69-69-a-sup-offering-technical-insights-into-how-to-integrate-deep-learning-into-the-existing-highly-efficient-run-time-speech-decoding-system-deployed-by-all-major-speech-recognition-systems-sup-id-cite-ref-book2014-10-3-class-reference-a-href-cite-note-book2014-10-10-a-sup-sup-id-cite-ref-referencea-73-0-class-reference-a-href-cite-note-referencea-73-73-a-sup-sup-id-cite-ref-74-class-reference-a-href-cite-note-74-74-a-sup-analysis-around-2009-2010-contrasted-the-gmm-and-other-generative-speech-models-vs-dnn-models-stimulated-early-industrial-investment-in-deep-learning-for-speech-recognition-sup-id-cite-ref-referenceicassp2013-72-1-class-reference-a-href-cite-note-referenceicassp2013-72-72-a-sup-sup-id-cite-ref-nips2009-69-2-class-reference-a-href-cite-note-nips2009-69-69-a-sup-eventually-leading-to-pervasive-and-dominant-use-in-that-industry-that-analysis-was-done-with-comparable-performance-less-than-1-5-in-error-rate-between-discriminative-dnns-and-generative-models-sup-id-cite-ref-hintondengyu2012-60-2-class-reference-a-href-cite-note-hintondengyu2012-60-60-a-sup-sup-id-cite-ref-referenceicassp2013-72-2-class-reference-a-href-cite-note-referenceicassp2013-72-72-a-sup-sup-id-cite-ref-hintonkeynoteicassp2013-70-1-class-reference-a-href-cite-note-hintonkeynoteicassp2013-70-70-a-sup-sup-id-cite-ref-interspeech2014keynote-75-0-class-reference-a-href-cite-note-interspeech2014keynote-75-75-a-sup-p-p-in-2010-researchers-extended-deep-learning-from-timit-to-large-vocabulary-speech-recognition-by-adopting-large-output-layers-of-the-dnn-based-on-context-dependent-hmm-states-constructed-by-a-href-wiki-decision-tree-title-decision-tree-decision-trees-a-sup-id-cite-ref-roles2010-76-0-class-reference-a-href-cite-note-roles2010-76-76-a-sup-sup-id-cite-ref-77-class-reference-a-href-cite-note-77-77-a-sup-sup-id-cite-ref-78-class-reference-a-href-cite-note-78-78-a-sup-sup-id-cite-ref-referencea-73-1-class-reference-a-href-cite-note-referencea-73-73-a-sup-p-p-advances-in-hardware-enabled-the-renewed-interest-in-2009-a-href-wiki-nvidia-title-nvidia-nvidia-a-was-involved-in-what-was-called-the-big-bang-of-deep-learning-as-deep-learning-neural-networks-were-trained-with-nvidia-a-href-wiki-graphics-processing-unit-title-graphics-processing-unit-graphics-processing-units-a-gpus-sup-id-cite-ref-79-class-reference-a-href-cite-note-79-79-a-sup-that-year-a-href-wiki-google-brain-title-google-brain-google-brain-a-used-nvidia-gpus-to-create-capable-dnns-while-there-a-href-wiki-andrew-ng-title-andrew-ng-andrew-ng-a-determined-that-gpus-could-increase-the-speed-of-deep-learning-systems-by-about-100-times-sup-id-cite-ref-80-class-reference-a-href-cite-note-80-80-a-sup-in-particular-gpus-are-well-suited-for-the-matrix-vector-math-involved-in-machine-learning-sup-id-cite-ref-jung2004-81-0-class-reference-a-href-cite-note-jung2004-81-81-a-sup-sup-id-cite-ref-chellapilla2006-82-0-class-reference-a-href-cite-note-chellapilla2006-82-82-a-sup-gpus-speed-up-training-algorithms-by-orders-of-magnitude-reducing-running-times-from-weeks-to-days-sup-id-cite-ref-3-83-0-class-reference-a-href-cite-note-3-83-83-a-sup-sup-id-cite-ref-84-class-reference-a-href-cite-note-84-84-a-sup-specialized-hardware-and-algorithm-optimizations-can-be-used-for-efficient-processing-sup-id-cite-ref-sze2017-85-0-class-reference-a-href-cite-note-sze2017-85-85-a-sup-p-h3-span-class-mw-headline-id-deep-learning-revolution-deep-learning-revolution-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-5-title-edit-section-deep-learning-revolution-edit-a-span-class-mw-editsection-bracket-span-span-h3-div-class-thumb-tright-div-class-thumbinner-style-width-222px-a-href-wiki-file-ai-ml-dl-png-class-image-img-alt-src-upload-wikimedia-org-wikipedia-commons-thumb-1-18-ai-ml-dl-png-220px-ai-ml-dl-png-decoding-async-width-220-height-249-class-thumbimage-srcset-upload-wikimedia-org-wikipedia-commons-thumb-1-18-ai-ml-dl-png-330px-ai-ml-dl-png-1-5x-upload-wikimedia-org-wikipedia-commons-thumb-1-18-ai-ml-dl-png-440px-ai-ml-dl-png-2x-data-file-width-859-data-file-height-972-a-div-class-thumbcaption-div-class-magnify-a-href-wiki-file-ai-ml-dl-png-class-internal-title-enlarge-a-div-how-deep-learning-is-a-subset-of-machine-learning-and-how-machine-learning-is-a-subset-of-artificial-intelligence-ai-div-div-div-p-in-2012-a-team-led-by-dahl-won-the-merck-molecular-activity-challenge-using-multi-task-deep-neural-networks-to-predict-the-a-href-wiki-biomolecular-target-class-mw-redirect-title-biomolecular-target-biomolecular-target-a-of-one-drug-sup-id-cite-ref-merck2012-86-0-class-reference-a-href-cite-note-merck2012-86-86-a-sup-sup-id-cite-ref-5-87-0-class-reference-a-href-cite-note-5-87-87-a-sup-in-2014-hochreiter-s-group-used-deep-learning-to-detect-off-target-and-toxic-effects-of-environmental-chemicals-in-nutrients-household-products-and-drugs-and-won-the-tox21-data-challenge-of-a-href-wiki-nih-class-mw-redirect-title-nih-nih-a-a-href-wiki-fda-class-mw-redirect-title-fda-fda-a-and-a-href-wiki-national-center-for-advancing-translational-sciences-title-national-center-for-advancing-translational-sciences-ncats-a-sup-id-cite-ref-tox21-88-0-class-reference-a-href-cite-note-tox21-88-88-a-sup-sup-id-cite-ref-tox21data-89-0-class-reference-a-href-cite-note-tox21data-89-89-a-sup-sup-id-cite-ref-11-90-0-class-reference-a-href-cite-note-11-90-90-a-sup-p-p-significant-additional-impacts-in-image-or-object-recognition-were-felt-from-2011-to-2012-although-cnns-trained-by-backpropagation-had-been-around-for-decades-and-gpu-implementations-of-nns-for-years-including-cnns-fast-implementations-of-cnns-with-max-pooling-on-gpus-in-the-style-of-ciresan-and-colleagues-were-needed-to-progress-on-computer-vision-sup-id-cite-ref-jung2004-81-1-class-reference-a-href-cite-note-jung2004-81-81-a-sup-sup-id-cite-ref-chellapilla2006-82-1-class-reference-a-href-cite-note-chellapilla2006-82-82-a-sup-sup-id-cite-ref-lecun1989-35-1-class-reference-a-href-cite-note-lecun1989-35-35-a-sup-sup-id-cite-ref-6-91-0-class-reference-a-href-cite-note-6-91-91-a-sup-sup-id-cite-ref-schidhub-2-5-class-reference-a-href-cite-note-schidhub-2-2-a-sup-in-2011-this-approach-achieved-for-the-first-time-superhuman-performance-in-a-visual-pattern-recognition-contest-also-in-2011-it-won-the-icdar-chinese-handwriting-contest-and-in-may-2012-it-won-the-isbi-image-segmentation-contest-sup-id-cite-ref-8-92-0-class-reference-a-href-cite-note-8-92-92-a-sup-until-2011-cnns-did-not-play-a-major-role-at-computer-vision-conferences-but-in-june-2012-a-paper-by-ciresan-et-al-at-the-leading-conference-cvpr-sup-id-cite-ref-9-4-1-class-reference-a-href-cite-note-9-4-4-a-sup-showed-how-max-pooling-cnns-on-gpu-can-dramatically-improve-many-vision-benchmark-records-in-october-2012-a-similar-system-by-krizhevsky-et-al-sup-id-cite-ref-krizhevsky2012-5-1-class-reference-a-href-cite-note-krizhevsky2012-5-5-a-sup-won-the-large-scale-a-href-wiki-imagenet-competition-class-mw-redirect-title-imagenet-competition-imagenet-competition-a-by-a-significant-margin-over-shallow-machine-learning-methods-in-november-2012-ciresan-et-al-s-system-also-won-the-icpr-contest-on-analysis-of-large-medical-images-for-cancer-detection-and-in-the-following-year-also-the-miccai-grand-challenge-on-the-same-topic-sup-id-cite-ref-ciresan2013miccai-93-0-class-reference-a-href-cite-note-ciresan2013miccai-93-93-a-sup-in-2013-and-2014-the-error-rate-on-the-imagenet-task-using-deep-learning-was-further-reduced-following-a-similar-trend-in-large-scale-speech-recognition-the-a-href-wiki-stephen-wolfram-title-stephen-wolfram-wolfram-a-image-identification-project-publicized-these-improvements-sup-id-cite-ref-94-class-reference-a-href-cite-note-94-94-a-sup-p-p-image-classification-was-then-extended-to-the-more-challenging-task-of-generating-descriptions-captions-for-images-often-as-a-combination-of-cnns-and-lstms-sup-id-cite-ref-1411-4555-95-0-class-reference-a-href-cite-note-1411-4555-95-95-a-sup-sup-id-cite-ref-1411-4952-96-0-class-reference-a-href-cite-note-1411-4952-96-96-a-sup-sup-id-cite-ref-1411-2539-97-0-class-reference-a-href-cite-note-1411-2539-97-97-a-sup-sup-id-cite-ref-98-class-reference-a-href-cite-note-98-98-a-sup-p-p-some-researchers-assess-that-the-october-2012-imagenet-victory-anchored-the-start-of-a-deep-learning-revolution-that-has-transformed-the-ai-industry-sup-id-cite-ref-99-class-reference-a-href-cite-note-99-99-a-sup-p-p-in-march-2019-a-href-wiki-yoshua-bengio-title-yoshua-bengio-yoshua-bengio-a-a-href-wiki-geoffrey-hinton-title-geoffrey-hinton-geoffrey-hinton-a-and-a-href-wiki-yann-lecun-title-yann-lecun-yann-lecun-a-were-awarded-the-a-href-wiki-turing-award-title-turing-award-turing-award-a-for-conceptual-and-engineering-breakthroughs-that-have-made-deep-neural-networks-a-critical-component-of-computing-p-h2-span-class-mw-headline-id-neural-networks-neural-networks-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-6-title-edit-section-neural-networks-edit-a-span-class-mw-editsection-bracket-span-span-h2-h3-span-class-mw-headline-id-artificial-neural-networks-artificial-neural-networks-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-7-title-edit-section-artificial-neural-networks-edit-a-span-class-mw-editsection-bracket-span-span-h3-div-role-note-class-hatnote-navigation-not-searchable-main-article-a-href-wiki-artificial-neural-network-title-artificial-neural-network-artificial-neural-network-a-div-p-b-artificial-neural-networks-b-b-anns-b-or-b-a-href-wiki-connectionism-title-connectionism-connectionist-a-systems-b-are-computing-systems-inspired-by-the-a-href-wiki-biological-neural-network-class-mw-redirect-title-biological-neural-network-biological-neural-networks-a-that-constitute-animal-brains-such-systems-learn-progressively-improve-their-ability-to-do-tasks-by-considering-examples-generally-without-task-specific-programming-for-example-in-image-recognition-they-might-learn-to-identify-images-that-contain-cats-by-analyzing-example-images-that-have-been-manually-a-href-wiki-labeled-data-title-labeled-data-labeled-a-as-cat-or-no-cat-and-using-the-analytic-results-to-identify-cats-in-other-images-they-have-found-most-use-in-applications-difficult-to-express-with-a-traditional-computer-algorithm-using-a-href-wiki-rule-based-programming-class-mw-redirect-title-rule-based-programming-rule-based-programming-a-p-p-an-ann-is-based-on-a-collection-of-connected-units-called-a-href-wiki-artificial-neuron-title-artificial-neuron-artificial-neurons-a-analogous-to-biological-neurons-in-a-a-href-wiki-brain-title-brain-biological-brain-a-each-connection-a-href-wiki-synapse-title-synapse-synapse-a-between-neurons-can-transmit-a-signal-to-another-neuron-the-receiving-postsynaptic-neuron-can-process-the-signal-s-and-then-signal-downstream-neurons-connected-to-it-neurons-may-have-state-generally-represented-by-a-href-wiki-real-numbers-class-mw-redirect-title-real-numbers-real-numbers-a-typically-between-0-and-1-neurons-and-synapses-may-also-have-a-weight-that-varies-as-learning-proceeds-which-can-increase-or-decrease-the-strength-of-the-signal-that-it-sends-downstream-p-p-typically-neurons-are-organized-in-layers-different-layers-may-perform-different-kinds-of-transformations-on-their-inputs-signals-travel-from-the-first-input-to-the-last-output-layer-possibly-after-traversing-the-layers-multiple-times-p-p-the-original-goal-of-the-neural-network-approach-was-to-solve-problems-in-the-same-way-that-a-human-brain-would-over-time-attention-focused-on-matching-specific-mental-abilities-leading-to-deviations-from-biology-such-as-backpropagation-or-passing-information-in-the-reverse-direction-and-adjusting-the-network-to-reflect-that-information-p-p-neural-networks-have-been-used-on-a-variety-of-tasks-including-computer-vision-a-href-wiki-speech-recognition-title-speech-recognition-speech-recognition-a-a-href-wiki-machine-translation-title-machine-translation-machine-translation-a-a-href-wiki-social-network-title-social-network-social-network-a-filtering-a-href-wiki-general-game-playing-title-general-game-playing-playing-board-and-video-games-a-and-medical-diagnosis-p-p-as-of-2017-neural-networks-typically-have-a-few-thousand-to-a-few-million-units-and-millions-of-connections-despite-this-number-being-several-order-of-magnitude-less-than-the-number-of-neurons-on-a-human-brain-these-networks-can-perform-many-tasks-at-a-level-beyond-that-of-humans-e-g-recognizing-faces-playing-go-sup-id-cite-ref-100-class-reference-a-href-cite-note-100-100-a-sup-p-h3-span-class-mw-headline-id-deep-neural-networks-deep-neural-networks-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-8-title-edit-section-deep-neural-networks-edit-a-span-class-mw-editsection-bracket-span-span-h3-table-class-box-technical-plainlinks-metadata-ambox-ambox-style-ambox-technical-role-presentation-tbody-tr-td-class-mbox-image-div-style-width-52px-img-alt-src-upload-wikimedia-org-wikipedia-en-thumb-f-f2-edit-clear-svg-40px-edit-clear-svg-png-decoding-async-width-40-height-40-srcset-upload-wikimedia-org-wikipedia-en-thumb-f-f2-edit-clear-svg-60px-edit-clear-svg-png-1-5x-upload-wikimedia-org-wikipedia-en-thumb-f-f2-edit-clear-svg-80px-edit-clear-svg-png-2x-data-file-width-48-data-file-height-48-div-td-td-class-mbox-text-div-class-mbox-text-span-this-section-b-may-be-too-technical-for-most-readers-to-understand-b-please-a-class-external-text-href-en-wikipedia-org-w-index-php-title-deep-learning-action-edit-help-improve-it-a-to-a-href-wiki-wikipedia-make-technical-articles-understandable-title-wikipedia-make-technical-articles-understandable-make-it-understandable-to-non-experts-a-without-removing-the-technical-details-small-class-date-container-i-span-class-date-july-2016-span-i-small-small-class-hide-when-compact-i-a-href-wiki-help-maintenance-template-removal-title-help-maintenance-template-removal-learn-how-and-when-to-remove-this-template-message-a-i-small-div-td-tr-tbody-table-p-a-deep-neural-network-dnn-is-an-a-href-wiki-artificial-neural-network-title-artificial-neural-network-artificial-neural-network-a-ann-with-multiple-layers-between-the-input-and-output-layers-sup-id-cite-ref-bengiodeep-11-3-class-reference-a-href-cite-note-bengiodeep-11-11-a-sup-sup-id-cite-ref-schidhub-2-6-class-reference-a-href-cite-note-schidhub-2-2-a-sup-the-dnn-finds-the-correct-mathematical-manipulation-to-turn-the-input-into-the-output-whether-it-be-a-a-href-wiki-linear-relationship-class-mw-redirect-title-linear-relationship-linear-relationship-a-or-a-non-linear-relationship-the-network-moves-through-the-layers-calculating-the-probability-of-each-output-for-example-a-dnn-that-is-trained-to-recognize-dog-breeds-will-go-over-the-given-image-and-calculate-the-probability-that-the-dog-in-the-image-is-a-certain-breed-the-user-can-review-the-results-and-select-which-probabilities-the-network-should-display-above-a-certain-threshold-etc-and-return-the-proposed-label-each-mathematical-manipulation-as-such-is-considered-a-layer-and-complex-dnn-have-many-layers-hence-the-name-deep-networks-p-p-dnns-can-model-complex-non-linear-relationships-dnn-architectures-generate-compositional-models-where-the-object-is-expressed-as-a-layered-composition-of-a-href-wiki-primitive-data-type-title-primitive-data-type-primitives-a-sup-id-cite-ref-101-class-reference-a-href-cite-note-101-101-a-sup-the-extra-layers-enable-composition-of-features-from-lower-layers-potentially-modeling-complex-data-with-fewer-units-than-a-similarly-performing-shallow-network-sup-id-cite-ref-bengiodeep-11-4-class-reference-a-href-cite-note-bengiodeep-11-11-a-sup-p-p-deep-architectures-include-many-variants-of-a-few-basic-approaches-each-architecture-has-found-success-in-specific-domains-it-is-not-always-possible-to-compare-the-performance-of-multiple-architectures-unless-they-have-been-evaluated-on-the-same-data-sets-p-p-dnns-are-typically-feedforward-networks-in-which-data-flows-from-the-input-layer-to-the-output-layer-without-looping-back-at-first-the-dnn-creates-a-map-of-virtual-neurons-and-assigns-random-numerical-values-or-weights-to-connections-between-them-the-weights-and-inputs-are-multiplied-and-return-an-output-between-0-and-1-if-the-network-didnt-accurately-recognize-a-particular-pattern-an-algorithm-would-adjust-the-weights-sup-id-cite-ref-102-class-reference-a-href-cite-note-102-102-a-sup-that-way-the-algorithm-can-make-certain-parameters-more-influential-until-it-determines-the-correct-mathematical-manipulation-to-fully-process-the-data-p-p-a-href-wiki-recurrent-neural-networks-class-mw-redirect-title-recurrent-neural-networks-recurrent-neural-networks-a-rnns-in-which-data-can-flow-in-any-direction-are-used-for-applications-such-as-a-href-wiki-language-model-title-language-model-language-modeling-a-sup-id-cite-ref-gers2001-103-0-class-reference-a-href-cite-note-gers2001-103-103-a-sup-sup-id-cite-ref-nips2014-104-0-class-reference-a-href-cite-note-nips2014-104-104-a-sup-sup-id-cite-ref-vinyals2016-105-0-class-reference-a-href-cite-note-vinyals2016-105-105-a-sup-sup-id-cite-ref-gillick2015-106-0-class-reference-a-href-cite-note-gillick2015-106-106-a-sup-sup-id-cite-ref-miko2010-107-0-class-reference-a-href-cite-note-miko2010-107-107-a-sup-long-short-term-memory-is-particularly-effective-for-this-use-sup-id-cite-ref-0-51-2-class-reference-a-href-cite-note-0-51-51-a-sup-sup-id-cite-ref-10-108-0-class-reference-a-href-cite-note-10-108-108-a-sup-p-p-a-href-wiki-convolutional-neural-network-title-convolutional-neural-network-convolutional-deep-neural-networks-cnns-a-are-used-in-computer-vision-sup-id-cite-ref-lecun86-109-0-class-reference-a-href-cite-note-lecun86-109-109-a-sup-cnns-also-have-been-applied-to-a-href-wiki-acoustic-model-title-acoustic-model-acoustic-modeling-a-for-automatic-speech-recognition-asr-sup-id-cite-ref-2-67-1-class-reference-a-href-cite-note-2-67-67-a-sup-p-h4-span-class-mw-headline-id-challenges-challenges-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-9-title-edit-section-challenges-edit-a-span-class-mw-editsection-bracket-span-span-h4-p-as-with-anns-many-issues-can-arise-with-naively-trained-dnns-two-common-issues-are-a-href-wiki-overfitting-title-overfitting-overfitting-a-and-computation-time-p-p-dnns-are-prone-to-overfitting-because-of-the-added-layers-of-abstraction-which-allow-them-to-model-rare-dependencies-in-the-training-data-a-href-wiki-regularization-mathematics-title-regularization-mathematics-regularization-a-methods-such-as-ivakhnenko-s-unit-pruning-sup-id-cite-ref-ivak1971-29-1-class-reference-a-href-cite-note-ivak1971-29-29-a-sup-or-a-href-wiki-weight-decay-class-mw-redirect-title-weight-decay-weight-decay-a-span-class-mwe-math-element-span-class-mwe-math-mathml-inline-mwe-math-mathml-a11y-style-display-none-math-xmlns-http-www-w3-org-1998-math-mathml-alttext-displaystyle-ell-2-semantics-mrow-class-mjx-texatom-ord-mstyle-displaystyle-true-scriptlevel-0-msub-mi-l-mi-mrow-class-mjx-texatom-ord-mn-2-mn-mrow-msub-mstyle-mrow-annotation-encoding-application-x-tex-displaystyle-ell-2-annotation-semantics-math-span-img-src-https-wikimedia-org-api-rest-v1-media-math-render-svg-85a4571ee9be10bd3c9df2480ab3d280f99e801a-class-mwe-math-fallback-image-inline-aria-hidden-true-style-vertical-align-0-671ex-width-2-024ex-height-2-509ex-alt-ell-2-span-regularization-or-a-href-wiki-sparse-matrix-title-sparse-matrix-sparsity-a-span-class-mwe-math-element-span-class-mwe-math-mathml-inline-mwe-math-mathml-a11y-style-display-none-math-xmlns-http-www-w3-org-1998-math-mathml-alttext-displaystyle-ell-1-semantics-mrow-class-mjx-texatom-ord-mstyle-displaystyle-true-scriptlevel-0-msub-mi-l-mi-mrow-class-mjx-texatom-ord-mn-1-mn-mrow-msub-mstyle-mrow-annotation-encoding-application-x-tex-displaystyle-ell-1-annotation-semantics-math-span-img-src-https-wikimedia-org-api-rest-v1-media-math-render-svg-361ddd720474aa41cb05453e03424fb7999d3b02-class-mwe-math-fallback-image-inline-aria-hidden-true-style-vertical-align-0-671ex-width-2-024ex-height-2-509ex-alt-ell-1-span-regularization-can-be-applied-during-training-to-combat-overfitting-sup-id-cite-ref-110-class-reference-a-href-cite-note-110-110-a-sup-alternatively-dropout-regularization-randomly-omits-units-from-the-hidden-layers-during-training-this-helps-to-exclude-rare-dependencies-sup-id-cite-ref-dahl2013-111-0-class-reference-a-href-cite-note-dahl2013-111-111-a-sup-finally-data-can-be-augmented-via-methods-such-as-cropping-and-rotating-such-that-smaller-training-sets-can-be-increased-in-size-to-reduce-the-chances-of-overfitting-sup-id-cite-ref-112-class-reference-a-href-cite-note-112-112-a-sup-p-p-dnns-must-consider-many-training-parameters-such-as-the-size-number-of-layers-and-number-of-units-per-layer-the-a-href-wiki-learning-rate-title-learning-rate-learning-rate-a-and-initial-weights-a-href-wiki-hyperparameter-optimization-grid-search-title-hyperparameter-optimization-sweeping-through-the-parameter-space-a-for-optimal-parameters-may-not-be-feasible-due-to-the-cost-in-time-and-computational-resources-various-tricks-such-as-batching-computing-the-gradient-on-several-training-examples-at-once-rather-than-individual-examples-sup-id-cite-ref-rbmtrain-113-0-class-reference-a-href-cite-note-rbmtrain-113-113-a-sup-speed-up-computation-large-processing-capabilities-of-many-core-architectures-such-as-gpus-or-the-intel-xeon-phi-have-produced-significant-speedups-in-training-because-of-the-suitability-of-such-processing-architectures-for-the-matrix-and-vector-computations-sup-id-cite-ref-114-class-reference-a-href-cite-note-114-114-a-sup-sup-id-cite-ref-115-class-reference-a-href-cite-note-115-115-a-sup-p-p-alternatively-engineers-may-look-for-other-types-of-neural-networks-with-more-straightforward-and-convergent-training-algorithms-cmac-a-href-wiki-cerebellar-model-articulation-controller-title-cerebellar-model-articulation-controller-cerebellar-model-articulation-controller-a-is-one-such-kind-of-neural-network-it-doesn-t-require-learning-rates-or-randomized-initial-weights-for-cmac-the-training-process-can-be-guaranteed-to-converge-in-one-step-with-a-new-batch-of-data-and-the-computational-complexity-of-the-training-algorithm-is-linear-with-respect-to-the-number-of-neurons-involved-sup-id-cite-ref-qin1-116-0-class-reference-a-href-cite-note-qin1-116-116-a-sup-sup-id-cite-ref-qin2-117-0-class-reference-a-href-cite-note-qin2-117-117-a-sup-p-h2-span-class-mw-headline-id-applications-applications-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-10-title-edit-section-applications-edit-a-span-class-mw-editsection-bracket-span-span-h2-h3-span-class-mw-headline-id-automatic-speech-recognition-automatic-speech-recognition-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-11-title-edit-section-automatic-speech-recognition-edit-a-span-class-mw-editsection-bracket-span-span-h3-div-role-note-class-hatnote-navigation-not-searchable-main-article-a-href-wiki-speech-recognition-title-speech-recognition-speech-recognition-a-div-p-large-scale-automatic-speech-recognition-is-the-first-and-most-convincing-successful-case-of-deep-learning-lstm-rnns-can-learn-very-deep-learning-tasks-sup-id-cite-ref-schidhub-2-7-class-reference-a-href-cite-note-schidhub-2-2-a-sup-that-involve-multi-second-intervals-containing-speech-events-separated-by-thousands-of-discrete-time-steps-where-one-time-step-corresponds-to-about-10-ms-lstm-with-forget-gates-sup-id-cite-ref-10-108-1-class-reference-a-href-cite-note-10-108-108-a-sup-is-competitive-with-traditional-speech-recognizers-on-certain-tasks-sup-id-cite-ref-graves2003-52-1-class-reference-a-href-cite-note-graves2003-52-52-a-sup-p-p-the-initial-success-in-speech-recognition-was-based-on-small-scale-recognition-tasks-based-on-timit-the-data-set-contains-630-speakers-from-eight-major-a-href-wiki-dialect-title-dialect-dialects-a-of-a-href-wiki-american-english-title-american-english-american-english-a-where-each-speaker-reads-10-sentences-sup-id-cite-ref-ldctimit-118-0-class-reference-a-href-cite-note-ldctimit-118-118-a-sup-its-small-size-lets-many-configurations-be-tried-more-importantly-the-timit-task-concerns-phone-sequence-recognition-which-unlike-word-sequence-recognition-allows-weak-phone-a-href-wiki-bigram-title-bigram-bigram-a-language-models-this-lets-the-strength-of-the-acoustic-modeling-aspects-of-speech-recognition-be-more-easily-analyzed-the-error-rates-listed-below-including-these-early-results-and-measured-as-percent-phone-error-rates-per-have-been-summarized-since-1991-p-table-class-wikitable-tbody-tr-th-method-th-th-percent-phone-br-error-rate-per-th-tr-tr-td-randomly-initialized-rnn-sup-id-cite-ref-119-class-reference-a-href-cite-note-119-119-a-sup-td-td-26-1-td-tr-tr-td-bayesian-triphone-gmm-hmm-td-td-25-6-td-tr-tr-td-hidden-trajectory-generative-model-td-td-24-8-td-tr-tr-td-monophone-randomly-initialized-dnn-td-td-23-4-td-tr-tr-td-monophone-dbn-dnn-td-td-22-4-td-tr-tr-td-triphone-gmm-hmm-with-bmmi-training-td-td-21-7-td-tr-tr-td-monophone-dbn-dnn-on-fbank-td-td-20-7-td-tr-tr-td-convolutional-dnn-sup-id-cite-ref-cnn-2014-120-0-class-reference-a-href-cite-note-cnn-2014-120-120-a-sup-td-td-20-0-td-tr-tr-td-convolutional-dnn-w-heterogeneous-pooling-td-td-18-7-td-tr-tr-td-ensemble-dnn-cnn-rnn-sup-id-cite-ref-ensembledl-121-0-class-reference-a-href-cite-note-ensembledl-121-121-a-sup-td-td-18-3-td-tr-tr-td-bidirectional-lstm-td-td-17-9-td-tr-tr-td-hierarchical-convolutional-deep-maxout-network-sup-id-cite-ref-hcdmm-122-0-class-reference-a-href-cite-note-hcdmm-122-122-a-sup-td-td-16-5-td-tr-tbody-table-p-the-debut-of-dnns-for-speaker-recognition-in-the-late-1990s-and-speech-recognition-around-2009-2011-and-of-lstm-around-2003-2007-accelerated-progress-in-eight-major-areas-sup-id-cite-ref-book2014-10-4-class-reference-a-href-cite-note-book2014-10-10-a-sup-sup-id-cite-ref-interspeech2014keynote-75-1-class-reference-a-href-cite-note-interspeech2014keynote-75-75-a-sup-sup-id-cite-ref-referencea-73-2-class-reference-a-href-cite-note-referencea-73-73-a-sup-p-ul-li-scale-up-out-and-acclerated-dnn-training-and-decoding-li-li-sequence-discriminative-training-li-li-feature-processing-by-deep-models-with-solid-understanding-of-the-underlying-mechanisms-li-li-adaptation-of-dnns-and-related-deep-models-li-li-a-href-wiki-multi-task-learning-title-multi-task-learning-multi-task-a-and-a-href-wiki-inductive-transfer-class-mw-redirect-title-inductive-transfer-transfer-learning-a-by-dnns-and-related-deep-models-li-li-cnns-and-how-to-design-them-to-best-exploit-a-href-wiki-domain-knowledge-title-domain-knowledge-domain-knowledge-a-of-speech-li-li-rnn-and-its-rich-lstm-variants-li-li-other-types-of-deep-models-including-tensor-based-models-and-integrated-deep-generative-discriminative-models-li-ul-p-all-major-commercial-speech-recognition-systems-e-g-microsoft-a-href-wiki-cortana-software-class-mw-redirect-title-cortana-software-cortana-a-a-href-wiki-xbox-title-xbox-xbox-a-a-href-wiki-skype-translator-title-skype-translator-skype-translator-a-a-href-wiki-amazon-alexa-title-amazon-alexa-amazon-alexa-a-a-href-wiki-google-now-title-google-now-google-now-a-a-href-wiki-siri-title-siri-apple-siri-a-a-href-wiki-baidu-title-baidu-baidu-a-and-a-href-wiki-iflytek-title-iflytek-iflytek-a-voice-search-and-a-range-of-a-href-wiki-nuance-communications-title-nuance-communications-nuance-a-speech-products-etc-are-based-on-deep-learning-sup-id-cite-ref-book2014-10-5-class-reference-a-href-cite-note-book2014-10-10-a-sup-sup-id-cite-ref-123-class-reference-a-href-cite-note-123-123-a-sup-sup-id-cite-ref-baidu-124-0-class-reference-a-href-cite-note-baidu-124-124-a-sup-sup-id-cite-ref-125-class-reference-a-href-cite-note-125-125-a-sup-p-h3-span-class-mw-headline-id-image-recognition-image-recognition-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-12-title-edit-section-image-recognition-edit-a-span-class-mw-editsection-bracket-span-span-h3-div-role-note-class-hatnote-navigation-not-searchable-main-article-a-href-wiki-computer-vision-title-computer-vision-computer-vision-a-div-p-a-common-evaluation-set-for-image-classification-is-the-mnist-database-data-set-mnist-is-composed-of-handwritten-digits-and-includes-60000-training-examples-and-10000-test-examples-as-with-timit-its-small-size-lets-users-test-multiple-configurations-a-comprehensive-list-of-results-on-this-set-is-available-sup-id-cite-ref-yannmnist-126-0-class-reference-a-href-cite-note-yannmnist-126-126-a-sup-p-p-deep-learning-based-image-recognition-has-become-superhuman-producing-more-accurate-results-than-human-contestants-this-first-occurred-in-2011-sup-id-cite-ref-7-127-0-class-reference-a-href-cite-note-7-127-127-a-sup-p-p-deep-learning-trained-vehicles-now-interpret-360deg-camera-views-sup-id-cite-ref-128-class-reference-a-href-cite-note-128-128-a-sup-another-example-is-facial-dysmorphology-novel-analysis-fdna-used-to-analyze-cases-of-human-malformation-connected-to-a-large-database-of-genetic-syndromes-p-h3-span-class-mw-headline-id-visual-art-processing-visual-art-processing-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-13-title-edit-section-visual-art-processing-edit-a-span-class-mw-editsection-bracket-span-span-h3-p-closely-related-to-the-progress-that-has-been-made-in-image-recognition-is-the-increasing-application-of-deep-learning-techniques-to-various-visual-art-tasks-dnns-have-proven-themselves-capable-for-example-of-a-identifying-the-style-period-of-a-given-painting-b-a-href-wiki-neural-style-transfer-title-neural-style-transfer-neural-style-transfer-a-capturing-the-style-of-a-given-artwork-and-applying-it-in-a-visually-pleasing-manner-to-an-arbitrary-photograph-or-video-and-c-generating-striking-imagery-based-on-random-visual-input-fields-sup-id-cite-ref-129-class-reference-a-href-cite-note-129-129-a-sup-sup-id-cite-ref-130-class-reference-a-href-cite-note-130-130-a-sup-p-h3-span-class-mw-headline-id-natural-language-processing-natural-language-processing-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-14-title-edit-section-natural-language-processing-edit-a-span-class-mw-editsection-bracket-span-span-h3-div-role-note-class-hatnote-navigation-not-searchable-main-article-a-href-wiki-natural-language-processing-title-natural-language-processing-natural-language-processing-a-div-p-neural-networks-have-been-used-for-implementing-language-models-since-the-early-2000s-sup-id-cite-ref-gers2001-103-1-class-reference-a-href-cite-note-gers2001-103-103-a-sup-sup-id-cite-ref-131-class-reference-a-href-cite-note-131-131-a-sup-lstm-helped-to-improve-machine-translation-and-language-modeling-sup-id-cite-ref-nips2014-104-1-class-reference-a-href-cite-note-nips2014-104-104-a-sup-sup-id-cite-ref-vinyals2016-105-1-class-reference-a-href-cite-note-vinyals2016-105-105-a-sup-sup-id-cite-ref-gillick2015-106-1-class-reference-a-href-cite-note-gillick2015-106-106-a-sup-p-p-other-key-techniques-in-this-field-are-negative-sampling-sup-id-cite-ref-goldberglevy2014-132-0-class-reference-a-href-cite-note-goldberglevy2014-132-132-a-sup-and-a-href-wiki-word-embedding-title-word-embedding-word-embedding-a-word-embedding-such-as-i-a-href-wiki-word2vec-title-word2vec-word2vec-a-i-can-be-thought-of-as-a-representational-layer-in-a-deep-learning-architecture-that-transforms-an-atomic-word-into-a-positional-representation-of-the-word-relative-to-other-words-in-the-dataset-the-position-is-represented-as-a-point-in-a-a-href-wiki-vector-space-title-vector-space-vector-space-a-using-word-embedding-as-an-rnn-input-layer-allows-the-network-to-parse-sentences-and-phrases-using-an-effective-compositional-vector-grammar-a-compositional-vector-grammar-can-be-thought-of-as-a-href-wiki-probabilistic-context-free-grammar-class-mw-redirect-title-probabilistic-context-free-grammar-probabilistic-context-free-grammar-a-pcfg-implemented-by-an-rnn-sup-id-cite-ref-sochermanning2014-133-0-class-reference-a-href-cite-note-sochermanning2014-133-133-a-sup-recursive-auto-encoders-built-atop-word-embeddings-can-assess-sentence-similarity-and-detect-paraphrasing-sup-id-cite-ref-sochermanning2014-133-1-class-reference-a-href-cite-note-sochermanning2014-133-133-a-sup-deep-neural-architectures-provide-the-best-results-for-a-href-wiki-statistical-parsing-title-statistical-parsing-constituency-parsing-a-sup-id-cite-ref-134-class-reference-a-href-cite-note-134-134-a-sup-a-href-wiki-sentiment-analysis-title-sentiment-analysis-sentiment-analysis-a-sup-id-cite-ref-135-class-reference-a-href-cite-note-135-135-a-sup-information-retrieval-sup-id-cite-ref-136-class-reference-a-href-cite-note-136-136-a-sup-sup-id-cite-ref-137-class-reference-a-href-cite-note-137-137-a-sup-spoken-language-understanding-sup-id-cite-ref-ieee-tasl2015-138-0-class-reference-a-href-cite-note-ieee-tasl2015-138-138-a-sup-machine-translation-sup-id-cite-ref-nips2014-104-2-class-reference-a-href-cite-note-nips2014-104-104-a-sup-sup-id-cite-ref-auto-139-0-class-reference-a-href-cite-note-auto-139-139-a-sup-contextual-entity-linking-sup-id-cite-ref-auto-139-1-class-reference-a-href-cite-note-auto-139-139-a-sup-writing-style-recognition-sup-id-cite-ref-broc2017-140-0-class-reference-a-href-cite-note-broc2017-140-140-a-sup-text-classification-and-others-sup-id-cite-ref-141-class-reference-a-href-cite-note-141-141-a-sup-p-p-recent-developments-generalize-a-href-wiki-word-embedding-title-word-embedding-word-embedding-a-to-a-href-wiki-sentence-embedding-title-sentence-embedding-sentence-embedding-a-p-p-a-href-wiki-google-translate-title-google-translate-google-translate-a-gt-uses-a-large-a-href-wiki-end-to-end-principle-title-end-to-end-principle-end-to-end-a-long-short-term-memory-network-sup-id-cite-ref-gt-turovsky-2016-142-0-class-reference-a-href-cite-note-gt-turovsky-2016-142-142-a-sup-sup-id-cite-ref-googleblog-gnmt-2016-143-0-class-reference-a-href-cite-note-googleblog-gnmt-2016-143-143-a-sup-sup-id-cite-ref-lstm1997-144-0-class-reference-a-href-cite-note-lstm1997-144-144-a-sup-sup-id-cite-ref-lstm2000-145-0-class-reference-a-href-cite-note-lstm2000-145-145-a-sup-sup-id-cite-ref-googletranslate-146-0-class-reference-a-href-cite-note-googletranslate-146-146-a-sup-sup-id-cite-ref-wiredgoogletranslate-147-0-class-reference-a-href-cite-note-wiredgoogletranslate-147-147-a-sup-a-href-wiki-google-neural-machine-translation-title-google-neural-machine-translation-google-neural-machine-translation-gnmt-a-uses-an-a-href-wiki-example-based-machine-translation-title-example-based-machine-translation-example-based-machine-translation-a-method-in-which-the-system-learns-from-millions-of-examples-sup-id-cite-ref-googleblog-gnmt-2016-143-1-class-reference-a-href-cite-note-googleblog-gnmt-2016-143-143-a-sup-it-translates-whole-sentences-at-a-time-rather-than-pieces-google-translate-supports-over-one-hundred-languages-sup-id-cite-ref-googleblog-gnmt-2016-143-2-class-reference-a-href-cite-note-googleblog-gnmt-2016-143-143-a-sup-the-network-encodes-the-semantics-of-the-sentence-rather-than-simply-memorizing-phrase-to-phrase-translations-sup-id-cite-ref-googleblog-gnmt-2016-143-3-class-reference-a-href-cite-note-googleblog-gnmt-2016-143-143-a-sup-sup-id-cite-ref-biotet-148-0-class-reference-a-href-cite-note-biotet-148-148-a-sup-gt-uses-english-as-an-intermediate-between-most-language-pairs-sup-id-cite-ref-biotet-148-1-class-reference-a-href-cite-note-biotet-148-148-a-sup-p-h3-span-class-mw-headline-id-drug-discovery-and-toxicology-drug-discovery-and-toxicology-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-15-title-edit-section-drug-discovery-and-toxicology-edit-a-span-class-mw-editsection-bracket-span-span-h3-div-role-note-class-hatnote-navigation-not-searchable-for-more-information-see-a-href-wiki-drug-discovery-title-drug-discovery-drug-discovery-a-and-a-href-wiki-toxicology-title-toxicology-toxicology-a-div-p-a-large-percentage-of-candidate-drugs-fail-to-win-regulatory-approval-these-failures-are-caused-by-insufficient-efficacy-on-target-effect-undesired-interactions-off-target-effects-or-unanticipated-a-href-wiki-toxicity-title-toxicity-toxic-effects-a-sup-id-cite-ref-arrowsmith2013-149-0-class-reference-a-href-cite-note-arrowsmith2013-149-149-a-sup-sup-id-cite-ref-verbiest2015-150-0-class-reference-a-href-cite-note-verbiest2015-150-150-a-sup-research-has-explored-use-of-deep-learning-to-predict-the-a-href-wiki-biomolecular-target-class-mw-redirect-title-biomolecular-target-biomolecular-targets-a-sup-id-cite-ref-merck2012-86-1-class-reference-a-href-cite-note-merck2012-86-86-a-sup-sup-id-cite-ref-5-87-1-class-reference-a-href-cite-note-5-87-87-a-sup-a-href-wiki-off-target-class-mw-redirect-title-off-target-off-targets-a-and-a-href-wiki-toxicity-title-toxicity-toxic-effects-a-of-environmental-chemicals-in-nutrients-household-products-and-drugs-sup-id-cite-ref-tox21-88-1-class-reference-a-href-cite-note-tox21-88-88-a-sup-sup-id-cite-ref-tox21data-89-1-class-reference-a-href-cite-note-tox21data-89-89-a-sup-sup-id-cite-ref-11-90-1-class-reference-a-href-cite-note-11-90-90-a-sup-p-p-atomnet-is-a-deep-learning-system-for-structure-based-a-href-wiki-drug-design-title-drug-design-rational-drug-design-a-sup-id-cite-ref-151-class-reference-a-href-cite-note-151-151-a-sup-atomnet-was-used-to-predict-novel-candidate-biomolecules-for-disease-targets-such-as-the-a-href-wiki-ebola-virus-class-mw-redirect-title-ebola-virus-ebola-virus-a-sup-id-cite-ref-152-class-reference-a-href-cite-note-152-152-a-sup-and-a-href-wiki-multiple-sclerosis-title-multiple-sclerosis-multiple-sclerosis-a-sup-id-cite-ref-153-class-reference-a-href-cite-note-153-153-a-sup-sup-id-cite-ref-154-class-reference-a-href-cite-note-154-154-a-sup-p-h3-span-class-mw-headline-id-customer-relationship-management-customer-relationship-management-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-16-title-edit-section-customer-relationship-management-edit-a-span-class-mw-editsection-bracket-span-span-h3-div-role-note-class-hatnote-navigation-not-searchable-main-article-a-href-wiki-customer-relationship-management-title-customer-relationship-management-customer-relationship-management-a-div-p-deep-reinforcement-learning-has-been-used-to-approximate-the-value-of-possible-a-href-wiki-direct-marketing-title-direct-marketing-direct-marketing-a-actions-defined-in-terms-of-a-href-wiki-rfm-customer-value-title-rfm-customer-value-rfm-a-variables-the-estimated-value-function-was-shown-to-have-a-natural-interpretation-as-a-href-wiki-customer-lifetime-value-title-customer-lifetime-value-customer-lifetime-value-a-sup-id-cite-ref-155-class-reference-a-href-cite-note-155-155-a-sup-p-h3-span-class-mw-headline-id-recommendation-systems-recommendation-systems-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-17-title-edit-section-recommendation-systems-edit-a-span-class-mw-editsection-bracket-span-span-h3-div-role-note-class-hatnote-navigation-not-searchable-main-article-a-href-wiki-recommender-system-title-recommender-system-recommender-system-a-div-p-recommendation-systems-have-used-deep-learning-to-extract-meaningful-features-for-a-latent-factor-model-for-content-based-music-recommendations-sup-id-cite-ref-156-class-reference-a-href-cite-note-156-156-a-sup-multiview-deep-learning-has-been-applied-for-learning-user-preferences-from-multiple-domains-sup-id-cite-ref-157-class-reference-a-href-cite-note-157-157-a-sup-the-model-uses-a-hybrid-collaborative-and-content-based-approach-and-enhances-recommendations-in-multiple-tasks-p-h3-span-class-mw-headline-id-bioinformatics-bioinformatics-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-18-title-edit-section-bioinformatics-edit-a-span-class-mw-editsection-bracket-span-span-h3-div-role-note-class-hatnote-navigation-not-searchable-main-article-a-href-wiki-bioinformatics-title-bioinformatics-bioinformatics-a-div-p-an-a-href-wiki-autoencoder-title-autoencoder-autoencoder-a-ann-was-used-in-a-href-wiki-bioinformatics-title-bioinformatics-bioinformatics-a-to-predict-a-href-wiki-gene-ontology-class-mw-redirect-title-gene-ontology-gene-ontology-a-annotations-and-gene-function-relationships-sup-id-cite-ref-158-class-reference-a-href-cite-note-158-158-a-sup-p-p-in-medical-informatics-deep-learning-was-used-to-predict-sleep-quality-based-on-data-from-wearables-sup-id-cite-ref-159-class-reference-a-href-cite-note-159-159-a-sup-and-predictions-of-health-complications-from-a-href-wiki-electronic-health-record-title-electronic-health-record-electronic-health-record-a-data-sup-id-cite-ref-160-class-reference-a-href-cite-note-160-160-a-sup-deep-learning-has-also-showed-efficacy-in-a-href-wiki-artificial-intelligence-in-healthcare-title-artificial-intelligence-in-healthcare-healthcare-a-sup-id-cite-ref-161-class-reference-a-href-cite-note-161-161-a-sup-p-h3-span-class-mw-headline-id-medical-image-analysis-medical-image-analysis-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-19-title-edit-section-medical-image-analysis-edit-a-span-class-mw-editsection-bracket-span-span-h3-p-deep-learning-has-been-shown-to-produce-competitive-results-in-medical-application-such-as-cancer-cell-classification-lesion-detection-organ-segmentation-and-image-enhancement-sup-id-cite-ref-162-class-reference-a-href-cite-note-162-162-a-sup-sup-id-cite-ref-163-class-reference-a-href-cite-note-163-163-a-sup-p-h3-span-class-mw-headline-id-mobile-advertising-mobile-advertising-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-20-title-edit-section-mobile-advertising-edit-a-span-class-mw-editsection-bracket-span-span-h3-p-finding-the-appropriate-mobile-audience-for-a-href-wiki-mobile-advertising-title-mobile-advertising-mobile-advertising-a-is-always-challenging-since-many-data-points-must-be-considered-and-assimilated-before-a-target-segment-can-be-created-and-used-in-ad-serving-by-any-ad-server-sup-id-cite-ref-164-class-reference-a-href-cite-note-164-164-a-sup-deep-learning-has-been-used-to-interpret-large-many-dimensioned-advertising-datasets-many-data-points-are-collected-during-the-request-serve-click-internet-advertising-cycle-this-information-can-form-the-basis-of-machine-learning-to-improve-ad-selection-p-h3-span-class-mw-headline-id-image-restoration-image-restoration-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-21-title-edit-section-image-restoration-edit-a-span-class-mw-editsection-bracket-span-span-h3-p-deep-learning-has-been-successfully-applied-to-a-href-wiki-inverse-problems-class-mw-redirect-title-inverse-problems-inverse-problems-a-such-as-a-href-wiki-denoising-class-mw-redirect-title-denoising-denoising-a-a-href-wiki-super-resolution-class-mw-redirect-title-super-resolution-super-resolution-a-a-href-wiki-inpainting-title-inpainting-inpainting-a-and-a-href-wiki-film-colorization-title-film-colorization-film-colorization-a-these-applications-include-learning-methods-such-as-shrinkage-fields-for-effective-image-restoration-sup-id-cite-ref-165-class-reference-a-href-cite-note-165-165-a-sup-which-trains-on-an-image-dataset-and-a-href-wiki-deep-image-prior-title-deep-image-prior-deep-image-prior-a-which-trains-on-the-image-that-needs-restoration-p-h3-span-class-mw-headline-id-financial-fraud-detection-financial-fraud-detection-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-22-title-edit-section-financial-fraud-detection-edit-a-span-class-mw-editsection-bracket-span-span-h3-p-deep-learning-is-being-successfully-applied-to-financial-a-href-wiki-fraud-detection-class-mw-redirect-title-fraud-detection-fraud-detection-a-and-anti-money-laundering-deep-anti-money-laundering-detection-system-can-spot-and-recognize-relationships-and-similarities-between-data-and-further-down-the-road-learn-to-detect-anomalies-or-classify-and-predict-specific-events-the-solution-leverages-both-supervised-learning-techniques-such-as-the-classification-of-suspicious-transactions-and-unsupervised-learning-e-g-anomaly-detection-sup-id-cite-ref-166-class-reference-a-href-cite-note-166-166-a-sup-p-h3-span-class-mw-headline-id-military-military-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-23-title-edit-section-military-edit-a-span-class-mw-editsection-bracket-span-span-h3-p-the-united-states-department-of-defense-applied-deep-learning-to-train-robots-in-new-tasks-through-observation-sup-id-cite-ref-12-167-0-class-reference-a-href-cite-note-12-167-167-a-sup-p-h2-span-class-mw-headline-id-relation-to-human-cognitive-and-brain-development-relation-to-human-cognitive-and-brain-development-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-24-title-edit-section-relation-to-human-cognitive-and-brain-development-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-deep-learning-is-closely-related-to-a-class-of-theories-of-a-href-wiki-brain-development-class-mw-redirect-title-brain-development-brain-development-a-specifically-neocortical-development-proposed-by-a-href-wiki-cognitive-neuroscientist-class-mw-redirect-title-cognitive-neuroscientist-cognitive-neuroscientists-a-in-the-early-1990s-sup-id-cite-ref-utgoff-168-0-class-reference-a-href-cite-note-utgoff-168-168-a-sup-sup-id-cite-ref-elman-169-0-class-reference-a-href-cite-note-elman-169-169-a-sup-sup-id-cite-ref-shrager-170-0-class-reference-a-href-cite-note-shrager-170-170-a-sup-sup-id-cite-ref-quartz-171-0-class-reference-a-href-cite-note-quartz-171-171-a-sup-these-developmental-theories-were-instantiated-in-computational-models-making-them-predecessors-of-deep-learning-systems-these-developmental-models-share-the-property-that-various-proposed-learning-dynamics-in-the-brain-e-g-a-wave-of-a-href-wiki-nerve-growth-factor-title-nerve-growth-factor-nerve-growth-factor-a-support-the-a-href-wiki-self-organization-title-self-organization-self-organization-a-somewhat-analogous-to-the-neural-networks-utilized-in-deep-learning-models-like-the-a-href-wiki-neocortex-title-neocortex-neocortex-a-neural-networks-employ-a-hierarchy-of-layered-filters-in-which-each-layer-considers-information-from-a-prior-layer-or-the-operating-environment-and-then-passes-its-output-and-possibly-the-original-input-to-other-layers-this-process-yields-a-self-organizing-stack-of-a-href-wiki-transducer-title-transducer-transducers-a-well-tuned-to-their-operating-environment-a-1995-description-stated-the-infant-s-brain-seems-to-organize-itself-under-the-influence-of-waves-of-so-called-trophic-factors-different-regions-of-the-brain-become-connected-sequentially-with-one-layer-of-tissue-maturing-before-another-and-so-on-until-the-whole-brain-is-mature-sup-id-cite-ref-blakeslee-172-0-class-reference-a-href-cite-note-blakeslee-172-172-a-sup-p-p-a-variety-of-approaches-have-been-used-to-investigate-the-plausibility-of-deep-learning-models-from-a-neurobiological-perspective-on-the-one-hand-several-variants-of-the-a-href-wiki-backpropagation-title-backpropagation-backpropagation-a-algorithm-have-been-proposed-in-order-to-increase-its-processing-realism-sup-id-cite-ref-173-class-reference-a-href-cite-note-173-173-a-sup-sup-id-cite-ref-174-class-reference-a-href-cite-note-174-174-a-sup-other-researchers-have-argued-that-unsupervised-forms-of-deep-learning-such-as-those-based-on-hierarchical-a-href-wiki-generative-model-title-generative-model-generative-models-a-and-a-href-wiki-deep-belief-network-title-deep-belief-network-deep-belief-networks-a-may-be-closer-to-biological-reality-sup-id-cite-ref-175-class-reference-a-href-cite-note-175-175-a-sup-sup-id-cite-ref-176-class-reference-a-href-cite-note-176-176-a-sup-in-this-respect-generative-neural-network-models-have-been-related-to-neurobiological-evidence-about-sampling-based-processing-in-the-cerebral-cortex-sup-id-cite-ref-177-class-reference-a-href-cite-note-177-177-a-sup-p-p-although-a-systematic-comparison-between-the-human-brain-organization-and-the-neuronal-encoding-in-deep-networks-has-not-yet-been-established-several-analogies-have-been-reported-for-example-the-computations-performed-by-deep-learning-units-could-be-similar-to-those-of-actual-neurons-sup-id-cite-ref-178-class-reference-a-href-cite-note-178-178-a-sup-sup-id-cite-ref-179-class-reference-a-href-cite-note-179-179-a-sup-and-neural-populations-sup-id-cite-ref-180-class-reference-a-href-cite-note-180-180-a-sup-similarly-the-representations-developed-by-deep-learning-models-are-similar-to-those-measured-in-the-primate-visual-system-sup-id-cite-ref-181-class-reference-a-href-cite-note-181-181-a-sup-both-at-the-single-unit-sup-id-cite-ref-182-class-reference-a-href-cite-note-182-182-a-sup-and-at-the-population-sup-id-cite-ref-183-class-reference-a-href-cite-note-183-183-a-sup-levels-p-h2-span-class-mw-headline-id-commercial-activity-commercial-activity-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-25-title-edit-section-commercial-activity-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-many-organizations-employ-deep-learning-for-particular-applications-a-href-wiki-facebook-title-facebook-facebook-a-s-ai-lab-performs-tasks-such-as-a-href-wiki-automatic-image-annotation-title-automatic-image-annotation-automatically-tagging-uploaded-pictures-a-with-the-names-of-the-people-in-them-sup-id-cite-ref-metz2013-184-0-class-reference-a-href-cite-note-metz2013-184-184-a-sup-p-p-google-s-a-href-wiki-deepmind-technologies-class-mw-redirect-title-deepmind-technologies-deepmind-technologies-a-developed-a-system-capable-of-learning-how-to-play-a-href-wiki-atari-title-atari-atari-a-video-games-using-only-pixels-as-data-input-in-2015-they-demonstrated-their-a-href-wiki-alphago-title-alphago-alphago-a-system-which-learned-the-game-of-a-href-wiki-go-game-title-go-game-go-a-well-enough-to-beat-a-professional-go-player-sup-id-cite-ref-185-class-reference-a-href-cite-note-185-185-a-sup-sup-id-cite-ref-186-class-reference-a-href-cite-note-186-186-a-sup-sup-id-cite-ref-187-class-reference-a-href-cite-note-187-187-a-sup-google-translate-uses-an-lstm-to-translate-between-more-than-100-languages-p-p-in-2015-a-href-wiki-blippar-title-blippar-blippar-a-demonstrated-a-mobile-a-href-wiki-augmented-reality-title-augmented-reality-augmented-reality-a-application-that-uses-deep-learning-to-recognize-objects-in-real-time-sup-id-cite-ref-188-class-reference-a-href-cite-note-188-188-a-sup-p-p-as-of-2008-sup-id-cite-ref-189-class-reference-a-href-cite-note-189-189-a-sup-researchers-at-a-href-wiki-university-of-texas-at-austin-title-university-of-texas-at-austin-the-university-of-texas-at-austin-a-ut-developed-a-machine-learning-framework-called-training-an-agent-manually-via-evaluative-reinforcement-or-tamer-which-proposed-new-methods-for-robots-or-computer-programs-to-learn-how-to-perform-tasks-by-interacting-with-a-human-instructor-sup-id-cite-ref-12-167-1-class-reference-a-href-cite-note-12-167-167-a-sup-p-p-first-developed-as-tamer-a-new-algorithm-called-deep-tamer-was-later-introduced-in-2018-during-a-collaboration-between-a-href-wiki-u-s-army-research-laboratory-class-mw-redirect-title-u-s-army-research-laboratory-u-s-army-research-laboratory-a-arl-and-ut-researchers-deep-tamer-used-deep-learning-to-provide-a-robot-the-ability-to-learn-new-tasks-through-observation-sup-id-cite-ref-12-167-2-class-reference-a-href-cite-note-12-167-167-a-sup-p-p-using-deep-tamer-a-robot-learned-a-task-with-a-human-trainer-watching-video-streams-or-observing-a-human-perform-a-task-in-person-the-robot-later-practiced-the-task-with-the-help-of-some-coaching-from-the-trainer-who-provided-feedback-such-as-good-job-and-bad-job-sup-id-cite-ref-190-class-reference-a-href-cite-note-190-190-a-sup-p-h2-span-class-mw-headline-id-criticism-and-comment-criticism-and-comment-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-26-title-edit-section-criticism-and-comment-edit-a-span-class-mw-editsection-bracket-span-span-h2-p-deep-learning-has-attracted-both-criticism-and-comment-in-some-cases-from-outside-the-field-of-computer-science-p-h3-span-class-mw-headline-id-theory-theory-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-27-title-edit-section-theory-edit-a-span-class-mw-editsection-bracket-span-span-h3-div-role-note-class-hatnote-navigation-not-searchable-see-also-a-href-wiki-explainable-ai-class-mw-redirect-title-explainable-ai-explainable-ai-a-div-p-a-main-criticism-concerns-the-lack-of-theory-surrounding-some-methods-sup-id-cite-ref-191-class-reference-a-href-cite-note-191-191-a-sup-learning-in-the-most-common-deep-architectures-is-implemented-using-well-understood-gradient-descent-however-the-theory-surrounding-other-algorithms-such-as-contrastive-divergence-is-less-clear-sup-class-noprint-inline-template-template-fact-style-white-space-nowrap-i-a-href-wiki-wikipedia-citation-needed-title-wikipedia-citation-needed-span-title-this-claim-needs-references-to-reliable-sources-july-2016-citation-needed-span-a-i-sup-e-g-does-it-converge-if-so-how-fast-what-is-it-approximating-deep-learning-methods-are-often-looked-at-as-a-a-href-wiki-black-box-title-black-box-black-box-a-with-most-confirmations-done-empirically-rather-than-theoretically-sup-id-cite-ref-knight-2017-192-0-class-reference-a-href-cite-note-knight-2017-192-192-a-sup-p-p-others-point-out-that-deep-learning-should-be-looked-at-as-a-step-towards-realizing-strong-ai-not-as-an-all-encompassing-solution-despite-the-power-of-deep-learning-methods-they-still-lack-much-of-the-functionality-needed-for-realizing-this-goal-entirely-research-psychologist-gary-marcus-noted-p-blockquote-p-realistically-deep-learning-is-only-part-of-the-larger-challenge-of-building-intelligent-machines-such-techniques-lack-ways-of-representing-a-href-wiki-causality-title-causality-causal-relationships-a-have-no-obvious-ways-of-performing-a-href-wiki-inference-title-inference-logical-inferences-a-and-they-are-also-still-a-long-way-from-integrating-abstract-knowledge-such-as-information-about-what-objects-are-what-they-are-for-and-how-they-are-typically-used-the-most-powerful-a-i-systems-like-a-href-wiki-watson-computer-title-watson-computer-watson-a-use-techniques-like-deep-learning-as-just-one-element-in-a-very-complicated-ensemble-of-techniques-ranging-from-the-statistical-technique-of-a-href-wiki-bayesian-inference-title-bayesian-inference-bayesian-inference-a-to-a-href-wiki-deductive-reasoning-title-deductive-reasoning-deductive-reasoning-a-sup-id-cite-ref-193-class-reference-a-href-cite-note-193-193-a-sup-p-blockquote-p-as-an-alternative-to-this-emphasis-on-the-limits-of-deep-learning-one-author-speculated-that-it-might-be-possible-to-train-a-machine-vision-stack-to-perform-the-sophisticated-task-of-discriminating-between-old-master-and-amateur-figure-drawings-and-hypothesized-that-such-a-sensitivity-might-represent-the-rudiments-of-a-non-trivial-machine-empathy-sup-id-cite-ref-194-class-reference-a-href-cite-note-194-194-a-sup-this-same-author-proposed-that-this-would-be-in-line-with-anthropology-which-identifies-a-concern-with-aesthetics-as-a-key-element-of-a-href-wiki-behavioral-modernity-title-behavioral-modernity-behavioral-modernity-a-sup-id-cite-ref-195-class-reference-a-href-cite-note-195-195-a-sup-p-p-in-further-reference-to-the-idea-that-artistic-sensitivity-might-inhere-within-relatively-low-levels-of-the-cognitive-hierarchy-a-published-series-of-graphic-representations-of-the-internal-states-of-deep-20-30-layers-neural-networks-attempting-to-discern-within-essentially-random-data-the-images-on-which-they-were-trained-sup-id-cite-ref-196-class-reference-a-href-cite-note-196-196-a-sup-demonstrate-a-visual-appeal-the-original-research-notice-received-well-over-1000-comments-and-was-the-subject-of-what-was-for-a-time-the-most-frequently-accessed-article-on-i-a-href-wiki-the-guardian-title-the-guardian-the-guardian-a-s-i-sup-id-cite-ref-197-class-reference-a-href-cite-note-197-197-a-sup-web-site-p-h3-span-class-mw-headline-id-errors-errors-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-28-title-edit-section-errors-edit-a-span-class-mw-editsection-bracket-span-span-h3-p-some-deep-learning-architectures-display-problematic-behaviors-sup-id-cite-ref-goertzel-198-0-class-reference-a-href-cite-note-goertzel-198-198-a-sup-such-as-confidently-classifying-unrecognizable-images-as-belonging-to-a-familiar-category-of-ordinary-images-sup-id-cite-ref-199-class-reference-a-href-cite-note-199-199-a-sup-and-misclassifying-minuscule-perturbations-of-correctly-classified-images-sup-id-cite-ref-200-class-reference-a-href-cite-note-200-200-a-sup-a-href-wiki-ben-goertzel-title-ben-goertzel-goertzel-a-hypothesized-that-these-behaviors-are-due-to-limitations-in-their-internal-representations-and-that-these-limitations-would-inhibit-integration-into-heterogeneous-multi-component-a-href-wiki-artificial-general-intelligence-title-artificial-general-intelligence-artificial-general-intelligence-a-agi-architectures-sup-id-cite-ref-goertzel-198-1-class-reference-a-href-cite-note-goertzel-198-198-a-sup-these-issues-may-possibly-be-addressed-by-deep-learning-architectures-that-internally-form-states-homologous-to-image-grammar-sup-id-cite-ref-201-class-reference-a-href-cite-note-201-201-a-sup-decompositions-of-observed-entities-and-events-sup-id-cite-ref-goertzel-198-2-class-reference-a-href-cite-note-goertzel-198-198-a-sup-a-href-wiki-grammar-induction-title-grammar-induction-learning-a-grammar-a-visual-or-linguistic-from-training-data-would-be-equivalent-to-restricting-the-system-to-a-href-wiki-commonsense-reasoning-title-commonsense-reasoning-commonsense-reasoning-a-that-operates-on-concepts-in-terms-of-grammatical-a-href-wiki-production-computer-science-title-production-computer-science-production-rules-a-and-is-a-basic-goal-of-both-human-language-acquisition-sup-id-cite-ref-202-class-reference-a-href-cite-note-202-202-a-sup-and-a-href-wiki-artificial-intelligence-title-artificial-intelligence-artificial-intelligence-a-ai-sup-id-cite-ref-203-class-reference-a-href-cite-note-203-203-a-sup-p-h3-span-class-mw-headline-id-cyber-threat-cyber-threat-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-29-title-edit-section-cyber-threat-edit-a-span-class-mw-editsection-bracket-span-span-h3-p-as-deep-learning-moves-from-the-lab-into-the-world-research-and-experience-shows-that-artificial-neural-networks-are-vulnerable-to-hacks-and-deception-by-identifying-patterns-that-these-systems-use-to-function-attackers-can-modify-inputs-to-anns-in-such-a-way-that-the-ann-finds-a-match-that-human-observers-would-not-recognize-for-example-an-attacker-can-make-subtle-changes-to-an-image-such-that-the-ann-finds-a-match-even-though-the-image-looks-to-a-human-nothing-like-the-search-target-such-a-manipulation-is-termed-an-adversarial-attack-in-2016-researchers-used-one-ann-to-doctor-images-in-trial-and-error-fashion-identify-another-s-focal-points-and-thereby-generate-images-that-deceived-it-the-modified-images-looked-no-different-to-human-eyes-another-group-showed-that-printouts-of-doctored-images-then-photographed-successfully-tricked-an-image-classification-system-sup-id-cite-ref-4-204-0-class-reference-a-href-cite-note-4-204-204-a-sup-one-defense-is-reverse-image-search-in-which-a-possible-fake-image-is-submitted-to-a-site-such-as-a-href-wiki-tineye-title-tineye-tineye-a-that-can-then-find-other-instances-of-it-a-refinement-is-to-search-using-only-parts-of-the-image-to-identify-images-from-which-that-piece-may-have-been-taken-b-b-sup-id-cite-ref-205-class-reference-a-href-cite-note-205-205-a-sup-p-p-another-group-showed-that-certain-a-href-wiki-psychedelic-art-title-psychedelic-art-psychedelic-a-spectacles-could-fool-a-a-href-wiki-facial-recognition-system-title-facial-recognition-system-facial-recognition-system-a-into-thinking-ordinary-people-were-celebrities-potentially-allowing-one-person-to-impersonate-another-in-2017-researchers-added-stickers-to-a-href-wiki-stop-sign-title-stop-sign-stop-signs-a-and-caused-an-ann-to-misclassify-them-sup-id-cite-ref-4-204-1-class-reference-a-href-cite-note-4-204-204-a-sup-p-p-anns-can-however-be-further-trained-to-detect-attempts-at-deception-potentially-leading-attackers-and-defenders-into-an-arms-race-similar-to-the-kind-that-already-defines-the-a-href-wiki-malware-title-malware-malware-a-defense-industry-anns-have-been-trained-to-defeat-ann-based-anti-malware-software-by-repeatedly-attacking-a-defense-with-malware-that-was-continually-altered-by-a-a-href-wiki-genetic-algorithm-title-genetic-algorithm-genetic-algorithm-a-until-it-tricked-the-anti-malware-while-retaining-its-ability-to-damage-the-target-sup-id-cite-ref-4-204-2-class-reference-a-href-cite-note-4-204-204-a-sup-p-p-another-group-demonstrated-that-certain-sounds-could-make-the-a-href-wiki-google-now-title-google-now-google-now-a-voice-command-system-open-a-particular-web-address-that-would-download-malware-sup-id-cite-ref-4-204-3-class-reference-a-href-cite-note-4-204-204-a-sup-p-p-in-data-poisoning-false-data-is-continually-smuggled-into-a-machine-learning-systems-training-set-to-prevent-it-from-achieving-mastery-sup-id-cite-ref-4-204-4-class-reference-a-href-cite-note-4-204-204-a-sup-p-h2-span-class-mw-headline-id-see-also-see-also-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-30-title-edit-section-see-also-edit-a-span-class-mw-editsection-bracket-span-span-h2-ul-li-a-href-wiki-applications-of-artificial-intelligence-title-applications-of-artificial-intelligence-applications-of-artificial-intelligence-a-li-li-a-href-wiki-comparison-of-deep-learning-software-class-mw-redirect-title-comparison-of-deep-learning-software-comparison-of-deep-learning-software-a-li-li-a-href-wiki-compressed-sensing-title-compressed-sensing-compressed-sensing-a-li-li-a-href-wiki-echo-state-network-title-echo-state-network-echo-state-network-a-li-li-a-href-wiki-list-of-artificial-intelligence-projects-title-list-of-artificial-intelligence-projects-list-of-artificial-intelligence-projects-a-li-li-a-href-wiki-liquid-state-machine-title-liquid-state-machine-liquid-state-machine-a-li-li-a-href-wiki-list-of-datasets-for-machine-learning-research-class-mw-redirect-title-list-of-datasets-for-machine-learning-research-list-of-datasets-for-machine-learning-research-a-li-li-a-href-wiki-reservoir-computing-title-reservoir-computing-reservoir-computing-a-li-li-a-href-wiki-sparse-coding-class-mw-redirect-title-sparse-coding-sparse-coding-a-li-ul-h2-span-class-mw-headline-id-references-references-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-31-title-edit-section-references-edit-a-span-class-mw-editsection-bracket-span-span-h2-div-class-reflist-columns-references-column-width-style-moz-column-width-30em-webkit-column-width-30em-column-width-30em-list-style-type-decimal-ol-class-references-li-id-cite-note-bengio2012-1-span-class-mw-cite-backlink-a-href-cite-ref-bengio2012-1-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-bengio2012-1-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-bengio2012-1-2-sup-i-b-c-b-i-sup-a-a-href-cite-ref-bengio2012-1-3-sup-i-b-d-b-i-sup-a-a-href-cite-ref-bengio2012-1-4-sup-i-b-e-b-i-sup-a-a-href-cite-ref-bengio2012-1-5-sup-i-b-f-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-bengio-y-courville-a-vincent-p-2013-representation-learning-a-review-and-new-perspectives-i-ieee-transactions-on-pattern-analysis-and-machine-intelligence-i-b-35-b-8-1798-1828-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1206-5538-1206-5538-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftpami-2013-50-10-1109-tpami-2013-50-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-23787338-23787338-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-pattern-analysis-and-machine-intelligence-rft-atitle-representation-learning-3a-a-review-and-new-perspectives-rft-volume-35-rft-issue-8-rft-pages-1798-1828-rft-date-2013-rft-id-info-3aarxiv-2f1206-5538-rft-id-info-3apmid-2f23787338-rft-id-info-3adoi-2f10-1109-2ftpami-2013-50-rft-aulast-bengio-rft-aufirst-y-rft-au-courville-2c-a-rft-au-vincent-2c-p-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-style-data-mw-deduplicate-templatestyles-r886058088-mw-parser-output-cite-citation-font-style-inherit-mw-parser-output-citation-q-quotes-mw-parser-output-citation-cs1-lock-free-a-background-url-upload-wikimedia-org-wikipedia-commons-thumb-6-65-lock-green-svg-9px-lock-green-svg-png-no-repeat-background-position-right-1em-center-mw-parser-output-citation-cs1-lock-limited-a-mw-parser-output-citation-cs1-lock-registration-a-background-url-upload-wikimedia-org-wikipedia-commons-thumb-d-d6-lock-gray-alt-2-svg-9px-lock-gray-alt-2-svg-png-no-repeat-background-position-right-1em-center-mw-parser-output-citation-cs1-lock-subscription-a-background-url-upload-wikimedia-org-wikipedia-commons-thumb-a-aa-lock-red-alt-2-svg-9px-lock-red-alt-2-svg-png-no-repeat-background-position-right-1em-center-mw-parser-output-cs1-subscription-mw-parser-output-cs1-registration-color-555-mw-parser-output-cs1-subscription-span-mw-parser-output-cs1-registration-span-border-bottom-1px-dotted-cursor-help-mw-parser-output-cs1-ws-icon-a-background-url-upload-wikimedia-org-wikipedia-commons-thumb-4-4c-wikisource-logo-svg-12px-wikisource-logo-svg-png-no-repeat-background-position-right-1em-center-mw-parser-output-code-cs1-code-color-inherit-background-inherit-border-inherit-padding-inherit-mw-parser-output-cs1-hidden-error-display-none-font-size-100-mw-parser-output-cs1-visible-error-font-size-100-mw-parser-output-cs1-maint-display-none-color-33aa33-margin-left-0-3em-mw-parser-output-cs1-subscription-mw-parser-output-cs1-registration-mw-parser-output-cs1-format-font-size-95-mw-parser-output-cs1-kern-left-mw-parser-output-cs1-kern-wl-left-padding-left-0-2em-mw-parser-output-cs1-kern-right-mw-parser-output-cs1-kern-wl-right-padding-right-0-2em-style-span-li-li-id-cite-note-schidhub-2-span-class-mw-cite-backlink-a-href-cite-ref-schidhub-2-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-schidhub-2-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-schidhub-2-2-sup-i-b-c-b-i-sup-a-a-href-cite-ref-schidhub-2-3-sup-i-b-d-b-i-sup-a-a-href-cite-ref-schidhub-2-4-sup-i-b-e-b-i-sup-a-a-href-cite-ref-schidhub-2-5-sup-i-b-f-b-i-sup-a-a-href-cite-ref-schidhub-2-6-sup-i-b-g-b-i-sup-a-a-href-cite-ref-schidhub-2-7-sup-i-b-h-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-schmidhuber-j-2015-deep-learning-in-neural-networks-an-overview-i-neural-networks-i-b-61-b-85-117-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1404-7828-1404-7828-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-neunet-2014-09-003-10-1016-j-neunet-2014-09-003-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-25462637-25462637-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neural-networks-rft-atitle-deep-learning-in-neural-networks-3a-an-overview-rft-volume-61-rft-pages-85-117-rft-date-2015-rft-id-info-3aarxiv-2f1404-7828-rft-id-info-3apmid-2f25462637-rft-id-info-3adoi-2f10-1016-2fj-neunet-2014-09-003-rft-aulast-schmidhuber-rft-aufirst-j-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-naturebengio-3-span-class-mw-cite-backlink-b-a-href-cite-ref-naturebengio-3-0-a-b-span-span-class-reference-text-cite-class-citation-journal-bengio-yoshua-lecun-yann-hinton-geoffrey-2015-deep-learning-i-nature-i-b-521-b-7553-436-444-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2015natur-521-436l-2015natur-521-436l-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1038-2fnature14539-10-1038-nature14539-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-26017442-26017442-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-nature-rft-atitle-deep-learning-rft-volume-521-rft-issue-7553-rft-pages-436-444-rft-date-2015-rft-id-info-3apmid-2f26017442-rft-id-info-3adoi-2f10-1038-2fnature14539-rft-id-info-3abibcode-2f2015natur-521-436l-rft-aulast-bengio-rft-aufirst-yoshua-rft-au-lecun-2c-yann-rft-au-hinton-2c-geoffrey-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-9-4-span-class-mw-cite-backlink-a-href-cite-ref-9-4-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-9-4-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-ciresan-dan-meier-u-schmidhuber-j-june-2012-a-rel-nofollow-class-external-text-href-http-ieeexplore-ieee-org-document-6248110-multi-column-deep-neural-networks-for-image-classification-a-i-2012-ieee-conference-on-computer-vision-and-pattern-recognition-i-3642-3649-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1202-2745-1202-2745-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2fcvpr-2012-6248110-10-1109-cvpr-2012-6248110-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-1-4673-1228-8-title-special-booksources-978-1-4673-1228-8-bdi-978-1-4673-1228-8-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-2012-ieee-conference-on-computer-vision-and-pattern-recognition-rft-atitle-multi-column-deep-neural-networks-for-image-classification-rft-pages-3642-3649-rft-date-2012-06-rft-id-info-3aarxiv-2f1202-2745-rft-id-info-3adoi-2f10-1109-2fcvpr-2012-6248110-rft-isbn-978-1-4673-1228-8-rft-aulast-ciresan-rft-aufirst-dan-rft-au-meier-2c-u-rft-au-schmidhuber-2c-j-rft-id-http-3a-2f-2fieeexplore-ieee-org-2fdocument-2f6248110-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-krizhevsky2012-5-span-class-mw-cite-backlink-a-href-cite-ref-krizhevsky2012-5-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-krizhevsky2012-5-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-krizhevsky-alex-sutskever-ilya-hinton-geoffry-2012-a-rel-nofollow-class-external-text-href-https-www-cs-toronto-edu-kriz-imagenet-classification-with-deep-convolutional-pdf-imagenet-classification-with-deep-convolutional-neural-networks-a-span-class-cs1-format-pdf-span-i-nips-2012-neural-information-processing-systems-lake-tahoe-nevada-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-nips-2012-3a-neural-information-processing-systems-2c-lake-tahoe-2c-nevada-rft-atitle-imagenet-classification-with-deep-convolutional-neural-networks-rft-date-2012-rft-aulast-krizhevsky-rft-aufirst-alex-rft-au-sutskever-2c-ilya-rft-au-hinton-2c-geoffry-rft-id-https-3a-2f-2fwww-cs-toronto-edu-2f-kriz-2fimagenet-classification-with-deep-convolutional-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-6-span-class-mw-cite-backlink-b-a-href-cite-ref-6-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-techcrunch-com-2017-05-24-alphago-beats-planets-best-human-go-player-ke-jie-amp-google-s-alphago-ai-wins-three-match-series-against-the-world-s-best-go-player-a-i-techcrunch-i-25-may-2017-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-techcrunch-rft-atitle-google-27s-alphago-ai-wins-three-match-series-against-the-world-27s-best-go-player-rft-date-2017-05-25-rft-id-https-3a-2f-2ftechcrunch-com-2f2017-2f05-2f24-2falphago-beats-planets-best-human-go-player-ke-jie-2famp-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-7-span-class-mw-cite-backlink-b-a-href-cite-ref-7-a-b-span-span-class-reference-text-cite-class-citation-journal-marblestone-adam-h-wayne-greg-kording-konrad-p-2016-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc5021692-toward-an-integration-of-deep-learning-and-neuroscience-a-i-frontiers-in-computational-neuroscience-i-b-10-b-94-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-3389-2ffncom-2016-00094-10-3389-fncom-2016-00094-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc5021692-5021692-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-27683554-27683554-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-frontiers-in-computational-neuroscience-rft-atitle-toward-an-integration-of-deep-learning-and-neuroscience-rft-volume-10-rft-pages-94-rft-date-2016-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc5021692-rft-id-info-3apmid-2f27683554-rft-id-info-3adoi-2f10-3389-2ffncom-2016-00094-rft-aulast-marblestone-rft-aufirst-adam-h-rft-au-wayne-2c-greg-rft-au-kording-2c-konrad-p-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc5021692-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-8-span-class-mw-cite-backlink-b-a-href-cite-ref-8-a-b-span-span-class-reference-text-cite-class-citation-journal-olshausen-b-a-1996-emergence-of-simple-cell-receptive-field-properties-by-learning-a-sparse-code-for-natural-images-i-nature-i-b-381-b-6583-607-609-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-1996natur-381-607o-1996natur-381-607o-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1038-2f381607a0-10-1038-381607a0-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-8637596-8637596-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-nature-rft-atitle-emergence-of-simple-cell-receptive-field-properties-by-learning-a-sparse-code-for-natural-images-rft-volume-381-rft-issue-6583-rft-pages-607-609-rft-date-1996-rft-id-info-3apmid-2f8637596-rft-id-info-3adoi-2f10-1038-2f381607a0-rft-id-info-3abibcode-2f1996natur-381-607o-rft-aulast-olshausen-rft-aufirst-b-a-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-9-span-class-mw-cite-backlink-b-a-href-cite-ref-9-a-b-span-span-class-reference-text-cite-class-citation-arxiv-bengio-yoshua-lee-dong-hyun-bornschein-jorg-mesnard-thomas-lin-zhouhan-2015-02-13-towards-biologically-plausible-deep-learning-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1502-04156-1502-04156-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-lg-cs-lg-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-towards-biologically-plausible-deep-learning-rft-date-2015-02-13-rft-id-info-3aarxiv-2f1502-04156-rft-aulast-bengio-rft-aufirst-yoshua-rft-au-lee-2c-dong-hyun-rft-au-bornschein-2c-jorg-rft-au-mesnard-2c-thomas-rft-au-lin-2c-zhouhan-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-book2014-10-span-class-mw-cite-backlink-a-href-cite-ref-book2014-10-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-book2014-10-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-book2014-10-2-sup-i-b-c-b-i-sup-a-a-href-cite-ref-book2014-10-3-sup-i-b-d-b-i-sup-a-a-href-cite-ref-book2014-10-4-sup-i-b-e-b-i-sup-a-a-href-cite-ref-book2014-10-5-sup-i-b-f-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-deng-l-yu-d-2014-a-rel-nofollow-class-external-text-href-http-research-microsoft-com-pubs-209355-deeplearning-nowpublishing-vol7-sig-039-pdf-deep-learning-methods-and-applications-a-span-class-cs1-format-pdf-span-i-foundations-and-trends-in-signal-processing-i-b-7-b-3-4-1-199-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1561-2f2000000039-10-1561-2000000039-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-foundations-and-trends-in-signal-processing-rft-atitle-deep-learning-3a-methods-and-applications-rft-volume-7-rft-issue-3-e2-80-934-rft-pages-1-199-rft-date-2014-rft-id-info-3adoi-2f10-1561-2f2000000039-rft-aulast-deng-rft-aufirst-l-rft-au-yu-2c-d-rft-id-http-3a-2f-2fresearch-microsoft-com-2fpubs-2f209355-2fdeeplearning-nowpublishing-vol7-sig-039-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-bengiodeep-11-span-class-mw-cite-backlink-a-href-cite-ref-bengiodeep-11-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-bengiodeep-11-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-bengiodeep-11-2-sup-i-b-c-b-i-sup-a-a-href-cite-ref-bengiodeep-11-3-sup-i-b-d-b-i-sup-a-a-href-cite-ref-bengiodeep-11-4-sup-i-b-e-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-bengio-yoshua-2009-a-rel-nofollow-class-external-text-href-http-sanghv-com-download-soft-machine-20learning-20artificial-20intelligence-20mathematics-20ebooks-ml-learning-20deep-20architectures-20for-20ai-20-282009-29-pdf-learning-deep-architectures-for-ai-a-span-class-cs1-format-pdf-span-i-foundations-and-trends-in-machine-learning-i-b-2-b-1-1-127-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-701-9550-10-1-1-701-9550-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1561-2f2200000006-10-1561-2200000006-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-foundations-and-trends-in-machine-learning-rft-atitle-learning-deep-architectures-for-ai-rft-volume-2-rft-issue-1-rft-pages-1-127-rft-date-2009-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-701-9550-rft-id-info-3adoi-2f10-1561-2f2200000006-rft-aulast-bengio-rft-aufirst-yoshua-rft-id-http-3a-2f-2fsanghv-com-2fdownload-2fsoft-2fmachine-2520learning-2c-2520artificial-2520intelligence-2c-2520mathematics-2520ebooks-2fml-2flearning-2520deep-2520architectures-2520for-2520ai-2520-25282009-2529-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-12-span-class-mw-cite-backlink-b-a-href-cite-ref-12-a-b-span-span-class-reference-text-cite-class-citation-journal-lecun-yann-bengio-yoshua-hinton-geoffrey-28-may-2015-deep-learning-i-nature-i-b-521-b-7553-436-444-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2015natur-521-436l-2015natur-521-436l-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1038-2fnature14539-10-1038-nature14539-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-26017442-26017442-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-nature-rft-atitle-deep-learning-rft-volume-521-rft-issue-7553-rft-pages-436-444-rft-date-2015-05-28-rft-id-info-3apmid-2f26017442-rft-id-info-3adoi-2f10-1038-2fnature14539-rft-id-info-3abibcode-2f2015natur-521-436l-rft-aulast-lecun-rft-aufirst-yann-rft-au-bengio-2c-yoshua-rft-au-hinton-2c-geoffrey-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-scholarpedia-13-span-class-mw-cite-backlink-a-href-cite-ref-scholarpedia-13-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-scholarpedia-13-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-jurgen-schmidhuber-2015-deep-learning-scholarpedia-10-11-32832-a-rel-nofollow-class-external-text-href-http-www-scholarpedia-org-article-deep-learning-online-a-span-li-li-id-cite-note-scholardbns-14-span-class-mw-cite-backlink-a-href-cite-ref-scholardbns-14-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-scholardbns-14-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-scholardbns-14-2-sup-i-b-c-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-hinton-g-e-2009-deep-belief-networks-i-scholarpedia-i-b-4-b-5-5947-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2009schpj-4-5947h-2009schpj-4-5947h-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-4249-2fscholarpedia-5947-10-4249-scholarpedia-5947-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-scholarpedia-rft-atitle-deep-belief-networks-rft-volume-4-rft-issue-5-rft-pages-5947-rft-date-2009-rft-id-info-3adoi-2f10-4249-2fscholarpedia-5947-rft-id-info-3abibcode-2f2009schpj-4-5947h-rft-aulast-hinton-rft-aufirst-g-e-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-referenceb-15-span-class-mw-cite-backlink-a-href-cite-ref-referenceb-15-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-referenceb-15-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-balazs-csanad-csaji-2001-approximation-with-artificial-neural-networks-faculty-of-sciences-eotvos-lorand-university-hungary-span-li-li-id-cite-note-cyb-16-span-class-mw-cite-backlink-a-href-cite-ref-cyb-16-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-cyb-16-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-cyb-16-2-sup-i-b-c-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-cybenko-1989-a-rel-nofollow-class-external-text-href-https-web-archive-org-web-20151010204407-http-deeplearning-cs-cmu-edu-pdfs-cybenko-pdf-approximations-by-superpositions-of-sigmoidal-functions-a-span-class-cs1-format-pdf-span-i-a-href-wiki-mathematics-of-control-signals-and-systems-title-mathematics-of-control-signals-and-systems-mathematics-of-control-signals-and-systems-a-i-b-2-b-4-303-314-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fbf02551274-10-1007-bf02551274-a-archived-from-a-rel-nofollow-class-external-text-href-http-deeplearning-cs-cmu-edu-pdfs-cybenko-pdf-the-original-a-span-class-cs1-format-pdf-span-on-2015-10-10-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-mathematics-of-control-2c-signals-2c-and-systems-rft-atitle-approximations-by-superpositions-of-sigmoidal-functions-rft-volume-2-rft-issue-4-rft-pages-303-314-rft-date-1989-rft-id-info-3adoi-2f10-1007-2fbf02551274-rft-au-cybenko-rft-id-http-3a-2f-2fdeeplearning-cs-cmu-edu-2fpdfs-2fcybenko-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-horn-17-span-class-mw-cite-backlink-a-href-cite-ref-horn-17-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-horn-17-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-horn-17-2-sup-i-b-c-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-hornik-kurt-1991-approximation-capabilities-of-multilayer-feedforward-networks-i-neural-networks-i-b-4-b-2-251-257-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2f0893-6080-2891-2990009-t-10-1016-0893-6080-91-90009-t-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neural-networks-rft-atitle-approximation-capabilities-of-multilayer-feedforward-networks-rft-volume-4-rft-issue-2-rft-pages-251-257-rft-date-1991-rft-id-info-3adoi-2f10-1016-2f0893-6080-2891-2990009-t-rft-aulast-hornik-rft-aufirst-kurt-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-haykin-simon-1998-18-span-class-mw-cite-backlink-a-href-cite-ref-haykin-simon-1998-18-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-haykin-simon-1998-18-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-book-haykin-simon-s-1999-a-rel-nofollow-class-external-text-href-https-books-google-com-books-id-bx4paqaamaaj-i-neural-networks-a-comprehensive-foundation-i-a-prentice-hall-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-0-13-273350-2-title-special-booksources-978-0-13-273350-2-bdi-978-0-13-273350-2-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-neural-networks-3a-a-comprehensive-foundation-rft-pub-prentice-hall-rft-date-1999-rft-isbn-978-0-13-273350-2-rft-aulast-haykin-rft-aufirst-simon-s-rft-id-https-3a-2f-2fbooks-google-com-2fbooks-3fid-3dbx4paqaamaaj-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-hassoun-m-1995-p-48-19-span-class-mw-cite-backlink-a-href-cite-ref-hassoun-m-1995-p-48-19-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-hassoun-m-1995-p-48-19-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-book-hassoun-mohamad-h-1995-a-rel-nofollow-class-external-text-href-https-books-google-com-books-id-otk32y3qkxqc-pg-pa48-i-fundamentals-of-artificial-neural-networks-i-a-mit-press-p-48-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-0-262-08239-6-title-special-booksources-978-0-262-08239-6-bdi-978-0-262-08239-6-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-fundamentals-of-artificial-neural-networks-rft-pages-48-rft-pub-mit-press-rft-date-1995-rft-isbn-978-0-262-08239-6-rft-aulast-hassoun-rft-aufirst-mohamad-h-rft-id-https-3a-2f-2fbooks-google-com-2fbooks-3fid-3dotk32y3qkxqc-26pg-3dpa48-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-zhoulu-20-span-class-mw-cite-backlink-a-href-cite-ref-zhoulu-20-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-zhoulu-20-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-lu-z-pu-h-wang-f-hu-z-wang-l-2017-a-rel-nofollow-class-external-text-href-http-papers-nips-cc-paper-7203-the-expressive-power-of-neural-networks-a-view-from-the-width-the-expressive-power-of-neural-networks-a-view-from-the-width-a-neural-information-processing-systems-6231-6239-span-li-li-id-cite-note-murphy-21-span-class-mw-cite-backlink-a-href-cite-ref-murphy-21-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-murphy-21-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-murphy-21-2-sup-i-b-c-b-i-sup-a-a-href-cite-ref-murphy-21-3-sup-i-b-d-b-i-sup-a-span-span-class-reference-text-cite-class-citation-book-murphy-kevin-p-24-august-2012-a-rel-nofollow-class-external-text-href-https-books-google-com-books-id-nzp6aqaaqbaj-i-machine-learning-a-probabilistic-perspective-i-a-mit-press-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-0-262-01802-9-title-special-booksources-978-0-262-01802-9-bdi-978-0-262-01802-9-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-machine-learning-3a-a-probabilistic-perspective-rft-pub-mit-press-rft-date-2012-08-24-rft-isbn-978-0-262-01802-9-rft-aulast-murphy-rft-aufirst-kevin-p-rft-id-https-3a-2f-2fbooks-google-com-2fbooks-3fid-3dnzp6aqaaqbaj-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-patel-nips-2016-22-span-class-mw-cite-backlink-b-a-href-cite-ref-patel-nips-2016-22-0-a-b-span-span-class-reference-text-cite-class-citation-journal-patel-ankit-nguyen-tan-baraniuk-richard-2016-a-rel-nofollow-class-external-text-href-https-papers-nips-cc-paper-6231-a-probabilistic-framework-for-deep-learning-pdf-a-probabilistic-framework-for-deep-learning-a-span-class-cs1-format-pdf-span-i-advances-in-neural-information-processing-systems-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-advances-in-neural-information-processing-systems-rft-atitle-a-probabilistic-framework-for-deep-learning-rft-date-2016-rft-aulast-patel-rft-aufirst-ankit-rft-au-nguyen-2c-tan-rft-au-baraniuk-2c-richard-rft-id-https-3a-2f-2fpapers-nips-cc-2fpaper-2f6231-a-probabilistic-framework-for-deep-learning-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-dropout-23-span-class-mw-cite-backlink-b-a-href-cite-ref-dropout-23-0-a-b-span-span-class-reference-text-cite-class-citation-arxiv-hinton-g-e-srivastava-n-krizhevsky-a-sutskever-i-salakhutdinov-r-r-2012-improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1207-0580-1207-0580-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-math-lg-math-lg-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors-rft-date-2012-rft-id-info-3aarxiv-2f1207-0580-rft-aulast-hinton-rft-aufirst-g-e-rft-au-srivastava-2c-n-rft-au-krizhevsky-2c-a-rft-au-sutskever-2c-i-rft-au-salakhutdinov-2c-r-r-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-prml-24-span-class-mw-cite-backlink-b-a-href-cite-ref-prml-24-0-a-b-span-span-class-reference-text-cite-class-citation-book-bishop-christopher-m-2006-a-rel-nofollow-class-external-text-href-http-users-isr-ist-utl-pt-wurmd-livros-school-bishop-20-20pattern-20recognition-20and-20machine-20learning-20-20springer-20-202006-pdf-i-pattern-recognition-and-machine-learning-i-a-span-class-cs1-format-pdf-span-springer-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-0-387-31073-2-title-special-booksources-978-0-387-31073-2-bdi-978-0-387-31073-2-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-pattern-recognition-and-machine-learning-rft-pub-springer-rft-date-2006-rft-isbn-978-0-387-31073-2-rft-au-bishop-2c-christopher-m-rft-id-http-3a-2f-2fusers-isr-ist-utl-pt-2f-wurmd-2flivros-2fschool-2fbishop-2520-2520pattern-2520recognition-2520and-2520machine-2520learning-2520-2520springer-2520-25202006-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-dechter1986-25-span-class-mw-cite-backlink-b-a-href-cite-ref-dechter1986-25-0-a-b-span-span-class-reference-text-a-href-wiki-rina-dechter-title-rina-dechter-rina-dechter-a-1986-learning-while-searching-in-constraint-satisfaction-problems-university-of-california-computer-science-department-cognitive-systems-laboratory-a-rel-nofollow-class-external-text-href-https-www-researchgate-net-publication-221605378-learning-while-searching-in-constraint-satisfaction-problems-online-a-span-li-li-id-cite-note-aizenberg2000-26-span-class-mw-cite-backlink-b-a-href-cite-ref-aizenberg2000-26-0-a-b-span-span-class-reference-text-igor-aizenberg-naum-n-aizenberg-joos-p-l-vandewalle-2000-multi-valued-and-universal-binary-neurons-theory-learning-and-applications-springer-science-business-media-span-li-li-id-cite-note-27-span-class-mw-cite-backlink-b-a-href-cite-ref-27-a-b-span-span-class-reference-text-co-evolving-recurrent-neurons-learn-deep-memory-pomdps-proc-gecco-washington-d-c-pp-1795-1802-acm-press-new-york-ny-usa-2005-span-li-li-id-cite-note-ivak1965-28-span-class-mw-cite-backlink-b-a-href-cite-ref-ivak1965-28-0-a-b-span-span-class-reference-text-cite-class-citation-book-ivakhnenko-a-g-1973-a-rel-nofollow-class-external-text-href-https-books-google-com-books-id-fhwvnqaacaaj-i-cybernetic-predicting-devices-i-a-ccm-information-corporation-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-cybernetic-predicting-devices-rft-pub-ccm-information-corporation-rft-date-1973-rft-aulast-ivakhnenko-rft-aufirst-a-g-rft-id-https-3a-2f-2fbooks-google-com-2fbooks-3fid-3dfhwvnqaacaaj-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-ivak1971-29-span-class-mw-cite-backlink-a-href-cite-ref-ivak1971-29-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-ivak1971-29-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-ivakhnenko-alexey-1971-polynomial-theory-of-complex-systems-i-ieee-transactions-on-systems-man-and-cybernetics-i-b-1-b-4-364-378-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftsmc-1971-4308320-10-1109-tsmc-1971-4308320-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-systems-2c-man-and-cybernetics-rft-atitle-polynomial-theory-of-complex-systems-rft-volume-1-rft-issue-4-rft-pages-364-378-rft-date-1971-rft-id-info-3adoi-2f10-1109-2ftsmc-1971-4308320-rft-aulast-ivakhnenko-rft-aufirst-alexey-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-fuku1980-30-span-class-mw-cite-backlink-b-a-href-cite-ref-fuku1980-30-0-a-b-span-span-class-reference-text-cite-class-citation-journal-fukushima-k-1980-neocognitron-a-self-organizing-neural-network-model-for-a-mechanism-of-pattern-recognition-unaffected-by-shift-in-position-i-biol-cybern-i-b-36-b-4-193-202-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fbf00344251-10-1007-bf00344251-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-7370364-7370364-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-biol-cybern-rft-atitle-neocognitron-3a-a-self-organizing-neural-network-model-for-a-mechanism-of-pattern-recognition-unaffected-by-shift-in-position-rft-volume-36-rft-issue-4-rft-pages-193-202-rft-date-1980-rft-id-info-3adoi-2f10-1007-2fbf00344251-rft-id-info-3apmid-2f7370364-rft-aulast-fukushima-rft-aufirst-k-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-lin1970-31-span-class-mw-cite-backlink-b-a-href-cite-ref-lin1970-31-0-a-b-span-span-class-reference-text-a-href-wiki-seppo-linnainmaa-title-seppo-linnainmaa-seppo-linnainmaa-a-1970-the-representation-of-the-cumulative-rounding-error-of-an-algorithm-as-a-taylor-expansion-of-the-local-rounding-errors-master-s-thesis-in-finnish-univ-helsinki-6-7-span-li-li-id-cite-note-grie2012-32-span-class-mw-cite-backlink-b-a-href-cite-ref-grie2012-32-0-a-b-span-span-class-reference-text-cite-class-citation-journal-griewank-andreas-2012-a-rel-nofollow-class-external-text-href-http-www-math-uiuc-edu-documenta-vol-ismp-52-griewank-andreas-b-pdf-who-invented-the-reverse-mode-of-differentiation-a-span-class-cs1-format-pdf-span-i-documenta-matematica-i-extra-volume-ismp-389-400-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-documenta-matematica-rft-atitle-who-invented-the-reverse-mode-of-differentiation-3f-rft-issue-extra-volume-ismp-rft-pages-389-400-rft-date-2012-rft-aulast-griewank-rft-aufirst-andreas-rft-id-http-3a-2f-2fwww-math-uiuc-edu-2fdocumenta-2fvol-ismp-2f52-griewank-andreas-b-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-werbos1974-33-span-class-mw-cite-backlink-b-a-href-cite-ref-werbos1974-33-0-a-b-span-span-class-reference-text-cite-class-citation-journal-werbos-p-1974-a-rel-nofollow-class-external-text-href-https-www-researchgate-net-publication-35657389-beyond-regression-new-tools-for-prediction-and-analysis-in-the-behavioral-sciences-a-i-harvard-university-i-span-class-reference-accessdate-retrieved-span-class-nowrap-12-june-span-2017-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-harvard-university-rft-atitle-beyond-regression-3a-new-tools-for-prediction-and-analysis-in-the-behavioral-sciences-rft-date-1974-rft-aulast-werbos-rft-aufirst-p-rft-id-https-3a-2f-2fwww-researchgate-net-2fpublication-2f35657389-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-werbos1982-34-span-class-mw-cite-backlink-b-a-href-cite-ref-werbos1982-34-0-a-b-span-span-class-reference-text-cite-class-citation-book-werbos-paul-1982-a-rel-nofollow-class-external-text-href-ftp-ftp-idsia-ch-pub-juergen-habilitation-pdf-applications-of-advances-in-nonlinear-sensitivity-analysis-a-span-class-cs1-format-pdf-span-i-system-modeling-and-optimization-i-springer-pp-762-770-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-bookitem-rft-atitle-applications-of-advances-in-nonlinear-sensitivity-analysis-rft-btitle-system-modeling-and-optimization-rft-pages-762-770-rft-pub-springer-rft-date-1982-rft-aulast-werbos-rft-aufirst-paul-rft-id-ftp-3a-2f-2fftp-idsia-ch-2fpub-2fjuergen-2fhabilitation-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-lecun1989-35-span-class-mw-cite-backlink-a-href-cite-ref-lecun1989-35-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-lecun1989-35-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-lecun-i-et-al-i-backpropagation-applied-to-handwritten-zip-code-recognition-i-neural-computation-i-1-pp-541-551-1989-span-li-li-id-cite-note-weng1992-36-span-class-mw-cite-backlink-b-a-href-cite-ref-weng1992-36-0-a-b-span-span-class-reference-text-j-weng-n-ahuja-and-t-s-huang-a-rel-nofollow-class-external-text-href-http-www-cse-msu-edu-weng-research-cresceptronijcnn1992-pdf-cresceptron-a-self-organizing-neural-network-which-grows-adaptively-a-i-proc-international-joint-conference-on-neural-networks-i-baltimore-maryland-vol-i-pp-576-581-june-1992-span-li-li-id-cite-note-weng1993-37-span-class-mw-cite-backlink-b-a-href-cite-ref-weng1993-37-0-a-b-span-span-class-reference-text-j-weng-n-ahuja-and-t-s-huang-a-rel-nofollow-class-external-text-href-http-www-cse-msu-edu-weng-research-cresceptroniccv1993-pdf-learning-recognition-and-segmentation-of-3-d-objects-from-2-d-images-a-i-proc-4th-international-conf-computer-vision-i-berlin-germany-pp-121-128-may-1993-span-li-li-id-cite-note-weng1997-38-span-class-mw-cite-backlink-b-a-href-cite-ref-weng1997-38-0-a-b-span-span-class-reference-text-j-weng-n-ahuja-and-t-s-huang-a-rel-nofollow-class-external-text-href-http-www-cse-msu-edu-weng-research-cresceptronijcv-pdf-learning-recognition-and-segmentation-using-the-cresceptron-a-i-international-journal-of-computer-vision-i-vol-25-no-2-pp-105-139-nov-1997-span-li-li-id-cite-note-39-span-class-mw-cite-backlink-b-a-href-cite-ref-39-a-b-span-span-class-reference-text-cite-class-citation-journal-de-carvalho-andre-c-l-f-fairhurst-mike-c-bisset-david-1994-08-08-an-integrated-boolean-neural-network-for-pattern-classification-i-pattern-recognition-letters-i-b-15-b-8-807-813-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2f0167-8655-2894-2990009-4-10-1016-0167-8655-94-90009-4-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-pattern-recognition-letters-rft-atitle-an-integrated-boolean-neural-network-for-pattern-classification-rft-volume-15-rft-issue-8-rft-pages-807-813-rft-date-1994-08-08-rft-id-info-3adoi-2f10-1016-2f0167-8655-2894-2990009-4-rft-aulast-de-carvalho-rft-aufirst-andre-c-l-f-rft-au-fairhurst-2c-mike-c-rft-au-bisset-2c-david-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-40-span-class-mw-cite-backlink-b-a-href-cite-ref-40-a-b-span-span-class-reference-text-cite-class-citation-journal-hinton-geoffrey-e-dayan-peter-frey-brendan-j-neal-radford-1995-05-26-the-wake-sleep-algorithm-for-unsupervised-neural-networks-i-science-i-b-268-b-5214-1158-1161-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-1995sci-268-1158h-1995sci-268-1158h-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1126-2fscience-7761831-10-1126-science-7761831-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-science-rft-atitle-the-wake-sleep-algorithm-for-unsupervised-neural-networks-rft-volume-268-rft-issue-5214-rft-pages-1158-1161-rft-date-1995-05-26-rft-id-info-3adoi-2f10-1126-2fscience-7761831-rft-id-info-3abibcode-2f1995sci-268-1158h-rft-aulast-hinton-rft-aufirst-geoffrey-e-rft-au-dayan-2c-peter-rft-au-frey-2c-brendan-j-rft-au-neal-2c-radford-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-hoch1991-41-span-class-mw-cite-backlink-a-href-cite-ref-hoch1991-41-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-hoch1991-41-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-s-hochreiter-a-rel-nofollow-class-external-text-href-http-people-idsia-ch-juergen-sepphochreiter1991thesisadvisorschmidhuber-pdf-untersuchungen-zu-dynamischen-neuronalen-netzen-a-i-diploma-thesis-institut-f-informatik-technische-univ-munich-advisor-j-schmidhuber-i-1991-span-li-li-id-cite-note-hoch2001-42-span-class-mw-cite-backlink-b-a-href-cite-ref-hoch2001-42-0-a-b-span-span-class-reference-text-cite-class-citation-book-hochreiter-s-et-al-15-january-2001-a-rel-nofollow-class-external-text-href-https-books-google-com-books-id-nwocmva64aac-gradient-flow-in-recurrent-nets-the-difficulty-of-learning-long-term-dependencies-a-in-kolen-john-f-kremer-stefan-c-eds-i-a-field-guide-to-dynamical-recurrent-networks-i-john-wiley-sons-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-0-7803-5369-5-title-special-booksources-978-0-7803-5369-5-bdi-978-0-7803-5369-5-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-bookitem-rft-atitle-gradient-flow-in-recurrent-nets-3a-the-difficulty-of-learning-long-term-dependencies-rft-btitle-a-field-guide-to-dynamical-recurrent-networks-rft-pub-john-wiley-26-sons-rft-date-2001-01-15-rft-isbn-978-0-7803-5369-5-rft-aulast-hochreiter-rft-aufirst-s-rft-id-https-3a-2f-2fbooks-google-com-2fbooks-3fid-3dnwocmva64aac-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-43-span-class-mw-cite-backlink-b-a-href-cite-ref-43-a-b-span-span-class-reference-text-cite-class-citation-journal-morgan-nelson-bourlard-herve-renals-steve-cohen-michael-franco-horacio-1993-08-01-hybrid-neural-network-hidden-markov-model-systems-for-continuous-speech-recognition-i-international-journal-of-pattern-recognition-and-artificial-intelligence-i-b-07-b-4-899-916-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1142-2fs0218001493000455-10-1142-s0218001493000455-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-0218-0014-0218-0014-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-international-journal-of-pattern-recognition-and-artificial-intelligence-rft-atitle-hybrid-neural-network-2fhidden-markov-model-systems-for-continuous-speech-recognition-rft-volume-07-rft-issue-4-rft-pages-899-916-rft-date-1993-08-01-rft-id-info-3adoi-2f10-1142-2fs0218001493000455-rft-issn-0218-0014-rft-aulast-morgan-rft-aufirst-nelson-rft-au-bourlard-2c-herv-c3-a9-rft-au-renals-2c-steve-rft-au-cohen-2c-michael-rft-au-franco-2c-horacio-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-robinson1992-44-span-class-mw-cite-backlink-b-a-href-cite-ref-robinson1992-44-0-a-b-span-span-class-reference-text-cite-class-citation-journal-a-href-wiki-tony-robinson-speech-recognition-title-tony-robinson-speech-recognition-robinson-t-a-1992-a-rel-nofollow-class-external-text-href-http-dl-acm-org-citation-cfm-id-1895720-a-real-time-recurrent-error-propagation-network-word-recognition-system-a-i-icassp-i-617-620-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-icassp-rft-atitle-a-real-time-recurrent-error-propagation-network-word-recognition-system-rft-pages-617-620-rft-date-1992-rft-aulast-robinson-rft-aufirst-t-rft-id-http-3a-2f-2fdl-acm-org-2fcitation-cfm-3fid-3d1895720-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-45-span-class-mw-cite-backlink-b-a-href-cite-ref-45-a-b-span-span-class-reference-text-cite-class-citation-journal-waibel-a-hanazawa-t-hinton-g-shikano-k-lang-k-j-march-1989-phoneme-recognition-using-time-delay-neural-networks-i-ieee-transactions-on-acoustics-speech-and-signal-processing-i-b-37-b-3-328-339-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2f29-21701-10-1109-29-21701-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-0096-3518-0096-3518-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-acoustics-2c-speech-2c-and-signal-processing-rft-atitle-phoneme-recognition-using-time-delay-neural-networks-rft-volume-37-rft-issue-3-rft-pages-328-339-rft-date-1989-03-rft-id-info-3adoi-2f10-1109-2f29-21701-rft-issn-0096-3518-rft-aulast-waibel-rft-aufirst-a-rft-au-hanazawa-2c-t-rft-au-hinton-2c-g-rft-au-shikano-2c-k-rft-au-lang-2c-k-j-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-baker2009-46-span-class-mw-cite-backlink-b-a-href-cite-ref-baker2009-46-0-a-b-span-span-class-reference-text-cite-class-citation-journal-baker-j-deng-li-glass-jim-khudanpur-s-lee-c-h-morgan-n-o-shaughnessy-d-2009-research-developments-and-directions-in-speech-recognition-and-understanding-part-1-i-ieee-signal-processing-magazine-i-b-26-b-3-75-80-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2009ispm-26-75b-2009ispm-26-75b-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2fmsp-2009-932166-10-1109-msp-2009-932166-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-signal-processing-magazine-rft-atitle-research-developments-and-directions-in-speech-recognition-and-understanding-2c-part-1-rft-volume-26-rft-issue-3-rft-pages-75-80-rft-date-2009-rft-id-info-3adoi-2f10-1109-2fmsp-2009-932166-rft-id-info-3abibcode-2f2009ispm-26-75b-rft-aulast-baker-rft-aufirst-j-rft-au-deng-2c-li-rft-au-glass-2c-jim-rft-au-khudanpur-2c-s-rft-au-lee-2c-c-h-rft-au-morgan-2c-n-rft-au-o-27shaughnessy-2c-d-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-bengio1991-47-span-class-mw-cite-backlink-b-a-href-cite-ref-bengio1991-47-0-a-b-span-span-class-reference-text-cite-class-citation-web-bengio-y-1991-a-rel-nofollow-class-external-text-href-https-www-researchgate-net-publication-41229141-artificial-neural-networks-and-their-application-to-speech-sequence-recognition-a-mcgill-university-ph-d-thesis-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-artificial-neural-networks-and-their-application-to-speech-2fsequence-recognition-rft-pub-mcgill-university-ph-d-thesis-rft-date-1991-rft-aulast-bengio-rft-aufirst-y-rft-id-https-3a-2f-2fwww-researchgate-net-2fpublication-2f41229141-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-deng1994-48-span-class-mw-cite-backlink-b-a-href-cite-ref-deng1994-48-0-a-b-span-span-class-reference-text-cite-class-citation-journal-deng-l-hassanein-k-elmasry-m-1994-analysis-of-correlation-structure-for-a-neural-predictive-model-with-applications-to-speech-recognition-i-neural-networks-i-b-7-b-2-331-339-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2f0893-6080-2894-2990027-2-10-1016-0893-6080-94-90027-2-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neural-networks-rft-atitle-analysis-of-correlation-structure-for-a-neural-predictive-model-with-applications-to-speech-recognition-rft-volume-7-rft-issue-2-rft-pages-331-339-rft-date-1994-rft-id-info-3adoi-2f10-1016-2f0893-6080-2894-2990027-2-rft-aulast-deng-rft-aufirst-l-rft-au-hassanein-2c-k-rft-au-elmasry-2c-m-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-heck2000-49-span-class-mw-cite-backlink-a-href-cite-ref-heck2000-49-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-heck2000-49-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-heck-l-konig-y-sonmez-m-weintraub-m-2000-robustness-to-telephone-handset-distortion-in-speaker-recognition-by-discriminative-feature-design-i-speech-communication-i-b-31-b-2-181-192-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fs0167-6393-2899-2900077-1-10-1016-s0167-6393-99-00077-1-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-speech-communication-rft-atitle-robustness-to-telephone-handset-distortion-in-speaker-recognition-by-discriminative-feature-design-rft-volume-31-rft-issue-2-rft-pages-181-192-rft-date-2000-rft-id-info-3adoi-2f10-1016-2fs0167-6393-2899-2900077-1-rft-aulast-heck-rft-aufirst-l-rft-au-konig-2c-y-rft-au-sonmez-2c-m-rft-au-weintraub-2c-m-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-50-span-class-mw-cite-backlink-b-a-href-cite-ref-50-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-researchgate-net-publication-266030526-acoustic-modeling-with-deep-neural-networks-using-raw-time-signal-for-lvcsr-pdf-download-available-a-i-researchgate-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2017-06-14-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-researchgate-rft-atitle-acoustic-modeling-with-deep-neural-networks-using-raw-time-signal-for-lvcsr-28pdf-download-available-29-rft-id-https-3a-2f-2fwww-researchgate-net-2fpublication-2f266030526-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-0-51-span-class-mw-cite-backlink-a-href-cite-ref-0-51-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-0-51-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-0-51-2-sup-i-b-c-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-hochreiter-sepp-schmidhuber-jurgen-1997-11-01-long-short-term-memory-i-neural-computation-i-b-9-b-8-1735-1780-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1162-2fneco-1997-9-8-1735-10-1162-neco-1997-9-8-1735-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-0899-7667-0899-7667-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-9377276-9377276-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neural-computation-rft-atitle-long-short-term-memory-rft-volume-9-rft-issue-8-rft-pages-1735-1780-rft-date-1997-11-01-rft-issn-0899-7667-rft-id-info-3apmid-2f9377276-rft-id-info-3adoi-2f10-1162-2fneco-1997-9-8-1735-rft-aulast-hochreiter-rft-aufirst-sepp-rft-au-schmidhuber-2c-j-c3-bcrgen-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-graves2003-52-span-class-mw-cite-backlink-a-href-cite-ref-graves2003-52-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-graves2003-52-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-web-graves-alex-eck-douglas-beringer-nicole-schmidhuber-jurgen-2003-a-rel-nofollow-class-external-text-href-ftp-ftp-idsia-ch-pub-juergen-bioadit2004-pdf-biologically-plausible-speech-recognition-with-lstm-neural-nets-a-span-class-cs1-format-pdf-span-i-1st-intl-workshop-on-biologically-inspired-approaches-to-advanced-information-technology-bio-adit-2004-lausanne-switzerland-i-pp-175-184-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-1st-intl-workshop-on-biologically-inspired-approaches-to-advanced-information-technology-2c-bio-adit-2004-2c-lausanne-2c-switzerland-rft-atitle-biologically-plausible-speech-recognition-with-lstm-neural-nets-rft-pages-175-184-rft-date-2003-rft-aulast-graves-rft-aufirst-alex-rft-au-eck-2c-douglas-rft-au-beringer-2c-nicole-rft-au-schmidhuber-2c-j-c3-bcrgen-rft-id-ftp-3a-2f-2fftp-idsia-ch-2fpub-2fjuergen-2fbioadit2004-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-1-53-span-class-mw-cite-backlink-a-href-cite-ref-1-53-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-1-53-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-graves-alex-fernandez-santiago-gomez-faustino-2006-connectionist-temporal-classification-labelling-unsegmented-sequence-data-with-recurrent-neural-networks-i-proceedings-of-the-international-conference-on-machine-learning-icml-2006-i-369-376-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-75-6306-10-1-1-75-6306-a-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-proceedings-of-the-international-conference-on-machine-learning-2c-icml-2006-rft-atitle-connectionist-temporal-classification-3a-labelling-unsegmented-sequence-data-with-recurrent-neural-networks-rft-pages-369-376-rft-date-2006-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-75-6306-rft-aulast-graves-rft-aufirst-alex-rft-au-fern-c3-a1ndez-2c-santiago-rft-au-gomez-2c-faustino-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-fernandez2007keyword-54-span-class-mw-cite-backlink-b-a-href-cite-ref-fernandez2007keyword-54-0-a-b-span-span-class-reference-text-santiago-fernandez-alex-graves-and-jurgen-schmidhuber-2007-a-rel-nofollow-class-external-text-href-https-mediatum-ub-tum-de-doc-1289941-file-pdf-an-application-of-recurrent-neural-networks-to-discriminative-keyword-spotting-a-proceedings-of-icann-2-pp-220-229-span-li-li-id-cite-note-sak2015-55-span-class-mw-cite-backlink-a-href-cite-ref-sak2015-55-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-sak2015-55-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-web-sak-hasim-senior-andrew-rao-kanishka-beaufays-francoise-schalkwyk-johan-september-2015-a-rel-nofollow-class-external-text-href-http-googleresearch-blogspot-ch-2015-09-google-voice-search-faster-and-more-html-google-voice-search-faster-and-more-accurate-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-google-voice-search-3a-faster-and-more-accurate-rft-date-2015-09-rft-aulast-sak-rft-aufirst-ha-c5-9fim-rft-au-senior-2c-andrew-rft-au-rao-2c-kanishka-rft-au-beaufays-2c-fran-c3-a7oise-rft-au-schalkwyk-2c-johan-rft-id-http-3a-2f-2fgoogleresearch-blogspot-ch-2f2015-2f09-2fgoogle-voice-search-faster-and-more-html-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-56-span-class-mw-cite-backlink-b-a-href-cite-ref-56-a-b-span-span-class-reference-text-cite-class-citation-journal-hinton-geoffrey-e-2007-10-01-a-rel-nofollow-class-external-text-href-http-www-cell-com-trends-cognitive-sciences-abstract-s1364-6613-07-00217-3-learning-multiple-layers-of-representation-a-i-trends-in-cognitive-sciences-i-b-11-b-10-428-434-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-tics-2007-09-004-10-1016-j-tics-2007-09-004-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-1364-6613-1364-6613-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-17921042-17921042-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-trends-in-cognitive-sciences-rft-atitle-learning-multiple-layers-of-representation-rft-volume-11-rft-issue-10-rft-pages-428-434-rft-date-2007-10-01-rft-issn-1364-6613-rft-id-info-3apmid-2f17921042-rft-id-info-3adoi-2f10-1016-2fj-tics-2007-09-004-rft-aulast-hinton-rft-aufirst-geoffrey-e-rft-id-http-3a-2f-2fwww-cell-com-2ftrends-2fcognitive-sciences-2fabstract-2fs1364-6613-2807-2900217-3-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-hinton06-57-span-class-mw-cite-backlink-b-a-href-cite-ref-hinton06-57-0-a-b-span-span-class-reference-text-cite-class-citation-journal-a-href-wiki-geoff-hinton-class-mw-redirect-title-geoff-hinton-hinton-g-e-a-osindero-s-teh-y-w-2006-a-rel-nofollow-class-external-text-href-http-www-cs-toronto-edu-hinton-absps-fastnc-pdf-a-fast-learning-algorithm-for-deep-belief-nets-a-span-class-cs1-format-pdf-span-i-a-href-wiki-neural-computation-journal-title-neural-computation-journal-neural-computation-a-i-b-18-b-7-1527-1554-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1162-2fneco-2006-18-7-1527-10-1162-neco-2006-18-7-1527-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-16764513-16764513-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neural-computation-rft-atitle-a-fast-learning-algorithm-for-deep-belief-nets-rft-volume-18-rft-issue-7-rft-pages-1527-1554-rft-date-2006-rft-id-info-3adoi-2f10-1162-2fneco-2006-18-7-1527-rft-id-info-3apmid-2f16764513-rft-aulast-hinton-rft-aufirst-g-e-rft-au-osindero-2c-s-rft-au-teh-2c-y-w-rft-id-http-3a-2f-2fwww-cs-toronto-edu-2f-hinton-2fabsps-2ffastnc-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-bengio2012-58-span-class-mw-cite-backlink-b-a-href-cite-ref-bengio2012-58-0-a-b-span-span-class-reference-text-cite-class-citation-arxiv-a-href-wiki-yoshua-bengio-title-yoshua-bengio-bengio-yoshua-a-2012-practical-recommendations-for-gradient-based-training-of-deep-architectures-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1206-5533-1206-5533-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-lg-cs-lg-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-practical-recommendations-for-gradient-based-training-of-deep-architectures-rft-date-2012-rft-id-info-3aarxiv-2f1206-5533-rft-aulast-bengio-rft-aufirst-yoshua-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-hinton2007-59-span-class-mw-cite-backlink-b-a-href-cite-ref-hinton2007-59-0-a-b-span-span-class-reference-text-g-e-hinton-a-rel-nofollow-class-external-text-href-http-www-csri-utoronto-ca-hinton-absps-ticsdraft-pdf-learning-multiple-layers-of-representation-a-i-trends-in-cognitive-sciences-i-11-pp-428-434-2007-span-li-li-id-cite-note-hintondengyu2012-60-span-class-mw-cite-backlink-a-href-cite-ref-hintondengyu2012-60-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-hintondengyu2012-60-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-hintondengyu2012-60-2-sup-i-b-c-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-hinton-g-deng-l-yu-d-dahl-g-mohamed-a-jaitly-n-senior-a-vanhoucke-v-nguyen-p-sainath-t-kingsbury-b-2012-deep-neural-networks-for-acoustic-modeling-in-speech-recognition-the-shared-views-of-four-research-groups-i-ieee-signal-processing-magazine-i-b-29-b-6-82-97-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2fmsp-2012-2205597-10-1109-msp-2012-2205597-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-signal-processing-magazine-rft-atitle-deep-neural-networks-for-acoustic-modeling-in-speech-recognition-the-shared-views-of-four-research-groups-rft-volume-29-rft-issue-6-rft-pages-82-97-rft-date-2012-rft-id-info-3adoi-2f10-1109-2fmsp-2012-2205597-rft-aulast-hinton-rft-aufirst-g-rft-au-deng-2c-l-rft-au-yu-2c-d-rft-au-dahl-2c-g-rft-au-mohamed-2c-a-rft-au-jaitly-2c-n-rft-au-senior-2c-a-rft-au-vanhoucke-2c-v-rft-au-nguyen-2c-p-rft-au-sainath-2c-t-rft-au-kingsbury-2c-b-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-61-span-class-mw-cite-backlink-b-a-href-cite-ref-61-a-b-span-span-class-reference-text-cite-class-citation-journal-deng-li-hinton-geoffrey-kingsbury-brian-1-may-2013-a-rel-nofollow-class-external-text-href-https-www-microsoft-com-en-us-research-publication-new-types-of-deep-neural-network-learning-for-speech-recognition-and-related-applications-an-overview-new-types-of-deep-neural-network-learning-for-speech-recognition-and-related-applications-an-overview-a-via-research-microsoft-com-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-atitle-new-types-of-deep-neural-network-learning-for-speech-recognition-and-related-applications-3a-an-overview-rft-date-2013-05-01-rft-aulast-deng-rft-aufirst-li-rft-au-hinton-2c-geoffrey-rft-au-kingsbury-2c-brian-rft-id-https-3a-2f-2fwww-microsoft-com-2fen-us-2fresearch-2fpublication-2fnew-types-of-deep-neural-network-learning-for-speech-recognition-and-related-applications-an-overview-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-62-span-class-mw-cite-backlink-b-a-href-cite-ref-62-a-b-span-span-class-reference-text-cite-class-citation-journal-deng-l-li-j-huang-j-t-yao-k-yu-d-seide-f-seltzer-m-zweig-g-he-x-may-2013-a-rel-nofollow-class-external-text-href-http-ieeexplore-ieee-org-document-6639345-recent-advances-in-deep-learning-for-speech-research-at-microsoft-a-i-2013-ieee-international-conference-on-acoustics-speech-and-signal-processing-i-8604-8608-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ficassp-2013-6639345-10-1109-icassp-2013-6639345-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-1-4799-0356-6-title-special-booksources-978-1-4799-0356-6-bdi-978-1-4799-0356-6-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-2013-ieee-international-conference-on-acoustics-2c-speech-and-signal-processing-rft-atitle-recent-advances-in-deep-learning-for-speech-research-at-microsoft-rft-pages-8604-8608-rft-date-2013-05-rft-id-info-3adoi-2f10-1109-2ficassp-2013-6639345-rft-isbn-978-1-4799-0356-6-rft-aulast-deng-rft-aufirst-l-rft-au-li-2c-j-rft-au-huang-2c-j-t-rft-au-yao-2c-k-rft-au-yu-2c-d-rft-au-seide-2c-f-rft-au-seltzer-2c-m-rft-au-zweig-2c-g-rft-au-he-2c-x-rft-id-http-3a-2f-2fieeexplore-ieee-org-2fdocument-2f6639345-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-sak2014-63-span-class-mw-cite-backlink-b-a-href-cite-ref-sak2014-63-0-a-b-span-span-class-reference-text-cite-class-citation-web-sak-hasim-senior-andrew-beaufays-francoise-2014-a-rel-nofollow-class-external-text-href-https-static-googleusercontent-com-media-research-google-com-en-pubs-archive-43905-pdf-long-short-term-memory-recurrent-neural-network-architectures-for-large-scale-acoustic-modeling-a-span-class-cs1-format-pdf-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-long-short-term-memory-recurrent-neural-network-architectures-for-large-scale-acoustic-modeling-rft-date-2014-rft-aulast-sak-rft-aufirst-hasim-rft-au-senior-2c-andrew-rft-au-beaufays-2c-francoise-rft-id-https-3a-2f-2fstatic-googleusercontent-com-2fmedia-2fresearch-google-com-2fen-2f-2fpubs-2farchive-2f43905-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-liwu2015-64-span-class-mw-cite-backlink-b-a-href-cite-ref-liwu2015-64-0-a-b-span-span-class-reference-text-cite-class-citation-arxiv-li-xiangang-wu-xihong-2014-constructing-long-short-term-memory-based-deep-recurrent-neural-networks-for-large-vocabulary-speech-recognition-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1410-4281-1410-4281-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cl-cs-cl-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-constructing-long-short-term-memory-based-deep-recurrent-neural-networks-for-large-vocabulary-speech-recognition-rft-date-2014-rft-id-info-3aarxiv-2f1410-4281-rft-aulast-li-rft-aufirst-xiangang-rft-au-wu-2c-xihong-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-zen2015-65-span-class-mw-cite-backlink-b-a-href-cite-ref-zen2015-65-0-a-b-span-span-class-reference-text-cite-class-citation-web-zen-heiga-sak-hasim-2015-a-rel-nofollow-class-external-text-href-https-static-googleusercontent-com-media-research-google-com-en-pubs-archive-43266-pdf-unidirectional-long-short-term-memory-recurrent-neural-network-with-recurrent-output-layer-for-low-latency-speech-synthesis-a-span-class-cs1-format-pdf-span-i-google-com-i-icassp-pp-4470-4474-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-google-com-rft-atitle-unidirectional-long-short-term-memory-recurrent-neural-network-with-recurrent-output-layer-for-low-latency-speech-synthesis-rft-pages-4470-4474-rft-date-2015-rft-aulast-zen-rft-aufirst-heiga-rft-au-sak-2c-hasim-rft-id-https-3a-2f-2fstatic-googleusercontent-com-2fmedia-2fresearch-google-com-2fen-2f-2fpubs-2farchive-2f43266-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-cnnspeech2013-66-span-class-mw-cite-backlink-b-a-href-cite-ref-cnnspeech2013-66-0-a-b-span-span-class-reference-text-cite-class-citation-web-deng-l-abdel-hamid-o-yu-d-2013-a-rel-nofollow-class-external-text-href-https-static-googleusercontent-com-media-research-google-com-en-pubs-archive-43266-pdf-a-deep-convolutional-neural-network-using-heterogeneous-pooling-for-trading-acoustic-invariance-with-phonetic-confusion-a-span-class-cs1-format-pdf-span-i-google-com-i-icassp-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-google-com-rft-atitle-a-deep-convolutional-neural-network-using-heterogeneous-pooling-for-trading-acoustic-invariance-with-phonetic-confusion-rft-date-2013-rft-aulast-deng-rft-aufirst-l-rft-au-abdel-hamid-2c-o-rft-au-yu-2c-d-rft-id-https-3a-2f-2fstatic-googleusercontent-com-2fmedia-2fresearch-google-com-2fen-2f-2fpubs-2farchive-2f43266-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-2-67-span-class-mw-cite-backlink-a-href-cite-ref-2-67-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-2-67-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-sainath-t-n-mohamed-a-r-kingsbury-b-ramabhadran-b-may-2013-a-rel-nofollow-class-external-text-href-http-ieeexplore-ieee-org-document-6639347-deep-convolutional-neural-networks-for-lvcsr-a-i-2013-ieee-international-conference-on-acoustics-speech-and-signal-processing-i-8614-8618-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ficassp-2013-6639347-10-1109-icassp-2013-6639347-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-1-4799-0356-6-title-special-booksources-978-1-4799-0356-6-bdi-978-1-4799-0356-6-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-2013-ieee-international-conference-on-acoustics-2c-speech-and-signal-processing-rft-atitle-deep-convolutional-neural-networks-for-lvcsr-rft-pages-8614-8618-rft-date-2013-05-rft-id-info-3adoi-2f10-1109-2ficassp-2013-6639347-rft-isbn-978-1-4799-0356-6-rft-aulast-sainath-rft-aufirst-t-n-rft-au-mohamed-2c-a-r-rft-au-kingsbury-2c-b-rft-au-ramabhadran-2c-b-rft-id-http-3a-2f-2fieeexplore-ieee-org-2fdocument-2f6639347-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-lecun2016slides-68-span-class-mw-cite-backlink-b-a-href-cite-ref-lecun2016slides-68-0-a-b-span-span-class-reference-text-a-href-wiki-yann-lecun-title-yann-lecun-yann-lecun-a-2016-slides-on-deep-learning-a-rel-nofollow-class-external-text-href-https-indico-cern-ch-event-510372-online-a-span-li-li-id-cite-note-nips2009-69-span-class-mw-cite-backlink-a-href-cite-ref-nips2009-69-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-nips2009-69-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-nips2009-69-2-sup-i-b-c-b-i-sup-a-span-span-class-reference-text-nips-workshop-deep-learning-for-speech-recognition-and-related-applications-whistler-bc-canada-dec-2009-organizers-li-deng-geoff-hinton-d-yu-span-li-li-id-cite-note-hintonkeynoteicassp2013-70-span-class-mw-cite-backlink-a-href-cite-ref-hintonkeynoteicassp2013-70-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-hintonkeynoteicassp2013-70-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-keynote-talk-recent-developments-in-deep-neural-networks-icassp-2013-by-geoff-hinton-span-li-li-id-cite-note-patent2011-71-span-class-mw-cite-backlink-b-a-href-cite-ref-patent2011-71-0-a-b-span-span-class-reference-text-d-yu-l-deng-g-li-and-f-seide-2011-discriminative-pretraining-of-deep-neural-networks-u-s-patent-filing-span-li-li-id-cite-note-referenceicassp2013-72-span-class-mw-cite-backlink-a-href-cite-ref-referenceicassp2013-72-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-referenceicassp2013-72-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-referenceicassp2013-72-2-sup-i-b-c-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-deng-l-hinton-g-kingsbury-b-2013-a-rel-nofollow-class-external-text-href-https-www-microsoft-com-en-us-research-wp-content-uploads-2016-02-icassp-2013-denghintonkingsbury-revised-pdf-new-types-of-deep-neural-network-learning-for-speech-recognition-and-related-applications-an-overview-icassp-a-span-class-cs1-format-pdf-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-atitle-new-types-of-deep-neural-network-learning-for-speech-recognition-and-related-applications-3a-an-overview-28icassp-29-rft-date-2013-rft-aulast-deng-rft-aufirst-l-rft-au-hinton-2c-g-rft-au-kingsbury-2c-b-rft-id-https-3a-2f-2fwww-microsoft-com-2fen-us-2fresearch-2fwp-content-2fuploads-2f2016-2f02-2ficassp-2013-denghintonkingsbury-revised-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-referencea-73-span-class-mw-cite-backlink-a-href-cite-ref-referencea-73-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-referencea-73-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-referencea-73-2-sup-i-b-c-b-i-sup-a-span-span-class-reference-text-cite-class-citation-book-yu-d-deng-l-2014-a-rel-nofollow-class-external-text-href-https-books-google-com-books-id-rubtbqaaqbaj-i-automatic-speech-recognition-a-deep-learning-approach-publisher-springer-i-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-1-4471-5779-3-title-special-booksources-978-1-4471-5779-3-bdi-978-1-4471-5779-3-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-automatic-speech-recognition-3a-a-deep-learning-approach-28publisher-3a-springer-29-rft-date-2014-rft-isbn-978-1-4471-5779-3-rft-aulast-yu-rft-aufirst-d-rft-au-deng-2c-l-rft-id-https-3a-2f-2fbooks-google-com-2fbooks-3fid-3drubtbqaaqbaj-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-74-span-class-mw-cite-backlink-b-a-href-cite-ref-74-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-microsoft-com-en-us-research-blog-deng-receives-prestigious-ieee-technical-achievement-award-deng-receives-prestigious-ieee-technical-achievement-award-microsoft-research-a-i-microsoft-research-i-3-december-2015-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-microsoft-research-rft-atitle-deng-receives-prestigious-ieee-technical-achievement-award-microsoft-research-rft-date-2015-12-03-rft-id-https-3a-2f-2fwww-microsoft-com-2fen-us-2fresearch-2fblog-2fdeng-receives-prestigious-ieee-technical-achievement-award-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-interspeech2014keynote-75-span-class-mw-cite-backlink-a-href-cite-ref-interspeech2014keynote-75-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-interspeech2014keynote-75-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-web-li-deng-september-2014-a-rel-nofollow-class-external-text-href-https-www-superlectures-com-interspeech2014-downloadfile-id-6-type-slides-filename-achievements-and-challenges-of-deep-learning-from-speech-analysis-and-recognition-to-language-and-multimodal-processing-keynote-talk-achievements-and-challenges-of-deep-learning-from-speech-analysis-and-recognition-to-language-and-multimodal-processing-span-class-cs1-kern-right-span-a-i-interspeech-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-interspeech-rft-atitle-keynote-talk-3a-27achievements-and-challenges-of-deep-learning-from-speech-analysis-and-recognition-to-language-and-multimodal-processing-27-rft-date-2014-09-rft-aulast-li-rft-aufirst-deng-rft-id-https-3a-2f-2fwww-superlectures-com-2finterspeech2014-2fdownloadfile-3fid-3d6-26type-3dslides-26filename-3dachievements-and-challenges-of-deep-learning-from-speech-analysis-and-recognition-to-language-and-multimodal-processing-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-roles2010-76-span-class-mw-cite-backlink-b-a-href-cite-ref-roles2010-76-0-a-b-span-span-class-reference-text-cite-class-citation-journal-yu-d-deng-l-2010-a-rel-nofollow-class-external-text-href-https-www-microsoft-com-en-us-research-publication-roles-of-pre-training-and-fine-tuning-in-context-dependent-dbn-hmms-for-real-world-speech-recognition-roles-of-pre-training-and-fine-tuning-in-context-dependent-dbn-hmms-for-real-world-speech-recognition-a-i-nips-workshop-on-deep-learning-and-unsupervised-feature-learning-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-nips-workshop-on-deep-learning-and-unsupervised-feature-learning-rft-atitle-roles-of-pre-training-and-fine-tuning-in-context-dependent-dbn-hmms-for-real-world-speech-recognition-rft-date-2010-rft-aulast-yu-rft-aufirst-d-rft-au-deng-2c-l-rft-id-https-3a-2f-2fwww-microsoft-com-2fen-us-2fresearch-2fpublication-2froles-of-pre-training-and-fine-tuning-in-context-dependent-dbn-hmms-for-real-world-speech-recognition-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-77-span-class-mw-cite-backlink-b-a-href-cite-ref-77-a-b-span-span-class-reference-text-cite-class-citation-journal-seide-f-li-g-yu-d-2011-a-rel-nofollow-class-external-text-href-https-www-microsoft-com-en-us-research-publication-conversational-speech-transcription-using-context-dependent-deep-neural-networks-conversational-speech-transcription-using-context-dependent-deep-neural-networks-a-i-interspeech-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-interspeech-rft-atitle-conversational-speech-transcription-using-context-dependent-deep-neural-networks-rft-date-2011-rft-aulast-seide-rft-aufirst-f-rft-au-li-2c-g-rft-au-yu-2c-d-rft-id-https-3a-2f-2fwww-microsoft-com-2fen-us-2fresearch-2fpublication-2fconversational-speech-transcription-using-context-dependent-deep-neural-networks-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-78-span-class-mw-cite-backlink-b-a-href-cite-ref-78-a-b-span-span-class-reference-text-cite-class-citation-journal-deng-li-li-jinyu-huang-jui-ting-yao-kaisheng-yu-dong-seide-frank-seltzer-mike-zweig-geoff-he-xiaodong-2013-05-01-a-rel-nofollow-class-external-text-href-https-www-microsoft-com-en-us-research-publication-recent-advances-in-deep-learning-for-speech-research-at-microsoft-recent-advances-in-deep-learning-for-speech-research-at-microsoft-a-i-microsoft-research-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-microsoft-research-rft-atitle-recent-advances-in-deep-learning-for-speech-research-at-microsoft-rft-date-2013-05-01-rft-aulast-deng-rft-aufirst-li-rft-au-li-2c-jinyu-rft-au-huang-2c-jui-ting-rft-au-yao-2c-kaisheng-rft-au-yu-2c-dong-rft-au-seide-2c-frank-rft-au-seltzer-2c-mike-rft-au-zweig-2c-geoff-rft-au-he-2c-xiaodong-rft-id-https-3a-2f-2fwww-microsoft-com-2fen-us-2fresearch-2fpublication-2frecent-advances-in-deep-learning-for-speech-research-at-microsoft-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-79-span-class-mw-cite-backlink-b-a-href-cite-ref-79-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-venturebeat-com-2016-04-05-nvidia-ceo-bets-big-on-deep-learning-and-vr-nvidia-ceo-bets-big-on-deep-learning-and-vr-a-i-a-href-wiki-venture-beat-class-mw-redirect-title-venture-beat-venture-beat-a-i-april-5-2016-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-nvidia-ceo-bets-big-on-deep-learning-and-vr-rft-pub-27-27venture-beat-27-27-rft-date-2016-04-05-rft-id-https-3a-2f-2fventurebeat-com-2f2016-2f04-2f05-2fnvidia-ceo-bets-big-on-deep-learning-and-vr-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-80-span-class-mw-cite-backlink-b-a-href-cite-ref-80-a-b-span-span-class-reference-text-cite-class-citation-news-a-rel-nofollow-class-external-text-href-https-www-economist-com-news-special-report-21700756-artificial-intelligence-boom-based-old-idea-modern-twist-not-from-not-working-to-neural-networking-a-i-a-href-wiki-the-economist-title-the-economist-the-economist-a-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-the-economist-rft-atitle-from-not-working-to-neural-networking-rft-id-https-3a-2f-2fwww-economist-com-2fnews-2fspecial-report-2f21700756-artificial-intelligence-boom-based-old-idea-modern-twist-not-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-jung2004-81-span-class-mw-cite-backlink-a-href-cite-ref-jung2004-81-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-jung2004-81-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-oh-k-s-jung-k-2004-gpu-implementation-of-neural-networks-i-pattern-recognition-i-b-37-b-6-1311-1314-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-patcog-2004-01-013-10-1016-j-patcog-2004-01-013-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-pattern-recognition-rft-atitle-gpu-implementation-of-neural-networks-rft-volume-37-rft-issue-6-rft-pages-1311-1314-rft-date-2004-rft-id-info-3adoi-2f10-1016-2fj-patcog-2004-01-013-rft-aulast-oh-rft-aufirst-k-s-rft-au-jung-2c-k-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-chellapilla2006-82-span-class-mw-cite-backlink-a-href-cite-ref-chellapilla2006-82-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-chellapilla2006-82-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-chellapilla-k-puri-s-and-simard-p-2006-high-performance-convolutional-neural-networks-for-document-processing-international-workshop-on-frontiers-in-handwriting-recognition-span-li-li-id-cite-note-3-83-span-class-mw-cite-backlink-b-a-href-cite-ref-3-83-0-a-b-span-span-class-reference-text-cite-class-citation-journal-ciresan-dan-claudiu-meier-ueli-gambardella-luca-maria-schmidhuber-jurgen-2010-09-21-deep-big-simple-neural-nets-for-handwritten-digit-recognition-i-neural-computation-i-b-22-b-12-3207-3220-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1003-0358-1003-0358-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1162-2fneco-a-00052-10-1162-neco-a-00052-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-0899-7667-0899-7667-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-20858131-20858131-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neural-computation-rft-atitle-deep-2c-big-2c-simple-neural-nets-for-handwritten-digit-recognition-rft-volume-22-rft-issue-12-rft-pages-3207-3220-rft-date-2010-09-21-rft-id-info-3aarxiv-2f1003-0358-rft-issn-0899-7667-rft-id-info-3apmid-2f20858131-rft-id-info-3adoi-2f10-1162-2fneco-a-00052-rft-aulast-cire-c5-9fan-rft-aufirst-dan-claudiu-rft-au-meier-2c-ueli-rft-au-gambardella-2c-luca-maria-rft-au-schmidhuber-2c-j-c3-bcrgen-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-84-span-class-mw-cite-backlink-b-a-href-cite-ref-84-a-b-span-span-class-reference-text-cite-class-citation-journal-raina-rajat-madhavan-anand-ng-andrew-y-2009-large-scale-deep-unsupervised-learning-using-graphics-processors-i-proceedings-of-the-26th-annual-international-conference-on-machine-learning-i-icml-09-new-york-ny-usa-acm-873-880-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-154-372-10-1-1-154-372-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1145-2f1553374-1553486-10-1145-1553374-1553486-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-9781605585161-title-special-booksources-9781605585161-bdi-9781605585161-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-proceedings-of-the-26th-annual-international-conference-on-machine-learning-rft-atitle-large-scale-deep-unsupervised-learning-using-graphics-processors-rft-pages-873-880-rft-date-2009-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-154-372-rft-id-info-3adoi-2f10-1145-2f1553374-1553486-rft-isbn-9781605585161-rft-aulast-raina-rft-aufirst-rajat-rft-au-madhavan-2c-anand-rft-au-ng-2c-andrew-y-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-sze2017-85-span-class-mw-cite-backlink-b-a-href-cite-ref-sze2017-85-0-a-b-span-span-class-reference-text-cite-class-citation-arxiv-sze-vivienne-chen-yu-hsin-yang-tien-ju-emer-joel-2017-efficient-processing-of-deep-neural-networks-a-tutorial-and-survey-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1703-09039-1703-09039-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-efficient-processing-of-deep-neural-networks-3a-a-tutorial-and-survey-rft-date-2017-rft-id-info-3aarxiv-2f1703-09039-rft-aulast-sze-rft-aufirst-vivienne-rft-au-chen-2c-yu-hsin-rft-au-yang-2c-tien-ju-rft-au-emer-2c-joel-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-merck2012-86-span-class-mw-cite-backlink-a-href-cite-ref-merck2012-86-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-merck2012-86-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-kaggle-com-c-merckactivity-details-winners-announcement-of-the-winners-of-the-merck-molecular-activity-challenge-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-announcement-of-the-winners-of-the-merck-molecular-activity-challenge-rft-id-https-3a-2f-2fwww-kaggle-com-2fc-2fmerckactivity-2fdetails-2fwinners-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-5-87-span-class-mw-cite-backlink-a-href-cite-ref-5-87-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-5-87-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-http-www-datascienceassn-org-content-multi-task-neural-networks-qsar-predictions-multi-task-neural-networks-for-qsar-predictions-data-science-association-a-i-www-datascienceassn-org-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2017-06-14-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-www-datascienceassn-org-rft-atitle-multi-task-neural-networks-for-qsar-predictions-7c-data-science-association-rft-id-http-3a-2f-2fwww-datascienceassn-org-2fcontent-2fmulti-task-neural-networks-qsar-predictions-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-tox21-88-span-class-mw-cite-backlink-a-href-cite-ref-tox21-88-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-tox21-88-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-toxicology-in-the-21st-century-data-challenge-span-li-li-id-cite-note-tox21data-89-span-class-mw-cite-backlink-a-href-cite-ref-tox21data-89-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-tox21data-89-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-tripod-nih-gov-tox21-challenge-leaderboard-jsp-ncats-announces-tox21-data-challenge-winners-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-ncats-announces-tox21-data-challenge-winners-rft-id-https-3a-2f-2ftripod-nih-gov-2ftox21-2fchallenge-2fleaderboard-jsp-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-11-90-span-class-mw-cite-backlink-a-href-cite-ref-11-90-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-11-90-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-web-archive-org-web-20150228225709-http-www-ncats-nih-gov-news-and-events-features-tox21-challenge-winners-html-archived-copy-a-archived-from-a-rel-nofollow-class-external-text-href-http-www-ncats-nih-gov-news-and-events-features-tox21-challenge-winners-html-the-original-a-on-2015-02-28-span-class-reference-accessdate-retrieved-span-class-nowrap-2015-03-05-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-archived-copy-rft-id-http-3a-2f-2fwww-ncats-nih-gov-2fnews-and-events-2ffeatures-2ftox21-challenge-winners-html-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-span-class-cs1-maint-citation-comment-cs1-maint-archived-copy-as-title-a-href-wiki-category-cs1-maint-archived-copy-as-title-title-category-cs1-maint-archived-copy-as-title-link-a-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-6-91-span-class-mw-cite-backlink-b-a-href-cite-ref-6-91-0-a-b-span-span-class-reference-text-cite-class-citation-journal-ciresan-d-c-meier-u-masci-j-gambardella-l-m-schmidhuber-j-2011-a-rel-nofollow-class-external-text-href-http-ijcai-org-papers11-papers-ijcai11-210-pdf-flexible-high-performance-convolutional-neural-networks-for-image-classification-a-span-class-cs1-format-pdf-span-i-international-joint-conference-on-artificial-intelligence-i-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-5591-2f978-1-57735-516-8-2fijcai11-210-10-5591-978-1-57735-516-8-ijcai11-210-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-international-joint-conference-on-artificial-intelligence-rft-atitle-flexible-2c-high-performance-convolutional-neural-networks-for-image-classification-rft-date-2011-rft-id-info-3adoi-2f10-5591-2f978-1-57735-516-8-2fijcai11-210-rft-aulast-ciresan-rft-aufirst-d-c-rft-au-meier-2c-u-rft-au-masci-2c-j-rft-au-gambardella-2c-l-m-rft-au-schmidhuber-2c-j-rft-id-http-3a-2f-2fijcai-org-2fpapers11-2fpapers-2fijcai11-210-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-8-92-span-class-mw-cite-backlink-b-a-href-cite-ref-8-92-0-a-b-span-span-class-reference-text-cite-class-citation-book-ciresan-dan-giusti-alessandro-gambardella-luca-m-schmidhuber-juergen-2012-pereira-f-burges-c-j-c-bottou-l-weinberger-k-q-eds-a-rel-nofollow-class-external-text-href-http-papers-nips-cc-paper-4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images-pdf-i-advances-in-neural-information-processing-systems-25-i-a-span-class-cs1-format-pdf-span-curran-associates-inc-pp-2843-2851-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-advances-in-neural-information-processing-systems-25-rft-pages-2843-2851-rft-pub-curran-associates-2c-inc-rft-date-2012-rft-aulast-ciresan-rft-aufirst-dan-rft-au-giusti-2c-alessandro-rft-au-gambardella-2c-luca-m-rft-au-schmidhuber-2c-juergen-rft-id-http-3a-2f-2fpapers-nips-cc-2fpaper-2f4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-ciresan2013miccai-93-span-class-mw-cite-backlink-b-a-href-cite-ref-ciresan2013miccai-93-0-a-b-span-span-class-reference-text-cite-class-citation-journal-ciresan-d-giusti-a-gambardella-l-m-schmidhuber-j-2013-mitosis-detection-in-breast-cancer-histology-images-using-deep-neural-networks-i-proceedings-miccai-i-lecture-notes-in-computer-science-b-7908-b-411-418-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2f978-3-642-40763-5-51-10-1007-978-3-642-40763-5-51-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-3-642-38708-1-title-special-booksources-978-3-642-38708-1-bdi-978-3-642-38708-1-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-proceedings-miccai-rft-atitle-mitosis-detection-in-breast-cancer-histology-images-using-deep-neural-networks-rft-volume-7908-rft-pages-411-418-rft-date-2013-rft-id-info-3adoi-2f10-1007-2f978-3-642-40763-5-51-rft-isbn-978-3-642-38708-1-rft-aulast-ciresan-rft-aufirst-d-rft-au-giusti-2c-a-rft-au-gambardella-2c-l-m-rft-au-schmidhuber-2c-j-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-94-span-class-mw-cite-backlink-b-a-href-cite-ref-94-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-imageidentify-com-the-wolfram-language-image-identification-project-a-i-www-imageidentify-com-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2017-03-22-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-www-imageidentify-com-rft-atitle-the-wolfram-language-image-identification-project-rft-id-https-3a-2f-2fwww-imageidentify-com-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-1411-4555-95-span-class-mw-cite-backlink-b-a-href-cite-ref-1411-4555-95-0-a-b-span-span-class-reference-text-cite-class-citation-arxiv-vinyals-oriol-toshev-alexander-bengio-samy-erhan-dumitru-2014-show-and-tell-a-neural-image-caption-generator-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1411-4555-1411-4555-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-show-and-tell-3a-a-neural-image-caption-generator-rft-date-2014-rft-id-info-3aarxiv-2f1411-4555-rft-aulast-vinyals-rft-aufirst-oriol-rft-au-toshev-2c-alexander-rft-au-bengio-2c-samy-rft-au-erhan-2c-dumitru-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-1411-4952-96-span-class-mw-cite-backlink-b-a-href-cite-ref-1411-4952-96-0-a-b-span-span-class-reference-text-cite-class-citation-arxiv-fang-hao-gupta-saurabh-iandola-forrest-srivastava-rupesh-deng-li-dollar-piotr-gao-jianfeng-he-xiaodong-mitchell-margaret-platt-john-c-lawrence-zitnick-c-zweig-geoffrey-2014-from-captions-to-visual-concepts-and-back-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1411-4952-1411-4952-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-from-captions-to-visual-concepts-and-back-rft-date-2014-rft-id-info-3aarxiv-2f1411-4952-rft-aulast-fang-rft-aufirst-hao-rft-au-gupta-2c-saurabh-rft-au-iandola-2c-forrest-rft-au-srivastava-2c-rupesh-rft-au-deng-2c-li-rft-au-doll-c3-a1r-2c-piotr-rft-au-gao-2c-jianfeng-rft-au-he-2c-xiaodong-rft-au-mitchell-2c-margaret-rft-au-platt-2c-john-c-rft-au-lawrence-zitnick-2c-c-rft-au-zweig-2c-geoffrey-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-1411-2539-97-span-class-mw-cite-backlink-b-a-href-cite-ref-1411-2539-97-0-a-b-span-span-class-reference-text-cite-class-citation-arxiv-kiros-ryan-salakhutdinov-ruslan-zemel-richard-s-2014-unifying-visual-semantic-embeddings-with-multimodal-neural-language-models-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1411-2539-1411-2539-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-lg-cs-lg-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-unifying-visual-semantic-embeddings-with-multimodal-neural-language-models-rft-date-2014-rft-id-info-3aarxiv-2f1411-2539-rft-aulast-kiros-rft-aufirst-ryan-rft-au-salakhutdinov-2c-ruslan-rft-au-zemel-2c-richard-s-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-98-span-class-mw-cite-backlink-b-a-href-cite-ref-98-a-b-span-span-class-reference-text-cite-class-citation-journal-zhong-sheng-hua-liu-yan-liu-yang-2011-bilinear-deep-learning-for-image-classification-i-proceedings-of-the-19th-acm-international-conference-on-multimedia-i-mm-11-new-york-ny-usa-acm-343-352-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1145-2f2072298-2072344-10-1145-2072298-2072344-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-9781450306164-title-special-booksources-9781450306164-bdi-9781450306164-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-proceedings-of-the-19th-acm-international-conference-on-multimedia-rft-atitle-bilinear-deep-learning-for-image-classification-rft-pages-343-352-rft-date-2011-rft-id-info-3adoi-2f10-1145-2f2072298-2072344-rft-isbn-9781450306164-rft-aulast-zhong-rft-aufirst-sheng-hua-rft-au-liu-2c-yan-rft-au-liu-2c-yang-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-99-span-class-mw-cite-backlink-b-a-href-cite-ref-99-a-b-span-span-class-reference-text-cite-class-citation-news-a-rel-nofollow-class-external-text-href-http-fortune-com-ai-artificial-intelligence-deep-machine-learning-why-deep-learning-is-suddenly-changing-your-life-a-i-fortune-i-2016-span-class-reference-accessdate-retrieved-span-class-nowrap-13-april-span-2018-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-fortune-rft-atitle-why-deep-learning-is-suddenly-changing-your-life-rft-date-2016-rft-id-http-3a-2f-2ffortune-com-2fai-artificial-intelligence-deep-machine-learning-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-100-span-class-mw-cite-backlink-b-a-href-cite-ref-100-a-b-span-span-class-reference-text-cite-class-citation-journal-silver-david-huang-aja-maddison-chris-j-guez-arthur-sifre-laurent-driessche-george-van-den-schrittwieser-julian-antonoglou-ioannis-panneershelvam-veda-january-2016-mastering-the-game-of-go-with-deep-neural-networks-and-tree-search-i-nature-i-b-529-b-7587-484-489-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2016natur-529-484s-2016natur-529-484s-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1038-2fnature16961-10-1038-nature16961-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-1476-4687-1476-4687-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-26819042-26819042-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-nature-rft-atitle-mastering-the-game-of-go-with-deep-neural-networks-and-tree-search-rft-volume-529-rft-issue-7587-rft-pages-484-489-rft-date-2016-01-rft-id-info-3adoi-2f10-1038-2fnature16961-rft-issn-1476-4687-rft-id-info-3apmid-2f26819042-rft-id-info-3abibcode-2f2016natur-529-484s-rft-aulast-silver-rft-aufirst-david-rft-au-huang-2c-aja-rft-au-maddison-2c-chris-j-rft-au-guez-2c-arthur-rft-au-sifre-2c-laurent-rft-au-driessche-2c-george-van-den-rft-au-schrittwieser-2c-julian-rft-au-antonoglou-2c-ioannis-rft-au-panneershelvam-2c-veda-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-101-span-class-mw-cite-backlink-b-a-href-cite-ref-101-a-b-span-span-class-reference-text-cite-class-citation-journal-szegedy-christian-toshev-alexander-erhan-dumitru-2013-a-rel-nofollow-class-external-text-href-https-papers-nips-cc-paper-5207-deep-neural-networks-for-object-detection-deep-neural-networks-for-object-detection-a-i-advances-in-neural-information-processing-systems-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-advances-in-neural-information-processing-systems-rft-atitle-deep-neural-networks-for-object-detection-rft-date-2013-rft-aulast-szegedy-rft-aufirst-christian-rft-au-toshev-2c-alexander-rft-au-erhan-2c-dumitru-rft-id-https-3a-2f-2fpapers-nips-cc-2fpaper-2f5207-deep-neural-networks-for-object-detection-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-102-span-class-mw-cite-backlink-b-a-href-cite-ref-102-a-b-span-span-class-reference-text-cite-class-citation-news-hof-robert-d-a-rel-nofollow-class-external-text-href-https-www-technologyreview-com-s-513696-deep-learning-is-artificial-intelligence-finally-coming-into-its-own-a-i-mit-technology-review-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2018-07-10-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-mit-technology-review-rft-atitle-is-artificial-intelligence-finally-coming-into-its-own-3f-rft-aulast-hof-rft-aufirst-robert-d-rft-id-https-3a-2f-2fwww-technologyreview-com-2fs-2f513696-2fdeep-learning-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-gers2001-103-span-class-mw-cite-backlink-a-href-cite-ref-gers2001-103-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-gers2001-103-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-gers-felix-a-schmidhuber-jurgen-2001-lstm-recurrent-networks-learn-simple-context-free-and-context-sensitive-languages-i-ieee-trans-neural-netw-i-b-12-b-6-1333-1340-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2f72-963769-10-1109-72-963769-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-18249962-18249962-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-trans-neural-netw-rft-atitle-lstm-recurrent-networks-learn-simple-context-free-and-context-sensitive-languages-rft-volume-12-rft-issue-6-rft-pages-1333-1340-rft-date-2001-rft-id-info-3adoi-2f10-1109-2f72-963769-rft-id-info-3apmid-2f18249962-rft-aulast-gers-rft-aufirst-felix-a-rft-au-schmidhuber-2c-j-c3-bcrgen-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-nips2014-104-span-class-mw-cite-backlink-a-href-cite-ref-nips2014-104-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-nips2014-104-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-nips2014-104-2-sup-i-b-c-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-sutskever-l-vinyals-o-le-q-2014-a-rel-nofollow-class-external-text-href-https-papers-nips-cc-paper-5346-sequence-to-sequence-learning-with-neural-networks-pdf-sequence-to-sequence-learning-with-neural-networks-a-span-class-cs1-format-pdf-span-i-proc-nips-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-proc-nips-rft-atitle-sequence-to-sequence-learning-with-neural-networks-rft-date-2014-rft-aulast-sutskever-rft-aufirst-l-rft-au-vinyals-2c-o-rft-au-le-2c-q-rft-id-https-3a-2f-2fpapers-nips-cc-2fpaper-2f5346-sequence-to-sequence-learning-with-neural-networks-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-vinyals2016-105-span-class-mw-cite-backlink-a-href-cite-ref-vinyals2016-105-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-vinyals2016-105-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-arxiv-jozefowicz-rafal-vinyals-oriol-schuster-mike-shazeer-noam-wu-yonghui-2016-exploring-the-limits-of-language-modeling-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1602-02410-1602-02410-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cl-cs-cl-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-exploring-the-limits-of-language-modeling-rft-date-2016-rft-id-info-3aarxiv-2f1602-02410-rft-aulast-jozefowicz-rft-aufirst-rafal-rft-au-vinyals-2c-oriol-rft-au-schuster-2c-mike-rft-au-shazeer-2c-noam-rft-au-wu-2c-yonghui-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-gillick2015-106-span-class-mw-cite-backlink-a-href-cite-ref-gillick2015-106-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-gillick2015-106-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-arxiv-gillick-dan-brunk-cliff-vinyals-oriol-subramanya-amarnag-2015-multilingual-language-processing-from-bytes-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1512-00103-1512-00103-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cl-cs-cl-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-multilingual-language-processing-from-bytes-rft-date-2015-rft-id-info-3aarxiv-2f1512-00103-rft-aulast-gillick-rft-aufirst-dan-rft-au-brunk-2c-cliff-rft-au-vinyals-2c-oriol-rft-au-subramanya-2c-amarnag-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-miko2010-107-span-class-mw-cite-backlink-b-a-href-cite-ref-miko2010-107-0-a-b-span-span-class-reference-text-cite-class-citation-journal-mikolov-t-et-al-2010-a-rel-nofollow-class-external-text-href-http-www-fit-vutbr-cz-research-groups-speech-servite-2010-rnnlm-mikolov-pdf-recurrent-neural-network-based-language-model-a-span-class-cs1-format-pdf-span-i-interspeech-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-interspeech-rft-atitle-recurrent-neural-network-based-language-model-rft-date-2010-rft-aulast-mikolov-rft-aufirst-t-rft-id-http-3a-2f-2fwww-fit-vutbr-cz-2fresearch-2fgroups-2fspeech-2fservite-2f2010-2frnnlm-mikolov-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-10-108-span-class-mw-cite-backlink-a-href-cite-ref-10-108-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-10-108-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-researchgate-net-publication-220320057-learning-precise-timing-with-lstm-recurrent-networks-pdf-download-available-a-i-researchgate-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2017-06-13-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-researchgate-rft-atitle-learning-precise-timing-with-lstm-recurrent-networks-28pdf-download-available-29-rft-id-https-3a-2f-2fwww-researchgate-net-2fpublication-2f220320057-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-lecun86-109-span-class-mw-cite-backlink-b-a-href-cite-ref-lecun86-109-0-a-b-span-span-class-reference-text-cite-class-citation-journal-lecun-y-et-al-1998-gradient-based-learning-applied-to-document-recognition-i-proceedings-of-the-ieee-i-b-86-b-11-2278-2324-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2f5-726791-10-1109-5-726791-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-proceedings-of-the-ieee-rft-atitle-gradient-based-learning-applied-to-document-recognition-rft-volume-86-rft-issue-11-rft-pages-2278-2324-rft-date-1998-rft-id-info-3adoi-2f10-1109-2f5-726791-rft-aulast-lecun-rft-aufirst-y-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-110-span-class-mw-cite-backlink-b-a-href-cite-ref-110-a-b-span-span-class-reference-text-cite-class-citation-journal-bengio-y-boulanger-lewandowski-n-pascanu-r-may-2013-a-rel-nofollow-class-external-text-href-http-ieeexplore-ieee-org-document-6639349-advances-in-optimizing-recurrent-networks-a-i-2013-ieee-international-conference-on-acoustics-speech-and-signal-processing-i-8624-8628-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1212-0901-1212-0901-a-span-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-752-9151-10-1-1-752-9151-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ficassp-2013-6639349-10-1109-icassp-2013-6639349-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-1-4799-0356-6-title-special-booksources-978-1-4799-0356-6-bdi-978-1-4799-0356-6-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-2013-ieee-international-conference-on-acoustics-2c-speech-and-signal-processing-rft-atitle-advances-in-optimizing-recurrent-networks-rft-pages-8624-8628-rft-date-2013-05-rft-id-info-3aarxiv-2f1212-0901-rft-id-info-3adoi-2f10-1109-2ficassp-2013-6639349-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-752-9151-rft-isbn-978-1-4799-0356-6-rft-aulast-bengio-rft-aufirst-y-rft-au-boulanger-lewandowski-2c-n-rft-au-pascanu-2c-r-rft-id-http-3a-2f-2fieeexplore-ieee-org-2fdocument-2f6639349-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-dahl2013-111-span-class-mw-cite-backlink-b-a-href-cite-ref-dahl2013-111-0-a-b-span-span-class-reference-text-cite-class-citation-journal-dahl-g-et-al-2013-a-rel-nofollow-class-external-text-href-http-www-cs-toronto-edu-gdahl-papers-reludropoutbn-icassp2013-pdf-improving-dnns-for-lvcsr-using-rectified-linear-units-and-dropout-a-span-class-cs1-format-pdf-span-i-icassp-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-icassp-rft-atitle-improving-dnns-for-lvcsr-using-rectified-linear-units-and-dropout-rft-date-2013-rft-aulast-dahl-rft-aufirst-g-rft-id-http-3a-2f-2fwww-cs-toronto-edu-2f-gdahl-2fpapers-2freludropoutbn-icassp2013-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-112-span-class-mw-cite-backlink-b-a-href-cite-ref-112-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-coursera-org-learn-convolutional-neural-networks-lecture-ayzbx-data-augmentation-data-augmentation-deeplearning-ai-coursera-a-i-coursera-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2017-11-30-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-coursera-rft-atitle-data-augmentation-deeplearning-ai-7c-coursera-rft-id-https-3a-2f-2fwww-coursera-org-2flearn-2fconvolutional-neural-networks-2flecture-2fayzbx-2fdata-augmentation-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-rbmtrain-113-span-class-mw-cite-backlink-b-a-href-cite-ref-rbmtrain-113-0-a-b-span-span-class-reference-text-cite-class-citation-journal-hinton-g-e-2010-a-rel-nofollow-class-external-text-href-https-www-researchgate-net-publication-221166159-a-practical-guide-to-training-restricted-boltzmann-machines-a-i-tech-rep-utml-tr-2010-003-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-tech-rep-utml-tr-2010-003-rft-atitle-a-practical-guide-to-training-restricted-boltzmann-machines-rft-date-2010-rft-aulast-hinton-rft-aufirst-g-e-rft-id-https-3a-2f-2fwww-researchgate-net-2fpublication-2f221166159-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-114-span-class-mw-cite-backlink-b-a-href-cite-ref-114-a-b-span-span-class-reference-text-cite-class-citation-web-you-yang-buluc-aydin-demmel-james-november-2017-a-rel-nofollow-class-external-text-href-https-dl-acm-org-citation-cfm-doid-3126908-3126912-scaling-deep-learning-on-gpu-and-knights-landing-clusters-a-sc-17-acm-span-class-reference-accessdate-retrieved-span-class-nowrap-5-march-span-2018-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-scaling-deep-learning-on-gpu-and-knights-landing-clusters-rft-pub-sc-2717-2c-acm-rft-date-2017-11-rft-aulast-you-rft-aufirst-yang-rft-au-bulu-c3-a7-2c-ayd-c4-b1n-rft-au-demmel-2c-james-rft-id-https-3a-2f-2fdl-acm-org-2fcitation-cfm-3fdoid-3d3126908-3126912-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-115-span-class-mw-cite-backlink-b-a-href-cite-ref-115-a-b-span-span-class-reference-text-cite-class-citation-journal-viebke-andre-memeti-suejb-pllana-sabri-abraham-ajith-march-2017-chaos-a-parallelization-scheme-for-training-convolutional-neural-networks-on-intel-xeon-phi-i-the-journal-of-supercomputing-i-b-75-b-197-227-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fs11227-017-1994-x-10-1007-s11227-017-1994-x-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-the-journal-of-supercomputing-rft-atitle-chaos-3a-a-parallelization-scheme-for-training-convolutional-neural-networks-on-intel-xeon-phi-rft-volume-75-rft-pages-197-227-rft-date-2017-03-rft-id-info-3adoi-2f10-1007-2fs11227-017-1994-x-rft-aulast-viebke-rft-aufirst-andr-c3-a9-rft-au-memeti-2c-suejb-rft-au-pllana-2c-sabri-rft-au-abraham-2c-ajith-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-qin1-116-span-class-mw-cite-backlink-b-a-href-cite-ref-qin1-116-0-a-b-span-span-class-reference-text-ting-qin-et-al-a-learning-algorithm-of-cmac-based-on-rls-neural-processing-letters-19-1-2004-49-61-span-li-li-id-cite-note-qin2-117-span-class-mw-cite-backlink-b-a-href-cite-ref-qin2-117-0-a-b-span-span-class-reference-text-ting-qin-et-al-a-rel-nofollow-class-external-text-href-http-www-control-eng-cam-ac-uk-homepage-papers-cued-control-997-pdf-continuous-cmac-qrls-and-its-systolic-array-a-neural-processing-letters-22-1-2005-1-16-span-li-li-id-cite-note-ldctimit-118-span-class-mw-cite-backlink-b-a-href-cite-ref-ldctimit-118-0-a-b-span-span-class-reference-text-i-timit-acoustic-phonetic-continuous-speech-corpus-i-linguistic-data-consortium-philadelphia-span-li-li-id-cite-note-119-span-class-mw-cite-backlink-b-a-href-cite-ref-119-a-b-span-span-class-reference-text-cite-class-citation-journal-a-href-wiki-tony-robinson-speech-recognition-title-tony-robinson-speech-recognition-robinson-tony-a-30-september-1991-several-improvements-to-a-recurrent-error-propagation-network-phone-recognition-system-i-cambridge-university-engineering-department-technical-report-i-cued-f-infeng-tr82-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-13140-2frg-2-2-15418-90567-10-13140-rg-2-2-15418-90567-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-cambridge-university-engineering-department-technical-report-rft-atitle-several-improvements-to-a-recurrent-error-propagation-network-phone-recognition-system-rft-volume-cued-2ff-infeng-2ftr82-rft-date-1991-09-30-rft-id-info-3adoi-2f10-13140-2frg-2-2-15418-90567-rft-aulast-robinson-rft-aufirst-tony-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-cnn-2014-120-span-class-mw-cite-backlink-b-a-href-cite-ref-cnn-2014-120-0-a-b-span-span-class-reference-text-cite-class-citation-journal-abdel-hamid-o-et-al-2014-convolutional-neural-networks-for-speech-recognition-i-ieee-acm-transactions-on-audio-speech-and-language-processing-i-b-22-b-10-1533-1545-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftaslp-2014-2339736-10-1109-taslp-2014-2339736-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-2facm-transactions-on-audio-2c-speech-2c-and-language-processing-rft-atitle-convolutional-neural-networks-for-speech-recognition-rft-volume-22-rft-issue-10-rft-pages-1533-1545-rft-date-2014-rft-id-info-3adoi-2f10-1109-2ftaslp-2014-2339736-rft-aulast-abdel-hamid-rft-aufirst-o-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-ensembledl-121-span-class-mw-cite-backlink-b-a-href-cite-ref-ensembledl-121-0-a-b-span-span-class-reference-text-cite-class-citation-journal-deng-l-platt-j-2014-a-rel-nofollow-class-external-text-href-https-pdfs-semanticscholar-org-8201-55ecb57325503183253b8796de5f4535eb16-pdf-ensemble-deep-learning-for-speech-recognition-a-span-class-cs1-format-pdf-span-i-proc-interspeech-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-proc-interspeech-rft-atitle-ensemble-deep-learning-for-speech-recognition-rft-date-2014-rft-aulast-deng-rft-aufirst-l-rft-au-platt-2c-j-rft-id-https-3a-2f-2fpdfs-semanticscholar-org-2f8201-2f55ecb57325503183253b8796de5f4535eb16-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-hcdmm-122-span-class-mw-cite-backlink-b-a-href-cite-ref-hcdmm-122-0-a-b-span-span-class-reference-text-cite-class-citation-journal-toth-laszlo-2015-a-rel-nofollow-class-external-text-href-http-publicatio-bibl-u-szeged-hu-5976-1-eurasip2015-pdf-phone-recognition-with-hierarchical-convolutional-deep-maxout-networks-a-span-class-cs1-format-pdf-span-i-eurasip-journal-on-audio-speech-and-music-processing-i-b-2015-b-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1186-2fs13636-015-0068-3-10-1186-s13636-015-0068-3-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-eurasip-journal-on-audio-2c-speech-2c-and-music-processing-rft-atitle-phone-recognition-with-hierarchical-convolutional-deep-maxout-networks-rft-volume-2015-rft-date-2015-rft-id-info-3adoi-2f10-1186-2fs13636-015-0068-3-rft-aulast-t-c3-b3th-rft-aufirst-laszl-c3-b3-rft-id-http-3a-2f-2fpublicatio-bibl-u-szeged-hu-2f5976-2f1-2feurasip2015-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-123-span-class-mw-cite-backlink-b-a-href-cite-ref-123-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-wired-com-2014-12-skype-used-ai-build-amazing-new-language-translator-how-skype-used-ai-to-build-its-amazing-new-language-translator-wired-a-i-www-wired-com-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2017-06-14-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-www-wired-com-rft-atitle-how-skype-used-ai-to-build-its-amazing-new-language-translator-7c-wired-rft-id-https-3a-2f-2fwww-wired-com-2f2014-2f12-2fskype-used-ai-build-amazing-new-language-translator-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-baidu-124-span-class-mw-cite-backlink-b-a-href-cite-ref-baidu-124-0-a-b-span-span-class-reference-text-cite-class-citation-arxiv-hannun-awni-case-carl-casper-jared-catanzaro-bryan-diamos-greg-elsen-erich-prenger-ryan-satheesh-sanjeev-sengupta-shubho-coates-adam-ng-andrew-y-2014-deep-speech-scaling-up-end-to-end-speech-recognition-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1412-5567-1412-5567-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cl-cs-cl-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-deep-speech-3a-scaling-up-end-to-end-speech-recognition-rft-date-2014-rft-id-info-3aarxiv-2f1412-5567-rft-aulast-hannun-rft-aufirst-awni-rft-au-case-2c-carl-rft-au-casper-2c-jared-rft-au-catanzaro-2c-bryan-rft-au-diamos-2c-greg-rft-au-elsen-2c-erich-rft-au-prenger-2c-ryan-rft-au-satheesh-2c-sanjeev-rft-au-sengupta-2c-shubho-rft-au-coates-2c-adam-rft-au-ng-2c-andrew-y-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-125-span-class-mw-cite-backlink-b-a-href-cite-ref-125-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-http-research-microsoft-com-en-us-people-deng-ieee-icassp-plenary-2016-mar24-lideng-posted-pdf-plenary-presentation-at-icassp-2016-a-span-class-cs1-format-pdf-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-plenary-presentation-at-icassp-2016-rft-id-http-3a-2f-2fresearch-microsoft-com-2fen-us-2fpeople-2fdeng-2fieee-icassp-plenary-2016-mar24-lideng-posted-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-yannmnist-126-span-class-mw-cite-backlink-b-a-href-cite-ref-yannmnist-126-0-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-http-yann-lecun-com-exdb-mnist-mnist-handwritten-digit-database-yann-lecun-corinna-cortes-and-chris-burges-a-i-yann-lecun-com-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-yann-lecun-com-rft-atitle-mnist-handwritten-digit-database-2c-yann-lecun-2c-corinna-cortes-and-chris-burges-rft-id-http-3a-2f-2fyann-lecun-com-2fexdb-2fmnist-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-7-127-span-class-mw-cite-backlink-b-a-href-cite-ref-7-127-0-a-b-span-span-class-reference-text-cite-class-citation-journal-ciresan-dan-meier-ueli-masci-jonathan-schmidhuber-jurgen-august-2012-multi-column-deep-neural-network-for-traffic-sign-classification-i-neural-networks-i-selected-papers-from-ijcnn-2011-b-32-b-333-338-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-226-8219-10-1-1-226-8219-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-neunet-2012-02-023-10-1016-j-neunet-2012-02-023-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-22386783-22386783-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neural-networks-rft-atitle-multi-column-deep-neural-network-for-traffic-sign-classification-rft-volume-32-rft-pages-333-338-rft-date-2012-08-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-226-8219-rft-id-info-3apmid-2f22386783-rft-id-info-3adoi-2f10-1016-2fj-neunet-2012-02-023-rft-aulast-cire-c5-9fan-rft-aufirst-dan-rft-au-meier-2c-ueli-rft-au-masci-2c-jonathan-rft-au-schmidhuber-2c-j-c3-bcrgen-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-128-span-class-mw-cite-backlink-b-a-href-cite-ref-128-a-b-span-span-class-reference-text-a-rel-nofollow-class-external-text-href-http-www-technologyreview-com-news-533936-nvidia-demos-a-car-computer-trained-with-deep-learning-nvidia-demos-a-car-computer-trained-with-deep-learning-a-2015-01-06-david-talbot-i-a-href-wiki-mit-technology-review-title-mit-technology-review-mit-technology-review-a-i-span-li-li-id-cite-note-129-span-class-mw-cite-backlink-b-a-href-cite-ref-129-a-b-span-span-class-reference-text-cite-class-citation-web-g-w-smith-frederic-fol-leymarie-10-april-2017-a-rel-nofollow-class-external-text-href-http-www-mdpi-com-2076-0752-6-2-5-the-machine-as-artist-an-introduction-a-arts-span-class-reference-accessdate-retrieved-span-class-nowrap-4-october-span-2017-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-the-machine-as-artist-3a-an-introduction-rft-pub-arts-rft-date-2017-04-10-rft-au-g-w-smith-rft-au-frederic-fol-leymarie-rft-id-http-3a-2f-2fwww-mdpi-com-2f2076-0752-2f6-2f2-2f5-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-130-span-class-mw-cite-backlink-b-a-href-cite-ref-130-a-b-span-span-class-reference-text-cite-class-citation-web-blaise-aguera-y-arcas-29-september-2017-a-rel-nofollow-class-external-text-href-http-www-mdpi-com-2076-0752-6-4-18-art-in-the-age-of-machine-intelligence-a-arts-span-class-reference-accessdate-retrieved-span-class-nowrap-4-october-span-2017-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-art-in-the-age-of-machine-intelligence-rft-pub-arts-rft-date-2017-09-29-rft-au-blaise-ag-c3-bcera-y-arcas-rft-id-http-3a-2f-2fwww-mdpi-com-2f2076-0752-2f6-2f4-2f18-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-131-span-class-mw-cite-backlink-b-a-href-cite-ref-131-a-b-span-span-class-reference-text-cite-class-citation-journal-bengio-yoshua-ducharme-rejean-vincent-pascal-janvin-christian-march-2003-a-rel-nofollow-class-external-text-href-http-dl-acm-org-citation-cfm-id-944919-944966-a-neural-probabilistic-language-model-a-i-j-mach-learn-res-i-b-3-b-1137-1155-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-1532-4435-1532-4435-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-j-mach-learn-res-rft-atitle-a-neural-probabilistic-language-model-rft-volume-3-rft-pages-1137-1155-rft-date-2003-03-rft-issn-1532-4435-rft-aulast-bengio-rft-aufirst-yoshua-rft-au-ducharme-2c-r-c3-a9jean-rft-au-vincent-2c-pascal-rft-au-janvin-2c-christian-rft-id-http-3a-2f-2fdl-acm-org-2fcitation-cfm-3fid-3d944919-944966-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-goldberglevy2014-132-span-class-mw-cite-backlink-b-a-href-cite-ref-goldberglevy2014-132-0-a-b-span-span-class-reference-text-cite-class-citation-arxiv-goldberg-yoav-levy-omar-2014-word2vec-explained-deriving-mikolov-et-al-s-negative-sampling-word-embedding-method-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1402-3722-1402-3722-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cl-cs-cl-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-word2vec-explained-3a-deriving-mikolov-et-al-27s-negative-sampling-word-embedding-method-rft-date-2014-rft-id-info-3aarxiv-2f1402-3722-rft-aulast-goldberg-rft-aufirst-yoav-rft-au-levy-2c-omar-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-sochermanning2014-133-span-class-mw-cite-backlink-a-href-cite-ref-sochermanning2014-133-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-sochermanning2014-133-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-web-socher-richard-manning-christopher-a-rel-nofollow-class-external-text-href-http-nlp-stanford-edu-courses-naacl2013-naacl2013-socher-manning-deeplearning-pdf-deep-learning-for-nlp-a-span-class-cs1-format-pdf-span-span-class-reference-accessdate-retrieved-span-class-nowrap-26-october-span-2014-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-deep-learning-for-nlp-rft-aulast-socher-rft-aufirst-richard-rft-au-manning-2c-christopher-rft-id-http-3a-2f-2fnlp-stanford-edu-2fcourses-2fnaacl2013-2fnaacl2013-socher-manning-deeplearning-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-134-span-class-mw-cite-backlink-b-a-href-cite-ref-134-a-b-span-span-class-reference-text-cite-class-citation-journal-socher-richard-bauer-john-manning-christopher-ng-andrew-2013-a-rel-nofollow-class-external-text-href-http-aclweb-org-anthology-p-p13-p13-1045-pdf-parsing-with-compositional-vector-grammars-a-span-class-cs1-format-pdf-span-i-proceedings-of-the-acl-2013-conference-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-proceedings-of-the-acl-2013-conference-rft-atitle-parsing-with-compositional-vector-grammars-rft-date-2013-rft-aulast-socher-rft-aufirst-richard-rft-au-bauer-2c-john-rft-au-manning-2c-christopher-rft-au-ng-2c-andrew-rft-id-http-3a-2f-2faclweb-org-2fanthology-2fp-2fp13-2fp13-1045-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-135-span-class-mw-cite-backlink-b-a-href-cite-ref-135-a-b-span-span-class-reference-text-cite-class-citation-journal-socher-richard-2013-a-rel-nofollow-class-external-text-href-http-nlp-stanford-edu-socherr-emnlp2013-rntn-pdf-recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank-a-span-class-cs1-format-pdf-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-atitle-recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank-rft-date-2013-rft-aulast-socher-rft-aufirst-richard-rft-id-http-3a-2f-2fnlp-stanford-edu-2f-socherr-2femnlp2013-rntn-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-136-span-class-mw-cite-backlink-b-a-href-cite-ref-136-a-b-span-span-class-reference-text-cite-class-citation-journal-shen-yelong-he-xiaodong-gao-jianfeng-deng-li-mesnil-gregoire-2014-11-01-a-rel-nofollow-class-external-text-href-https-www-microsoft-com-en-us-research-publication-a-latent-semantic-model-with-convolutional-pooling-structure-for-information-retrieval-a-latent-semantic-model-with-convolutional-pooling-structure-for-information-retrieval-a-i-microsoft-research-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-microsoft-research-rft-atitle-a-latent-semantic-model-with-convolutional-pooling-structure-for-information-retrieval-rft-date-2014-11-01-rft-aulast-shen-rft-aufirst-yelong-rft-au-he-2c-xiaodong-rft-au-gao-2c-jianfeng-rft-au-deng-2c-li-rft-au-mesnil-2c-gregoire-rft-id-https-3a-2f-2fwww-microsoft-com-2fen-us-2fresearch-2fpublication-2fa-latent-semantic-model-with-convolutional-pooling-structure-for-information-retrieval-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-137-span-class-mw-cite-backlink-b-a-href-cite-ref-137-a-b-span-span-class-reference-text-cite-class-citation-journal-huang-po-sen-he-xiaodong-gao-jianfeng-deng-li-acero-alex-heck-larry-2013-10-01-a-rel-nofollow-class-external-text-href-https-www-microsoft-com-en-us-research-publication-learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data-learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data-a-i-microsoft-research-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-microsoft-research-rft-atitle-learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data-rft-date-2013-10-01-rft-aulast-huang-rft-aufirst-po-sen-rft-au-he-2c-xiaodong-rft-au-gao-2c-jianfeng-rft-au-deng-2c-li-rft-au-acero-2c-alex-rft-au-heck-2c-larry-rft-id-https-3a-2f-2fwww-microsoft-com-2fen-us-2fresearch-2fpublication-2flearning-deep-structured-semantic-models-for-web-search-using-clickthrough-data-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-ieee-tasl2015-138-span-class-mw-cite-backlink-b-a-href-cite-ref-ieee-tasl2015-138-0-a-b-span-span-class-reference-text-cite-class-citation-journal-mesnil-g-dauphin-y-yao-k-bengio-y-deng-l-hakkani-tur-d-he-x-heck-l-tur-g-yu-d-zweig-g-2015-using-recurrent-neural-networks-for-slot-filling-in-spoken-language-understanding-i-ieee-transactions-on-audio-speech-and-language-processing-i-b-23-b-3-530-539-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ftaslp-2014-2383614-10-1109-taslp-2014-2383614-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-ieee-transactions-on-audio-2c-speech-2c-and-language-processing-rft-atitle-using-recurrent-neural-networks-for-slot-filling-in-spoken-language-understanding-rft-volume-23-rft-issue-3-rft-pages-530-539-rft-date-2015-rft-id-info-3adoi-2f10-1109-2ftaslp-2014-2383614-rft-aulast-mesnil-rft-aufirst-g-rft-au-dauphin-2c-y-rft-au-yao-2c-k-rft-au-bengio-2c-y-rft-au-deng-2c-l-rft-au-hakkani-tur-2c-d-rft-au-he-2c-x-rft-au-heck-2c-l-rft-au-tur-2c-g-rft-au-yu-2c-d-rft-au-zweig-2c-g-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-auto-139-span-class-mw-cite-backlink-a-href-cite-ref-auto-139-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-auto-139-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-journal-gao-jianfeng-he-xiaodong-yih-scott-wen-tau-deng-li-2014-06-01-a-rel-nofollow-class-external-text-href-https-www-microsoft-com-en-us-research-publication-learning-continuous-phrase-representations-for-translation-modeling-learning-continuous-phrase-representations-for-translation-modeling-a-i-microsoft-research-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-microsoft-research-rft-atitle-learning-continuous-phrase-representations-for-translation-modeling-rft-date-2014-06-01-rft-aulast-gao-rft-aufirst-jianfeng-rft-au-he-2c-xiaodong-rft-au-yih-2c-scott-wen-tau-rft-au-deng-2c-li-rft-id-https-3a-2f-2fwww-microsoft-com-2fen-us-2fresearch-2fpublication-2flearning-continuous-phrase-representations-for-translation-modeling-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-broc2017-140-span-class-mw-cite-backlink-b-a-href-cite-ref-broc2017-140-0-a-b-span-span-class-reference-text-cite-class-citation-journal-brocardo-marcelo-luiz-traore-issa-woungang-isaac-obaidat-mohammad-s-2017-authorship-verification-using-deep-belief-network-systems-i-international-journal-of-communication-systems-i-b-30-b-12-e3259-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1002-2fdac-3259-10-1002-dac-3259-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-international-journal-of-communication-systems-rft-atitle-authorship-verification-using-deep-belief-network-systems-rft-volume-30-rft-issue-12-rft-pages-e3259-rft-date-2017-rft-id-info-3adoi-2f10-1002-2fdac-3259-rft-aulast-brocardo-rft-aufirst-marcelo-luiz-rft-au-traore-2c-issa-rft-au-woungang-2c-isaac-rft-au-obaidat-2c-mohammad-s-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-141-span-class-mw-cite-backlink-b-a-href-cite-ref-141-a-b-span-span-class-reference-text-cite-class-citation-news-a-rel-nofollow-class-external-text-href-https-www-microsoft-com-en-us-research-project-deep-learning-for-natural-language-processing-theory-and-practice-cikm2014-tutorial-deep-learning-for-natural-language-processing-theory-and-practice-cikm2014-tutorial-microsoft-research-a-i-microsoft-research-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2017-06-14-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-microsoft-research-rft-atitle-deep-learning-for-natural-language-processing-3a-theory-and-practice-28cikm2014-tutorial-29-microsoft-research-rft-id-https-3a-2f-2fwww-microsoft-com-2fen-us-2fresearch-2fproject-2fdeep-learning-for-natural-language-processing-theory-and-practice-cikm2014-tutorial-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-gt-turovsky-2016-142-span-class-mw-cite-backlink-b-a-href-cite-ref-gt-turovsky-2016-142-0-a-b-span-span-class-reference-text-cite-class-citation-web-turovsky-barak-november-15-2016-a-rel-nofollow-class-external-text-href-https-blog-google-products-translate-found-translation-more-accurate-fluent-sentences-google-translate-found-in-translation-more-accurate-fluent-sentences-in-google-translate-a-i-the-keyword-google-blog-i-span-class-reference-accessdate-retrieved-span-class-nowrap-march-23-span-2017-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-the-keyword-google-blog-rft-atitle-found-in-translation-3a-more-accurate-2c-fluent-sentences-in-google-translate-rft-date-2016-11-15-rft-aulast-turovsky-rft-aufirst-barak-rft-id-https-3a-2f-2fblog-google-2fproducts-2ftranslate-2ffound-translation-more-accurate-fluent-sentences-google-translate-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-googleblog-gnmt-2016-143-span-class-mw-cite-backlink-a-href-cite-ref-googleblog-gnmt-2016-143-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-googleblog-gnmt-2016-143-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-googleblog-gnmt-2016-143-2-sup-i-b-c-b-i-sup-a-a-href-cite-ref-googleblog-gnmt-2016-143-3-sup-i-b-d-b-i-sup-a-span-span-class-reference-text-cite-class-citation-web-schuster-mike-johnson-melvin-thorat-nikhil-november-22-2016-a-rel-nofollow-class-external-text-href-https-research-googleblog-com-2016-11-zero-shot-translation-with-googles-html-zero-shot-translation-with-google-s-multilingual-neural-machine-translation-system-a-i-google-research-blog-i-span-class-reference-accessdate-retrieved-span-class-nowrap-march-23-span-2017-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-google-research-blog-rft-atitle-zero-shot-translation-with-google-27s-multilingual-neural-machine-translation-system-rft-date-2016-11-22-rft-aulast-schuster-rft-aufirst-mike-rft-au-johnson-2c-melvin-rft-au-thorat-2c-nikhil-rft-id-https-3a-2f-2fresearch-googleblog-com-2f2016-2f11-2fzero-shot-translation-with-googles-html-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-lstm1997-144-span-class-mw-cite-backlink-b-a-href-cite-ref-lstm1997-144-0-a-b-span-span-class-reference-text-cite-class-citation-journal-sepp-hochreiter-jurgen-schmidhuber-1997-a-rel-nofollow-class-external-text-href-https-www-researchgate-net-publication-13853244-long-short-term-memory-a-i-a-href-wiki-neural-computation-journal-title-neural-computation-journal-neural-computation-a-i-b-9-b-8-1735-1780-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1162-2fneco-1997-9-8-1735-10-1162-neco-1997-9-8-1735-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-9377276-9377276-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neural-computation-rft-atitle-long-short-term-memory-rft-volume-9-rft-issue-8-rft-pages-1735-1780-rft-date-1997-rft-id-info-3adoi-2f10-1162-2fneco-1997-9-8-1735-rft-id-info-3apmid-2f9377276-rft-au-sepp-hochreiter-rft-au-j-c3-bcrgen-schmidhuber-rft-id-https-3a-2f-2fwww-researchgate-net-2fpublication-2f13853244-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-lstm2000-145-span-class-mw-cite-backlink-b-a-href-cite-ref-lstm2000-145-0-a-b-span-span-class-reference-text-cite-class-citation-journal-felix-a-gers-jurgen-schmidhuber-fred-cummins-2000-learning-to-forget-continual-prediction-with-lstm-i-a-href-wiki-neural-computation-journal-title-neural-computation-journal-neural-computation-a-i-b-12-b-10-2451-2471-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-55-5709-10-1-1-55-5709-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1162-2f089976600300015015-10-1162-089976600300015015-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neural-computation-rft-atitle-learning-to-forget-3a-continual-prediction-with-lstm-rft-volume-12-rft-issue-10-rft-pages-2451-2471-rft-date-2000-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-55-5709-rft-id-info-3adoi-2f10-1162-2f089976600300015015-rft-au-felix-a-gers-rft-au-j-c3-bcrgen-schmidhuber-rft-au-fred-cummins-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-googletranslate-146-span-class-mw-cite-backlink-b-a-href-cite-ref-googletranslate-146-0-a-b-span-span-class-reference-text-cite-class-citation-arxiv-wu-yonghui-schuster-mike-chen-zhifeng-le-quoc-v-norouzi-mohammad-macherey-wolfgang-krikun-maxim-cao-yuan-gao-qin-macherey-klaus-klingner-jeff-shah-apurva-johnson-melvin-liu-xiaobing-kaiser-lukasz-gouws-stephan-kato-yoshikiyo-kudo-taku-kazawa-hideto-stevens-keith-kurian-george-patil-nishant-wang-wei-young-cliff-smith-jason-riesa-jason-rudnick-alex-vinyals-oriol-corrado-greg-et-al-2016-google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1609-08144-1609-08144-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cl-cs-cl-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-google-27s-neural-machine-translation-system-3a-bridging-the-gap-between-human-and-machine-translation-rft-date-2016-rft-id-info-3aarxiv-2f1609-08144-rft-aulast-wu-rft-aufirst-yonghui-rft-au-schuster-2c-mike-rft-au-chen-2c-zhifeng-rft-au-le-2c-quoc-v-rft-au-norouzi-2c-mohammad-rft-au-macherey-2c-wolfgang-rft-au-krikun-2c-maxim-rft-au-cao-2c-yuan-rft-au-gao-2c-qin-rft-au-macherey-2c-klaus-rft-au-klingner-2c-jeff-rft-au-shah-2c-apurva-rft-au-johnson-2c-melvin-rft-au-liu-2c-xiaobing-rft-au-kaiser-2c-c5-81ukasz-rft-au-gouws-2c-stephan-rft-au-kato-2c-yoshikiyo-rft-au-kudo-2c-taku-rft-au-kazawa-2c-hideto-rft-au-stevens-2c-keith-rft-au-kurian-2c-george-rft-au-patil-2c-nishant-rft-au-wang-2c-wei-rft-au-young-2c-cliff-rft-au-smith-2c-jason-rft-au-riesa-2c-jason-rft-au-rudnick-2c-alex-rft-au-vinyals-2c-oriol-rft-au-corrado-2c-greg-rft-au-hughes-2c-macduff-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-wiredgoogletranslate-147-span-class-mw-cite-backlink-b-a-href-cite-ref-wiredgoogletranslate-147-0-a-b-span-span-class-reference-text-an-infusion-of-ai-makes-google-translate-more-powerful-than-ever-cade-metz-wired-date-of-publication-09-27-16-a-rel-nofollow-class-external-free-href-https-www-wired-com-2016-09-google-claims-ai-breakthrough-machine-translation-https-www-wired-com-2016-09-google-claims-ai-breakthrough-machine-translation-a-span-li-li-id-cite-note-biotet-148-span-class-mw-cite-backlink-a-href-cite-ref-biotet-148-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-biotet-148-1-sup-i-b-b-b-i-sup-a-span-span-class-reference-text-cite-class-citation-web-boitet-christian-blanchon-herve-seligman-mark-bellynck-valerie-2010-a-rel-nofollow-class-external-text-href-http-www-clips-imag-fr-geta-herve-blanchon-pdfs-nlp-ke-10-pdf-mt-on-and-for-the-web-a-span-class-cs1-format-pdf-span-span-class-reference-accessdate-retrieved-span-class-nowrap-december-1-span-2016-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-mt-on-and-for-the-web-rft-date-2010-rft-aulast-boitet-rft-aufirst-christian-rft-au-blanchon-2c-herv-c3-a9-rft-au-seligman-2c-mark-rft-au-bellynck-2c-val-c3-a9rie-rft-id-http-3a-2f-2fwww-clips-imag-fr-2fgeta-2fherve-blanchon-2fpdfs-2fnlp-ke-10-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-arrowsmith2013-149-span-class-mw-cite-backlink-b-a-href-cite-ref-arrowsmith2013-149-0-a-b-span-span-class-reference-text-cite-class-citation-journal-arrowsmith-j-miller-p-2013-trial-watch-phase-ii-and-phase-iii-attrition-rates-2011-2012-i-nature-reviews-drug-discovery-i-b-12-b-8-569-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1038-2fnrd4090-10-1038-nrd4090-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-23903212-23903212-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-nature-reviews-drug-discovery-rft-atitle-trial-watch-3a-phase-ii-and-phase-iii-attrition-rates-2011-2012-rft-volume-12-rft-issue-8-rft-pages-569-rft-date-2013-rft-id-info-3adoi-2f10-1038-2fnrd4090-rft-id-info-3apmid-2f23903212-rft-aulast-arrowsmith-rft-aufirst-j-rft-au-miller-2c-p-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-verbiest2015-150-span-class-mw-cite-backlink-b-a-href-cite-ref-verbiest2015-150-0-a-b-span-span-class-reference-text-cite-class-citation-journal-verbist-b-klambauer-g-vervoort-l-talloen-w-the-qstar-consortium-shkedy-z-thas-o-bender-a-gohlmann-h-w-hochreiter-s-2015-using-transcriptomics-to-guide-lead-optimization-in-drug-discovery-projects-lessons-learned-from-the-qstar-project-i-drug-discovery-today-i-b-20-b-5-505-513-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-drudis-2014-12-014-10-1016-j-drudis-2014-12-014-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-25582842-25582842-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-drug-discovery-today-rft-atitle-using-transcriptomics-to-guide-lead-optimization-in-drug-discovery-projects-3a-lessons-learned-from-the-qstar-project-rft-volume-20-rft-issue-5-rft-pages-505-513-rft-date-2015-rft-id-info-3adoi-2f10-1016-2fj-drudis-2014-12-014-rft-id-info-3apmid-2f25582842-rft-aulast-verbist-rft-aufirst-b-rft-au-klambauer-2c-g-rft-au-vervoort-2c-l-rft-au-talloen-2c-w-rft-au-the-qstar-2c-consortium-rft-au-shkedy-2c-z-rft-au-thas-2c-o-rft-au-bender-2c-a-rft-au-g-c3-b6hlmann-2c-h-w-rft-au-hochreiter-2c-s-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-151-span-class-mw-cite-backlink-b-a-href-cite-ref-151-a-b-span-span-class-reference-text-cite-class-citation-arxiv-wallach-izhar-dzamba-michael-heifets-abraham-2015-10-09-atomnet-a-deep-convolutional-neural-network-for-bioactivity-prediction-in-structure-based-drug-discovery-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1510-02855-1510-02855-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-lg-cs-lg-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-atomnet-3a-a-deep-convolutional-neural-network-for-bioactivity-prediction-in-structure-based-drug-discovery-rft-date-2015-10-09-rft-id-info-3aarxiv-2f1510-02855-rft-aulast-wallach-rft-aufirst-izhar-rft-au-dzamba-2c-michael-rft-au-heifets-2c-abraham-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-152-span-class-mw-cite-backlink-b-a-href-cite-ref-152-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-theglobeandmail-com-report-on-business-small-business-starting-out-toronto-startup-has-a-faster-way-to-discover-effective-medicines-article25660419-toronto-startup-has-a-faster-way-to-discover-effective-medicines-a-i-the-globe-and-mail-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2015-11-09-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-the-globe-and-mail-rft-atitle-toronto-startup-has-a-faster-way-to-discover-effective-medicines-rft-id-https-3a-2f-2fwww-theglobeandmail-com-2freport-on-business-2fsmall-business-2fstarting-out-2ftoronto-startup-has-a-faster-way-to-discover-effective-medicines-2farticle25660419-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-153-span-class-mw-cite-backlink-b-a-href-cite-ref-153-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-http-ww2-kqed-org-futureofyou-2015-05-27-startup-harnesses-supercomputers-to-seek-cures-startup-harnesses-supercomputers-to-seek-cures-a-i-kqed-future-of-you-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2015-11-09-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-kqed-future-of-you-rft-atitle-startup-harnesses-supercomputers-to-seek-cures-rft-id-http-3a-2f-2fww2-kqed-org-2ffutureofyou-2f2015-2f05-2f27-2fstartup-harnesses-supercomputers-to-seek-cures-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-154-span-class-mw-cite-backlink-b-a-href-cite-ref-154-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-theglobeandmail-com-report-on-business-small-business-starting-out-toronto-startup-has-a-faster-way-to-discover-effective-medicines-article25660419-5d-20and-20multiple-20sclerosis-20-5b-toronto-startup-has-a-faster-way-to-discover-effective-medicines-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-toronto-startup-has-a-faster-way-to-discover-effective-medicines-rft-id-https-3a-2f-2fwww-theglobeandmail-com-2freport-on-business-2fsmall-business-2fstarting-out-2ftoronto-startup-has-a-faster-way-to-discover-effective-medicines-2farticle25660419-2f-255d-2520and-2520multiple-2520sclerosis-2520-255b-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-155-span-class-mw-cite-backlink-b-a-href-cite-ref-155-a-b-span-span-class-reference-text-cite-class-citation-arxiv-tkachenko-yegor-april-8-2015-autonomous-crm-control-via-clv-approximation-with-deep-reinforcement-learning-in-discrete-and-continuous-action-space-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1504-01840-1504-01840-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-lg-cs-lg-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-autonomous-crm-control-via-clv-approximation-with-deep-reinforcement-learning-in-discrete-and-continuous-action-space-rft-date-2015-04-08-rft-id-info-3aarxiv-2f1504-01840-rft-aulast-tkachenko-rft-aufirst-yegor-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-156-span-class-mw-cite-backlink-b-a-href-cite-ref-156-a-b-span-span-class-reference-text-cite-class-citation-book-van-den-oord-aaron-dieleman-sander-schrauwen-benjamin-2013-burges-c-j-c-bottou-l-welling-m-ghahramani-z-weinberger-k-q-eds-a-rel-nofollow-class-external-text-href-http-papers-nips-cc-paper-5004-deep-content-based-music-recommendation-pdf-i-advances-in-neural-information-processing-systems-26-i-a-span-class-cs1-format-pdf-span-curran-associates-inc-pp-2643-2651-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-advances-in-neural-information-processing-systems-26-rft-pages-2643-2651-rft-pub-curran-associates-2c-inc-rft-date-2013-rft-aulast-van-den-oord-rft-aufirst-aaron-rft-au-dieleman-2c-sander-rft-au-schrauwen-2c-benjamin-rft-id-http-3a-2f-2fpapers-nips-cc-2fpaper-2f5004-deep-content-based-music-recommendation-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-157-span-class-mw-cite-backlink-b-a-href-cite-ref-157-a-b-span-span-class-reference-text-cite-class-citation-journal-elkahky-ali-mamdouh-song-yang-he-xiaodong-2015-05-01-a-rel-nofollow-class-external-text-href-https-www-microsoft-com-en-us-research-publication-a-multi-view-deep-learning-approach-for-cross-domain-user-modeling-in-recommendation-systems-a-multi-view-deep-learning-approach-for-cross-domain-user-modeling-in-recommendation-systems-a-i-microsoft-research-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-microsoft-research-rft-atitle-a-multi-view-deep-learning-approach-for-cross-domain-user-modeling-in-recommendation-systems-rft-date-2015-05-01-rft-aulast-elkahky-rft-aufirst-ali-mamdouh-rft-au-song-2c-yang-rft-au-he-2c-xiaodong-rft-id-https-3a-2f-2fwww-microsoft-com-2fen-us-2fresearch-2fpublication-2fa-multi-view-deep-learning-approach-for-cross-domain-user-modeling-in-recommendation-systems-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-158-span-class-mw-cite-backlink-b-a-href-cite-ref-158-a-b-span-span-class-reference-text-cite-class-citation-book-chicco-davide-sadowski-peter-baldi-pierre-1-january-2014-i-deep-autoencoder-neural-networks-for-gene-ontology-annotation-predictions-i-i-proceedings-of-the-5th-acm-conference-on-bioinformatics-computational-biology-and-health-informatics-bcb-14-i-acm-pp-533-540-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1145-2f2649387-2649442-10-1145-2649387-2649442-a-a-href-wiki-handle-system-title-handle-system-hdl-a-a-rel-nofollow-class-external-text-href-hdl-handle-net-11311-2f964622-11311-964622-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-9781450328944-title-special-booksources-9781450328944-bdi-9781450328944-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-deep-autoencoder-neural-networks-for-gene-ontology-annotation-predictions-rft-pages-533-540-rft-pub-acm-rft-date-2014-01-01-rft-id-info-3ahdl-2f11311-2f964622-rft-id-info-3adoi-2f10-1145-2f2649387-2649442-rft-isbn-9781450328944-rft-aulast-chicco-rft-aufirst-davide-rft-au-sadowski-2c-peter-rft-au-baldi-2c-pierre-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-159-span-class-mw-cite-backlink-b-a-href-cite-ref-159-a-b-span-span-class-reference-text-cite-class-citation-journal-sathyanarayana-aarti-2016-01-01-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc5116102-sleep-quality-prediction-from-wearable-data-using-deep-learning-a-i-jmir-mhealth-and-uhealth-i-b-4-b-4-e125-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-2196-2fmhealth-6562-10-2196-mhealth-6562-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc5116102-5116102-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-27815231-27815231-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-jmir-mhealth-and-uhealth-rft-atitle-sleep-quality-prediction-from-wearable-data-using-deep-learning-rft-volume-4-rft-issue-4-rft-pages-e125-rft-date-2016-01-01-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc5116102-rft-id-info-3apmid-2f27815231-rft-id-info-3adoi-2f10-2196-2fmhealth-6562-rft-aulast-sathyanarayana-rft-aufirst-aarti-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc5116102-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-160-span-class-mw-cite-backlink-b-a-href-cite-ref-160-a-b-span-span-class-reference-text-cite-class-citation-journal-choi-edward-schuetz-andy-stewart-walter-f-sun-jimeng-2016-08-13-a-rel-nofollow-class-external-text-href-http-jamia-oxfordjournals-org-content-early-2016-08-13-jamia-ocw112-using-recurrent-neural-network-models-for-early-detection-of-heart-failure-onset-a-i-journal-of-the-american-medical-informatics-association-i-b-24-b-2-361-370-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1093-2fjamia-2focw112-10-1093-jamia-ocw112-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-1067-5027-1067-5027-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc5391725-5391725-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-27521897-27521897-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-the-american-medical-informatics-association-rft-atitle-using-recurrent-neural-network-models-for-early-detection-of-heart-failure-onset-rft-volume-24-rft-issue-2-rft-pages-361-370-rft-date-2016-08-13-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc5391725-rft-issn-1067-5027-rft-id-info-3apmid-2f27521897-rft-id-info-3adoi-2f10-1093-2fjamia-2focw112-rft-aulast-choi-rft-aufirst-edward-rft-au-schuetz-2c-andy-rft-au-stewart-2c-walter-f-rft-au-sun-2c-jimeng-rft-id-http-3a-2f-2fjamia-oxfordjournals-org-2fcontent-2fearly-2f2016-2f08-2f13-2fjamia-ocw112-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-161-span-class-mw-cite-backlink-b-a-href-cite-ref-161-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-medium-com-the-mission-deep-learning-in-healthcare-challenges-and-opportunities-d2eee7e2545-deep-learning-in-healthcare-challenges-and-opportunities-a-i-medium-i-2016-08-12-span-class-reference-accessdate-retrieved-span-class-nowrap-2018-04-10-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-medium-rft-atitle-deep-learning-in-healthcare-3a-challenges-and-opportunities-rft-date-2016-08-12-rft-id-https-3a-2f-2fmedium-com-2fthe-mission-2fdeep-learning-in-healthcare-challenges-and-opportunities-d2eee7e2545-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-162-span-class-mw-cite-backlink-b-a-href-cite-ref-162-a-b-span-span-class-reference-text-cite-class-citation-journal-litjens-geert-kooi-thijs-bejnordi-babak-ehteshami-setio-arnaud-arindra-adiyoso-ciompi-francesco-ghafoorian-mohsen-van-der-laak-jeroen-a-w-m-van-ginneken-bram-sanchez-clara-i-december-2017-a-rel-nofollow-class-external-text-href-https-linkinghub-elsevier-com-retrieve-pii-s1361841517301135-a-survey-on-deep-learning-in-medical-image-analysis-a-i-medical-image-analysis-i-b-42-b-60-88-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-media-2017-07-005-10-1016-j-media-2017-07-005-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-medical-image-analysis-rft-atitle-a-survey-on-deep-learning-in-medical-image-analysis-rft-volume-42-rft-pages-60-88-rft-date-2017-12-rft-id-info-3adoi-2f10-1016-2fj-media-2017-07-005-rft-aulast-litjens-rft-aufirst-geert-rft-au-kooi-2c-thijs-rft-au-bejnordi-2c-babak-ehteshami-rft-au-setio-2c-arnaud-arindra-adiyoso-rft-au-ciompi-2c-francesco-rft-au-ghafoorian-2c-mohsen-rft-au-van-der-laak-2c-jeroen-a-w-m-rft-au-van-ginneken-2c-bram-rft-au-s-c3-a1nchez-2c-clara-i-rft-id-https-3a-2f-2flinkinghub-elsevier-com-2fretrieve-2fpii-2fs1361841517301135-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-163-span-class-mw-cite-backlink-b-a-href-cite-ref-163-a-b-span-span-class-reference-text-cite-class-citation-journal-forslid-gustav-wieslander-hakan-bengtsson-ewert-wahlby-carolina-hirsch-jan-michael-stark-christina-runow-sadanandan-sajith-kecheril-october-2017-a-rel-nofollow-class-external-text-href-http-ieeexplore-ieee-org-document-8265228-deep-convolutional-neural-networks-for-detecting-cellular-changes-due-to-malignancy-a-i-2017-ieee-international-conference-on-computer-vision-workshops-iccvw-i-venice-ieee-82-89-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2ficcvw-2017-18-10-1109-iccvw-2017-18-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-9781538610343-title-special-booksources-9781538610343-bdi-9781538610343-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-2017-ieee-international-conference-on-computer-vision-workshops-28iccvw-29-rft-atitle-deep-convolutional-neural-networks-for-detecting-cellular-changes-due-to-malignancy-rft-pages-82-89-rft-date-2017-10-rft-id-info-3adoi-2f10-1109-2ficcvw-2017-18-rft-isbn-9781538610343-rft-aulast-forslid-rft-aufirst-gustav-rft-au-wieslander-2c-hakan-rft-au-bengtsson-2c-ewert-rft-au-wahlby-2c-carolina-rft-au-hirsch-2c-jan-michael-rft-au-stark-2c-christina-runow-rft-au-sadanandan-2c-sajith-kecheril-rft-id-http-3a-2f-2fieeexplore-ieee-org-2fdocument-2f8265228-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-164-span-class-mw-cite-backlink-b-a-href-cite-ref-164-a-b-span-span-class-reference-text-cite-class-citation-journal-de-shaunak-maity-abhishek-goel-vritti-shitole-sanjay-bhattacharya-avik-2017-a-rel-nofollow-class-external-text-href-https-ieeexplore-ieee-org-document-8066548-predicting-the-popularity-of-instagram-posts-for-a-lifestyle-magazine-using-deep-learning-a-i-2nd-ieee-conference-on-communication-systems-computing-and-it-applications-i-174-177-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1109-2fcscita-2017-8066548-10-1109-cscita-2017-8066548-a-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-1-5090-4381-1-title-special-booksources-978-1-5090-4381-1-bdi-978-1-5090-4381-1-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-2nd-ieee-conference-on-communication-systems-2c-computing-and-it-applications-rft-atitle-predicting-the-popularity-of-instagram-posts-for-a-lifestyle-magazine-using-deep-learning-rft-pages-174-177-rft-date-2017-rft-id-info-3adoi-2f10-1109-2fcscita-2017-8066548-rft-isbn-978-1-5090-4381-1-rft-aulast-de-rft-aufirst-shaunak-rft-au-maity-2c-abhishek-rft-au-goel-2c-vritti-rft-au-shitole-2c-sanjay-rft-au-bhattacharya-2c-avik-rft-id-https-3a-2f-2fieeexplore-ieee-org-2fdocument-2f8066548-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-165-span-class-mw-cite-backlink-b-a-href-cite-ref-165-a-b-span-span-class-reference-text-cite-class-citation-conference-schmidt-uwe-roth-stefan-a-rel-nofollow-class-external-text-href-http-research-uweschmidt-org-pubs-cvpr14schmidt-pdf-i-shrinkage-fields-for-effective-image-restoration-i-a-span-class-cs1-format-pdf-span-computer-vision-and-pattern-recognition-cvpr-2014-ieee-conference-on-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-conference-rft-btitle-shrinkage-fields-for-effective-image-restoration-rft-aulast-schmidt-rft-aufirst-uwe-rft-au-roth-2c-stefan-rft-id-http-3a-2f-2fresearch-uweschmidt-org-2fpubs-2fcvpr14schmidt-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-166-span-class-mw-cite-backlink-b-a-href-cite-ref-166-a-b-span-span-class-reference-text-cite-class-citation-journal-czech-tomasz-a-rel-nofollow-class-external-text-href-https-www-globalbankingandfinance-com-deep-learning-the-next-frontier-for-money-laundering-detection-deep-learning-the-next-frontier-for-money-laundering-detection-a-i-global-banking-and-finance-review-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-global-banking-and-finance-review-rft-atitle-deep-learning-3a-the-next-frontier-for-money-laundering-detection-rft-aulast-czech-rft-aufirst-tomasz-rft-id-https-3a-2f-2fwww-globalbankingandfinance-com-2fdeep-learning-the-next-frontier-for-money-laundering-detection-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-12-167-span-class-mw-cite-backlink-a-href-cite-ref-12-167-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-12-167-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-12-167-2-sup-i-b-c-b-i-sup-a-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-www-eurekalert-org-pub-releases-2018-02-uarl-ard020218-php-army-researchers-develop-new-algorithms-to-train-robots-a-i-eurekalert-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2018-08-29-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-eurekalert-21-rft-atitle-army-researchers-develop-new-algorithms-to-train-robots-rft-id-https-3a-2f-2fwww-eurekalert-org-2fpub-releases-2f2018-02-2fuarl-ard020218-php-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-utgoff-168-span-class-mw-cite-backlink-b-a-href-cite-ref-utgoff-168-0-a-b-span-span-class-reference-text-cite-class-citation-journal-utgoff-p-e-stracuzzi-d-j-2002-many-layered-learning-i-neural-computation-i-b-14-b-10-2497-2529-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1162-2f08997660260293319-10-1162-08997660260293319-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-12396572-12396572-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neural-computation-rft-atitle-many-layered-learning-rft-volume-14-rft-issue-10-rft-pages-2497-2529-rft-date-2002-rft-id-info-3adoi-2f10-1162-2f08997660260293319-rft-id-info-3apmid-2f12396572-rft-aulast-utgoff-rft-aufirst-p-e-rft-au-stracuzzi-2c-d-j-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-elman-169-span-class-mw-cite-backlink-b-a-href-cite-ref-elman-169-0-a-b-span-span-class-reference-text-cite-class-citation-book-elman-jeffrey-l-1998-a-rel-nofollow-class-external-text-href-https-books-google-com-books-id-velaru-mrwoc-i-rethinking-innateness-a-connectionist-perspective-on-development-i-a-mit-press-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-0-262-55030-7-title-special-booksources-978-0-262-55030-7-bdi-978-0-262-55030-7-bdi-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-rethinking-innateness-3a-a-connectionist-perspective-on-development-rft-pub-mit-press-rft-date-1998-rft-isbn-978-0-262-55030-7-rft-aulast-elman-rft-aufirst-jeffrey-l-rft-id-https-3a-2f-2fbooks-google-com-2fbooks-3fid-3dvelaru-mrwoc-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-shrager-170-span-class-mw-cite-backlink-b-a-href-cite-ref-shrager-170-0-a-b-span-span-class-reference-text-cite-class-citation-journal-shrager-j-johnson-mh-1996-dynamic-plasticity-influences-the-emergence-of-function-in-a-simple-cortical-array-i-neural-networks-i-b-9-b-7-1119-1129-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2f0893-6080-2896-2900033-0-10-1016-0893-6080-96-00033-0-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-12662587-12662587-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neural-networks-rft-atitle-dynamic-plasticity-influences-the-emergence-of-function-in-a-simple-cortical-array-rft-volume-9-rft-issue-7-rft-pages-1119-1129-rft-date-1996-rft-id-info-3adoi-2f10-1016-2f0893-6080-2896-2900033-0-rft-id-info-3apmid-2f12662587-rft-aulast-shrager-rft-aufirst-j-rft-au-johnson-2c-mh-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-quartz-171-span-class-mw-cite-backlink-b-a-href-cite-ref-quartz-171-0-a-b-span-span-class-reference-text-cite-class-citation-journal-quartz-sr-sejnowski-tj-1997-the-neural-basis-of-cognitive-development-a-constructivist-manifesto-i-behavioral-and-brain-sciences-i-b-20-b-4-537-556-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-41-7854-10-1-1-41-7854-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1017-2fs0140525x97001581-10-1017-s0140525x97001581-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-behavioral-and-brain-sciences-rft-atitle-the-neural-basis-of-cognitive-development-3a-a-constructivist-manifesto-rft-volume-20-rft-issue-4-rft-pages-537-556-rft-date-1997-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-41-7854-rft-id-info-3adoi-2f10-1017-2fs0140525x97001581-rft-aulast-quartz-rft-aufirst-sr-rft-au-sejnowski-2c-tj-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-blakeslee-172-span-class-mw-cite-backlink-b-a-href-cite-ref-blakeslee-172-0-a-b-span-span-class-reference-text-s-blakeslee-in-brain-s-early-growth-timetable-may-be-critical-i-the-new-york-times-science-section-i-pp-b5-b6-1995-span-li-li-id-cite-note-173-span-class-mw-cite-backlink-b-a-href-cite-ref-173-a-b-span-span-class-reference-text-cite-class-citation-journal-mazzoni-p-andersen-r-a-jordan-m-i-1991-05-15-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc51674-a-more-biologically-plausible-learning-rule-for-neural-networks-a-i-proceedings-of-the-national-academy-of-sciences-i-b-88-b-10-4433-4437-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-1991pnas-88-4433m-1991pnas-88-4433m-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1073-2fpnas-88-10-4433-10-1073-pnas-88-10-4433-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-0027-8424-0027-8424-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc51674-51674-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-1903542-1903542-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-proceedings-of-the-national-academy-of-sciences-rft-atitle-a-more-biologically-plausible-learning-rule-for-neural-networks-rft-volume-88-rft-issue-10-rft-pages-4433-4437-rft-date-1991-05-15-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc51674-rft-id-info-3abibcode-2f1991pnas-88-4433m-rft-id-info-3apmid-2f1903542-rft-id-info-3adoi-2f10-1073-2fpnas-88-10-4433-rft-issn-0027-8424-rft-aulast-mazzoni-rft-aufirst-p-rft-au-andersen-2c-r-a-rft-au-jordan-2c-m-i-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc51674-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-174-span-class-mw-cite-backlink-b-a-href-cite-ref-174-a-b-span-span-class-reference-text-cite-class-citation-journal-o-reilly-randall-c-1996-07-01-biologically-plausible-error-driven-learning-using-local-activation-differences-the-generalized-recirculation-algorithm-i-neural-computation-i-b-8-b-5-895-938-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1162-2fneco-1996-8-5-895-10-1162-neco-1996-8-5-895-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-0899-7667-0899-7667-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neural-computation-rft-atitle-biologically-plausible-error-driven-learning-using-local-activation-differences-3a-the-generalized-recirculation-algorithm-rft-volume-8-rft-issue-5-rft-pages-895-938-rft-date-1996-07-01-rft-id-info-3adoi-2f10-1162-2fneco-1996-8-5-895-rft-issn-0899-7667-rft-aulast-o-27reilly-rft-aufirst-randall-c-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-175-span-class-mw-cite-backlink-b-a-href-cite-ref-175-a-b-span-span-class-reference-text-cite-class-citation-journal-testolin-alberto-zorzi-marco-2016-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4943066-probabilistic-models-and-generative-neural-networks-towards-an-unified-framework-for-modeling-normal-and-impaired-neurocognitive-functions-a-i-frontiers-in-computational-neuroscience-i-b-10-b-73-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-3389-2ffncom-2016-00073-10-3389-fncom-2016-00073-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-1662-5188-1662-5188-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc4943066-4943066-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-27468262-27468262-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-frontiers-in-computational-neuroscience-rft-atitle-probabilistic-models-and-generative-neural-networks-3a-towards-an-unified-framework-for-modeling-normal-and-impaired-neurocognitive-functions-rft-volume-10-rft-pages-73-rft-date-2016-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4943066-rft-issn-1662-5188-rft-id-info-3apmid-2f27468262-rft-id-info-3adoi-2f10-3389-2ffncom-2016-00073-rft-aulast-testolin-rft-aufirst-alberto-rft-au-zorzi-2c-marco-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc4943066-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-176-span-class-mw-cite-backlink-b-a-href-cite-ref-176-a-b-span-span-class-reference-text-cite-class-citation-journal-testolin-alberto-stoianov-ivilin-zorzi-marco-september-2017-letter-perception-emerges-from-unsupervised-deep-learning-and-recycling-of-natural-image-features-i-nature-human-behaviour-i-b-1-b-9-657-664-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1038-2fs41562-017-0186-2-10-1038-s41562-017-0186-2-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-2397-3374-2397-3374-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-nature-human-behaviour-rft-atitle-letter-perception-emerges-from-unsupervised-deep-learning-and-recycling-of-natural-image-features-rft-volume-1-rft-issue-9-rft-pages-657-664-rft-date-2017-09-rft-id-info-3adoi-2f10-1038-2fs41562-017-0186-2-rft-issn-2397-3374-rft-aulast-testolin-rft-aufirst-alberto-rft-au-stoianov-2c-ivilin-rft-au-zorzi-2c-marco-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-177-span-class-mw-cite-backlink-b-a-href-cite-ref-177-a-b-span-span-class-reference-text-cite-class-citation-journal-buesing-lars-bill-johannes-nessler-bernhard-maass-wolfgang-2011-11-03-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc3207943-neural-dynamics-as-sampling-a-model-for-stochastic-computation-in-recurrent-networks-of-spiking-neurons-a-i-plos-computational-biology-i-b-7-b-11-e1002211-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2011plscb-7e2211b-2011plscb-7e2211b-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1371-2fjournal-pcbi-1002211-10-1371-journal-pcbi-1002211-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-1553-7358-1553-7358-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc3207943-3207943-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-22096452-22096452-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-plos-computational-biology-rft-atitle-neural-dynamics-as-sampling-3a-a-model-for-stochastic-computation-in-recurrent-networks-of-spiking-neurons-rft-volume-7-rft-issue-11-rft-pages-e1002211-rft-date-2011-11-03-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc3207943-rft-id-info-3abibcode-2f2011plscb-7e2211b-rft-id-info-3apmid-2f22096452-rft-id-info-3adoi-2f10-1371-2fjournal-pcbi-1002211-rft-issn-1553-7358-rft-aulast-buesing-rft-aufirst-lars-rft-au-bill-2c-johannes-rft-au-nessler-2c-bernhard-rft-au-maass-2c-wolfgang-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc3207943-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-178-span-class-mw-cite-backlink-b-a-href-cite-ref-178-a-b-span-span-class-reference-text-cite-class-citation-journal-morel-danielle-singh-chandan-levy-william-b-2018-01-25-linearization-of-excitatory-synaptic-integration-at-no-extra-cost-i-journal-of-computational-neuroscience-i-b-44-b-2-173-188-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1007-2fs10827-017-0673-5-10-1007-s10827-017-0673-5-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-0929-5313-0929-5313-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-29372434-29372434-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-computational-neuroscience-rft-atitle-linearization-of-excitatory-synaptic-integration-at-no-extra-cost-rft-volume-44-rft-issue-2-rft-pages-173-188-rft-date-2018-01-25-rft-issn-0929-5313-rft-id-info-3apmid-2f29372434-rft-id-info-3adoi-2f10-1007-2fs10827-017-0673-5-rft-aulast-morel-rft-aufirst-danielle-rft-au-singh-2c-chandan-rft-au-levy-2c-william-b-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-179-span-class-mw-cite-backlink-b-a-href-cite-ref-179-a-b-span-span-class-reference-text-cite-class-citation-journal-cash-s-yuste-r-february-1999-linear-summation-of-excitatory-inputs-by-ca1-pyramidal-neurons-i-neuron-i-b-22-b-2-383-394-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fs0896-6273-2800-2981098-3-10-1016-s0896-6273-00-81098-3-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-0896-6273-0896-6273-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-10069343-10069343-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-neuron-rft-atitle-linear-summation-of-excitatory-inputs-by-ca1-pyramidal-neurons-rft-volume-22-rft-issue-2-rft-pages-383-394-rft-date-1999-02-rft-issn-0896-6273-rft-id-info-3apmid-2f10069343-rft-id-info-3adoi-2f10-1016-2fs0896-6273-2800-2981098-3-rft-aulast-cash-rft-aufirst-s-rft-au-yuste-2c-r-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-180-span-class-mw-cite-backlink-b-a-href-cite-ref-180-a-b-span-span-class-reference-text-cite-class-citation-journal-olshausen-b-field-d-2004-08-01-sparse-coding-of-sensory-inputs-i-current-opinion-in-neurobiology-i-b-14-b-4-481-487-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1016-2fj-conb-2004-07-007-10-1016-j-conb-2004-07-007-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-0959-4388-0959-4388-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-current-opinion-in-neurobiology-rft-atitle-sparse-coding-of-sensory-inputs-rft-volume-14-rft-issue-4-rft-pages-481-487-rft-date-2004-08-01-rft-id-info-3adoi-2f10-1016-2fj-conb-2004-07-007-rft-issn-0959-4388-rft-aulast-olshausen-rft-aufirst-b-rft-au-field-2c-d-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-181-span-class-mw-cite-backlink-b-a-href-cite-ref-181-a-b-span-span-class-reference-text-cite-class-citation-journal-yamins-daniel-l-k-dicarlo-james-j-march-2016-using-goal-driven-deep-learning-models-to-understand-sensory-cortex-i-nature-neuroscience-i-b-19-b-3-356-365-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1038-2fnn-4244-10-1038-nn-4244-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-1546-1726-1546-1726-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-nature-neuroscience-rft-atitle-using-goal-driven-deep-learning-models-to-understand-sensory-cortex-rft-volume-19-rft-issue-3-rft-pages-356-365-rft-date-2016-03-rft-id-info-3adoi-2f10-1038-2fnn-4244-rft-issn-1546-1726-rft-aulast-yamins-rft-aufirst-daniel-l-k-rft-au-dicarlo-2c-james-j-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-182-span-class-mw-cite-backlink-b-a-href-cite-ref-182-a-b-span-span-class-reference-text-cite-class-citation-journal-zorzi-marco-testolin-alberto-2018-02-19-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc5784047-an-emergentist-perspective-on-the-origin-of-number-sense-a-i-phil-trans-r-soc-b-i-b-373-b-1740-20170043-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1098-2frstb-2017-0043-10-1098-rstb-2017-0043-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-0962-8436-0962-8436-a-a-href-wiki-pubmed-central-title-pubmed-central-pmc-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pmc-articles-pmc5784047-5784047-a-span-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-29292348-29292348-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-phil-trans-r-soc-b-rft-atitle-an-emergentist-perspective-on-the-origin-of-number-sense-rft-volume-373-rft-issue-1740-rft-pages-20170043-rft-date-2018-02-19-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc5784047-rft-issn-0962-8436-rft-id-info-3apmid-2f29292348-rft-id-info-3adoi-2f10-1098-2frstb-2017-0043-rft-aulast-zorzi-rft-aufirst-marco-rft-au-testolin-2c-alberto-rft-id-2f-2fwww-ncbi-nlm-nih-gov-2fpmc-2farticles-2fpmc5784047-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-183-span-class-mw-cite-backlink-b-a-href-cite-ref-183-a-b-span-span-class-reference-text-cite-class-citation-journal-guclu-umut-van-gerven-marcel-a-j-2015-07-08-deep-neural-networks-reveal-a-gradient-in-the-complexity-of-neural-representations-across-the-ventral-stream-i-journal-of-neuroscience-i-b-35-b-27-10005-10014-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1411-6422-1411-6422-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1523-2fjneurosci-5023-14-2015-10-1523-jneurosci-5023-14-2015-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-26157000-26157000-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-journal-of-neuroscience-rft-atitle-deep-neural-networks-reveal-a-gradient-in-the-complexity-of-neural-representations-across-the-ventral-stream-rft-volume-35-rft-issue-27-rft-pages-10005-10014-rft-date-2015-07-08-rft-id-info-3aarxiv-2f1411-6422-rft-id-info-3apmid-2f26157000-rft-id-info-3adoi-2f10-1523-2fjneurosci-5023-14-2015-rft-aulast-g-c3-bc-c3-a7l-c3-bc-rft-aufirst-umut-rft-au-van-gerven-2c-marcel-a-j-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-metz2013-184-span-class-mw-cite-backlink-b-a-href-cite-ref-metz2013-184-0-a-b-span-span-class-reference-text-cite-class-citation-magazine-metz-c-12-december-2013-a-rel-nofollow-class-external-text-href-https-www-wired-com-wiredenterprise-2013-12-facebook-yann-lecun-qa-facebook-s-deep-learning-guru-reveals-the-future-of-ai-a-i-wired-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-wired-rft-atitle-facebook-27s-27deep-learning-27-guru-reveals-the-future-of-ai-rft-date-2013-12-12-rft-aulast-metz-rft-aufirst-c-rft-id-https-3a-2f-2fwww-wired-com-2fwiredenterprise-2f2013-2f12-2ffacebook-yann-lecun-qa-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-185-span-class-mw-cite-backlink-b-a-href-cite-ref-185-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-http-www-nature-com-news-google-ai-algorithm-masters-ancient-game-of-go-1-19234-google-ai-algorithm-masters-ancient-game-of-go-a-i-nature-news-comment-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2016-01-30-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-nature-news-26-comment-rft-atitle-google-ai-algorithm-masters-ancient-game-of-go-rft-id-http-3a-2f-2fwww-nature-com-2fnews-2fgoogle-ai-algorithm-masters-ancient-game-of-go-1-19234-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-186-span-class-mw-cite-backlink-b-a-href-cite-ref-186-a-b-span-span-class-reference-text-cite-class-citation-journal-a-href-wiki-david-silver-programmer-title-david-silver-programmer-silver-david-a-a-href-wiki-aja-huang-title-aja-huang-huang-aja-a-maddison-chris-j-guez-arthur-sifre-laurent-driessche-george-van-den-schrittwieser-julian-antonoglou-ioannis-panneershelvam-veda-lanctot-marc-dieleman-sander-grewe-dominik-nham-john-kalchbrenner-nal-a-href-wiki-ilya-sutskever-title-ilya-sutskever-sutskever-ilya-a-lillicrap-timothy-leach-madeleine-kavukcuoglu-koray-graepel-thore-a-href-wiki-demis-hassabis-title-demis-hassabis-hassabis-demis-a-28-january-2016-mastering-the-game-of-go-with-deep-neural-networks-and-tree-search-i-a-href-wiki-nature-journal-title-nature-journal-nature-a-i-b-529-b-7587-484-489-a-href-wiki-bibcode-title-bibcode-bibcode-a-a-rel-nofollow-class-external-text-href-http-adsabs-harvard-edu-abs-2016natur-529-484s-2016natur-529-484s-a-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1038-2fnature16961-10-1038-nature16961-a-a-href-wiki-international-standard-serial-number-title-international-standard-serial-number-issn-a-a-rel-nofollow-class-external-text-href-www-worldcat-org-issn-0028-0836-0028-0836-a-a-href-wiki-pubmed-identifier-class-mw-redirect-title-pubmed-identifier-pmid-a-a-rel-nofollow-class-external-text-href-www-ncbi-nlm-nih-gov-pubmed-26819042-26819042-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-nature-rft-atitle-mastering-the-game-of-go-with-deep-neural-networks-and-tree-search-rft-volume-529-rft-issue-7587-rft-pages-484-489-rft-date-2016-01-28-rft-id-info-3adoi-2f10-1038-2fnature16961-rft-issn-0028-0836-rft-id-info-3apmid-2f26819042-rft-id-info-3abibcode-2f2016natur-529-484s-rft-aulast-silver-rft-aufirst-david-rft-au-huang-2c-aja-rft-au-maddison-2c-chris-j-rft-au-guez-2c-arthur-rft-au-sifre-2c-laurent-rft-au-driessche-2c-george-van-den-rft-au-schrittwieser-2c-julian-rft-au-antonoglou-2c-ioannis-rft-au-panneershelvam-2c-veda-rft-au-lanctot-2c-marc-rft-au-dieleman-2c-sander-rft-au-grewe-2c-dominik-rft-au-nham-2c-john-rft-au-kalchbrenner-2c-nal-rft-au-sutskever-2c-ilya-rft-au-lillicrap-2c-timothy-rft-au-leach-2c-madeleine-rft-au-kavukcuoglu-2c-koray-rft-au-graepel-2c-thore-rft-au-hassabis-2c-demis-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-style-position-relative-top-2px-a-href-wiki-paywall-title-closed-access-publication-behind-paywall-img-alt-closed-access-src-upload-wikimedia-org-wikipedia-commons-thumb-0-0e-closed-access-logo-transparent-svg-9px-closed-access-logo-transparent-svg-png-decoding-async-width-9-height-14-srcset-upload-wikimedia-org-wikipedia-commons-thumb-0-0e-closed-access-logo-transparent-svg-14px-closed-access-logo-transparent-svg-png-1-5x-upload-wikimedia-org-wikipedia-commons-thumb-0-0e-closed-access-logo-transparent-svg-18px-closed-access-logo-transparent-svg-png-2x-data-file-width-640-data-file-height-1000-a-span-span-li-li-id-cite-note-187-span-class-mw-cite-backlink-b-a-href-cite-ref-187-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-http-www-technologyreview-com-news-546066-googles-ai-masters-the-game-of-go-a-decade-earlier-than-expected-a-google-deepmind-algorithm-uses-deep-learning-and-more-to-master-the-game-of-go-mit-technology-review-a-i-mit-technology-review-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2016-01-30-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-mit-technology-review-rft-atitle-a-google-deepmind-algorithm-uses-deep-learning-and-more-to-master-the-game-of-go-7c-mit-technology-review-rft-id-http-3a-2f-2fwww-technologyreview-com-2fnews-2f546066-2fgoogles-ai-masters-the-game-of-go-a-decade-earlier-than-expected-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-188-span-class-mw-cite-backlink-b-a-href-cite-ref-188-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-techcrunch-com-2015-12-08-blippar-demonstrates-new-real-time-augmented-reality-app-blippar-demonstrates-new-real-time-augmented-reality-app-a-i-techcrunch-i-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-techcrunch-rft-atitle-blippar-demonstrates-new-real-time-augmented-reality-app-rft-id-https-3a-2f-2ftechcrunch-com-2f2015-2f12-2f08-2fblippar-demonstrates-new-real-time-augmented-reality-app-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-189-span-class-mw-cite-backlink-b-a-href-cite-ref-189-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-ieeexplore-ieee-org-document-4640845-tamer-training-an-agent-manually-via-evaluative-reinforcement-ieee-conference-publication-a-i-ieeexplore-ieee-org-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2018-08-29-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-ieeexplore-ieee-org-rft-atitle-tamer-3a-training-an-agent-manually-via-evaluative-reinforcement-ieee-conference-publication-rft-id-https-3a-2f-2fieeexplore-ieee-org-2fdocument-2f4640845-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-190-span-class-mw-cite-backlink-b-a-href-cite-ref-190-a-b-span-span-class-reference-text-cite-class-citation-web-a-rel-nofollow-class-external-text-href-https-governmentciomedia-com-talk-algorithms-ai-becomes-faster-learner-talk-to-the-algorithms-ai-becomes-a-faster-learner-a-i-governmentciomedia-com-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2018-08-29-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-governmentciomedia-com-rft-atitle-talk-to-the-algorithms-3a-ai-becomes-a-faster-learner-rft-id-https-3a-2f-2fgovernmentciomedia-com-2ftalk-algorithms-ai-becomes-faster-learner-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-191-span-class-mw-cite-backlink-b-a-href-cite-ref-191-a-b-span-span-class-reference-text-cite-class-citation-web-marcus-gary-2018-01-14-a-rel-nofollow-class-external-text-href-https-medium-com-garymarcus-in-defense-of-skepticism-about-deep-learning-6e8bfd5ae0f1-in-defense-of-skepticism-about-deep-learning-a-i-gary-marcus-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2018-10-11-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-gary-marcus-rft-atitle-in-defense-of-skepticism-about-deep-learning-rft-date-2018-01-14-rft-aulast-marcus-rft-aufirst-gary-rft-id-https-3a-2f-2fmedium-com-2f-40garymarcus-2fin-defense-of-skepticism-about-deep-learning-6e8bfd5ae0f1-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-knight-2017-192-span-class-mw-cite-backlink-b-a-href-cite-ref-knight-2017-192-0-a-b-span-span-class-reference-text-cite-class-citation-web-knight-will-2017-03-14-a-rel-nofollow-class-external-text-href-https-www-technologyreview-com-s-603795-the-us-military-wants-its-autonomous-machines-to-explain-themselves-darpa-is-funding-projects-that-will-try-to-open-up-ai-s-black-boxes-a-i-mit-technology-review-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2017-11-02-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-unknown-rft-jtitle-mit-technology-review-rft-atitle-darpa-is-funding-projects-that-will-try-to-open-up-ai-27s-black-boxes-rft-date-2017-03-14-rft-aulast-knight-rft-aufirst-will-rft-id-https-3a-2f-2fwww-technologyreview-com-2fs-2f603795-2fthe-us-military-wants-its-autonomous-machines-to-explain-themselves-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-193-span-class-mw-cite-backlink-b-a-href-cite-ref-193-a-b-span-span-class-reference-text-cite-class-citation-magazine-marcus-gary-november-25-2012-a-rel-nofollow-class-external-text-href-http-www-newyorker-com-is-deep-learning-a-revolution-in-artificial-intelligence-a-i-the-new-yorker-i-span-class-reference-accessdate-retrieved-span-class-nowrap-2017-06-14-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-the-new-yorker-rft-atitle-is-22deep-learning-22-a-revolution-in-artificial-intelligence-3f-rft-date-2012-11-25-rft-aulast-marcus-rft-aufirst-gary-rft-id-http-3a-2f-2fwww-newyorker-com-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-194-span-class-mw-cite-backlink-b-a-href-cite-ref-194-a-b-span-span-class-reference-text-cite-class-citation-web-smith-g-w-march-27-2015-a-rel-nofollow-class-external-text-href-https-web-archive-org-web-20170625075845-http-artent-net-2015-03-27-art-and-artificial-intelligence-by-g-w-smith-art-and-artificial-intelligence-a-artent-archived-from-the-original-on-june-25-2017-span-class-reference-accessdate-retrieved-span-class-nowrap-march-27-span-2015-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-art-and-artificial-intelligence-rft-pub-artent-rft-date-2015-03-27-rft-au-smith-2c-g-w-rft-id-http-3a-2f-2fartent-net-2f2015-2f03-2f27-2fart-and-artificial-intelligence-by-g-w-smith-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-span-class-cs1-maint-citation-comment-cs1-maint-bot-original-url-status-unknown-a-href-wiki-category-cs1-maint-bot-original-url-status-unknown-title-category-cs1-maint-bot-original-url-status-unknown-link-a-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-195-span-class-mw-cite-backlink-b-a-href-cite-ref-195-a-b-span-span-class-reference-text-cite-class-citation-web-mellars-paul-february-1-2005-a-rel-nofollow-class-external-text-href-http-repositriodeficheiros-yolasite-com-resources-texto-2028-pdf-the-impossible-coincidence-a-single-species-model-for-the-origins-of-modern-human-behavior-in-europe-a-span-class-cs1-format-pdf-span-evolutionary-anthropology-issues-news-and-reviews-span-class-reference-accessdate-retrieved-span-class-nowrap-april-5-span-2017-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-the-impossible-coincidence-3a-a-single-species-model-for-the-origins-of-modern-human-behavior-in-europe-rft-pub-evolutionary-anthropology-3a-issues-2c-news-2c-and-reviews-rft-date-2005-02-01-rft-au-mellars-2c-paul-rft-id-http-3a-2f-2frepositriodeficheiros-yolasite-com-2fresources-2ftexto-252028-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-196-span-class-mw-cite-backlink-b-a-href-cite-ref-196-a-b-span-span-class-reference-text-cite-class-citation-web-alexander-mordvintsev-christopher-olah-mike-tyka-june-17-2015-a-rel-nofollow-class-external-text-href-http-googleresearch-blogspot-co-uk-2015-06-inceptionism-going-deeper-into-neural-html-inceptionism-going-deeper-into-neural-networks-a-google-research-blog-span-class-reference-accessdate-retrieved-span-class-nowrap-june-20-span-2015-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-inceptionism-3a-going-deeper-into-neural-networks-rft-pub-google-research-blog-rft-date-2015-06-17-rft-au-alexander-mordvintsev-rft-au-christopher-olah-rft-au-mike-tyka-rft-id-http-3a-2f-2fgoogleresearch-blogspot-co-uk-2f2015-2f06-2finceptionism-going-deeper-into-neural-html-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-197-span-class-mw-cite-backlink-b-a-href-cite-ref-197-a-b-span-span-class-reference-text-cite-class-citation-news-alex-hern-june-18-2015-a-rel-nofollow-class-external-text-href-https-www-theguardian-com-technology-2015-jun-18-google-image-recognition-neural-network-androids-dream-electric-sheep-yes-androids-do-dream-of-electric-sheep-a-i-the-guardian-i-span-class-reference-accessdate-retrieved-span-class-nowrap-june-20-span-2015-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-the-guardian-rft-atitle-yes-2c-androids-do-dream-of-electric-sheep-rft-date-2015-06-18-rft-au-alex-hern-rft-id-https-3a-2f-2fwww-theguardian-com-2ftechnology-2f2015-2fjun-2f18-2fgoogle-image-recognition-neural-network-androids-dream-electric-sheep-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-goertzel-198-span-class-mw-cite-backlink-a-href-cite-ref-goertzel-198-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-goertzel-198-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-goertzel-198-2-sup-i-b-c-b-i-sup-a-span-span-class-reference-text-cite-class-citation-web-goertzel-ben-2015-a-rel-nofollow-class-external-text-href-http-goertzel-org-deeplearning-v1-pdf-are-there-deep-reasons-underlying-the-pathologies-of-today-s-deep-learning-algorithms-a-span-class-cs1-format-pdf-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-are-there-deep-reasons-underlying-the-pathologies-of-today-27s-deep-learning-algorithms-3f-rft-date-2015-rft-aulast-goertzel-rft-aufirst-ben-rft-id-http-3a-2f-2fgoertzel-org-2fdeeplearning-v1-pdf-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-199-span-class-mw-cite-backlink-b-a-href-cite-ref-199-a-b-span-span-class-reference-text-cite-class-citation-arxiv-nguyen-anh-yosinski-jason-clune-jeff-2014-deep-neural-networks-are-easily-fooled-high-confidence-predictions-for-unrecognizable-images-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1412-1897-1412-1897-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-deep-neural-networks-are-easily-fooled-3a-high-confidence-predictions-for-unrecognizable-images-rft-date-2014-rft-id-info-3aarxiv-2f1412-1897-rft-aulast-nguyen-rft-aufirst-anh-rft-au-yosinski-2c-jason-rft-au-clune-2c-jeff-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-200-span-class-mw-cite-backlink-b-a-href-cite-ref-200-a-b-span-span-class-reference-text-cite-class-citation-arxiv-szegedy-christian-zaremba-wojciech-sutskever-ilya-bruna-joan-erhan-dumitru-goodfellow-ian-fergus-rob-2013-intriguing-properties-of-neural-networks-a-href-wiki-arxiv-title-arxiv-arxiv-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-arxiv-org-abs-1312-6199-1312-6199-a-span-a-rel-nofollow-class-external-text-href-arxiv-org-archive-cs-cv-cs-cv-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-preprint-rft-jtitle-arxiv-rft-atitle-intriguing-properties-of-neural-networks-rft-date-2013-rft-id-info-3aarxiv-2f1312-6199-rft-aulast-szegedy-rft-aufirst-christian-rft-au-zaremba-2c-wojciech-rft-au-sutskever-2c-ilya-rft-au-bruna-2c-joan-rft-au-erhan-2c-dumitru-rft-au-goodfellow-2c-ian-rft-au-fergus-2c-rob-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-201-span-class-mw-cite-backlink-b-a-href-cite-ref-201-a-b-span-span-class-reference-text-cite-class-citation-journal-zhu-s-c-mumford-d-2006-a-stochastic-grammar-of-images-i-found-trends-comput-graph-vis-i-b-2-b-4-259-362-a-href-wiki-citeseerx-title-citeseerx-citeseerx-a-span-class-cs1-lock-free-title-freely-accessible-a-rel-nofollow-class-external-text-href-citeseerx-ist-psu-edu-viewdoc-summary-doi-10-1-1-681-2190-10-1-1-681-2190-a-span-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1561-2f0600000018-10-1561-0600000018-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-found-trends-comput-graph-vis-rft-atitle-a-stochastic-grammar-of-images-rft-volume-2-rft-issue-4-rft-pages-259-362-rft-date-2006-rft-id-2f-2fciteseerx-ist-psu-edu-2fviewdoc-2fsummary-3fdoi-3d10-1-1-681-2190-rft-id-info-3adoi-2f10-1561-2f0600000018-rft-aulast-zhu-rft-aufirst-s-c-rft-au-mumford-2c-d-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-202-span-class-mw-cite-backlink-b-a-href-cite-ref-202-a-b-span-span-class-reference-text-miller-g-a-and-n-chomsky-pattern-conception-paper-for-conference-on-pattern-detection-university-of-michigan-1957-span-li-li-id-cite-note-203-span-class-mw-cite-backlink-b-a-href-cite-ref-203-a-b-span-span-class-reference-text-cite-class-citation-web-eisner-jason-a-rel-nofollow-class-external-text-href-http-techtalks-tv-talks-deep-learning-of-recursive-structure-grammar-induction-58089-deep-learning-of-recursive-structure-grammar-induction-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-unknown-rft-btitle-deep-learning-of-recursive-structure-3a-grammar-induction-rft-aulast-eisner-rft-aufirst-jason-rft-id-http-3a-2f-2ftechtalks-tv-2ftalks-2fdeep-learning-of-recursive-structure-grammar-induction-2f58089-2f-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-4-204-span-class-mw-cite-backlink-a-href-cite-ref-4-204-0-sup-i-b-a-b-i-sup-a-a-href-cite-ref-4-204-1-sup-i-b-b-b-i-sup-a-a-href-cite-ref-4-204-2-sup-i-b-c-b-i-sup-a-a-href-cite-ref-4-204-3-sup-i-b-d-b-i-sup-a-a-href-cite-ref-4-204-4-sup-i-b-e-b-i-sup-a-span-span-class-reference-text-cite-class-citation-news-a-rel-nofollow-class-external-text-href-https-singularityhub-com-2017-10-10-ai-is-easy-to-fool-why-that-needs-to-change-ai-is-easy-to-fool-why-that-needs-to-change-a-i-singularity-hub-i-2017-10-10-span-class-reference-accessdate-retrieved-span-class-nowrap-2017-10-11-span-span-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-singularity-hub-rft-atitle-ai-is-easy-to-fool-e2-80-94why-that-needs-to-change-rft-date-2017-10-10-rft-id-https-3a-2f-2fsingularityhub-com-2f2017-2f10-2f10-2fai-is-easy-to-fool-why-that-needs-to-change-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-li-id-cite-note-205-span-class-mw-cite-backlink-b-a-href-cite-ref-205-a-b-span-span-class-reference-text-cite-class-citation-journal-gibney-elizabeth-2017-a-rel-nofollow-class-external-text-href-https-www-nature-com-news-the-scientist-who-spots-fake-videos-1-22784-the-scientist-who-spots-fake-videos-a-i-nature-i-a-href-wiki-digital-object-identifier-title-digital-object-identifier-doi-a-a-rel-nofollow-class-external-text-href-doi-org-10-1038-2fnature-2017-22784-10-1038-nature-2017-22784-a-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3ajournal-rft-genre-article-rft-jtitle-nature-rft-atitle-the-scientist-who-spots-fake-videos-rft-date-2017-rft-id-info-3adoi-2f10-1038-2fnature-2017-22784-rft-aulast-gibney-rft-aufirst-elizabeth-rft-id-https-3a-2f-2fwww-nature-com-2fnews-2fthe-scientist-who-spots-fake-videos-1-22784-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-span-li-ol-div-h2-span-class-mw-headline-id-further-reading-further-reading-span-span-class-mw-editsection-span-class-mw-editsection-bracket-span-a-href-w-index-php-title-deep-learning-action-edit-section-32-title-edit-section-further-reading-edit-a-span-class-mw-editsection-bracket-span-span-h2-style-data-mw-deduplicate-templatestyles-r886047268-mw-parser-output-refbegin-font-size-90-margin-bottom-0-5em-mw-parser-output-refbegin-hanging-indents-ul-list-style-type-none-margin-left-0-mw-parser-output-refbegin-hanging-indents-ul-li-mw-parser-output-refbegin-hanging-indents-dl-dd-margin-left-0-padding-left-3-2em-text-indent-3-2em-list-style-none-mw-parser-output-refbegin-100-font-size-100-style-div-class-refbegin-style-ul-li-cite-class-citation-book-a-href-wiki-ian-goodfellow-title-ian-goodfellow-goodfellow-ian-a-a-href-wiki-yoshua-bengio-title-yoshua-bengio-bengio-yoshua-a-courville-aaron-2016-a-rel-nofollow-class-external-text-href-http-www-deeplearningbook-org-i-deep-learning-i-a-mit-press-a-href-wiki-international-standard-book-number-title-international-standard-book-number-isbn-a-a-href-wiki-special-booksources-978-0-26203561-3-title-special-booksources-978-0-26203561-3-bdi-978-0-26203561-3-bdi-a-introductory-textbook-cite-span-title-ctx-ver-z39-88-2004-rft-val-fmt-info-3aofi-2ffmt-3akev-3amtx-3abook-rft-genre-book-rft-btitle-deep-learning-rft-pub-mit-press-rft-date-2016-rft-isbn-978-0-26203561-3-rft-aulast-goodfellow-rft-aufirst-ian-rft-au-bengio-2c-yoshua-rft-au-courville-2c-aaron-rft-id-http-3a-2f-2fwww-deeplearningbook-org-rfr-id-info-3asid-2fen-wikipedia-org-3adeep-learning-class-z3988-span-link-rel-mw-deduplicated-inline-style-href-mw-data-templatestyles-r886058088-li-ul-div-newpp-limit-report-parsed-by-mw1288-cached-time-20190622180931-cache-expiry-2592000-dynamic-content-false-complications-vary-revision-cpu-time-usage-2-092-seconds-real-time-usage-2-316-seconds-preprocessor-visited-node-count-10779-1000000-preprocessor-generated-node-count-0-1500000-post-expand-include-size-393322-2097152-bytes-template-argument-size-4749-2097152-bytes-highest-expansion-depth-14-40-expensive-parser-function-count-15-500-unstrip-recursion-depth-1-20-unstrip-post-expand-size-596935-5000000-bytes-number-of-wikibase-entities-loaded-7-400-lua-time-usage-1-238-10-000-seconds-lua-memory-usage-7-98-mb-50-mb-transclusion-expansion-time-report-ms-calls-template-100-00-1963-569-1-total-79-17-1554-586-1-template-reflist-43-67-857-420-94-template-cite-journal-9-63-189-082-45-template-cite-web-5-00-98-155-13-template-cite-book-3-92-76-950-11-template-cite-arxiv-2-68-52-684-3-template-citation-needed-2-67-52-500-1-template-machine-learning-bar-2-60-51-089-4-template-fix-2-47-48-512-1-template-sidebar-with-collapsible-lists-saved-in-parser-cache-with-key-enwiki-pcache-idhash-32472154-0-canonical-math-5-and-timestamp-20190622180929-and-revision-id-902979782-div-noscript-img-src-en-wikipedia-org-wiki-special-centralautologin-start-type-1x1-alt-title-width-1-height-1-style-border-none-position-absolute-noscript-div-div-class-printfooter-retrieved-from-a-dir-ltr-href-https-en-wikipedia-org-w-index-php-title-deep-learning-oldid-902979782-https-en-wikipedia-org-w-index-php-title-deep-learning-oldid-902979782-a-div-div-id-catlinks-class-catlinks-data-mw-interface-div-id-mw-normal-catlinks-class-mw-normal-catlinks-a-href-wiki-help-category-title-help-category-categories-a-ul-li-a-href-wiki-category-deep-learning-title-category-deep-learning-deep-learning-a-li-li-a-href-wiki-category-artificial-neural-networks-title-category-artificial-neural-networks-artificial-neural-networks-a-li-li-a-href-wiki-category-artificial-intelligence-title-category-artificial-intelligence-artificial-intelligence-a-li-li-a-href-wiki-category-emerging-technologies-title-category-emerging-technologies-emerging-technologies-a-li-ul-div-div-id-mw-hidden-catlinks-class-mw-hidden-catlinks-mw-hidden-cats-hidden-hidden-categories-ul-li-a-href-wiki-category-cs1-maint-archived-copy-as-title-title-category-cs1-maint-archived-copy-as-title-cs1-maint-archived-copy-as-title-a-li-li-a-href-wiki-category-cs1-long-volume-value-title-category-cs1-long-volume-value-cs1-long-volume-value-a-li-li-a-href-wiki-category-cs1-maint-bot-original-url-status-unknown-title-category-cs1-maint-bot-original-url-status-unknown-cs1-maint-bot-original-url-status-unknown-a-li-li-a-href-wiki-category-all-articles-with-unsourced-statements-title-category-all-articles-with-unsourced-statements-all-articles-with-unsourced-statements-a-li-li-a-href-wiki-category-articles-with-unsourced-statements-from-april-2018-title-category-articles-with-unsourced-statements-from-april-2018-articles-with-unsourced-statements-from-april-2018-a-li-li-a-href-wiki-category-wikipedia-articles-needing-clarification-from-september-2017-title-category-wikipedia-articles-needing-clarification-from-september-2017-wikipedia-articles-needing-clarification-from-september-2017-a-li-li-a-href-wiki-category-articles-with-unsourced-statements-from-september-2017-title-category-articles-with-unsourced-statements-from-september-2017-articles-with-unsourced-statements-from-september-2017-a-li-li-a-href-wiki-category-wikipedia-articles-that-are-too-technical-from-july-2016-title-category-wikipedia-articles-that-are-too-technical-from-july-2016-wikipedia-articles-that-are-too-technical-from-july-2016-a-li-li-a-href-wiki-category-all-articles-that-are-too-technical-title-category-all-articles-that-are-too-technical-all-articles-that-are-too-technical-a-li-li-a-href-wiki-category-articles-needing-expert-attention-from-july-2016-title-category-articles-needing-expert-attention-from-july-2016-articles-needing-expert-attention-from-july-2016-a-li-li-a-href-wiki-category-all-articles-needing-expert-attention-title-category-all-articles-needing-expert-attention-all-articles-needing-expert-attention-a-li-li-a-href-wiki-category-articles-with-unsourced-statements-from-july-2016-title-category-articles-with-unsourced-statements-from-july-2016-articles-with-unsourced-statements-from-july-2016-a-li-li-a-href-wiki-category-articles-prone-to-spam-from-june-2015-title-category-articles-prone-to-spam-from-june-2015-articles-prone-to-spam-from-june-2015-a-li-ul-div-div-div-class-visualclear-div-div-div-div-id-mw-navigation-h2-navigation-menu-h2-div-id-mw-head-div-id-p-personal-role-navigation-aria-labelledby-p-personal-label-h3-id-p-personal-label-personal-tools-h3-ul-li-id-pt-anonuserpage-not-logged-in-li-li-id-pt-anontalk-a-href-wiki-special-mytalk-title-discussion-about-edits-from-this-ip-address-n-accesskey-n-talk-a-li-li-id-pt-anoncontribs-a-href-wiki-special-mycontributions-title-a-list-of-edits-made-from-this-ip-address-y-accesskey-y-contributions-a-li-li-id-pt-createaccount-a-href-w-index-php-title-special-createaccount-returnto-deep-learning-title-you-are-encouraged-to-create-an-account-and-log-in-however-it-is-not-mandatory-create-account-a-li-li-id-pt-login-a-href-w-index-php-title-special-userlogin-returnto-deep-learning-title-youre-encouraged-to-log-in-however-its-not-mandatory-o-accesskey-o-log-in-a-li-ul-div-div-id-left-navigation-div-id-p-namespaces-role-navigation-class-vectortabs-aria-labelledby-p-namespaces-label-h3-id-p-namespaces-label-namespaces-h3-ul-li-id-ca-nstab-main-class-selected-span-a-href-wiki-deep-learning-title-view-the-content-page-c-accesskey-c-article-a-span-li-li-id-ca-talk-span-a-href-wiki-talk-deep-learning-rel-discussion-title-discussion-about-the-content-page-t-accesskey-t-talk-a-span-li-ul-div-div-id-p-variants-role-navigation-class-vectormenu-emptyportlet-aria-labelledby-p-variants-label-input-type-checkbox-class-vectormenucheckbox-aria-labelledby-p-variants-label-h3-id-p-variants-label-span-variants-span-h3-ul-class-menu-ul-div-div-div-id-right-navigation-div-id-p-views-role-navigation-class-vectortabs-aria-labelledby-p-views-label-h3-id-p-views-label-views-h3-ul-li-id-ca-view-class-collapsible-selected-span-a-href-wiki-deep-learning-read-a-span-li-li-id-ca-edit-class-collapsible-span-a-href-w-index-php-title-deep-learning-action-edit-title-edit-this-page-e-accesskey-e-edit-a-span-li-li-id-ca-history-class-collapsible-span-a-href-w-index-php-title-deep-learning-action-history-title-past-revisions-of-this-page-h-accesskey-h-view-history-a-span-li-ul-div-div-id-p-cactions-role-navigation-class-vectormenu-emptyportlet-aria-labelledby-p-cactions-label-input-type-checkbox-class-vectormenucheckbox-aria-labelledby-p-cactions-label-h3-id-p-cactions-label-span-more-span-h3-ul-class-menu-ul-div-div-id-p-search-role-search-h3-label-for-searchinput-search-label-h3-form-action-w-index-php-id-searchform-div-id-simplesearch-input-type-search-name-search-placeholder-search-wikipedia-title-search-wikipedia-f-accesskey-f-id-searchinput-input-type-hidden-value-special-search-name-title-input-type-submit-name-fulltext-value-search-title-search-wikipedia-for-this-text-id-mw-searchbutton-class-searchbutton-mw-fallbacksearchbutton-input-type-submit-name-go-value-go-title-go-to-a-page-with-this-exact-name-if-it-exists-id-searchbutton-class-searchbutton-div-form-div-div-div-div-id-mw-panel-div-id-p-logo-role-banner-a-class-mw-wiki-logo-href-wiki-main-page-title-visit-the-main-page-a-div-div-class-portal-role-navigation-id-p-navigation-aria-labelledby-p-navigation-label-h3-id-p-navigation-label-navigation-h3-div-class-body-ul-li-id-n-mainpage-description-a-href-wiki-main-page-title-visit-the-main-page-z-accesskey-z-main-page-a-li-li-id-n-contents-a-href-wiki-portal-contents-title-guides-to-browsing-wikipedia-contents-a-li-li-id-n-featuredcontent-a-href-wiki-portal-featured-content-title-featured-content-the-best-of-wikipedia-featured-content-a-li-li-id-n-currentevents-a-href-wiki-portal-current-events-title-find-background-information-on-current-events-current-events-a-li-li-id-n-randompage-a-href-wiki-special-random-title-load-a-random-article-x-accesskey-x-random-article-a-li-li-id-n-sitesupport-a-href-https-donate-wikimedia-org-wiki-special-fundraiserredirector-utm-source-donate-utm-medium-sidebar-utm-campaign-c13-en-wikipedia-org-uselang-en-title-support-us-donate-to-wikipedia-a-li-li-id-n-shoplink-a-href-shop-wikimedia-org-title-visit-the-wikipedia-store-wikipedia-store-a-li-ul-div-div-div-class-portal-role-navigation-id-p-interaction-aria-labelledby-p-interaction-label-h3-id-p-interaction-label-interaction-h3-div-class-body-ul-li-id-n-help-a-href-wiki-help-contents-title-guidance-on-how-to-use-and-edit-wikipedia-help-a-li-li-id-n-aboutsite-a-href-wiki-wikipedia-about-title-find-out-about-wikipedia-about-wikipedia-a-li-li-id-n-portal-a-href-wiki-wikipedia-community-portal-title-about-the-project-what-you-can-do-where-to-find-things-community-portal-a-li-li-id-n-recentchanges-a-href-wiki-special-recentchanges-title-a-list-of-recent-changes-in-the-wiki-r-accesskey-r-recent-changes-a-li-li-id-n-contactpage-a-href-en-wikipedia-org-wiki-wikipedia-contact-us-title-how-to-contact-wikipedia-contact-page-a-li-ul-div-div-div-class-portal-role-navigation-id-p-tb-aria-labelledby-p-tb-label-h3-id-p-tb-label-tools-h3-div-class-body-ul-li-id-t-whatlinkshere-a-href-wiki-special-whatlinkshere-deep-learning-title-list-of-all-english-wikipedia-pages-containing-links-to-this-page-j-accesskey-j-what-links-here-a-li-li-id-t-recentchangeslinked-a-href-wiki-special-recentchangeslinked-deep-learning-rel-nofollow-title-recent-changes-in-pages-linked-from-this-page-k-accesskey-k-related-changes-a-li-li-id-t-upload-a-href-wiki-wikipedia-file-upload-wizard-title-upload-files-u-accesskey-u-upload-file-a-li-li-id-t-specialpages-a-href-wiki-special-specialpages-title-a-list-of-all-special-pages-q-accesskey-q-special-pages-a-li-li-id-t-permalink-a-href-w-index-php-title-deep-learning-oldid-902979782-title-permanent-link-to-this-revision-of-the-page-permanent-link-a-li-li-id-t-info-a-href-w-index-php-title-deep-learning-action-info-title-more-information-about-this-page-page-information-a-li-li-id-t-wikibase-a-href-https-www-wikidata-org-wiki-special-entitypage-q197536-title-link-to-connected-data-repository-item-g-accesskey-g-wikidata-item-a-li-li-id-t-cite-a-href-w-index-php-title-special-citethispage-page-deep-learning-id-902979782-title-information-on-how-to-cite-this-page-cite-this-page-a-li-ul-div-div-div-class-portal-role-navigation-id-p-wikibase-otherprojects-aria-labelledby-p-wikibase-otherprojects-label-h3-id-p-wikibase-otherprojects-label-in-other-projects-h3-div-class-body-ul-li-class-wb-otherproject-link-wb-otherproject-commons-a-href-https-commons-wikimedia-org-wiki-category-deep-learning-hreflang-en-wikimedia-commons-a-li-ul-div-div-div-class-portal-role-navigation-id-p-coll-print-export-aria-labelledby-p-coll-print-export-label-h3-id-p-coll-print-export-label-print-export-h3-div-class-body-ul-li-id-coll-create-a-book-a-href-w-index-php-title-special-book-bookcmd-book-creator-referer-deep-learning-create-a-book-a-li-li-id-coll-download-as-rl-a-href-w-index-php-title-special-electronpdf-page-deep-learning-action-show-download-screen-download-as-pdf-a-li-li-id-t-print-a-href-w-index-php-title-deep-learning-printable-yes-title-printable-version-of-this-page-p-accesskey-p-printable-version-a-li-ul-div-div-div-class-portal-role-navigation-id-p-lang-aria-labelledby-p-lang-label-h3-id-p-lang-label-languages-h3-div-class-body-ul-li-class-interlanguage-link-interwiki-ar-a-href-https-ar-wikipedia-org-wiki-d8-aa-d8-b9-d9-84-d9-85-d9-85-d8-aa-d8-b9-d9-85-d9-82-title-t-lm-mt-mq-arabic-lang-ar-hreflang-ar-class-interlanguage-link-target-l-rby-a-li-li-class-interlanguage-link-interwiki-zh-min-nan-a-href-https-zh-min-nan-wikipedia-org-wiki-chhim-t-c5-8d-cd-98-ha-cc-8dk-si-cc-8dp-title-chhim-to-hak-sip-chinese-min-nan-lang-nan-hreflang-nan-class-interlanguage-link-target-ban-lam-gu-a-li-li-class-interlanguage-link-interwiki-ca-a-href-https-ca-wikipedia-org-wiki-aprenentatge-profund-title-aprenentatge-profund-catalan-lang-ca-hreflang-ca-class-interlanguage-link-target-catala-a-li-li-class-interlanguage-link-interwiki-cs-a-href-https-cs-wikipedia-org-wiki-hlubok-c3-a9-u-c4-8den-c3-ad-title-hluboke-uceni-czech-lang-cs-hreflang-cs-class-interlanguage-link-target-cestina-a-li-li-class-interlanguage-link-interwiki-de-a-href-https-de-wikipedia-org-wiki-deep-learning-title-deep-learning-german-lang-de-hreflang-de-class-interlanguage-link-target-deutsch-a-li-li-class-interlanguage-link-interwiki-et-a-href-https-et-wikipedia-org-wiki-s-c3-bcva-c3-b5pe-title-suvaope-estonian-lang-et-hreflang-et-class-interlanguage-link-target-eesti-a-li-li-class-interlanguage-link-interwiki-es-a-href-https-es-wikipedia-org-wiki-aprendizaje-profundo-title-aprendizaje-profundo-spanish-lang-es-hreflang-es-class-interlanguage-link-target-espanol-a-li-li-class-interlanguage-link-interwiki-eu-a-href-https-eu-wikipedia-org-wiki-ikaskuntza-sakon-title-ikaskuntza-sakon-basque-lang-eu-hreflang-eu-class-interlanguage-link-target-euskara-a-li-li-class-interlanguage-link-interwiki-fa-a-href-https-fa-wikipedia-org-wiki-db-8c-d8-a7-d8-af-da-af-db-8c-d8-b1-db-8c-d8-b9-d9-85-db-8c-d9-82-title-ydgyry-myq-persian-lang-fa-hreflang-fa-class-interlanguage-link-target-frsy-a-li-li-class-interlanguage-link-interwiki-fr-a-href-https-fr-wikipedia-org-wiki-apprentissage-profond-title-apprentissage-profond-french-lang-fr-hreflang-fr-class-interlanguage-link-target-francais-a-li-li-class-interlanguage-link-interwiki-ko-a-href-https-ko-wikipedia-org-wiki-eb-94-a5-eb-9f-ac-eb-8b-9d-title-dib-reoning-korean-lang-ko-hreflang-ko-class-interlanguage-link-target-hangugeo-a-li-li-class-interlanguage-link-interwiki-hy-a-href-https-hy-wikipedia-org-wiki-d4-bd-d5-b8-d6-80-d5-b8-d6-82-d5-bd-d5-b8-d6-82-d6-81-d5-b8-d6-82-d5-b4-title-khor-owsowts-owm-armenian-lang-hy-hreflang-hy-class-interlanguage-link-target-hayeren-a-li-li-class-interlanguage-link-interwiki-id-a-href-https-id-wikipedia-org-wiki-pembelajaran-dalam-title-pembelajaran-dalam-indonesian-lang-id-hreflang-id-class-interlanguage-link-target-bahasa-indonesia-a-li-li-class-interlanguage-link-interwiki-it-a-href-https-it-wikipedia-org-wiki-apprendimento-profondo-title-apprendimento-profondo-italian-lang-it-hreflang-it-class-interlanguage-link-target-italiano-a-li-li-class-interlanguage-link-interwiki-he-a-href-https-he-wikipedia-org-wiki-d7-9c-d7-9e-d7-99-d7-93-d7-94-d7-a2-d7-9e-d7-95-d7-a7-d7-94-title-lmydh-mvqh-hebrew-lang-he-hreflang-he-class-interlanguage-link-target-bryt-a-li-li-class-interlanguage-link-interwiki-mn-a-href-https-mn-wikipedia-org-wiki-deep-learning-title-deep-learning-mongolian-lang-mn-hreflang-mn-class-interlanguage-link-target-mongol-a-li-li-class-interlanguage-link-interwiki-nl-a-href-https-nl-wikipedia-org-wiki-deep-learning-title-deep-learning-dutch-lang-nl-hreflang-nl-class-interlanguage-link-target-nederlands-a-li-li-class-interlanguage-link-interwiki-ja-a-href-https-ja-wikipedia-org-wiki-e3-83-87-e3-82-a3-e3-83-bc-e3-83-97-e3-83-a9-e3-83-bc-e3-83-8b-e3-83-b3-e3-82-b0-title-deipuraningu-japanese-lang-ja-hreflang-ja-class-interlanguage-link-target-ri-ben-yu-a-li-li-class-interlanguage-link-interwiki-no-a-href-https-no-wikipedia-org-wiki-dyp-l-c3-a6ring-title-dyp-laering-norwegian-lang-no-hreflang-no-class-interlanguage-link-target-norsk-a-li-li-class-interlanguage-link-interwiki-oc-a-href-https-oc-wikipedia-org-wiki-aprendissatge-prigond-title-aprendissatge-prigond-occitan-lang-oc-hreflang-oc-class-interlanguage-link-target-occitan-a-li-li-class-interlanguage-link-interwiki-or-a-href-https-or-wikipedia-org-wiki-e0-ac-a1-e0-ac-bf-e0-ac-aa-e0-ad-8d-e0-ac-b2-e0-ac-b0-e0-ad-8d-e0-ac-a3-e0-ad-8d-e0-ac-a3-e0-ac-bf-e0-ac-99-e0-ad-8d-e0-ac-97-e0-ad-8d-title-ddip-lrnnnningg-odia-lang-or-hreflang-or-class-interlanguage-link-target-oddiaa-a-li-li-class-interlanguage-link-interwiki-pt-a-href-https-pt-wikipedia-org-wiki-aprendizagem-profunda-title-aprendizagem-profunda-portuguese-lang-pt-hreflang-pt-class-interlanguage-link-target-portugues-a-li-li-class-interlanguage-link-interwiki-ro-a-href-https-ro-wikipedia-org-wiki-c3-8env-c4-83-c8-9bare-profund-c4-83-title-invatare-profunda-romanian-lang-ro-hreflang-ro-class-interlanguage-link-target-romana-a-li-li-class-interlanguage-link-interwiki-ru-a-href-https-ru-wikipedia-org-wiki-d0-93-d0-bb-d1-83-d0-b1-d0-be-d0-ba-d0-be-d0-b5-d0-be-d0-b1-d1-83-d1-87-d0-b5-d0-bd-d0-b8-d0-b5-title-glubokoe-obuchenie-russian-lang-ru-hreflang-ru-class-interlanguage-link-target-russkii-a-li-li-class-interlanguage-link-interwiki-simple-a-href-https-simple-wikipedia-org-wiki-deep-learning-title-deep-learning-simple-english-lang-en-simple-hreflang-en-simple-class-interlanguage-link-target-simple-english-a-li-li-class-interlanguage-link-interwiki-sl-a-href-https-sl-wikipedia-org-wiki-globoko-u-c4-8denje-title-globoko-ucenje-slovenian-lang-sl-hreflang-sl-class-interlanguage-link-target-slovenscina-a-li-li-class-interlanguage-link-interwiki-ckb-a-href-https-ckb-wikipedia-org-wiki-d9-81-db-8e-d8-b1-d8-a8-d9-88-d9-88-d9-86-db-8c-d9-82-d9-88-d9-88-da-b5-title-fyrbwwny-qwwl-central-kurdish-lang-ckb-hreflang-ckb-class-interlanguage-link-target-khwrdy-a-li-li-class-interlanguage-link-interwiki-sr-a-href-https-sr-wikipedia-org-wiki-d0-94-d1-83-d0-b1-d0-be-d0-ba-d0-be-d1-83-d1-87-d0-b5-d1-9a-d0-b5-title-duboko-uchenje-serbian-lang-sr-hreflang-sr-class-interlanguage-link-target-srpski-srpski-a-li-li-class-interlanguage-link-interwiki-fi-a-href-https-fi-wikipedia-org-wiki-syv-c3-a4oppiminen-title-syvaoppiminen-finnish-lang-fi-hreflang-fi-class-interlanguage-link-target-suomi-a-li-li-class-interlanguage-link-interwiki-sv-a-href-https-sv-wikipedia-org-wiki-djupinl-c3-a4rning-title-djupinlarning-swedish-lang-sv-hreflang-sv-class-interlanguage-link-target-svenska-a-li-li-class-interlanguage-link-interwiki-ta-a-href-https-ta-wikipedia-org-wiki-e0-ae-86-e0-ae-b4-e0-ae-ae-e0-ae-be-e0-ae-a9-e0-ae-95-e0-ae-b1-e0-af-8d-e0-ae-b1-e0-ae-b2-e0-af-8d-title-aalllmaannn-krrrrl-tamil-lang-ta-hreflang-ta-class-interlanguage-link-target-tmilll-a-li-li-class-interlanguage-link-interwiki-th-a-href-https-th-wikipedia-org-wiki-e0-b8-81-e0-b8-b2-e0-b8-a3-e0-b9-80-e0-b8-a3-e0-b8-b5-e0-b8-a2-e0-b8-99-e0-b8-a3-e0-b8-b9-e0-b9-89-e0-b9-80-e0-b8-8a-e0-b8-b4-e0-b8-87-e0-b8-a5-e0-b8-b6-e0-b8-81-title-kaareriiynruuechingluek-thai-lang-th-hreflang-th-class-interlanguage-link-target-aithy-a-li-li-class-interlanguage-link-interwiki-tr-a-href-https-tr-wikipedia-org-wiki-derin-c3-b6-c4-9frenme-title-derin-ogrenme-turkish-lang-tr-hreflang-tr-class-interlanguage-link-target-turkce-a-li-li-class-interlanguage-link-interwiki-uk-a-href-https-uk-wikipedia-org-wiki-d0-93-d0-bb-d0-b8-d0-b1-d0-b8-d0-bd-d0-bd-d0-b5-d0-bd-d0-b0-d0-b2-d1-87-d0-b0-d0-bd-d0-bd-d1-8f-title-glibinne-navchannia-ukrainian-lang-uk-hreflang-uk-class-interlanguage-link-target-ukrayinska-a-li-li-class-interlanguage-link-interwiki-vi-a-href-https-vi-wikipedia-org-wiki-h-e1-bb-8dc-s-c3-a2u-title-hoc-sau-vietnamese-lang-vi-hreflang-vi-class-interlanguage-link-target-tieng-viet-a-li-li-class-interlanguage-link-interwiki-zh-a-href-https-zh-wikipedia-org-wiki-e6-b7-b1-e5-ba-a6-e5-ad-a6-e4-b9-a0-title-shen-du-xue-xi-chinese-lang-zh-hreflang-zh-class-interlanguage-link-target-zhong-wen-a-li-ul-div-class-after-portlet-after-portlet-lang-span-class-wb-langlinks-edit-wb-langlinks-link-a-href-https-www-wikidata-org-wiki-special-entitypage-q197536-sitelinks-wikipedia-title-edit-interlanguage-links-class-wbc-editpage-edit-links-a-span-div-div-div-div-div-div-id-footer-role-contentinfo-ul-id-footer-info-li-id-footer-info-lastmod-this-page-was-last-edited-on-22-june-2019-at-18-09-span-class-anonymous-show-utc-span-li-li-id-footer-info-copyright-text-is-available-under-the-a-rel-license-href-en-wikipedia-org-wiki-wikipedia-text-of-creative-commons-attribution-sharealike-3-0-unported-license-creative-commons-attribution-sharealike-license-a-a-rel-license-href-creativecommons-org-licenses-by-sa-3-0-style-display-none-a-additional-terms-may-apply-by-using-this-site-you-agree-to-the-a-href-foundation-wikimedia-org-wiki-terms-of-use-terms-of-use-a-and-a-href-foundation-wikimedia-org-wiki-privacy-policy-privacy-policy-a-wikipedia-r-is-a-registered-trademark-of-the-a-href-www-wikimediafoundation-org-wikimedia-foundation-inc-a-a-non-profit-organization-li-ul-ul-id-footer-places-li-id-footer-places-privacy-a-href-https-foundation-wikimedia-org-wiki-privacy-policy-class-extiw-title-wmf-privacy-policy-privacy-policy-a-li-li-id-footer-places-about-a-href-wiki-wikipedia-about-title-wikipedia-about-about-wikipedia-a-li-li-id-footer-places-disclaimer-a-href-wiki-wikipedia-general-disclaimer-title-wikipedia-general-disclaimer-disclaimers-a-li-li-id-footer-places-contact-a-href-en-wikipedia-org-wiki-wikipedia-contact-us-contact-wikipedia-a-li-li-id-footer-places-developers-a-href-https-www-mediawiki-org-wiki-special-mylanguage-how-to-contribute-developers-a-li-li-id-footer-places-cookiestatement-a-href-https-foundation-wikimedia-org-wiki-cookie-statement-cookie-statement-a-li-li-id-footer-places-mobileview-a-href-en-m-wikipedia-org-w-index-php-title-deep-learning-mobileaction-toggle-view-mobile-class-noprint-stopmobileredirecttoggle-mobile-view-a-li-ul-ul-id-footer-icons-class-noprint-li-id-footer-copyrightico-a-href-https-wikimediafoundation-org-img-src-static-images-wikimedia-button-png-srcset-static-images-wikimedia-button-1-5x-png-1-5x-static-images-wikimedia-button-2x-png-2x-width-88-height-31-alt-wikimedia-foundation-a-li-li-id-footer-poweredbyico-a-href-https-www-mediawiki-org-img-src-static-images-poweredby-mediawiki-88x31-png-alt-powered-by-mediawiki-srcset-static-images-poweredby-mediawiki-132x47-png-1-5x-static-images-poweredby-mediawiki-176x62-png-2x-width-88-height-31-a-li-ul-div-style-clear-both-div-div-script-rlq-window-rlq-push-function-mw-config-set-wgpageparsereport-limitreport-cputime-2-092-walltime-2-316-ppvisitednodes-value-10779-limit-1000000-ppgeneratednodes-value-0-limit-1500000-postexpandincludesize-value-393322-limit-2097152-templateargumentsize-value-4749-limit-2097152-expansiondepth-value-14-limit-40-expensivefunctioncount-value-15-limit-500-unstrip-depth-value-1-limit-20-unstrip-size-value-596935-limit-5000000-entityaccesscount-value-7-limit-400-timingprofile-100-00-1963-569-1-total-79-17-1554-586-1-template-reflist-43-67-857-420-94-template-cite-journal-9-63-189-082-45-template-cite-web-5-00-98-155-13-template-cite-book-3-92-76-950-11-template-cite-arxiv-2-68-52-684-3-template-citation-needed-2-67-52-500-1-template-machine-learning-bar-2-60-51-089-4-template-fix-2-47-48-512-1-template-sidebar-with-collapsible-lists-scribunto-limitreport-timeusage-value-1-238-limit-10-000-limitreport-memusage-value-8367848-limit-52428800-limitreport-logs-table-1-n-size-tiny-n-n-cachereport-origin-mw1288-timestamp-20190622180931-ttl-2592000-transientcontent-false-script-script-type-application-ld-json-context-https-schema-org-type-article-name-deep-learning-url-https-en-wikipedia-org-wiki-deep-learning-sameas-http-www-wikidata-org-entity-q197536-mainentity-http-www-wikidata-org-entity-q197536-author-type-organization-name-contributors-to-wikimedia-projects-publisher-type-organization-name-wikimedia-foundation-inc-logo-type-imageobject-url-https-www-wikimedia-org-static-images-wmf-hor-googpub-png-datepublished-2011-07-20t06-24-47z-datemodified-2019-06-22t18-09-12z-image-https-upload-wikimedia-org-wikipedia-commons-f-fe-kernel-machine-svg-headline-branch-of-machine-learning-script-script-rlq-window-rlq-push-function-mw-config-set-wgbackendresponsetime-164-wghostname-mw1263-script-body-html